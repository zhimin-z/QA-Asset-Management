[
    {
        "Question_id":73276837,
        "Question_title":"Is it possible to use authentication and authorization in MLFlow Server?",
        "Question_body":"<p>MLFlow does not have integrated authentication (openID, LDAP, kerberos, AAD...) or authorization (RBAC, ABAC, ACL...)<\/p>\n<p>Is it only possible with a web proxy in MLFlow? p.e: nginx<\/p>\n<p>Does anyone know of an option similar to Apache Sentry or Apache Ranger for MLFlow?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1659956478063,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":57,
        "Owner_creation_time":1463943156183,
        "Owner_last_access_time":1663834484890,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73276837",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67953241,
        "Question_title":"mlflow run git-uri clone to specific directory",
        "Question_body":"<p>I am using mlflow run with a GitHub uri.<\/p>\n<p>When I run using the below command<\/p>\n<pre><code>mlflow run &lt;git-uri&gt;\n<\/code><\/pre>\n<p>The command sets up a conda environment and then <em>clones the Git repo into a <strong>temp<\/strong> directory, But I need it setup in a <strong>specific<\/strong> directory<\/em><\/p>\n<p>I checked the entire document, but I can't find it. Is there no such option to do so in one shot?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1623534343453,
        "Question_score":1,
        "Question_tags":"python-3.x|mlflow",
        "Question_view_count":239,
        "Owner_creation_time":1575348765723,
        "Owner_last_access_time":1663079223380,
        "Owner_location":"Chennai, Tamil Nadu, India",
        "Owner_reputation":1049,
        "Owner_up_votes":55,
        "Owner_down_votes":68,
        "Owner_views":192,
        "Question_last_edit_time":null,
        "Answer_body":"<p>For non-local URIs, MLflow uses the Python's <code>tempfile.mkdtemp<\/code> function (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/1c43176cefb5531fbb243975b9c8c5bfb9775e66\/mlflow\/projects\/utils.py#L140\" rel=\"nofollow noreferrer\">source code<\/a>), that creates the temporary directory.  You may have some control over it by setting the <code>TMPDIR<\/code> environment variable as described in <a href=\"https:\/\/docs.python.org\/3\/library\/tempfile.html#tempfile.mkstemp\" rel=\"nofollow noreferrer\">Python docs<\/a> (it lists <code>TMP<\/code> &amp; <code>TEMP<\/code> as well, but they didn't work for me on MacOS) - but it will set only &quot;base path&quot; for temporary directories and files, the directory\/file names are still will be random.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1623570743820,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1623614468897,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67953241",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70620074,
        "Question_title":"Serving multiple ML models using mlflow in a single VM",
        "Question_body":"<p>I have setup an mlflow service in a VM and I am able to serve the model using mlflow serve command.\nWanted to know if we can host multiple models in a single VM ?<\/p>\n<p>I am using the below command to serve a model using mlflow in a vm.<\/p>\n<p>command:<\/p>\n<pre><code>\/mlflow models serve -m models:\/$Model-Name\/$Version --no-conda -p 443 -h 0.0.0.0\n<\/code><\/pre>\n<p>Above command creates a model serving and runs it on 443 port.\nIs it possible to have an endpoint like below being created with model name in it ?<\/p>\n<p>Current URL:\nhttps:\/\/localhost:443\/invocations<\/p>\n<p>Expected URL:\nhttps:\/\/localhost:443\/model-name\/invocations ?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_creation_time":1641552500160,
        "Question_score":0,
        "Question_tags":"apache-spark|machine-learning|databricks|mlflow",
        "Question_view_count":544,
        "Owner_creation_time":1568969745383,
        "Owner_last_access_time":1663915778593,
        "Owner_location":null,
        "Owner_reputation":344,
        "Owner_up_votes":39,
        "Owner_down_votes":0,
        "Owner_views":72,
        "Question_last_edit_time":1641558820040,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70620074",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69466354,
        "Question_title":"MLflow S3UploadFailedError: Failed to upload",
        "Question_body":"<p>I've created with docker a MinioS3 artifact storage and a mysql bakend storage using the next docker-compose:<\/p>\n<pre><code>    version: '3.8'\n    services:\n        db:\n           environment:\n              - MYSQL_DATABASE=${MYSQL_DATABASE}\n              - MYSQL_USER=${MYSQL_USER}\n              - MYSQL_PASSWORD=${MYSQL_PASSWORD}\n              - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\n           expose:\n              - '3306'        \n           volumes:\n              - '(path)\/server_backend:\/var\/lib\/mysql '\n           image: 'mysql'\n           container_name: db\n\n        storage:\n            environment:\n                - MINIO_ACCESS_KEY=${MINIO_USR}\n                - MINIO_SECRET_KEY=${MINIO_PASS}\n            expose:\n                - '9000'\n            ports:\n                - '9000:9000'        \n            depends_on:\n                - db\n            command: server \/data\n            volumes:\n                - '(path)\/server_artifact:\/data'\n            image: minio\/minio:RELEASE.2021-02-14T04-01-33Z\n            container_name: MinIO\n\n        mlflow:\n            build: .\/mlflow\n            environment:\n                - AWS_ACCESS_KEY_ID=${MINIO_USR}\n                - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n            expose:\n                - '5000'\n            ports:\n                - '5000:5000'\n            depends_on:\n                - storage                       \n            image: 'mlflow:Dockerfile'\n            container_name: server\n<\/code><\/pre>\n<p>The Mlflow server docker was created using the next Dockerfile:<\/p>\n<pre><code>    FROM python:3.8-slim-buster\n    WORKDIR \/usr\/src\/app\n    RUN pip install cryptography mlflow psycopg2-binary boto3 pymysql\n    ENV MLFLOW_S3_ENDPOINT_URL=http:\/\/storage:9000\n    CMD mlflow server \\\n        --backend-store-uri mysql+pymysql:\/\/MLFLOW:temporal@db:3306\/DBMLFLOW \\\n        --default-artifact-root s3:\/\/artifacts \\\n        --host 0.0.0.0\n<\/code><\/pre>\n<p>The credantials are defined in a <code>.env<\/code> file.<\/p>\n<p>The results of the <code>docker-compose<\/code> up command :<\/p>\n<pre><code>\n    [+] Running 21\/22\n     - mlflow Error                                                                                                                              5.6s\n     - storage Pulled                                                                                                                           36.9s\n       - a6b97b4963f5 Pull complete                                                                                                             24.6s\n       - 13948a011eec Pull complete                                                                                                             24.7s\n       - 40cdef9976a6 Pull complete                                                                                                             24.7s\n       - f47162848743 Pull complete                                                                                                             24.8s\n       - 5f2758d8e94c Pull complete                                                                                                             24.9s\n       - c2950439edb8 Pull complete                                                                                                             25.0s\n       - 1b08f8a15998 Pull complete                                                                                                             30.7s\n     - db Pulled                                                                                                                                45.8s\n       - 07aded7c29c6 Already exists                                                                                                             0.0s\n       - f68b8cbd22de Pull complete                                                                                                              0.7s\n       - 30c1754a28c4 Pull complete                                                                                                              2.1s\n       - 1b7cb4d6fe05 Pull complete                                                                                                              2.2s\n       - 79a41dc56b9a Pull complete                                                                                                              2.3s\n       - 00a75e3842fb Pull complete                                                                                                              6.7s\n       - b36a6919c217 Pull complete                                                                                                              6.8s\n       - 635b0b84d686 Pull complete                                                                                                              6.8s\n       - 6d24c7242d02 Pull complete                                                                                                             39.4s\n       - 5be6c5edf16f Pull complete                                                                                                             39.5s\n       - cb35eac1242c Pull complete                                                                                                             39.5s\n       - a573d4e1c407 Pull complete                                                                                                             39.6s\n    [+] Building 1.4s (7\/7) FINISHED\n     =&gt; [internal] load build definition from Dockerfile                                                                                         0.0s\n     =&gt; =&gt; transferring dockerfile: 32B                                                                                                          0.0s\n     =&gt; [internal] load .dockerignore                                                                                                            0.0s\n     =&gt; =&gt; transferring context: 2B                                                                                                              0.0s\n     =&gt; [internal] load metadata for docker.io\/library\/python:3.8-slim-buster                                                                    1.3s\n     =&gt; [1\/3] FROM docker.io\/library\/python:3.8-slim-buster@sha256:13a3f2bffb4b18ff7eda2763a3b0ba316dd82e548f52ea8b4fd11c94b97afa7d              0.0s\n     =&gt; CACHED [2\/3] WORKDIR \/usr\/src\/app                                                                                                        0.0s\n     =&gt; CACHED [3\/3] RUN pip install cryptography mlflow psycopg2-binary boto3 pymysql                                                           0.0s\n     =&gt; exporting to image                                                                                                                       0.0s\n     =&gt; =&gt; exporting layers                                                                                                                      0.0s\n     =&gt; =&gt; writing image sha256:76d4e4462b5c7c1826734e59a54488b56660de0dd5ecc188c308202608a8f20b                                                 0.0s\n     =&gt; =&gt; naming to docker.io\/library\/mlflow:Dockerfile                                                                                         0.0s\n    \n    Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n    [+] Running 3\/3\n     - Container db  Created                                                                                                       0.5s\n     - Container MinIO      Created                                                                                                       0.1s\n     - Container server     Created                                                                                                       0.1s\n    Attaching to server, MinIO, db\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.26-1debian10 started.\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.26-1debian10 started.\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Initializing database files\n    db  | 2021-10-06T12:12:57.679527Z 0 [System] [MY-013169] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) initializing of server in progress as process 44\n    db  | 2021-10-06T12:12:57.687748Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:12:58.230036Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:12:59.888820Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:12:59.889102Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:12:59.997461Z 6 [Warning] [MY-010453] [Server] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.\n    MinIO      | Attempting encryption of all config, IAM users and policies on MinIO backend\n    MinIO      | Endpoint: http:\/\/172.18.0.3:9000  http:\/\/127.0.0.1:9000\n    MinIO      |\n    MinIO      | Browser Access:\n    MinIO      |    http:\/\/172.18.0.3:9000  http:\/\/127.0.0.1:9000\n    MinIO      |\n    MinIO      | Object API (Amazon S3 compatible):\n    MinIO      |    Go:         https:\/\/docs.min.io\/docs\/golang-client-quickstart-guide\n    MinIO      |    Java:       https:\/\/docs.min.io\/docs\/java-client-quickstart-guide\n    MinIO      |    Python:     https:\/\/docs.min.io\/docs\/python-client-quickstart-guide\n    MinIO      |    JavaScript: https:\/\/docs.min.io\/docs\/javascript-client-quickstart-guide\n    MinIO      |    .NET:       https:\/\/docs.min.io\/docs\/dotnet-client-quickstart-guide\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.1 seconds\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.3 seconds\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.7 seconds\n    server     | 2021\/10\/06 12:13:03 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 1.5 seconds\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Database files initialized\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Starting temporary server\n    db  | 2021-10-06T12:13:04.422603Z 0 [System] [MY-010116] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) starting as process 93\n    db  | 2021-10-06T12:13:04.439806Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:13:04.575773Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:13:04.827307Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:04.827865Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:04.832827Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.\n    db  | 2021-10-06T12:13:04.834132Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.\n    db  | 2021-10-06T12:13:04.841629Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '\/var\/run\/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.\n    db  | 2021-10-06T12:13:04.855748Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Socket: \/var\/run\/mysqld\/mysqlx.sock\n    db  | 2021-10-06T12:13:04.855801Z 0 [System] [MY-010931] [Server] \/usr\/sbin\/mysqld: ready for connections. Version: '8.0.26'  socket: '\/var\/run\/mysqld\/mysqld.sock'  port: 0  MySQL Community Server - GPL.\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Temporary server started.\n    server     | 2021\/10\/06 12:13:05 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 3.1 seconds\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/iso3166.tab' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/leap-seconds.list' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/zone.tab' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/zone1970.tab' as time zone. Skipping it.\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Creating database DBMLFLOW\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Creating user MLFLOW\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Giving user MLFLOW access to schema DBMLFLOW\n    db  |\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Stopping temporary server\n    db  | 2021-10-06T12:13:06.948482Z 13 [System] [MY-013172] [Server] Received SHUTDOWN from user root. Shutting down mysqld (Version: 8.0.26).\n    server     | 2021\/10\/06 12:13:08 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 6.3 seconds\n    db  | 2021-10-06T12:13:08.716131Z 0 [System] [MY-010910] [Server] \/usr\/sbin\/mysqld: Shutdown complete (mysqld 8.0.26)  MySQL Community Server - GPL.\n    db  | 2021-10-06 12:13:08+00:00 [Note] [Entrypoint]: Temporary server stopped\n    db  |\n    db  | 2021-10-06 12:13:08+00:00 [Note] [Entrypoint]: MySQL init process done. Ready for start up.\n    db  |\n    db  | 2021-10-06T12:13:09.159115Z 0 [System] [MY-010116] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) starting as process 1\n    db  | 2021-10-06T12:13:09.167405Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:13:09.298925Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:13:09.488958Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:09.489087Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:09.489934Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.\n    db  | 2021-10-06T12:13:09.490169Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.\n    db  | 2021-10-06T12:13:09.494728Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '\/var\/run\/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.\n    db  | 2021-10-06T12:13:09.509856Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '::' port: 33060, socket: \/var\/run\/mysqld\/mysqlx.sock\n    db  | 2021-10-06T12:13:09.509982Z 0 [System] [MY-010931] [Server] \/usr\/sbin\/mysqld: ready for connections. Version: '8.0.26'  socket: '\/var\/run\/mysqld\/mysqld.sock'  port: 3306  MySQL Community Server - GPL.\n    db  | mbind: Operation not permitted\n    server     | 2021\/10\/06 12:13:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n    server     | 2021\/10\/06 12:13:14 INFO mlflow.store.db.utils: Updating database tables\n    server     | INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n    server     | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n    server     | INFO  [alembic.runtime.migration] Running upgrade  -&gt; 451aebb31d03, add metric step\n    server     | INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -&gt; 90e64c465722, migrate user column to tags\n    server     | INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -&gt; 181f10493468, allow nulls for metric values\n    server     | INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -&gt; df50e92ffc5e, Add Experiment Tags Table\n    server     | INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -&gt; 7ac759974ad8, Update run tags with larger limit\n    server     | INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -&gt; 89d4b8295536, create latest metrics table\n    server     | INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n    server     | INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -&gt; 2b4d017a5e9b, add model registry tables to db\n    server     | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n    server     | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n    server     | INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -&gt; cfd24bdc0731, Update run status constraint with killed\n    server     | INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -&gt; 0a8213491aaa, drop_duplicate_killed_constraint\n    server     | INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -&gt; 728d730b5ebd, add registered model tags table\n    server     | INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -&gt; 27a6a02d2cf1, add model version tags table\n    server     | INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -&gt; 84291f40a231, add run_link to model_version\n    server     | INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -&gt; a8c4a736bde6, allow nulls for run_id\n    server     | INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -&gt; 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n    server     | INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -&gt; c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n    server     | INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n    server     | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n    db  | mbind: Operation not permitted\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Starting gunicorn 20.1.0\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Listening at: http:\/\/0.0.0.0:5000 (17)\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Using worker: sync\n    server     | [2021-10-06 12:13:16 +0000] [19] [INFO] Booting worker with pid: 19\n    server     | [2021-10-06 12:13:16 +0000] [20] [INFO] Booting worker with pid: 20\n    server     | [2021-10-06 12:13:16 +0000] [21] [INFO] Booting worker with pid: 21\n    server     | [2021-10-06 12:13:16 +0000] [22] [INFO] Booting worker with pid: 22\n\n<\/code><\/pre>\n<p>It makes me suspect because on the second line appears <code>- mlflow Error<\/code> but i think that this is why the other builds haven't finished.<\/p>\n<p>Then I've set my environment variables on the client to create the information flow between my script and the storages:<\/p>\n<pre><code>\n    os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/localhost:9000\/'\n    os.environ['AWS_ACCESS_KEY_ID'] = 'key'\n    os.environ['AWS_SECRET_ACCESS_KEY'] = 'pw'\n    \n    remote_server_uri = &quot;http:\/\/localhost:5000\/&quot; # server URI\n    mlflow.set_tracking_uri(remote_server_uri)\n    \n    mlflow.set_experiment(&quot;mnist_mLflow_demo&quot;)\n\n<\/code><\/pre>\n<p>finally i trained a tensorflow network and i didn't have problems storing parameters and metrics but gave me some warnings (refering to next error). But the model haven't been auto log, so i tryed to do it manually:<\/p>\n<pre><code>    with mlflow.start_run(run_name = &quot;test0&quot;) as run:\n    \n        mlflow.keras.log_model(model2, 'model2')\n\n    mlflow.end_run()\n<\/code><\/pre>\n<p>It dosen't work and it gives me the next INFO (but essencialy an error):<\/p>\n<pre><code>    INFO:tensorflow:Assets written to: (path)\\Temp\\tmpgr5eaha2\\model\\data\\model\\assets\n    INFO:tensorflow:Assets written to: (path)\\Temp\\tmpgr5eaha2\\model\\data\\model\\assets\n    2021\/10\/06 14:16:00 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: (path)\\AppData\\Local\\Temp\\tmpgr5eaha2\\model, flavor: keras)\n    Traceback (most recent call last):\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\environment.py&quot;, line 212, in infer_pip_requirements\n        return _infer_requirements(model_uri, flavor)\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 263, in _infer_requirements\n        modules = _capture_imported_modules(model_uri, flavor)\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 221, in _capture_imported_modules\n        _run_command(\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 163, in _run_command\n        stderr = stderr.decode(&quot;utf-8&quot;)\n    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf1 in position 349: invalid continuation byte\n\n<\/code><\/pre>\n<p>And the next error:<\/p>\n<pre><code>\n    ClientError                               Traceback (most recent call last)\n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py in upload_file(self, filename, bucket, key, callback, extra_args)\n        278         try:\n    --&gt; 279             future.result()\n        280         # If a client error was raised, add the backwards compatibility layer\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py in result(self)\n        105             # out of this and propogate the exception.\n    --&gt; 106             return self._coordinator.result()\n        107         except KeyboardInterrupt as e:\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py in result(self)\n        264         if self._exception:\n    --&gt; 265             raise self._exception\n        266         return self._result\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py in __call__(self)\n        125             if not self._transfer_coordinator.done():\n    --&gt; 126                 return self._execute_main(kwargs)\n        127         except Exception as e:\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py in _execute_main(self, kwargs)\n        149 \n    --&gt; 150         return_value = self._main(**kwargs)\n        151         # If the task is the final task, then set the TransferFuture's\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\upload.py in _main(self, client, fileobj, bucket, key, extra_args)\n        693         with fileobj as body:\n    --&gt; 694             client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)\n        695 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\botocore\\client.py in _api_call(self, *args, **kwargs)\n        385             # The &quot;self&quot; in this scope is referring to the BaseClient.\n    --&gt; 386             return self._make_api_call(operation_name, kwargs)\n        387 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\botocore\\client.py in _make_api_call(self, operation_name, api_params)\n        704             error_class = self.exceptions.from_code(error_code)\n    --&gt; 705             raise error_class(parsed_response, operation_name)\n        706         else:\n    \n    ClientError: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The Access Key Id you provided does not exist in our records.\n    \n    During handling of the above exception, another exception occurred:\n    \n    S3UploadFailedError                       Traceback (most recent call last)\n    C:\\Users\\FCAIZA~1\\AppData\\Local\\Temp\/ipykernel_7164\/2476247499.py in &lt;module&gt;\n          1 with mlflow.start_run(run_name = &quot;test0&quot;) as run:\n          2 \n    ----&gt; 3     mlflow.keras.log_model(model2, 'model2')\n          4 \n          5 mlflow.end_run()\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\keras.py in log_model(keras_model, artifact_path, conda_env, custom_objects, keras_module, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, **kwargs)\n        402             mlflow.keras.log_model(keras_model, &quot;models&quot;)\n        403     &quot;&quot;&quot;\n    --&gt; 404     Model.log(\n        405         artifact_path=artifact_path,\n        406         flavor=mlflow.keras,\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\models\\model.py in log(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\n        186             mlflow_model = cls(artifact_path=artifact_path, run_id=run_id)\n        187             flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n    --&gt; 188             mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\n        189             try:\n        190                 mlflow.tracking.fluent._record_logged_model(mlflow_model)\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\fluent.py in log_artifacts(local_dir, artifact_path)\n        582     &quot;&quot;&quot;\n        583     run_id = _get_or_start_run().info.run_id\n    --&gt; 584     MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\n        585 \n        586 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\client.py in log_artifacts(self, run_id, local_dir, artifact_path)\n        975             is_dir: True\n        976         &quot;&quot;&quot;\n    --&gt; 977         self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\n        978 \n        979     @contextlib.contextmanager\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py in log_artifacts(self, run_id, local_dir, artifact_path)\n        332         :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n        333         &quot;&quot;&quot;\n    --&gt; 334         self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\n        335 \n        336     def list_artifacts(self, run_id, path=None):\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\n        102                 upload_path = posixpath.join(dest_path, rel_path)\n        103             for f in filenames:\n    --&gt; 104                 self._upload_file(\n        105                     s3_client=s3_client,\n        106                     local_file=os.path.join(root, f),\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py in _upload_file(self, s3_client, local_file, bucket, key)\n         78         if environ_extra_args is not None:\n         79             extra_args.update(environ_extra_args)\n    ---&gt; 80         s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)\n         81 \n         82     def log_artifact(self, local_file, artifact_path=None):\n    \n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\inject.py in upload_file(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\n        128     &quot;&quot;&quot;\n        129     with S3Transfer(self, Config) as transfer:\n    --&gt; 130         return transfer.upload_file(\n        131             filename=Filename, bucket=Bucket, key=Key,\n        132             extra_args=ExtraArgs, callback=Callback)\n    \n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py in upload_file(self, filename, bucket, key, callback, extra_args)\n        283         # client error.\n        284         except ClientError as e:\n    --&gt; 285             raise S3UploadFailedError(\n        286                 &quot;Failed to upload %s to %s: %s&quot; % (\n        287                     filename, '\/'.join([bucket, key]), e))\n    \n    S3UploadFailedError: Failed to upload (path)\\AppData\\Local\\Temp\\tmpgr5eaha2\\model\\conda.yaml to artifacts\/1\/5ae5fcef2d07432d811c3d7eb534382c\/artifacts\/model2\/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The Access Key Id you provided does not exist in our records.\n\n<\/code><\/pre>\n<p>Do you know how to help me with it? I have been looking all this morning but i did not find a solution. Thank you!!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1633525784987,
        "Question_score":1,
        "Question_tags":"python|mysql|docker|minio|mlflow",
        "Question_view_count":969,
        "Owner_creation_time":1580841805373,
        "Owner_last_access_time":1663792613347,
        "Owner_location":"Seville, Spain",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I found the solution of this issue. It is a tricky problem due to spanish characters, my system's user profile in &quot;C:\/&quot; is &quot;fca\u00f1izares&quot; (Ca\u00f1izares is my first last name). I have created another user named &quot;fcanizares&quot; and all is working fine. Hope you find this solution helpfull.<\/p>\n<p>PS: Moral of the issue, get rid of the extrange characters!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1633680248313,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69466354",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70781419,
        "Question_title":"mlflow static_prefix url in set_tracking_uri is not working",
        "Question_body":"<p>I am starting mlflow with below command<\/p>\n<pre><code>mlflow server --static_prefix=\/myprefix --backend-store-uri postgresql:\/\/psql_user_name:psql_password@localhost\/mlflow_db --default-artifact-root s3:\/\/my-mlflow-bucket\/ --host 0.0.0.0 -p 8000\n<\/code><\/pre>\n<p>everything worked fine and I can see mlflow UI when I open url http:\/\/localhost:8000\/myprefix\nbut when I use mlflow.set_tracking_uri() i have to give url path as &quot;http:\/\/localhost:8000\/&quot;<\/p>\n<p>why cant we use full url , which has static prefix &quot;http:\/\/localhost:8000\/myprefix&quot; ?<\/p>\n<p>if i use full url ,I am getting request to api endpoint fail and api is experiments\/list error 404 !=200\nis there any way to add url with static prefix in set_tracking_uri<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1642658164867,
        "Question_score":0,
        "Question_tags":"machine-learning|artificial-intelligence|mlflow",
        "Question_view_count":246,
        "Owner_creation_time":1625731242200,
        "Owner_last_access_time":1659594320980,
        "Owner_location":null,
        "Owner_reputation":145,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70781419",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64209196,
        "Question_title":"How to update a previous run into MLFlow?",
        "Question_body":"<p>I would like to update previous runs done with MLFlow, ie. changing\/updating a parameter value to accommodate a change in the implementation. Typical uses cases:<\/p>\n<ul>\n<li>Log runs using a parameter A, and much later, log parameters A and B. It would be useful to update the value of parameter B of previous runs using its default value.<\/li>\n<li>&quot;Specialize&quot; a parameter. Implement a model using a boolean flag as a parameter. Update the implementation to take a string instead. Now we need to update the values of the parameter for the previous runs so that it stays consistent with the new behavior.<\/li>\n<li>Correct a wrong parameter value loggued in the previous runs.<\/li>\n<\/ul>\n<p>It is not always easy to trash the whole experiment as I need to keep the previous runs for statistical purpose. I would like also not to generate new experiments just for a single new parameter, to keep a single database of runs.<\/p>\n<p>What is the best way to do this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1601903047533,
        "Question_score":6,
        "Question_tags":"logging|data-science|mlflow",
        "Question_view_count":2834,
        "Owner_creation_time":1347312347147,
        "Owner_last_access_time":1664043273217,
        "Owner_location":null,
        "Owner_reputation":1022,
        "Owner_up_votes":1127,
        "Owner_down_votes":19,
        "Owner_views":66,
        "Question_last_edit_time":1607788863850,
        "Answer_body":"<p>To add or correct a parameter, metric or artifact of an existing run, pass run_id instead of experiment_id to mlflow.start_run function<\/p>\n<pre><code>with mlflow.start_run(run_id=&quot;your_run_id&quot;) as run:\n    mlflow.log_param(&quot;p1&quot;,&quot;your_corrected_value&quot;)\n    mlflow.log_metric(&quot;m1&quot;,42.0) # your corrected metrics\n    mlflow.log_artifact(&quot;data_sample.html&quot;) # your corrected artifact file\n<\/code><\/pre>\n<p>You can correct, add to, or delete any MLflow run any time after it is complete. Get the run_id either from the UI or by using <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.search_runs\" rel=\"noreferrer\">mlflow.search_runs<\/a>.<\/p>\n<p>Source: <a href=\"https:\/\/towardsdatascience.com\/5-tips-for-mlflow-experiment-tracking-c70ae117b03f\" rel=\"noreferrer\">https:\/\/towardsdatascience.com\/5-tips-for-mlflow-experiment-tracking-c70ae117b03f<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1606920349240,
        "Answer_score":10.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64209196",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71315446,
        "Question_title":"How do I take an already existing MLflow model on my local filesystem and log it to a remote tracking server?",
        "Question_body":"<p>Let's say I already have an existing MLflow model on my local system of the <code>mlflow.pyfunc<\/code> flavor.<\/p>\n<p>The directory looks like this<\/p>\n<pre><code>model\/\n  data\/\n  code\/\n  conda.yml\n  MLmodel\n<\/code><\/pre>\n<p>Where <code>MLmodel<\/code> is something like<\/p>\n<pre><code>flavors:\n  python_function:\n    code: code\n    data: data\n    env: conda.yml\n    loader_module: loader # model\/code\/loader.py has the entrypoint\n<\/code><\/pre>\n<p>I now try and log this model to a remote tracking server using (I'm in the directory above <code>model\/<\/code>, so <code>.\/model\/data<\/code> works, etc)<\/p>\n<pre><code>import mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.pyfunc.log_model(\n  &quot;my-model-artifact&quot;,\n  registered_model_name=&quot;my-model&quot;, # same for all model versions,\n  data_path=&quot;model\/data&quot;,\n  code_path=&quot;model\/code&quot;,\n  loader_module=&quot;model\/code\/loader&quot;\n)\n<\/code><\/pre>\n<p>The tracking server ends up logging a nested MLflow model.. this is inside of the <code>.\/artifacts\/my-model-artifact<\/code> directory on the tracking server<\/p>\n<pre><code>.\/artifacts\/my-model-artifact\n  conda.yaml\n  MLmodel # *not* my MLmodel, one newly generated by MLflow\n  data\/\n  code\/\n<\/code><\/pre>\n<p>Where <code>data<\/code> now points nested to my entire <code>model\/data<\/code> directory and <code>code<\/code> points to a nested <code>model\/code<\/code> directory.<\/p>\n<p>It's like it doesn't understand that I already have this full artifact..<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1646174584637,
        "Question_score":0,
        "Question_tags":"model|mlflow",
        "Question_view_count":336,
        "Owner_creation_time":1425965839877,
        "Owner_last_access_time":1663961190290,
        "Owner_location":"Santa Cruz, CA",
        "Owner_reputation":3256,
        "Owner_up_votes":81,
        "Owner_down_votes":0,
        "Owner_views":164,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71315446",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60088889,
        "Question_title":"How Do You \"Permanently\" Delete An Experiment In Mlflow?",
        "Question_body":"<p>Permanent deletion of an experiment isn't documented anywhere. I'm using Mlflow w\/ backend postgres db<\/p>\n\n<p>Here's what I've run: <\/p>\n\n<pre><code>client = MlflowClient(tracking_uri=server)\nclient.delete_experiment(1)\n<\/code><\/pre>\n\n<p>This deletes the the experiment, but when I run a new experiment with the same name as the one I just deleted, it will return this error:<\/p>\n\n<pre><code>mlflow.exceptions.MlflowException: Cannot set a deleted experiment 'cross-sell' as the active experiment. You can restore the experiment, or permanently delete the  experiment to create a new one.\n<\/code><\/pre>\n\n<p>I cannot find anywhere in the documentation that shows how to permanently delete everything.<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_creation_time":1580970401043,
        "Question_score":20,
        "Question_tags":"python|mlflow",
        "Question_view_count":13984,
        "Owner_creation_time":1443225809767,
        "Owner_last_access_time":1663898334270,
        "Owner_location":"Vancouver, BC, Canada",
        "Owner_reputation":2332,
        "Owner_up_votes":133,
        "Owner_down_votes":3,
        "Owner_views":560,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Unfortunately it seems there is no way to do this via the UI or CLI at the moment :-\/<\/p>\n\n<p>The way to do it depends on the type of backend file store that you are using.<\/p>\n\n<p><strong>Filestore<\/strong>:<\/p>\n\n<p>If you are using the filesystem as a storage mechanism (the default) then it is easy. The 'deleted' experiments are moved to a <code>.trash<\/code> folder. You just need to clear that out:<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>rm -rf mlruns\/.trash\/*\n<\/code><\/pre>\n\n<p>As of the current version of the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/cli.html#mlflow-experiments-delete\" rel=\"noreferrer\">documentation<\/a> (1.7.2), they remark:<\/p>\n\n<blockquote>\n  <p>It is recommended to use a cron job or an alternate workflow mechanism to clear <code>.trash<\/code> folder.<\/p>\n<\/blockquote>\n\n<p><strong>SQL Database:<\/strong><\/p>\n\n<p>This is more tricky, as there are dependencies that need to be deleted. I am using MySQL, and these commands work for me:<\/p>\n\n<pre class=\"lang-sql prettyprint-override\"><code>USE mlflow_db;  # the name of your database\nDELETE FROM experiment_tags WHERE experiment_id=ANY(\n    SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n);\nDELETE FROM latest_metrics WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM metrics WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM tags WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM runs WHERE experiment_id=ANY(\n    SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n);\nDELETE FROM experiments where lifecycle_stage=\"deleted\";\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1585231513453,
        "Answer_score":22.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60088889",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70967052,
        "Question_title":"Does Hugging face defaults allow to log mlflow artifacts and name every run of mlflow log?",
        "Question_body":"<p>I am training a simple binary classification model using Hugging face models using pytorch.<\/p>\n<p>Bert PyTorch HuggingFace.<\/p>\n<p>Here is the code:<\/p>\n<pre><code>import transformers\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\nfrom transformers import AutoTokenizer\n\n \nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,BertConfig\n<\/code><\/pre>\n<pre><code>def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n   \n\n    predictions = np.argmax(logits, axis=-1)\n    \n    acc = np.sum(predictions == labels) \/ predictions.shape[0]\n    return {&quot;accuracy&quot;: acc,\n            'precision': metrics.precision_score(labels, predictions),\n            'recall': metrics.recall_score(labels, predictions),\n            'f1': metrics.f1_score(labels, predictions)}\n\ntraining_args = tr.TrainingArguments(\n    #report_to = 'wandb',\n    output_dir='\/home\/pc\/proj\/Exp2_conv_stampy_data\/results_exp0',          # output directory\n    overwrite_output_dir = True,\n    num_train_epochs=2,              # total number of training epochs\n    per_device_train_batch_size=32,  # batch size per device during training\n    per_device_eval_batch_size=32,   # batch size for evaluation\n    learning_rate=2e-5,\n    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='.\/logs_exp0',            # directory for storing logs\n    logging_steps=137,\n    evaluation_strategy=&quot;epoch&quot;\n    ,save_strategy=&quot;epoch&quot;\n    ,load_best_model_at_end=True\n    ,fp16=True\n    ,run_name=&quot;final_model0&quot;\n    \n)\n\n\n# counter = 0\n# results_lst = []\n\nfrom transformers import TrainerCallback\nfrom copy import deepcopy\n\nmodel = tr.XLMRobertaForSequenceClassification.from_pretrained(&quot;\/home\/pc\/multilingual_toxic_xlm_roberta&quot;,problem_type=&quot;single_label_classification&quot;, num_labels=2,ignore_mismatched_sizes=True, id2label={0: 'negative', 1: 'positive'})\n\n\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors=&quot;pt&quot;)\n\n\ntrain_data = SEDataset(train_encodings, train_labels)\nval_data = SEDataset(val_encodings, val_labels)\n\nmodel.to(device)\n\nclass CustomCallback(TrainerCallback):\n    \n    def __init__(self, trainer) -&gt; None:\n        super().__init__()\n        self._trainer = trainer\n    \n    def on_epoch_end(self, args, state, control, **kwargs):\n        if control.should_evaluate:\n            control_copy = deepcopy(control)\n            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=&quot;train&quot;)\n            return control_copy\n\ntrainer = tr.Trainer(\n    model=model,                         # the instantiated Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_data,         # training dataset\n    eval_dataset=val_data,          # evaluation dataset\n    compute_metrics=compute_metrics    # the callback that computes metrics of interest\n)\ntrainer.add_callback(CustomCallback(trainer)) \ntrain = trainer.train()\n\n\n\ntrainer.save_model(&quot;\/home\/pc\/proj\/Exp2_conv_stampy_data\/result_toxic_model_exp0&quot;)\n\n<\/code><\/pre>\n<p>I see by default <code>mlruns<\/code> directory is created.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rD25L.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rD25L.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>What is <code>0' and what are these 2 folders inside <\/code>0`?<\/strong><\/p>\n<p><strong>How can rename to something useful and understandable.?<\/strong><\/p>\n<p><strong>If I run multiple runs, how can I log every run of model with something like <code>run1<\/code>, <code>run2<\/code> under same experiment?<\/strong><\/p>\n<p><strong>Also I see artifact folder is empty, how to log final model?<\/strong><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1643871620400,
        "Question_score":0,
        "Question_tags":"pytorch|huggingface-transformers|mlflow",
        "Question_view_count":818,
        "Owner_creation_time":1528361086053,
        "Owner_last_access_time":1663924548837,
        "Owner_location":null,
        "Owner_reputation":1127,
        "Owner_up_votes":526,
        "Owner_down_votes":93,
        "Owner_views":283,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70967052",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60531166,
        "Question_title":"How to safely shutdown mlflow ui?",
        "Question_body":"<p>After running <code>mlflow ui<\/code> on a remote server, I'm unable to reopen the <code>mlflow ui<\/code> again.<br>\nA workaround is to kill all my processes in the server using <code>pkill -u MyUserName<\/code>.<br>\nOtherwise I get the following error:  <\/p>\n\n<pre><code>[INFO] Starting gunicorn 20.0.4  \n[ERROR] Connection in use: ('127.0.0.1', 5000)\n[ERROR] Retrying in 1 second.  \n...\nRunning the mlflow server failed. Please see ther logs above for details.\n<\/code><\/pre>\n\n<p>I understand the error but I don't understand:<br>\n1. What is the correct way to shutdown <code>mlflow ui<\/code><br>\n2. How can I identify the <code>mlflow ui<\/code> process in order to only kill that process and not use the <code>pkill<\/code>  <\/p>\n\n<p>Currently I close the browser or use ctrl+C <\/p>",
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_creation_time":1583341247020,
        "Question_score":6,
        "Question_tags":"python|r|machine-learning|mlflow",
        "Question_view_count":9850,
        "Owner_creation_time":1453321149903,
        "Owner_last_access_time":1662925257297,
        "Owner_location":"Israel",
        "Owner_reputation":1153,
        "Owner_up_votes":113,
        "Owner_down_votes":14,
        "Owner_views":168,
        "Question_last_edit_time":1630433880327,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60531166",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66858683,
        "Question_title":"How to integrate mlflow and airflow? Is there any way to connect to mlflow server from airflow",
        "Question_body":"<p>Lets say I have a ML model in mlflow server artifacts. I want to run this model from airflow Dag. Also after running in airflow, metric logs should be visible in mlflow.\nHow can I achieve this?\nThere are connections in airflow, I couldn't find any connection type for mlflow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1617038196660,
        "Question_score":2,
        "Question_tags":"airflow|mlflow",
        "Question_view_count":389,
        "Owner_creation_time":1496203946490,
        "Owner_last_access_time":1664009984060,
        "Owner_location":null,
        "Owner_reputation":838,
        "Owner_up_votes":89,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66858683",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60286506,
        "Question_title":"mlflow Exception: Run with UUID is already active",
        "Question_body":"<p>Used mlflow.set_tracking_uri to set up tracking_uri and set_experiment, got an error and check back to run following code again. got an error that \"Exception: Run with UUID  is already active.\"\nTry to use <code>mlflow.end_run<\/code> to end current run, but got RestException: RESOURCE_DOES_NOT_EXIST: Run UUID not found.\nCurrently stuck in this infinite loop. Any suggestion?    <\/p>\n\n<pre><code>    mlflow.set_experiment(\"my_experiment\")\n    mlflow.start_run(run_name='my_project')\n    mlflow.set_tag('input_len',len(input))\n    mlflow.log_param('metrics', r2)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1582047247790,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":2813,
        "Owner_creation_time":1409958744170,
        "Owner_last_access_time":1663993998083,
        "Owner_location":"Los Angeles, CA, USA",
        "Owner_reputation":1997,
        "Owner_up_votes":33,
        "Owner_down_votes":0,
        "Owner_views":175,
        "Question_last_edit_time":1582049042567,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60286506",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73806968,
        "Question_title":"How to use a @pandas_udf function inside a class with pyspark?",
        "Question_body":"<p>I am trying to use one of the Hugging Face models with ML flow. My input is a pyspark DataFrame.\nThe issue is Mlflow doesn't support directly HuggingFace models, so need to use the flavor pyfunc to save it. So I need create a Python class that inherits from PythonModel and then place everything needed there.\nHow can I use a pandas_udf function inside this PythonModel? It keeps failing because I haven't specified the hint type for all the parameters inside my pandas_udf.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class RobertaClassifier(PythonModel):\n\n    def load_context(self, context: PythonModelContext):\n        import os\n        from transformers.models.auto import AutoConfig,   AutoModelForSequenceClassification\n        from transformers.models.auto.tokenization_auto import AutoTokenizer\n        \n        config_file = os.path.dirname(context.artifacts[&quot;config&quot;])\n        self.config = AutoConfig.from_pretrained(config_file)\n        self.tokenizer = AutoTokenizer.from_pretrained(config_file)\n        self.model = AutoModelForSequenceClassification.from_pretrained(config_file, config=self.config)\n        \n        if torch.cuda.is_available():\n            print('[INFO] Model is being sent to CUDA device as GPU is available')\n            self.model = self.model.cuda()\n        else:\n            print('[INFO] Model will use CPU runtime')\n        \n        _ = self.model.eval()\n    \n    \n    @pandas_udf(&quot;label string, score float&quot;)\n    def predict_batch_udf(self, data: pd.Series) -&gt; pd.Series:\n        import torch\n        import pandas as pd\n        \n        with torch.no_grad():\n            inputs = preprocessing(data['content'])\n            inputs = self.tokenizer(inputs, padding=True, return_tensors='pt', max_length=512, truncation=True)\n        \n            if self.model.device.index != None:\n                torch.cuda.empty_cache()\n                for key in inputs.keys():\n                    inputs[key] = inputs[key].to(self.model.device.index)\n\n            predictions = self.model(**inputs)\n            probs = torch.nn.Softmax(dim=1)(predictions.logits)\n            probs = probs.detach().cpu().numpy()\n\n            labels = probs.argmax(axis=1)\n            scores = probs.max(axis=1)\n\n            return labels, scores\n        \n    def predict(self, context: PythonModelContext, data: pd.Series) -&gt; pd.Series:\n        import math\n        import numpy as np\n        \n        batch_size = 64\n        sample_size = len(data)\n        \n        labels = np.zeros(sample_size)\n        scores = np.zeros(sample_size)\n\n        for batch_idx in range(0, math.ceil(sample_size \/ batch_size)):\n            bfrom = batch_idx * batch_size\n            bto = bfrom + batch_size\n            \n            l, s = self._predict_batch(data.iloc[bfrom:bto])\n            labels[bfrom:bto] = l\n            scores[bfrom:bto] = s\n            \n        return pd.DataFrame({'label': [self.config.id2label[l] for l in labels], \n                             'score': scores })\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663794595057,
        "Question_score":0,
        "Question_tags":"dataframe|class|pyspark|mlflow|pandas-udf",
        "Question_view_count":18,
        "Owner_creation_time":1663793210607,
        "Owner_last_access_time":1663883366877,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1663827527230,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73806968",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56866214,
        "Question_title":"No usable temporary directory found with AWS Lambda function",
        "Question_body":"<p>I am trying to download a model with <code>mlflow<\/code> in an <code>aws lambda function<\/code> as described here: <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#referencing-artifacts\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#referencing-artifacts<\/a><\/p>\n\n<p>However the following error is thrown:<\/p>\n\n<pre><code>  File \"\/tmp\/mlflow-api-server\/mlflow\/tracking\/artifact_utils.py\", line 66, in _download_artifact_from_uri\n  artifact_path=artifact_path, dst_path=output_path)\n  File \"\/tmp\/mlflow-api-server\/mlflow\/store\/artifact_repo.py\", line 94, in download_artifacts\n  dst_path = tempfile.mkdtemp()\n  File \"\/var\/lang\/lib\/python3.6\/tempfile.py\", line 360, in mkdtemp\n  prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n  File \"\/var\/lang\/lib\/python3.6\/tempfile.py\", line 130, in _sanitize_params\n  dir = gettempdir()\n  File \"\/var\/lang\/lib\/python3.6\/tempfile.py\", line 298, in gettempdir\n  tempdir = _get_default_tempdir()\n  File \"\/var\/lang\/lib\/python3.6\/tempfile.py\", line 233, in _get_default_tempdir\n  dirlist)\nFileNotFoundError: [Errno 2] No usable temporary directory found in ['\/tmp', '\/var\/tmp', '\/usr\/tmp']\n<\/code><\/pre>\n\n<p>The sklearn <code>model.pkl<\/code> file that <code>mlflow<\/code> should download has 627 Byte and the <code>aws lambda<\/code> limit should be 512 MB which should be enough space.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_time":1562143532867,
        "Question_score":1,
        "Question_tags":"python|amazon-web-services|aws-lambda|mlflow",
        "Question_view_count":2058,
        "Owner_creation_time":1510064331503,
        "Owner_last_access_time":1664041948290,
        "Owner_location":"M\u00fcnchen, Deutschland",
        "Owner_reputation":5537,
        "Owner_up_votes":1253,
        "Owner_down_votes":7,
        "Owner_views":215,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56866214",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70010405,
        "Question_title":"Run experiments on Azure ML with Kedro and Mlflow",
        "Question_body":"<p>I'm trying to run the whole Kedro pipeline as an Azure ML experiment. I had two options here. The first one was to use the built-in logging feature of Azure ML and the second one was to use the azumeml-mlflow package that integrates Azure ML with Mlflow.<\/p>\n<p>I only tried the second approach as I did not know how to implement the Run() method of Azure ML inside the Kedro hooks.<\/p>\n<p>So, for the second approach, I presumed everything should be the same as when using Mlflow only. However, I couldn't get it to work even though it worked well outside of the Kedro structure ==&gt; I could launch experiments from other scripts.<\/p>\n<p>What I get with Kedro is that the pipeline runs well but nothing happens on Azure ML.<\/p>\n<p>Here's the code (hooks are inside a ModelTrackingHooks class):<\/p>\n<pre><code>@hook_impl\ndef before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n    &quot;&quot;&quot;Hook implementation to start an MLflow run\n    with the same run_id as the Kedro pipeline run.\n    &quot;&quot;&quot;\n\n\n    # Get Azure workspace\n    ws = Workspace.get(name=&quot;...&quot;,\n                       subscription_id=&quot;...&quot;,\n                       resource_group=&quot;...&quot;)\n    # Set tracking uri\n    mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n\n    # Create an Azure ML experiment in the workspace\n    experiment = Experiment(workspace=ws, name='kedro-mlflow-experiment')\n    mlflow.set_experiment(experiment.name)\n\n    #Start logging\n    mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n    mlflow.log_params(run_params)        \n\n@hook_impl\ndef after_node_run(\n    self, node: Node, outputs: Dict[str, Any], inputs: Dict[str, Any]\n) -&gt; None:\n    &quot;&quot;&quot;Hook implementation to add model tracking after some node runs.\n    In this example, we will:\n    * Log the parameters after the data splitting node runs.\n    * Log the model after the model training node runs.\n    * Log the model's metrics after the model evaluating node runs.\n    &quot;&quot;&quot;\n    \n    if node._func_name == &quot;cross_val&quot;:\n        mlflow.log_params(\n            {&quot;best_estimator&quot;: outputs[&quot;best_estimator&quot;],\n             &quot;best_params&quot;: outputs[&quot;best_params&quot;]}\n        )\n        model = outputs[&quot;validated_model&quot;]\n        mlflow.sklearn.log_model(model, &quot;model&quot;)\n\n    elif node._func_name == &quot;fit_and_save_transformer&quot;:\n        transformer = outputs[&quot;custom_transformer&quot;]\n        mlflow.sklearn.log_model(transformer, &quot;customer_transformer&quot;)\n\n    elif node._func_name == &quot;classification_reporting&quot;:\n        mlflow.log_metrics(outputs[&quot;metrics&quot;])\n    \n\n@hook_impl\ndef after_pipeline_run(self) -&gt; None:\n    &quot;&quot;&quot;Hook implementation to end the MLflow run\n    after the Kedro pipeline finishes.\n    &quot;&quot;&quot;\n\n    mlflow.end_run()\n<\/code><\/pre>\n<p>Am I doing it the wrong way ?<\/p>\n<p>Do you have any idea or examples on how to use Kedro and Azure ML by leveraging only the built-in capabilities of Azure ML (i.e. without going through Mlflow) ?<\/p>\n<p>Thank you in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1637177187910,
        "Question_score":0,
        "Question_tags":"python|mlflow|azure-machine-learning-service|kedro|mlops",
        "Question_view_count":266,
        "Owner_creation_time":1586517832390,
        "Owner_last_access_time":1660328393330,
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":1637184025437,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70010405",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73304176,
        "Question_title":"mlflow warning: Experiment ID mismatch for exp Iris. ID recorded as \u20181\u2019 in metadata\u2026",
        "Question_body":"<p>I\u2019m completely new to mlflow.<\/p>\n<p>I\u2019ve started with a couple of the standard tutorials and created examples using the well-known Iris and wine-quality datasets and named the experiments accordingly.<\/p>\n<p>When I run my code I get warnings:<\/p>\n<pre><code>WARNING:root:Experiment ID mismatch for exp iris.  ID recorded as \u20181\u2019 in meta data.  Experiment will be ignored.\n\nNoneType: None\n\nWARNING:root:Experiment ID mismatch for exp mlruns. ID recorded as \u20188\u2019 in meta data.  Experiment will be ignored.\n\nNoneType: None\n\nWARNING:root:Experiment ID mismatch for exp wine-quality. ID recorded as \u20185\u2019 in meta data.  Experiment will be ignored.\n\nNoneType: None\n<\/code><\/pre>\n<p>However, when I run the following in a jupyter notebook cell:<\/p>\n<pre><code>From mlflow.tracking import MlflowClient\n\nclient=Mlflow.Client()\n\nexperiments=client.list_experiments()\n\nexperiments\n<\/code><\/pre>\n<p>I see the list of experiments, including the 3 above, whose ID matches their names.<\/p>\n<p>When I look in the <code>mlruns\/wine-quality\/1<\/code> folder says, the <code>meta.yaml<\/code> states correctly that <code>Experiment id<\/code> is 5.<\/p>\n<p>Can someone help explain why I am getting these warnings?<\/p>\n<p>(When I run <code>mlflow ui \u2014backend-store-uri file:C:\/Users\/jb8\/mlruns<\/code> I see the experimental runs being logged as I\u2019d hope\u2026)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1660125120537,
        "Question_score":0,
        "Question_tags":"python|warnings|mlflow",
        "Question_view_count":36,
        "Owner_creation_time":1513941499320,
        "Owner_last_access_time":1663929826060,
        "Owner_location":"Portsmouth, United Kingdom",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1660143634743,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73304176",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65824711,
        "Question_title":"Mlflow download_artifacts giving Not Found error",
        "Question_body":"<p>I have mlflow and minio running under docker compose. Mlflow successfully logs artifacts to minio and retrieves them. Minio and mlflow have their relevant ports 900 and 5000 exposed by docker.\nIf I run MlflowClient().download_artifacts for predictions from within the docker environment, everything works smoothly.\nIf I run MlflowClient().download_artifacts from outside docker (local machine or remotely), I get the below error. There is no issue in fetching the logged metrics.<\/p>\n<p>botocore.exceptions.ClientError: An error occurred (404) when calling the ListObjectsV2 operation: Not Found<\/p>\n<p>My code:<\/p>\n<pre><code>os.environ['AWS_ACCESS_KEY_ID'] = &quot;x&quot;\nmlflow.set_tracking_uri('http:\/\/10.0.0.1:5000')\nos.environ['AWS_SECRET_ACCESS_KEY'] = &quot;x&quot;\nos.environ['MINIO_ACCESS_KEY_ID'] = &quot;x&quot;\nos.environ['MINIO_SECRET_ACCESS_KEY'] = &quot;x\/me &quot;\n\nfrom mlflow.tracking import MlflowClient\nMlflowClient().download_artifacts(&quot;323e1527d49d4e77bd14c387bbdf6372&quot;, &quot;model&quot;, local_dir)\n<\/code><\/pre>\n<p>Any help would be most appreciated.<\/p>\n<p>Thanks<\/p>\n<p>Best Regards,<\/p>\n<p>Adeel<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1611222048143,
        "Question_score":2,
        "Question_tags":"docker|docker-compose|mlflow",
        "Question_view_count":254,
        "Owner_creation_time":1445990517173,
        "Owner_last_access_time":1663982428387,
        "Owner_location":"Sydney, New South Wales, Australia",
        "Owner_reputation":689,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":87,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65824711",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72994988,
        "Question_title":"How to mlflow-autolog a sklearn ConfusionMatrixDisplay?",
        "Question_body":"<p>I'm trying to log the plot of a <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator\" rel=\"nofollow noreferrer\">confusion matrix generated with scikit-learn<\/a> for a <em>test<\/em> set using <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.sklearn.html\" rel=\"nofollow noreferrer\">mlflow's support for scikit-learn<\/a>.<\/p>\n<p>For this, I tried something that resemble the code below (I'm using mlflow hosted on Databricks, and <code>sklearn==1.0.1<\/code>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sklearn.datasets\nimport pandas as pd\nimport numpy as np\nimport mlflow\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nmlflow.set_tracking_uri(&quot;databricks&quot;)\nmlflow.set_experiment(&quot;\/Users\/name.surname\/plotcm&quot;)\n\ndata = sklearn.datasets.fetch_20newsgroups(categories=['alt.atheism', 'sci.space'])\n\ndf = pd.DataFrame(data = np.c_[data['data'], data['target']])\\\n       .rename({0:'text', 1:'class'}, axis = 'columns')\n\ntrain, test = train_test_split(df)\n\nmy_pipeline = Pipeline([\n    ('vectorizer', TfidfVectorizer()),\n    ('classifier', SGDClassifier(loss='modified_huber')),\n])\n\nmlflow.sklearn.autolog()\n\nfrom sklearn.metrics import ConfusionMatrixDisplay # should I import this after the call to `.autolog()`?\n\nmy_pipeline.fit(train['text'].values, train['class'].values)\n\ncm = ConfusionMatrixDisplay.from_predictions(\n      y_true=test[&quot;class&quot;], y_pred=my_pipeline.predict(test[&quot;text&quot;])\n  )\n<\/code><\/pre>\n<p>while the confusion matrix for the training set is saved in my mlflow run, no png file is created in the mlflow frontend for the <code>test<\/code> set.<\/p>\n<p>If I try to add<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>cm.figure_.savefig('test_confusion_matrix.png')\nmlflow.log_artifact('test_confusion_matrix.png')\n<\/code><\/pre>\n<p>that does the job, but requires explicitly logging the artifact.<\/p>\n<p>Is there an idiomatic\/proper way to autolog the confusion matrix computed using a test set after <code>my_pipeline.fit()<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1657892681357,
        "Question_score":0,
        "Question_tags":"python|scikit-learn|confusion-matrix|mlflow",
        "Question_view_count":157,
        "Owner_creation_time":1415722650717,
        "Owner_last_access_time":1664051478173,
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Question_last_edit_time":1658083880967,
        "Answer_body":"<p>The proper way to do this is to use <code>mlflow.log_figure<\/code> as a fluent API announced in <code>MLflow 1.13.0<\/code>. You can read the documentation <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_figure\" rel=\"nofollow noreferrer\">here<\/a>. This code will do the job.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.log_figure(cm.figure_, 'test_confusion_matrix.png')\n<\/code><\/pre>\n<p>This function implicitly store the image, and then calls <code>log_artifact<\/code> against that path, something like you did.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1658304934100,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72994988",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58956459,
        "Question_title":"How to run authentication on a mlFlow server?",
        "Question_body":"<p>As I am logging my entire models and params into mlflow I thought it will be a good idea to have  it protected under a user name and password.<\/p>\n\n<p>I use the following code to run the mlflow server<\/p>\n\n<p><code>mlflow server --host 0.0.0.0 --port 11111<\/code>\nworks perfect,in mybrowser i type <code>myip:11111<\/code> and i see everything (which eventually is the problem)<\/p>\n\n<p>If I understood the documentation and the following <a href=\"https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8\" rel=\"noreferrer\">https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8<\/a> link here correct, I should use nginx to create the authentication.<\/p>\n\n<p>I installed <code>nginx open sourcre<\/code>  and <code>apache2-utils<\/code><\/p>\n\n<p>created <code>sudo htpasswd -c \/etc\/apache2\/.htpasswd user1<\/code> user and passwords.<\/p>\n\n<p>I edited my <code>\/etc\/nginx\/nginx.conf<\/code> to the following:<\/p>\n\n<pre><code>server {\n        listen 80;\n        listen 443 ssl;\n\n        server_name my_ip;\n        root NOT_SURE_WHICH_PATH_TO_PUT_HERE, THE VENV?;\n        location \/ {\n            proxy_pass                      my_ip:11111\/;\n            auth_basic                      \"Restricted Content\";\n            auth_basic_user_file \/home\/path to the password file\/.htpasswd;\n        }\n    }\n<\/code><\/pre>\n\n<p><strong>but no authentication appears.<\/strong><\/p>\n\n<p>if I change the conf to listen to  <code>listen 11111<\/code>\nI get an error that the port is already in use ( of course, by the mlflow server....)<\/p>\n\n<p>my wish is to have a authentication window before anyone can enter by the mlflow with a browser.<\/p>\n\n<p>would be happy to hear any suggestions.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_creation_time":1574259400087,
        "Question_score":11,
        "Question_tags":"nginx|basic-authentication|mlflow",
        "Question_view_count":13870,
        "Owner_creation_time":1554298968017,
        "Owner_last_access_time":1662838530057,
        "Owner_location":"wondeland",
        "Owner_reputation":1540,
        "Owner_up_votes":21,
        "Owner_down_votes":3,
        "Owner_views":118,
        "Question_last_edit_time":null,
        "Answer_body":"<p>the problem here is that both <code>mlflow<\/code> and <code>nginx<\/code> are trying to run on the <strong>same port<\/strong>... <\/p>\n\n<ol>\n<li><p>first lets deal with nginx:<\/p>\n\n<p>1.1 in \/etc\/nginx\/sites-enable make a new file <code>sudo nano mlflow<\/code> and delete the exist default.<\/p>\n\n<p>1.2 in mlflow file:<\/p><\/li>\n<\/ol>\n\n<pre><code>server {\n    listen YOUR_PORT;\n    server_name YOUR_IP_OR_DOMAIN;\n    auth_basic           \u201cAdministrator\u2019s Area\u201d;\n    auth_basic_user_file \/etc\/apache2\/.htpasswd; #read the link below how to set username and pwd in nginx\n\n    location \/ {\n        proxy_pass http:\/\/localhost:8000;\n        include \/etc\/nginx\/proxy_params;\n        proxy_redirect off;\n    }\n}\n<\/code><\/pre>\n\n<p>1.3.  restart nginx <code>sudo systemctl restart nginx<\/code><\/p>\n\n<ol start=\"2\">\n<li>on your server run mlflow  <code>mlflow server --host localhost --port 8000<\/code><\/li>\n<\/ol>\n\n<p>Now if you try access the YOUR_IP_OR_DOMAIN:YOUR_PORT within your browser an auth popup should appear, enter your host and pass and now you in mlflow<\/p>\n\n<ol start=\"3\">\n<li><p>now there are 2 options to tell the mlflow server about it:<\/p>\n\n<p>3.1 set username and pwd as environment variable \n<code>export MLFLOW_TRACKING_USERNAME=user export MLFLOW_TRACKING_PASSWORD=pwd<\/code><\/p>\n\n<p>3.2 edit in your <code>\/venv\/lib\/python3.6\/site-packages\/mlflowpackages\/mlflow\/tracking\/_tracking_service\/utils.py<\/code> the function <\/p><\/li>\n<\/ol>\n\n<pre><code>def _get_rest_store(store_uri, **_):\n    def get_default_host_creds():\n        return rest_utils.MlflowHostCreds(\n            host=store_uri,\n            username=replace with nginx user\n            password=replace with nginx pwd\n            token=os.environ.get(_TRACKING_TOKEN_ENV_VAR),\n            ignore_tls_verification=os.environ.get(_TRACKING_INSECURE_TLS_ENV_VAR) == 'true',\n        )\n<\/code><\/pre>\n\n<p>in your .py file where you work with mlflow:<\/p>\n\n<pre><code>import mlflow\nremote_server_uri = \"YOUR_IP_OR_DOMAIN:YOUR_PORT\" # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\nmlflow.set_experiment(\"\/my-experiment\")\nwith mlflow.start_run():\n    mlflow.log_param(\"a\", 1)\n    mlflow.log_metric(\"b\", 2)\n<\/code><\/pre>\n\n<p>A link to nginx authentication doc <a href=\"https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/\" rel=\"noreferrer\">https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1576255052617,
        "Answer_score":8.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58956459",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58519367,
        "Question_title":"MLFlow model not logging to Azure Blob Storage",
        "Question_body":"<p>I am trying to use MLFlow to log artifacts to Azure Blob Storage. Though the logging to dbfs works fine, when I try to log it to Azure Blob Storage, I only see a folder with the corresponding runid but inside it there are no contents.<\/p>\n\n<p>Here is what I do-<\/p>\n\n<ol>\n<li><p>Create a experiment from Azure Databricks, give it a name and the artifacts location as wasbs:\/\/mlartifacts@myazurestorageaccount.blob.core.windows.net\/ .<\/p><\/li>\n<li><p>In the spark cluster, in the environemtn Variables section pass on the AZURE_STORAGE_ACCESS_KEY=\"ValueoftheKey\" <\/p><\/li>\n<li>In the notebook, use mlflow to log metrics, param and finally the model using a snippet like below<\/li>\n<\/ol>\n\n<pre><code>\nwith mlflow.start_run():\n      lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n      lr.fit(train_x, train_y)\n\n      predicted_qualities = lr.predict(test_x)\n\n      (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n      print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n      print(\"  RMSE: %s\" % rmse)\n      print(\"  MAE: %s\" % mae)\n      print(\"  R2: %s\" % r2)\n\n      mlflow.log_param(\"alpha\", alpha)\n      mlflow.log_param(\"l1_ratio\", l1_ratio)\n      mlflow.log_metric(\"rmse\", rmse)\n      mlflow.log_metric(\"r2\", r2)\n      mlflow.log_metric(\"mae\", mae)\n\n      mlflow.sklearn.log_model(lr, \"model\")\n<\/code><\/pre>\n\n<p>Of course before using it , I set the experiment to the one where I have defined the artifacts store to be azure blob storage<\/p>\n\n<pre><code>experiment_name = \"\/Users\/user@domain.com\/mltestazureblob\"\nmlflow.set_experiment(experiment_name)\n<\/code><\/pre>\n\n<p>The metrices and params I can from the MLFlow  UI within Databricks but as since my artifacts location is Azure Blob Storage , I expect the model, the .pkl and conda.yaml file to be in the container in the Azure Blob Storage but when I go to check it, I only see a folder corresponding to the run id of the experiment but with nothing inside.<\/p>\n\n<p>I do not know what I am missing. In case, someone needs additional details I will be happy to provide.<\/p>\n\n<p>Point to note everything works fine when I use the default location i.e. dbfs.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1571821965343,
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":812,
        "Owner_creation_time":1428654714763,
        "Owner_last_access_time":1664012257383,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58519367",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67062145,
        "Question_title":"Continue stopped run in MLflow",
        "Question_body":"<p>We run our experiment on AWS spot instances. Sometimes the experiments are stopped, and we would prefer to continue logging to the same run. How can you set the run-id of the active run?<\/p>\n<p>Something like this pseudocode (not working):<\/p>\n<pre><code>if new:\n    mlflow.start_run(experiment_id=1, run_name=x)\nelse:\n    mlflow.set_run(run_id)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1618244956103,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":131,
        "Owner_creation_time":1484838464573,
        "Owner_last_access_time":1663858511743,
        "Owner_location":"Amsterdam, Nederland",
        "Owner_reputation":3937,
        "Owner_up_votes":672,
        "Owner_down_votes":27,
        "Owner_views":387,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can pass the run_id directly to <code>start_run<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.start_run(experiment_id=1,\n                 run_name=x,\n                 run_id=&lt;run_id_of_interrupted_run&gt; # pass None to start a new run\n                 ) \n<\/code><\/pre>\n<p>Of course, you have to store the run_id for this. You can get it with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.entities.html#mlflow.entities.RunInfo.run_id\" rel=\"nofollow noreferrer\"><code>run.info.run_id<\/code><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1631884865500,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67062145",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70259594,
        "Question_title":"Setting array of tags to MLFlow registered model",
        "Question_body":"<p>I have a model registered in ML Flow and would like associate a list of tags to that model.\nBut when i looked at the reference APIs, it looks like we can add only one tag at a time with a single http request.<\/p>\n<pre><code>https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#set-registered-model-tag\n<\/code><\/pre>\n<p>Is it possible to create an array of tags and associate that with model in a single http call ?\nLike how we do during model creation API ?<\/p>\n<pre><code>https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#create-registeredmodel\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1638877684190,
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":173,
        "Owner_creation_time":1568969745383,
        "Owner_last_access_time":1663915778593,
        "Owner_location":null,
        "Owner_reputation":344,
        "Owner_up_votes":39,
        "Owner_down_votes":0,
        "Owner_views":72,
        "Question_last_edit_time":1638878114697,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70259594",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71151054,
        "Question_title":"How to log a table of metrics into mlflow",
        "Question_body":"<p>I am trying to see if mlflow is the right place to store my metrics in the model tracking.  According to the doc log_metric takes either a key value or a dict of key-values.  I am wondering how to log something like below into mlflow so it can be visualized meaningfully.<\/p>\n<pre><code>          precision    recall  f1-score   support\n\n  class1       0.89      0.98      0.93       174\n  class2       0.96      0.90      0.93        30\n  class3       0.96      0.90      0.93        30\n  class4       1.00      1.00      1.00         7\n  class5       0.93      1.00      0.96        13\n  class6       1.00      0.73      0.85        15\n  class7       0.95      0.97      0.96        39\n  class8       0.80      0.67      0.73         6\n  class9       0.97      0.86      0.91        37\n class10       0.95      0.81      0.88        26\n class11       0.50      1.00      0.67         5\n class12       0.93      0.89      0.91        28\n class13       0.73      0.84      0.78        19\n class14       1.00      1.00      1.00         6\n class15       0.45      0.83      0.59         6\n class16       0.97      0.98      0.97       245\n class17       0.93      0.86      0.89       206\n\naccuracy                           0.92       892\n<\/code><\/pre>\n<p>macro avg       0.88      0.90      0.88       892\nweighted avg       0.93      0.92      0.92       892<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1645058143563,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":546,
        "Owner_creation_time":1426639280947,
        "Owner_last_access_time":1650573965300,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71151054",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60530176,
        "Question_title":"mlflow How to save a sklearn pipeline with custom transformer?",
        "Question_body":"<p>I am trying to save with mlflow a sklearn machine-learning model, which is a pipeline containing a custom transformer I have defined, and load it in another project.\nMy custom transformer inherits from BaseEstimator and TransformerMixin.<\/p>\n\n<p>Let's say I have 2 projects:<\/p>\n\n<ul>\n<li>train_project: it has the custom transformers in src.ml.transformers.py<\/li>\n<li>use_project: it has other things in src, or has no src catalog at all<\/li>\n<\/ul>\n\n<p>So in my train_project I do :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>and then when I try to load it into use_project :<\/p>\n\n<pre><code>preprocess_pipe = mlflow.sklearn.load_model(f'{ref_model_path}\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>An error occurs :<\/p>\n\n<pre><code>[...]\nFile \"\/home\/quentin\/anaconda3\/envs\/api_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 210, in _load_model_from_local_file\n    return pickle.load(f)\nModuleNotFoundError: No module named 'train_project'\n<\/code><\/pre>\n\n<p>I tried to use format mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n<\/code><\/pre>\n\n<p>but I get the same error during load.<\/p>\n\n<p>I saw option <strong>code_path<\/strong> into <strong>mlflow.pyfunc.log_model<\/strong> but its use and purpose is not clear to me. <\/p>\n\n<p>I thought mlflow provide a easy way to save model and serialize them so they can be used anywhere, Is that true only if you have native sklearn models (or keras, ...)?<\/p>\n\n<p>It's seem that this issue is more related to pickle functioning (mlflow use it and pickle needs to have all dependencies installed). <\/p>\n\n<p>The only solution I found so far is to make my transformer a package, import it in both project. Save version of my transformer library with <em>conda_env<\/em> argument of <em>log_model<\/em>, and check if it's same version when I load the model into my use_project.\nBut it's painfull if I have to change my transformer or debug in it...<\/p>\n\n<p>Is anybody have a better solution? \nMore elegent? Maybe there is some mlflow functionality I would have missed?<\/p>\n\n<p>other informations :<br>\nworking on linux (ubuntu)<br>\nmlflow=1.5.0<br>\npython=3.7.3   <\/p>\n\n<p>I saw in test of mlflow.sklearn api that they do a test with custom transformer, but they load it into the same file so it seems not resolve my issue but maybe it can helps other poeple :<\/p>\n\n<p><a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py\" rel=\"noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1583338083850,
        "Question_score":8,
        "Question_tags":"python|machine-learning|scikit-learn|pickle|mlflow",
        "Question_view_count":3317,
        "Owner_creation_time":1583251456143,
        "Owner_last_access_time":1583925117020,
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60530176",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73729205,
        "Question_title":"MLFlow: how to get additional methods from a loaded model?",
        "Question_body":"<p><strong>Use case:<\/strong><\/p>\n<p>A <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#mlflow.pyfunc.PyFuncModel\" rel=\"nofollow noreferrer\"><code>mlflow.pyfunc.PyFuncModel<\/code><\/a> is defined with some more utilities methods in order to provide a way of parsing its prediction result to different formats.<\/p>\n<p><strong>After the model is loaded from registry, is there a way to access those methods?<\/strong><\/p>\n<p><strong>A contrived example:<\/strong><\/p>\n<p>A <code>mlflow.pyfunc.PyFuncModel<\/code> model defining additional methods:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class MyModel(mlflow.pyfunc.PythonModel):\n    def predict(self, context, model_input):\n        prediction = # do some prediction\n        return prediction\n\n    @staticmethod\n    def parse_prediction_to_format_x(prediction):\n        prediction_formatted = # do some parsing\n        return prediction_formatted\n\n    def parse_prediction_to_format_y(self, prediction):\n        prediction_formatted = # do some parsing\n        return prediction_formatted\n<\/code><\/pre>\n<p>Note: I added one static and one non static, because both use cases are relevant.<\/p>\n<p>Now, some other system goes to MLFlow Registry and loads the model from there:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>        loaded_model = mlflow.pyfunc.load_model(\n            model_uri=saved_model_path.absolute().as_uri()\n        )\n<\/code><\/pre>\n<p>This system, which naturally does not hold the model source code, but the registry path to load it from there, wants to use the additional methods above.\nIt can use predict, since it is part of all pyfunc models:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>predicted = loaded_model.predict(input_data)\n<\/code><\/pre>\n<p><strong>But how can this system access helper methods in the model class (static or instance methods)?<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>predicted = loaded_model.predict(input_data)\n\n# pseudo code:\npredicted_and_formated = loaded_model.parse_prediction_to_format_y(predicted)\n<\/code><\/pre>\n<p>Thank you.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663236278537,
        "Question_score":0,
        "Question_tags":"python|databricks|mlflow",
        "Question_view_count":15,
        "Owner_creation_time":1581629032807,
        "Owner_last_access_time":1663889245757,
        "Owner_location":null,
        "Owner_reputation":477,
        "Owner_up_votes":59,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73729205",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71292619,
        "Question_title":"Error on Spark MLFlow Model Registery using DataBricks after upgrade: cannot load trained XGBoost model",
        "Question_body":"<p>I had some code for training and then using XGBoost models on a Databricks environment. As my runtime version got deprecated, I upgraded it, but I quickly noticed I could not load my trained models anymore. The reason seems to be a change in the naming of functions in Sparkdl:<\/p>\n<pre><code>Error loading metadata: Expected class name sparkdl.xgboost.xgboost_core.XgboostClassifierModel but found class name sparkdl.xgboost.xgboost.XgboostClassifierModel\n<\/code><\/pre>\n<p>Would anyone have advise on how to fix this issue? Maybe modify the metadata?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1646039018097,
        "Question_score":1,
        "Question_tags":"pyspark|xgboost|azure-databricks|mlflow",
        "Question_view_count":111,
        "Owner_creation_time":1498319618333,
        "Owner_last_access_time":1662636545553,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71292619",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72238610,
        "Question_title":"how to save mlflow metrics and paramters to an s3 bucket without a server?",
        "Question_body":"<p>I want to save the parameters and metrics gotten from mlflow into an s3 bucket. Usually I get these from setting the <code>tracking_uri<\/code> in mlflow and that saves it on a server but I can't have a server in this case(was told no) and just want to store my parameters and metrics on the s3 bucket in the same manner as it would using the <code>tracking_uri<\/code>.<\/p>\n<p>I can store the artifacts on the s3 bucket without issue but not the params\/metrics.<\/p>\n<p>Here is some code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def mlflow_testing():\n    \n    tracking_uri =  &quot;s3:\/\/bucket_name\/mlflow\/&quot;,\n    experiment_name = &quot;test&quot;,\n    artifact_uri= &quot;s3:\/\/bucket_name\/mlflow\/&quot;\n    \n    mlflow.set_tracking_uri(tracking_uri)\n    mlflow.create_experiment(experiment_name, artifact_uri)\n    mlflow.set_experiment(experiment_name)\n    \n    with mlflow.start_run() as run:\n        mlflow.log_param(&quot;test1&quot;, 0)\n        mlflow.log_metric(&quot;test2&quot;, 1)\n    \n        with open(&quot;test.txt&quot;, &quot;w&quot;) as f:\n            f.write(&quot;this is an artifact&quot;)\n    \n        mlflow.log_artifact(&quot;test.txt&quot;)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This is capable of storing the artifact text file on the s3 bucket(so long as I make the uri a local path like <code>local_data\/mlflow<\/code> instead of the s3 bucket).<\/p>\n<p>Setting the s3 bucket for the <code>tracking_uri<\/code> results in this error:<\/p>\n<pre><code>mlflow.tracking.registry.UnsupportedModelRegistryStoreURIException:\nModel registry functionality is unavailable; got unsupported URI\n's3:\/\/bucket_location\/mlflow\/' for model registry data storage.\nSupported URI schemes are: ['', 'file', 'databricks', 'http', 'https',\n'postgresql', 'mysql', 'sqlite', 'mssql']. See\nhttps:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to\nrun an MLflow server against one of the supported backend storage\nlocations.\n<\/code><\/pre>\n<p>Does anyone have advice on getting around this without setting up a server? I just want those metrics and params.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1652517689357,
        "Question_score":2,
        "Question_tags":"python|amazon-s3|amazon-sagemaker|mlflow",
        "Question_view_count":818,
        "Owner_creation_time":1615994492347,
        "Owner_last_access_time":1657796021117,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":1652537683397,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72238610",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56370096,
        "Question_title":"Deploying ml model using azureml and mlflow",
        "Question_body":"<p>I'm new to databricks and deploying models using mlflow and azureml, I'm trying to deploy my model but haven't found a lot of documentation or examples.<\/p>\n\n<p>I have my model which I save using:<\/p>\n\n<pre><code>mlflow.sklearn.save_model(model, model_path, \n                          conda_env=conda_env_file_name)\n<\/code><\/pre>\n\n<p>I created the workspace and the aci webservice, the next step is to create the image and the webservice:<\/p>\n\n<pre><code># image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                                    runtime = \"python\", \n                                                    conda_file = conda_env_file_name)\n\n# Webservice creation\nmyservice = AciWebservice.deploy_from_model(\n  workspace=ws, \n  name=\"service\",\n  deployment_config = aciconfig,\n  models = [model_path],\n  image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n\n<p>However when I try to create the webservice I receive an error and looking at the log:<\/p>\n\n<pre><code>mlflow.exceptions.MlflowException: Could not find an \"MLmodel\" configuration file at \"mode_path\"\n<\/code><\/pre>\n\n<p>My score file init function is like this:<\/p>\n\n<pre><code>def init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('model_path')\n    model = joblib.load(model_path)\n<\/code><\/pre>\n\n<p>It seems like it cannot find the path to the model. I'm not sure in the moment the image is saved, the model is not saved in it and thus it cannot be found by sklearn.load_model. I'm quite confused cause I've seen that a model can be deployed using mlflow or azureml. I think the problems is that mlflow.save_model does not register the model and then there's no path. Have someone been able to solve this? What is the best way to deploy a model?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1559175361693,
        "Question_score":3,
        "Question_tags":"web-services|deployment|mlflow",
        "Question_view_count":933,
        "Owner_creation_time":1461539594160,
        "Owner_last_access_time":1663956732217,
        "Owner_location":null,
        "Owner_reputation":737,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":116,
        "Question_last_edit_time":1559831718177,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56370096",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68219396,
        "Question_title":"MLFlow SparkTrials maxNumConcurrentTasks([]) does not exist",
        "Question_body":"<p>I'm very new at using mlflow and I'm currently having some issues on its SparkTrials. I'm running the following code in my Jupyter notebook using Anaconda:<\/p>\n<pre><code>import mlflow\nfrom hyperopt import hp, fmin, tpe, rand, SparkTrials, STATUS_OK, STATUS_FAIL, space_eval\n\n# replicate input_pd dataframe to workers in Spark cluster\ninputs = sc.broadcast(input_pd)\n\n# configure hyperopt settings to distribute to all executors on workers\nspark_trials = SparkTrials()\n\n# select optimization algorithm\nalgo = tpe.suggest\n\n# perform hyperparameter tuning (logging iterations to mlflow)\nargmin = fmin(\n  fn=evaluate_model,\n  space=search_space,\n  algo=algo,\n  max_evals=100,\n  trials=spark_trials\n  )\n\n# release the broadcast dataset\ninputs.unpersist()\n<\/code><\/pre>\n<p>But, I get the following error:<\/p>\n<pre><code>  Py4JError: An error occurred while calling o233.maxNumConcurrentTasks. Trace:\n    py4j.Py4JException: Method maxNumConcurrentTasks([]) does not exist\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n        at py4j.Gateway.invoke(Gateway.java:274)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:238)\n        at java.lang.Thread.run(Unknown Source)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1625197883137,
        "Question_score":2,
        "Question_tags":"python|jupyter|mlflow",
        "Question_view_count":187,
        "Owner_creation_time":1617289926807,
        "Owner_last_access_time":1647594928473,
        "Owner_location":null,
        "Owner_reputation":165,
        "Owner_up_votes":19,
        "Owner_down_votes":0,
        "Owner_views":68,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68219396",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63230793,
        "Question_title":"How to handle errors in MLflow when a model has been served using \"mlflow models serve\"?",
        "Question_body":"<p>During training, it is possible to use tags as a way to handle exceptions according to <a href=\"https:\/\/stackoverflow.com\/questions\/59856641\/how-can-i-throw-an-exception-from-within-an-mlflow-project\">this question<\/a>.<\/p>\n<p>If a model has been created using <code>mlflow.pyfunc.PythonModel<\/code>, is it possible to throw exceptions? Is there a way to allow error handling for a model that has been served?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1596462943310,
        "Question_score":0,
        "Question_tags":"python|rest|mlflow",
        "Question_view_count":266,
        "Owner_creation_time":1472932425400,
        "Owner_last_access_time":1623748857057,
        "Owner_location":"Pune, Maharashtra, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63230793",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60979310,
        "Question_title":"Not able to log model or artifact to Mlflow",
        "Question_body":"<p>I have a MLFlow remote server and I am able to log things from rstudio like:<\/p>\n\n<pre><code>  mlflow_log_param(\"param1\", 5)\n  mlflow_log_param(\"param2\", 5)\n  mlflow_log_metric(\"foo\", 1)\n  mlflow_log_metric(\"foo\", 2)\n  mlflow_log_metric(\"foo\", 3)\n<\/code><\/pre>\n\n<p>But when I try to log things like:<\/p>\n\n<pre><code>  writeLines(\"Hello world!\", \"output.txt\") \n  mlflow_log_artifact(\"output.txt\")\n<\/code><\/pre>\n\n<p>I have this error:<\/p>\n\n<pre><code>2020\/04\/01 21:45:27 INFO mlflow.store.artifact.cli: Logged artifact from local file output.txt to artifact_path=None\nRoot URI: .\/mlruns\/12\/3256cfd3cd1b44b99334040bd5c7c9ee\/artifacts\n<\/code><\/pre>\n\n<p>And when I try to log a model:<\/p>\n\n<pre><code> mlflow_log_model(predictor, \"model1\")\n<\/code><\/pre>\n\n<p>I have next error:<\/p>\n\n<pre><code> 2020\/04\/01 21:56:44 INFO mlflow.store.artifact.cli: Logged artifact from local dir D:\/user\/AppData\/Local\/Temp\/RtmpcBwDOP\/model1 to artifact_path=model1\n    Root URI: .\/mlruns\/12\/07d84e0f252a4248bb2473229297d318\/artifacts\n    # A tibble: 0 x 0\n    Warning message:\n    In value[[3L]](cond) :\n      Logging model metadata to the tracking server has failed, possibly due to older server version. The model artifacts have been logged successfully. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n<\/code><\/pre>\n\n<p>The server is updated and also the client.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1585771185263,
        "Question_score":2,
        "Question_tags":"r|mlflow",
        "Question_view_count":605,
        "Owner_creation_time":1521885997267,
        "Owner_last_access_time":1663857830210,
        "Owner_location":null,
        "Owner_reputation":99,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Question_last_edit_time":1627866203927,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60979310",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57878280,
        "Question_title":"How do you start using MLflow SQL storage instead of the file system storage?",
        "Question_body":"<p>If I were getting started with MLflow, then how would I set up a database store? Is it sufficient to create a new MySQL database or a SQLite database and point MLflow to that?<\/p>\n\n<p>I tried to set the tracking URI, but that didn't create a database if it didn't exist.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1568150011390,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":882,
        "Owner_creation_time":1364931488083,
        "Owner_last_access_time":1663957662590,
        "Owner_location":"San Francisco, CA, USA",
        "Owner_reputation":31,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57878280",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73746436,
        "Question_title":"Mlflow-got error no host supplied,provided uri tracking,help me to resolve it",
        "Question_body":"<p>In below image can see i mention tracking uri and trying to load model but facing error in host supplied. <a href=\"https:\/\/i.stack.imgur.com\/GmLeq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GmLeq.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663338869023,
        "Question_score":0,
        "Question_tags":"mlflow|mlops",
        "Question_view_count":12,
        "Owner_creation_time":1576127245140,
        "Owner_last_access_time":1664053852373,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73746436",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65939058,
        "Question_title":"MLflow stores artifacts on GCP buckets but is not able to read them",
        "Question_body":"<p>I've found an almost identical question <a href=\"https:\/\/stackoverflow.com\/questions\/63727235\/mlflow-artifacts-storing-artifactsgoogle-cloud-storage-but-not-displaying-them?newreg=923da08a362547daab64c7d7e2275423\">here<\/a> but don't have enough reputation to add comments so will ask again hoping that someone has found a solution in the mean time.<\/p>\n<p>I am using MLflow (1.13.1) to track model performance and GCP Storage to store model artifacts.\nMLflow is running on a GCP VM instance and my python application uses a service account with Storage Object Creator and Storage Object Viewer roles (and then I've also added storage.buckets.get permissions) to store artifacts in GCP buckets and read from them.\nEverything is working as expected with parameters and metrics correctly displaying in MLflow UI and model artifacts correctly stored in buckets. The problem is that the model artifacts do not show up in MLflow UI because of this error:<\/p>\n<pre><code>Unable to list artifacts stored under gs:\/******\/artifacts for the current run. \nPlease contact your tracking server administrator to notify them of this error, \nwhich can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.\n<\/code><\/pre>\n<p>The quoted artifacts location exists and contains the correct model artifacts, and MLflow should be able to read the artifacts because of the Storage Object Viewer role and the storage.buckets.get permissions.<\/p>\n<p>Any suggestion on what could be wrong? Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1611843895217,
        "Question_score":1,
        "Question_tags":"google-cloud-platform|mlflow",
        "Question_view_count":428,
        "Owner_creation_time":1611841996690,
        "Owner_last_access_time":1637883583270,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I've found the problem just after posting the question.\nI had forgotten to install the <code>google-cloud-storage<\/code> library on the GCP VM. Everything works as expected now.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1611845294603,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65939058",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59051212,
        "Question_title":"MLFlow deployment example",
        "Question_body":"<p>I have  models  create  I want learn to deploy   ML Flow  model on production. can I get setp by sep  tutorial  whee  I can deply model.on my PC [assuming it to production env]<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1574772113833,
        "Question_score":0,
        "Question_tags":"deep-learning|artificial-intelligence|mlflow",
        "Question_view_count":70,
        "Owner_creation_time":1555011534987,
        "Owner_last_access_time":1647953103740,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59051212",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71687131,
        "Question_title":"How to import MLflow tracking server WSGI application via Flask or FastAPI?",
        "Question_body":"<p>MLflow provides a very cool tracking server, however, this server does not provide authentication or RBAC which is required for my needs.<\/p>\n<p>I would like to add my own authentication and RBAC functionality. I think one way to accomplish this is to import the MLflow WSGI application object and add some middleware layers to perform authentication \/ authorization before passing requests through to the tracking server, essentially proxying requests through my custom middleware stack.<\/p>\n<p>How do I go about doing this? I can see from <a href=\"https:\/\/fastapi.tiangolo.com\/advanced\/wsgi\/\" rel=\"nofollow noreferrer\">these docs<\/a> that I can use FastAPI to import another WSGI application and add custom middleware, but I'm not sure of a few things<\/p>\n<ol>\n<li>Where do I find the MLflow tracking server WSGI app (where can it be imported from)?<\/li>\n<li>How do I pass through the relevant arguments to the MLflow tracking server? I.e. the tracking server expects params to configure the backend storage layer, host, and port. If I just import the application object, how do I pass those parameters to it?<\/li>\n<\/ol>\n<p>edit - it looks like the Flask application can be found here <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/__init__.py#L28\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/__init__.py#L28<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1648703157780,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":394,
        "Owner_creation_time":1425965839877,
        "Owner_last_access_time":1663961190290,
        "Owner_location":"Santa Cruz, CA",
        "Owner_reputation":3256,
        "Owner_up_votes":81,
        "Owner_down_votes":0,
        "Owner_views":164,
        "Question_last_edit_time":1648705670280,
        "Answer_body":"<p>This was actually very simple, below is an example using FastAPI to import and mount the MLflow WSGI application.<\/p>\n<pre><code>import os\nimport subprocess\nfrom fastapi import FastAPI\nfrom fastapi.middleware.wsgi import WSGIMiddleware\n\nfrom mlflow.server import app as mlflow_app\n\napp = FastAPI()\napp.mount(&quot;\/&quot;, WSGIMiddleware(mlflow_app))\n\nBACKEND_STORE_URI_ENV_VAR = &quot;_MLFLOW_SERVER_FILE_STORE&quot;\nARTIFACT_ROOT_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACT_ROOT&quot;\nARTIFACTS_DESTINATION_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACT_DESTINATION&quot;\nPROMETHEUS_EXPORTER_ENV_VAR = &quot;prometheus_multiproc_dir&quot;\nSERVE_ARTIFACTS_ENV_VAR = &quot;_MLFLOW_SERVER_SERVE_ARTIFACTS&quot;\nARTIFACTS_ONLY_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACTS_ONLY&quot;\n\ndef parse_args():\n    a = argparse.ArgumentParser()\n    a.add_argument(&quot;--host&quot;, type=str, default=&quot;0.0.0.0&quot;)\n    a.add_argument(&quot;--port&quot;, type=str, default=&quot;5000&quot;)\n    a.add_argument(&quot;--backend-store-uri&quot;, type=str, default=&quot;sqlite:\/\/\/mlflow.db&quot;)\n    a.add_argument(&quot;--serve-artifacts&quot;, action=&quot;store_true&quot;, default=False)\n    a.add_argument(&quot;--artifacts-destination&quot;, type=str)\n    a.add_argument(&quot;--default-artifact-root&quot;, type=str)\n    a.add_argument(&quot;--gunicorn-opts&quot;, type=str, default=&quot;&quot;)\n    a.add_argument(&quot;--n-workers&quot;, type=str, default=1)\n    return a.parse_args()\n\ndef run_command(cmd, env, cwd=None):\n    cmd_env = os.environ.copy()\n    if cmd_env:\n        cmd_env.update(env)\n    child = subprocess.Popen(\n        cmd, env=cmd_env, cwd=cwd, text=True, stdin=subprocess.PIPE\n    )\n    child.communicate()\n    exit_code = child.wait()\n    if exit_code != 0:\n        raise Exception(&quot;Non-zero exitcode: %s&quot; % (exit_code))\n    return exit_code\n\ndef run_server(args):\n    env_map = dict()\n    if args.backend_store_uri:\n        env_map[BACKEND_STORE_URI_ENV_VAR] = args.backend_store_uri\n    if args.serve_artifacts:\n        env_map[SERVE_ARTIFACTS_ENV_VAR] = &quot;true&quot;\n    if args.artifacts_destination:\n        env_map[ARTIFACTS_DESTINATION_ENV_VAR] = args.artifacts_destination\n    if args.default_artifact_root:\n        env_map[ARTIFACT_ROOT_ENV_VAR] = args.default_artifact_root\n\n    print(f&quot;Envmap: {env_map}&quot;)\n\n    #opts = args.gunicorn_opts.split(&quot; &quot;) if args.gunicorn_opts else []\n    opts = args.gunicorn_opts if args.gunicorn_opts else &quot;&quot;\n\n    cmd = [\n        &quot;gunicorn&quot;, &quot;-b&quot;, f&quot;{args.host}:{args.port}&quot;, &quot;-w&quot;, f&quot;{args.n_workers}&quot;, &quot;-k&quot;, &quot;uvicorn.workers.UvicornWorker&quot;, &quot;server:app&quot;\n    ]\n    run_command(cmd, env_map)\n\ndef main():\n    args = parse_args()\n    run_server(args)\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>Run like<\/p>\n<pre><code>python server.py --artifacts-destination s3:\/\/mlflow-mr --default-artifact-root s3:\/\/mlflow-mr --serve-artifacts\n<\/code><\/pre>\n<p>Then navigate to your browser and see the tracking server running! This allows you to insert custom FastAPI middleware in front of the tracking server<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1648708838090,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71687131",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68356746,
        "Question_title":"Changing subdirectory of MLflow artifact store",
        "Question_body":"<p>Is there anything in the Python API that lets you alter the artifact subdirectories? For example, I have a .json file stored here:<\/p>\n<p><code>s3:\/\/mlflow\/3\/1353808bf7324824b7343658882b1e45\/artifacts\/feature_importance_split.json<\/code><\/p>\n<p>MlFlow creates a <code>3\/<\/code> key in s3. Is there a way to change to modify this key to something else (a date or the name of the experiment)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1626152546053,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":1493,
        "Owner_creation_time":1394078070850,
        "Owner_last_access_time":1663707363467,
        "Owner_location":null,
        "Owner_reputation":913,
        "Owner_up_votes":156,
        "Owner_down_votes":5,
        "Owner_views":88,
        "Question_last_edit_time":null,
        "Answer_body":"<p>As I commented above, yes, <code>mlflow.create_experiment()<\/code> does allow you set the artifact location using the <code>artifact_location<\/code> parameter.<\/p>\n<p>However, sort of related, the problem with setting the <code>artifact_location<\/code> using the <code>create_experiment()<\/code> function is that once you create a experiment, MLflow will throw an error if you run the <code>create_experiment()<\/code> function again.<\/p>\n<p>I didn't see this in the docs but it's confirmed that if an experiment already exists in the backend-store, MlFlow will not allow you to run the same <code>create_experiment()<\/code> function again. And as of this post, MLfLow does not have <code>check_if_exists<\/code> flag or a <code>create_experiments_if_not_exists()<\/code> function.<\/p>\n<p>To make things more frustrating, you cannot set the <code>artifcact_location<\/code> in the <code>set_experiment()<\/code> function either.<\/p>\n<p>So here is a pretty easy work around, it also avoids the &quot;ERROR mlflow.utils.rest_utils...&quot; stdout logging as well.\n:<\/p>\n<pre><code>import os\nfrom random import random, randint\n\nfrom mlflow import mlflow,log_metric, log_param, log_artifacts\nfrom mlflow.exceptions import MlflowException\n\ntry:\n    experiment = mlflow.get_experiment_by_name('oof')\n    experiment_id = experiment.experiment_id\nexcept AttributeError:\n    experiment_id = mlflow.create_experiment('oof', artifact_location='s3:\/\/mlflow-minio\/sample\/')\n\nwith mlflow.start_run(experiment_id=experiment_id) as run:\n    mlflow.set_tracking_uri('http:\/\/localhost:5000')\n    print(&quot;Running mlflow_tracking.py&quot;)\n\n    log_param(&quot;param1&quot;, randint(0, 100))\n    \n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>If it is the user's first time creating the experiment, the code will run into an AttributeError since <code>experiment_id<\/code> does not exist and the <code>except<\/code> code block gets executed creating the experiment.<\/p>\n<p>If it is the second, third, etc the code is run, it will only execute the code under the <code>try<\/code> statement since the experiment now exists. Mlflow will now create a 'sample' key in your s3 bucket. Not fully tested but it works for me at least.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1626213927413,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1626236794420,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68356746",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62579563,
        "Question_title":"NameError: name 'dbutils' is not defined",
        "Question_body":"<p>I've .py file with following code line and it lives in git.<\/p>\n<pre><code>dbutils.widgets.text(name='CORPORATION_ID', defaultValue='1234') \n<\/code><\/pre>\n<p>I am using mlflow to run it in remote databricks job cluster. I've conda.yml and MLProject file to pick it up from git and run it in databricks job cluster but I am getting following error.<\/p>\n<pre><code>  File &quot;tea\/src\/cltv_xgb_tea.py&quot;, line 40, in &lt;module&gt;\n    dbutils.widgets.text(name='CORPORATION_ID', defaultValue='1234')\nNameError: name 'dbutils' is not defined\n<\/code><\/pre>\n<p>Any help\/solution is much appreciated.<\/p>\n<hr \/>\n<p>My current files in git<\/p>\n<p>Conda.yml has<\/p>\n<pre><code>name: cicd-environment\nchannels:\n  - defaults\ndependencies:\n  - python=3.7\n  - pip=19.0.3\n  - pip:\n    - mlflow==1.7.2\n    - DBUtils==1.3\n    - ipython==7.14.0\n    - databricks-connect==6.5.1\n    - invoke==1.4.1\n    - awscli==1.18.87\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1593101026770,
        "Question_score":0,
        "Question_tags":"pyspark|conda|databricks|mlflow",
        "Question_view_count":810,
        "Owner_creation_time":1555347036127,
        "Owner_last_access_time":1663694487237,
        "Owner_location":"Minnesota, USA",
        "Owner_reputation":352,
        "Owner_up_votes":27,
        "Owner_down_votes":1,
        "Owner_views":88,
        "Question_last_edit_time":1593403896033,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62579563",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63133902,
        "Question_title":"How to send data to server for Prediction - MLflow",
        "Question_body":"<p>I am able to create ml model server using following command<\/p>\n<pre><code>mlflow models serve -m file:\/\/\/C:\/Users\/SawarkarFamily\/Desktop\/mlflow-master\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/9aeb7ba16d7e4c20870b664e267524ea\/artifacts\/model -p 8000\n2020\/07\/28 17:10:59 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2020\/07\/28 17:11:03 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d &amp; waitress-serve --host=127.0.0.1 --port=8000 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\nc:\\users\\sawarkarfamily\\anaconda3\\envs\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\lib\\site-packages\\waitress\\adjustments.py:441: DeprecationWarning: In future versions of Waitress clear_untrusted_proxy_headers will be set to True by default. You may opt-out by setting this value to False, or opt-in explicitly by setting this to True.\n  warnings.warn(\nServing on http:\/\/DESKTOP-AO59MJC:8000\n<\/code><\/pre>\n<p>In documentation it is given that send that for prediction using curl command as follows:<\/p>\n<pre><code>curl -X POST -H &quot;Content-Type:application\/json; format=pandas-split&quot; --data '{&quot;columns&quot;:[&quot;alcohol&quot;, &quot;chlorides&quot;, &quot;citric acid&quot;, &quot;density&quot;, &quot;fixed acidity&quot;, &quot;free sulfur dioxide&quot;, &quot;pH&quot;, &quot;residual sugar&quot;, &quot;sulphates&quot;, &quot;total sulfur dioxide&quot;, &quot;volatile acidity&quot;],&quot;data&quot;:[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http:\/\/127.0.0.1:1234\/invocations\n<\/code><\/pre>\n<p>I replaced port number with 8000, but getting error.<\/p>\n<pre><code>curl: (6) Could not resolve host: chlorides,\ncurl: (6) Could not resolve host: citric acid,\ncurl: (6) Could not resolve host: density,\ncurl: (6) Could not resolve host: fixed acidity,\ncurl: (6) Could not resolve host: free sulfur dioxide,\ncurl: (6) Could not resolve host: pH,\ncurl: (6) Could not resolve host: residual sugar,\ncurl: (6) Could not resolve host: sulphates,\ncurl: (6) Could not resolve host: total sulfur dioxide,\ncurl: (3) [globbing] unmatched close brace\/bracket in column 17\ncurl: (6) Could not resolve host: 0.029,\ncurl: (6) Could not resolve host: 0.48,\ncurl: (6) Could not resolve host: 0.98,\ncurl: (6) Could not resolve host: 6.2,\ncurl: (6) Could not resolve host: 29,\ncurl: (6) Could not resolve host: 3.33,\ncurl: (6) Could not resolve host: 1.2,\ncurl: (6) Could not resolve host: 0.39,\ncurl: (6) Could not resolve host: 75,\ncurl: (3) [globbing] unmatched close brace\/bracket in column 5\n{&quot;error_code&quot;: &quot;MALFORMED_REQUEST&quot;, &quot;message&quot;: &quot;Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient='split')` method.&quot;, &quot;stack_trace&quot;: &quot;Traceback (most recent call last):\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\mlflow\\\\pyfunc\\\\scoring_server\\\\__init__.py\\&quot;, line 74, in parse_json_input\\n    return _dataframe_from_json(json_input, pandas_orient=orient, schema=schema)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\mlflow\\\\utils\\\\proto_json_utils.py\\&quot;, line 106, in _dataframe_from_json\\n    return pd.read_json(path_or_str, orient=pandas_orient, dtype=False,\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\util\\\\_decorators.py\\&quot;, line 214, in wrapper\\n    return func(*args, **kwargs)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 608, in read_json\\n    result = json_reader.read()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 731, in read\\n    obj = self._get_object_parser(self.data)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 753, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 857, in parse\\n    self._parse_no_numpy()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 1094, in _parse_no_numpy\\n    for k, v in loads(json, precise_float=self.precise_float).items()\\nValueError: Expected object or value\\n&quot;}\n<\/code><\/pre>\n<p>Kindly someone help me with this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1595938501813,
        "Question_score":3,
        "Question_tags":"python|json|curl|mlflow|mlops",
        "Question_view_count":1362,
        "Owner_creation_time":1595938236260,
        "Owner_last_access_time":1633010020190,
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1595942184983,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63133902",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69841126,
        "Question_title":"Adjusting docker environment for each MLflow model",
        "Question_body":"<p>Imagine a situation, where you have two teams working on some models, for example XGBoost. They\ntrain it and then log the model to common MLflow Tracking Server. One of the teams is using older version,\nfor example 1.1 and the other team is using newest 1.6 version.<\/p>\n<p>Is it possible to use both of these models to make predictions inside one container,\nwhich downloades the models from MLflow tracking server? Since these two mentioned models\nuse different versions of XGboost, and the runtime in which they are going to be run has\ncertain version of the pip packages installed, there is going to be compatibility problem -&gt;\nonly one model will be able to run in this enviroment without changes. However, both of these models have\nrequirements.txt file saved as the artifact, and this file specifies the package versions, which the\ngiven model needs. Is it possible to adjust package versions running in the container according to\nthe currently used model using the requirements.txt artifact file? Or is the only\nsolution to create two separate docker images, for each of the models and with the\npackages that the model needs?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1636037303067,
        "Question_score":0,
        "Question_tags":"docker|pip|mlflow",
        "Question_view_count":95,
        "Owner_creation_time":1636036906520,
        "Owner_last_access_time":1663933591417,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69841126",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71203995,
        "Question_title":"RuntimeError: Java gateway process exited before sending its port number when Deploying Pyspark model to Azure Container Instance",
        "Question_body":"<p>I am trying to deploy a PySpark model trained in Azure Databricks with MLflow to an ACI in Azure Machine Learning.<\/p>\n<p>I am following the steps in this link:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks<\/a><\/p>\n<p>but I get this error:<\/p>\n<pre><code>SPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2022-02-21 09:29:30,269 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-02-21 09:29:30,270 | root | INFO | Starting up request id generator\n2022-02-21 09:29:30,270 | root | INFO | Starting up app insight hooks\n2022-02-21 09:29:30,270 | root | INFO | Invoking user's init function\nJAVA_HOME is not set\n2022-02-21 09:29:31,267 | root | ERROR | User's init function failed\n2022-02-21 09:29:31,268 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 191, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/execution_script.py&quot;, line 15, in init\n    model = load_model(model_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 667, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/spark.py&quot;, line 703, in _load_pyfunc\n    pyspark.sql.SparkSession.builder.config(&quot;spark.python.worker.reuse&quot;, True)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/sql\/session.py&quot;, line 228, in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 392, in getOrCreate\n    SparkContext(conf=conf or SparkConf())\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 144, in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 339, in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/java_gateway.py&quot;, line 108, in launch_gateway\n    raise RuntimeError(&quot;Java gateway process exited before sending its port number&quot;)\nRuntimeError: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>My code looks like this:<\/p>\n<pre><code>from mlflow.deployments import get_deploy_client\n\n# set the tracking uri as the deployment client\nclient = get_deploy_client(mlflow.get_tracking_uri())\n\n# set the model path \nmodel_path = &quot;k_means_model&quot;\n\n    # define the model path and the name is the service name\n    # the model gets registered automatically and a name is autogenerated using the &quot;name&quot; parameter below \n    client.create_deployment(model_uri='runs:\/{}\/{}'.format(run_id, model_path), name = 'k-means-model-ml-flow')\n<\/code><\/pre>\n<p>While my model settings are:<\/p>\n<pre><code>artifact_path: k_means_model\ndatabricks_runtime: 10.3.x-cpu-ml-scala2.12\nflavors:\n  python_function:\n    data: sparkml\n    env: conda.yaml\n    loader_module: mlflow.spark\n    python_version: 3.8.10\n  spark:\n    model_data: sparkml\n    pyspark_version: 3.2.1\nmodel_uuid: 76ba9dfb01e1428ab8145a161ec3cf32\nrun_id: c0090fa9-b382-45b8-be08-d05e16f3cd62\nutc_time_created: '2022-02-21 08:47:34.967167'\n<\/code><\/pre>\n<p>Can someone help please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1645436044400,
        "Question_score":1,
        "Question_tags":"pyspark|azure-databricks|azure-machine-learning-service|mlflow",
        "Question_view_count":289,
        "Owner_creation_time":1635865186583,
        "Owner_last_access_time":1657599189513,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1645439952347,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71203995",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62160734,
        "Question_title":"Hyperopt failed to execute mlflow.end_run() with tracking URI: databricks",
        "Question_body":"<p>I'm using Azure Databricks + Hyperopt + MLflow for some hyperparameter tuning on a small dataset.  Seem like the job is running, and I get output in MLflow, but the job ends with the following error message:<\/p>\n\n<pre><code>Hyperopt failed to execute mlflow.end_run() with tracking URI: databricks\n<\/code><\/pre>\n\n<p>Here is my code code with some information redacted:<\/p>\n\n<pre><code>from pyspark.sql import SparkSession\n\n# spark session initialization\nspark = (SparkSession.builder.getOrCreate())\nsc = spark.sparkContext\n\n# Data Processing\nimport pandas as pd\nimport numpy as np\n# Hyperparameter Tuning\nfrom hyperopt import fmin, tpe, hp, anneal, Trials, space_eval, SparkTrials, STATUS_OK\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n# Modeling\nfrom sklearn.ensemble import RandomForestClassifier\n# cleaning\nimport gc\n# tracking\nimport mlflow\n# track runtime\nfrom datetime import date, datetime\n\nmlflow.set_experiment('\/user\/myname\/myexp')\n# notebook settings \\ variable settings\nn_splits = #\nn_repeats = #\nmax_evals = #\n\ndfL = pd.read_csv(\"\/my\/data\/loc\/mydata.csv\")\n\nx_train = dfL[['f1','f2','f3']]\ny_train = dfL['target']\n\ndef define_model(params):\n    model = RandomForestClassifier(n_estimators=int(params['n_estimators']),\n                                   criterion=params['criterion'], \n                                   max_depth=int(params['max_depth']), \n                                   min_samples_split=params['min_samples_split'], \n                                   min_samples_leaf=params['min_samples_leaf'], \n                                   min_weight_fraction_leaf=params['min_weight_fraction_leaf'], \n                                   max_features=params['max_features'], \n                                   max_leaf_nodes=None, \n                                   min_impurity_decrease=params['min_impurity_decrease'], \n                                   min_impurity_split=None, \n                                   bootstrap=params['bootstrap'], \n                                   oob_score=False, \n                                   n_jobs=-1, \n                                   random_state=int(params['random_state']), \n                                   verbose=0, \n                                   warm_start=False, \n                                   class_weight={0:params['class_0_weight'], 1:params['class_1_weight']})\n        return model\n\n\nspace = {'n_estimators': hp.quniform('n_estimators', #, #, #),\n         'criterion': hp.choice('#', ['#','#']),\n         'max_depth': hp.quniform('max_depth', #, #, #),\n         'min_samples_split': hp.quniform('min_samples_split', #, #, #),\n         'min_samples_leaf': hp.quniform('min_samples_leaf', #, #, #),\n         'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', #, #, #),\n         'max_features': hp.quniform('max_features', #, #, #),\n         'min_impurity_decrease': hp.quniform('min_impurity_decrease', #, #, #),\n         'bootstrap': hp.choice('bootstrap', [#,#]),\n         'random_state': hp.quniform('random_state', #, #, #),\n         'class_0_weight': hp.choice('class_0_weight', [#,#,#]),\n         'class_1_weight': hp.choice('class_1_weight', [#,#,#])}\n\n# define hyperopt objective\ndef objective(params, n_splits=n_splits, n_repeats=n_repeats):\n\n    # define model\n    model = define_model(params)\n    # get cv splits\n    kfold = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=1331)\n    # define and run sklearn cv scorer\n    scores = cross_val_score(model, x_train, y_train, cv=kfold, scoring='roc_auc')\n    score = scores.mean()\n\n    return {'loss': score*(-1), 'status': STATUS_OK}\n\nspark_trials = SparkTrials(parallelism=36, spark_session=spark)\nwith mlflow.start_run():\n  best = fmin(objective, space, algo=tpe.suggest, trials=spark_trials, max_evals=max_evals)\n<\/code><\/pre>\n\n<p>and then at the end I get..<\/p>\n\n<pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200\/200 [1:35:28&lt;00:00, 100.49s\/trial, best loss: -0.9584565527065526]\n\nHyperopt failed to execute mlflow.end_run() with tracking URI: databricks\n\nException: 'MLFLOW_RUN_ID'\n\nTotal Trials: 200: 200 succeeded, 0 failed, 0 cancelled.\n<\/code><\/pre>\n\n<p>My Azure Databricks cluster is..<\/p>\n\n<pre><code>6.6 ML (includes Apache Spark 2.4.5, Scala 2.11)\nStandard_DS3_v2\nmin 9 max 18 nodes\n<\/code><\/pre>\n\n<p>Am I doing something wrong or is this a bug?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1591129195507,
        "Question_score":2,
        "Question_tags":"pyspark|databricks|azure-databricks|mlflow|hyperopt",
        "Question_view_count":604,
        "Owner_creation_time":1528603052363,
        "Owner_last_access_time":1663971435213,
        "Owner_location":null,
        "Owner_reputation":247,
        "Owner_up_votes":637,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62160734",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73448308,
        "Question_title":"How to configure `backend-store-uri` with huggingface Trainer",
        "Question_body":"<p>When configuring a Hugging Face TrainingArguments <a href=\"https:\/\/huggingface.co\/transformers\/v4.8.0\/main_classes\/trainer.html\" rel=\"nofollow noreferrer\">https:\/\/huggingface.co\/transformers\/v4.8.0\/main_classes\/trainer.html<\/a> you can set the <code>logging_dir<\/code> and <code>output_dir<\/code>.<\/p>\n<p>There is also the <code>mlruns<\/code> directory which according to <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#backend-stores\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tracking.html#backend-stores<\/a> you can configure using <code>--set-backend-uri<\/code>. Though that is an mlflow doc, not a Hugging Face doc.<\/p>\n<p>What is the best way to specify a different <code>mlruns<\/code> directory programmatically when setting up the Hugging Face Trainer?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1661185918393,
        "Question_score":0,
        "Question_tags":"mlflow|huggingface",
        "Question_view_count":19,
        "Owner_creation_time":1484305691263,
        "Owner_last_access_time":1663933845823,
        "Owner_location":"London, United Kingdom",
        "Owner_reputation":161,
        "Owner_up_votes":169,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73448308",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68668190,
        "Question_title":"Shape error while converting Image to JSON file",
        "Question_body":"<p>I am trying to convert image to JSON file and POST it with REST API by using MLFLow. Below you can see my code. I got an error like &quot;cannot reshape array of size 535500 into shape (1,4096)&quot;. Can you please help me. Thank you in advance.<\/p>\n<pre><code>import json\nimport cv2\nimport requests\nimport base64\nimport numpy as np\nfrom PIL import Image\n\n\ndata = np.asarray(Image.open('Dataset\/test2\/dog_PNG50348.png').convert('LA'))\ndata = data.reshape((1, 64*64))\ncolumns = [f&quot;col_{c}&quot; for c in range(0, data[0].shape[0])]\ndct = {&quot;columns&quot;: columns, &quot;data&quot;: [data[0].tolist()]}\nprint(json.dumps(dct, indent=2) + &quot;\\n&quot;)\n\n#print(data)\nheaders = {'Content-Type': 'application\/json'}\nrequest_uri = 'http:\/\/127.0.0.1:5000\/invocations'\n\nif __name__ == '__main__':\n    try:\n        response = requests.post(request_uri, data=json.dumps(dct,indent=2)+&quot;\\n&quot;, headers=headers)\n        print(response.content)\n        print('done!!!')\n    except Exception as ex:\n        raise (ex)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1628172503093,
        "Question_score":0,
        "Question_tags":"python|json|numpy|rest|mlflow",
        "Question_view_count":70,
        "Owner_creation_time":1460657116247,
        "Owner_last_access_time":1652910305520,
        "Owner_location":null,
        "Owner_reputation":98,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68668190",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73789674,
        "Question_title":"How can I know how many iterations are left when tuning accross multiple hyperparameters in SparkML?",
        "Question_body":"<p>I'm running a crossvalidation accross a grid of multiple hyperparameters with XgBoost model using Pyspark in Databricks and I would like to know the progress of this operation...So far it has been running for almost 24 hours and I have no idea if it's halfway done or only 10% of the way. I have a 128k combinations of hyperparameters of 5 folds each so a total of 640k runs...<\/p>\n<p>I've tried clicking on MLflow logged run but it's an empty page with an UNFINISHED status. Is there any way to know the progress ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663690227917,
        "Question_score":0,
        "Question_tags":"databricks|cross-validation|apache-spark-mllib|hyperparameters|mlflow",
        "Question_view_count":13,
        "Owner_creation_time":1558118783690,
        "Owner_last_access_time":1663939366183,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1663694262410,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73789674",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57693162,
        "Question_title":"Specify database backend store creation in specific schema",
        "Question_body":"<p>When creating an mlflow tracking server and specifying that a SQL Server database is to be used as a backend store, mlflow creates a bunch of table within the dbo schema. Does anyone know if it is possible to specify a different schema in which to create these tables?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1566997596983,
        "Question_score":1,
        "Question_tags":"python|sqlalchemy|mlflow",
        "Question_view_count":823,
        "Owner_creation_time":1566996760530,
        "Owner_last_access_time":1630269065473,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57693162",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72368541,
        "Question_title":"Does mlflow support spacy model serving\/ life-cycle management",
        "Question_body":"<p>How much does MLflow support for spaCy model lifecycle management?<\/p>\n<p>SpaCy model building <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/spacy\" rel=\"nofollow noreferrer\">example<\/a> is given here.<\/p>\n<p>But model serving is failing and showing below error:\n<a href=\"https:\/\/i.stack.imgur.com\/04InD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/04InD.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1653420858453,
        "Question_score":0,
        "Question_tags":"spacy|cicd|mlflow",
        "Question_view_count":75,
        "Owner_creation_time":1495572503257,
        "Owner_last_access_time":1664063965120,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1653464335820,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72368541",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63175684,
        "Question_title":"fitting and predicting model with mlflow",
        "Question_body":"<p>I'm very new to understanding the use of MLFlow but need assistance, I'm trying to understand on how to try and fit and predict my model once again. I'm able to call my model by:<\/p>\n<pre><code>PLS_model = mlflow.pyfunc.load_model(&quot;runs:\/FFFFF!@#!@#@!#!\/logged_model&quot;, suppress_warnings = True)\n<\/code><\/pre>\n<p>and get:<\/p>\n<pre><code>mlflow.pyfunc.loaded_model:\n  artifact_path: logged_model\n  flavor: mlflow.sklearn\n  run_id: FFFFF!@#!@#@!#!\n<\/code><\/pre>\n<p>But when I try to call any methods as:<\/p>\n<p>1).fit or .predict. I get the following error<\/p>\n<pre><code>AttributeError: 'PyFuncModel' object has no attribute 'fit'\n\nAttributeError: 'PyFuncModel' object has no attribute 'predict'\n<\/code><\/pre>\n<p>Here I encountered on how to actually call these functions but not sure if I'm doing this correctly. In summary, how can I predict, fit to my new data.<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1596120433613,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":1702,
        "Owner_creation_time":1508861451607,
        "Owner_last_access_time":1661949233680,
        "Owner_location":"Netherlands",
        "Owner_reputation":458,
        "Owner_up_votes":104,
        "Owner_down_votes":1,
        "Owner_views":71,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63175684",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68059536,
        "Question_title":"Could not connect to MLFlow model hosted on Docker",
        "Question_body":"<p>I hosted a model inside a docker container.\nOn running the DockerFile, It runs the following command:<\/p>\n<p><code>mlflow models serve -m model --port 8080 --no-conda<\/code><\/p>\n<p>It serves the model succesfully , And I can now make calls to it.\nBut, I keep getting Max retries exceeded with url<\/p>\n<p>When I host the same model without using Docker(And follow the same steps), it works perfectly.<\/p>\n<p>I use the following command to run the docker container\n<code>docker run -it --rm --network host imagename:random<\/code><\/p>\n<p>I have also tried mapping port 8080, But still not able to get a response.<\/p>\n<p>Not able to understand what the possible issues could be.<\/p>\n<p>Dockerfile for reference<\/p>\n<pre><code>  \nFROM ubuntu:20.04\nENV DEBIAN_FRONTEND=noninteractive\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential software-properties-common\\\n    libboost-dev libboost-serialization-dev libssl-dev \\\n    cmake vim\\\n    wget \\\n    make libbz2-dev libexpat1-dev swig python-dev\nRUN add-apt-repository -y ppa:ubuntugis\/ppa &amp;&amp; apt-get -q update\nRUN apt-get -y install gdal-bin libgdal-dev\nRUN apt-get update\n\nRUN apt install -y python3-pip\nRUN pip3 install --upgrade pip\nRUN pip install mlflow\nRUN pip install pandas\n\nRUN mkdir -p \/tmp\nCOPY .\/main.py \/tmp\/\nCOPY .\/run.sh \/tmp\/\n\nENV LC_ALL=C.UTF-8\nENV LANG=C.UTF-8\nRUN chmod +x run.sh\nCMD .\/run.sh\n<\/code><\/pre>\n<p>Where, run.sh is<\/p>\n<pre><code>python3 main.py\nmlflow models serve -m \/tmp\/mlflow_model --port 8080 --no-conda\n<\/code><\/pre>\n<p>When I run the commands of run.sh file outside of docker container, It is able to serve the model correctly,And I get the correct response.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1624218724787,
        "Question_score":1,
        "Question_tags":"docker|python-requests|port|mlflow",
        "Question_view_count":195,
        "Owner_creation_time":1539037621213,
        "Owner_last_access_time":1658940050953,
        "Owner_location":"New Delhi, Delhi, India",
        "Owner_reputation":75,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68059536",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69905990,
        "Question_title":"Registering model without weights with MLFLow",
        "Question_body":"<p>I would like to be able to register untrained models with MLFLow to use as prototypes for instantiating models for training. I need this because we need to train thousands of models of the same type. Is this possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1636497891150,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":46,
        "Owner_creation_time":1636497545873,
        "Owner_last_access_time":1640893909690,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69905990",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61266578,
        "Question_title":"How can an mlflow model be scaled to serve more requests?",
        "Question_body":"<p>I would like to have multiple instances of my MLFlow model running in parallel but hidden behind a common the same endpoint\/port so it's not visible to the user. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1587109863510,
        "Question_score":0,
        "Question_tags":"multithreading|gunicorn|mlflow",
        "Question_view_count":228,
        "Owner_creation_time":1579017872663,
        "Owner_last_access_time":1637341304770,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61266578",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73499320,
        "Question_title":"Error loading model from mlflow: java.io.StreamCorruptedException: invalid type code: 00",
        "Question_body":"<p>I'm using Databricks Connect version 9.1.16 to connect to a databricks external cluster with spark version 3.1 and download a Pyspark ML model that's been trained and saved using mlflow.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(&quot;databricks&quot;)\nmodel_h = mlflow.spark.load_model(model_uri=&quot;models:\/model_name\/model_version&quot;)\n<\/code><\/pre>\n<p>I get the following output and error:<\/p>\n<pre><code>2022\/08\/26 11:54:18 INFO mlflow.spark: 'models:\/model_name\/model_version' resolved as 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model'\n2022\/08\/26 11:54:25 INFO mlflow.spark: URI 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model\/sparkml' does not point to the current DFS.\n2022\/08\/26 11:54:25 INFO mlflow.spark: File 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model\/sparkml' not found on DFS. Will attempt to upload the file.\n2022\/08\/26 11:55:06 INFO mlflow.spark: Copied SparkML model to \/tmp\/mlflow\/model_id\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\nc:\\Users\\carlafernandez\\Documents\\my_notebook.ipynb Celda 5 in &lt;cell line: 2&gt;()\n      1 mlflow.set_tracking_uri(&quot;databricks&quot;)\n----&gt; 2 model_h = mlflow.spark.load_model(model_uri=&quot;models:\/model_name\/model_version&quot;)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:711, in load_model(model_uri, dfs_tmpdir)\n    708 local_model_path = _download_artifact_from_uri(model_uri)\n    709 _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n--&gt; 711 return _load_model(model_uri=model_uri, dfs_tmpdir_base=dfs_tmpdir)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:660, in _load_model(model_uri, dfs_tmpdir_base)\n    658     return _load_model_databricks(model_uri, dfs_tmpdir)\n    659 model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\n--&gt; 660 return PipelineModel.load(model_uri)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:463, in MLReadable.load(cls, path)\n    460 @classmethod\n    461 def load(cls, path):\n    462     &quot;&quot;&quot;Reads an ML instance from the input path, a shortcut of `read().load(path)`.&quot;&quot;&quot;\n--&gt; 463     return cls.read().load(path)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\pipeline.py:258, in PipelineModelReader.load(self, path)\n    256 metadata = DefaultParamsReader.loadMetadata(path, self.sc)\n    257 if 'language' not in metadata['paramMap'] or metadata['paramMap']['language'] != 'Python':\n--&gt; 258     return JavaMLReader(self.cls).load(path)\n    259 else:\n    260     uid, stages = PipelineSharedReadWrite.load(metadata, self.sc, path)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:413, in JavaMLReader.load(self, path)\n    411 if not isinstance(path, str):\n    412     raise TypeError(&quot;path should be a string, got type %s&quot; % type(path))\n--&gt; 413 java_obj = self._jread.load(path)\n    414 if not hasattr(self._clazz, &quot;_from_java&quot;):\n    415     raise NotImplementedError(&quot;This Java ML type cannot be loaded into Python currently: %r&quot;\n    416                               % self._clazz)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\java_gateway.py:1304, in JavaMember.__call__(self, *args)\n   1298 command = proto.CALL_COMMAND_NAME +\\\n   1299     self.command_header +\\\n   1300     args_command +\\\n   1301     proto.END_COMMAND_PART\n   1303 answer = self.gateway_client.send_command(command)\n-&gt; 1304 return_value = get_return_value(\n   1305     answer, self.gateway_client, self.target_id, self.name)\n   1307 for temp_arg in temp_args:\n   1308     temp_arg._detach()\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\sql\\utils.py:117, in capture_sql_exception.&lt;locals&gt;.deco(*a, **kw)\n    115 def deco(*a, **kw):\n    116     try:\n--&gt; 117         return f(*a, **kw)\n    118     except py4j.protocol.Py4JJavaError as e:\n    119         converted = convert_exception(e.java_exception)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)\n    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n    325 if answer[1] == REFERENCE_TYPE:\n--&gt; 326     raise Py4JJavaError(\n    327         &quot;An error occurred while calling {0}{1}{2}.\\n&quot;.\n    328         format(target_id, &quot;.&quot;, name), value)\n    329 else:\n    330     raise Py4JError(\n    331         &quot;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&quot;.\n    332         format(target_id, &quot;.&quot;, name, value))\n\nPy4JJavaError: An error occurred while calling o645.load.\n: java.io.StreamCorruptedException: invalid type code: 00\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1698)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n    at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\n    at sun.reflect.GeneratedMethodAccessor311.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n    at org.apache.spark.sql.util.ProtoSerializer.$anonfun$deserializeObject$1(ProtoSerializer.scala:6631)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at org.apache.spark.sql.util.ProtoSerializer.deserializeObject(ProtoSerializer.scala:6616)\n    at com.databricks.service.SparkServiceRPCHandler.execute0(SparkServiceRPCHandler.scala:728)\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC0$1(SparkServiceRPCHandler.scala:477)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC0(SparkServiceRPCHandler.scala:372)\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:323)\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:309)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC$1(SparkServiceRPCHandler.scala:359)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC(SparkServiceRPCHandler.scala:336)\n    at com.databricks.service.SparkServiceRPCServlet.doPost(SparkServiceRPCServer.scala:167)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)\n    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n    at org.eclipse.jetty.server.Server.handle(Server.java:516)\n    at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n    at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n    at java.lang.Thread.run(Thread.java:748)\n<\/code><\/pre>\n<p>So it seems like it's able to find a copy the model, but then somehow it cannot read it. It's worth noting that the same <strong>works in a databricks notebook<\/strong>, the problem only occurs using databricks connect.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1661508308487,
        "Question_score":0,
        "Question_tags":"pyspark|databricks|mlflow|databricks-connect",
        "Question_view_count":23,
        "Owner_creation_time":1506240907953,
        "Owner_last_access_time":1663933103760,
        "Owner_location":"Madrid, Espa\u00f1a",
        "Owner_reputation":56,
        "Owner_up_votes":47,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73499320",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71679081,
        "Question_title":"How can I connect mlflow server via nginx ssl authentication?",
        "Question_body":"<p>System information\nOS Platform and Distribution: Windows 10\nMLflow installed: using pip\nMLflow version: version 1.24.0\n**Python version: Python 3.9.7 **<\/p>\n<p>Describe the problem\nI have created a docker-compose system with a backend\/artifact storages, mlflow server and nginx to add an authentication layer.<\/p>\n<pre><code>...\nmlflow:\n        restart: always\n        build: .\n        environment:\n            - AWS_ACCESS_KEY_ID=${MINIO_USR}\n            - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n        expose:\n            - '5000'\n        networks:\n            - frontend\n            - backend\n        depends_on:\n            - storage                       \n        image: 'mlflow:Dockerfile'\n        container_name: mlflow_server_nginx\n\n    nginx:\n        restart: always\n        build: .\/nginx\n        container_name: mlflow_nginx\n        ports:\n            - 5043:443\n        links:\n            - mlflow:mlflow\n        volumes:\n            - 'path\/to\/nginx\/auth:\/etc\/nginx\/conf.d'\n            - 'path\/to\/nginx\/nginx.conf:\/etc\/nginx\/nginx.conf:ro'\n        networks:\n            - frontend\n        depends_on:\n            - mlflow\n<\/code><\/pre>\n<p>I have created an user\/password via htpasswd and a custom SSL CA (.pem\/.key) using openssl and my-mlflow.com server-name.<\/p>\n<p>When the docker-compose system is built i can access to mlflow UI via my browser. But when i try to create a new experiment using python trying diferent approaches, i get next errors:\nExecuted code 1:<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1108)')))\n<\/code><\/pre>\n<p>After read some notes in the documentation and realated issues I tryed next<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\nos.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4012)')))\n<\/code><\/pre>\n<p>Finally<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\nos.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(&quot;hostname 'localhost' doesn't match '*.my-mlflow.com'&quot;)))\n<\/code><\/pre>\n<p>Can you give me some hints about how to solve it?<\/p>\n<p>Thank you very much!\nFernando....<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1648650339347,
        "Question_score":1,
        "Question_tags":"python-3.x|docker|nginx|docker-compose|mlflow",
        "Question_view_count":625,
        "Owner_creation_time":1580841805373,
        "Owner_last_access_time":1663792613347,
        "Owner_location":"Seville, Spain",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can set:<\/p>\n<pre><code>os.environ['MLFLOW_TRACKING_INSECURE_TLS'] = 'true'\n<\/code><\/pre>\n<p>And then try to get your cert-chain straight from there for production use.<\/p>\n<p>Also see Documentation: <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1652276299263,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1652448943407,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71679081",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56328367,
        "Question_title":"Linear regression model with integration of MLFlow",
        "Question_body":"<p>Does anybody has a link to sample Linear Regression code integrated with MLFlow and explaining all three concepts of MLFlow i.e. Tracking, Project and Model? <\/p>\n\n<p>I'm particularly looking for a demo link to the same.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1558968873863,
        "Question_score":1,
        "Question_tags":"python|machine-learning|linear-regression|azure-databricks|mlflow",
        "Question_view_count":204,
        "Owner_creation_time":1453907226643,
        "Owner_last_access_time":1604947189130,
        "Owner_location":null,
        "Owner_reputation":329,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56328367",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":54233746,
        "Question_title":"Filter mlflow runs by commit ID",
        "Question_body":"<p>When using the UI of MlFlow, is it possible to filter\/search the runs using the (git) commit ID? I manage to search by parameters but it doesn't seem like there's a way to filter by the commit ID.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/npkFO.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/npkFO.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1547720560897,
        "Question_score":4,
        "Question_tags":"machine-learning|version-control|mlflow",
        "Question_view_count":982,
        "Owner_creation_time":1300789717227,
        "Owner_last_access_time":1663941101560,
        "Owner_location":null,
        "Owner_reputation":11410,
        "Owner_up_votes":2846,
        "Owner_down_votes":6,
        "Owner_views":1782,
        "Question_last_edit_time":1547796230323,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54233746",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60633328,
        "Question_title":"Mlflow it is possible to log confusion matrix every step?",
        "Question_body":"<p>It is possible to log with mlflow the confusion matrix every step like a simple metrics?\nIf it is possible it have a visualization like this?\n<a href=\"https:\/\/i.stack.imgur.com\/bYbgo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bYbgo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1583920669630,
        "Question_score":0,
        "Question_tags":"data-visualization|confusion-matrix|mlflow",
        "Question_view_count":2334,
        "Owner_creation_time":1547467399037,
        "Owner_last_access_time":1663856296190,
        "Owner_location":"Busto Arsizio, VA, Italia",
        "Owner_reputation":171,
        "Owner_up_votes":31,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Question_last_edit_time":1584009263430,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60633328",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69482686,
        "Question_title":"logging models in mlflow with a pyspark process in Kerberized HDP 3.1.5",
        "Question_body":"<p>I'm currently testing mlflow to log pyspark models in a HDP3.1.x Cluster KERBERIZED.\nI've configured mlflow to use HDFS (of the same HDP cluster) for model storage.<\/p>\n<p>Whenever I launch a pyspark process to log a model on MLFlow with &quot;spark-submit --deploy-mode=cluster ...&quot;, I've got the exception<\/p>\n<blockquote>\n<p>AccessControlException: Client cannot authenticate via:[TOKEN, KERBEROS]java.io.IOException: DestHost:destPort\nnamenode01.hdp.site:8020 , LocalHost:localPort\nworker05.hdp.site\/192.168.0.208:0. Failed on local exception:\njava.io.IOException:\n<strong>org.apache.hadoop.security.AccessControlException: Client cannot\nauthenticate via:[TOKEN, KERBEROS]<\/strong><\/p>\n<p>(...)<\/p>\n<p>Caused by: java.io.IOException:\norg.apache.hadoop.security.AccessControlException: Client cannot\nauthenticate via:[TOKEN, KERBEROS]    at\norg.apache.hadoop.ipc.Client$Connection$1.run(Client.java:758)    at\njava.security.AccessController.doPrivileged(Native Method)    at\njavax.security.auth.Subject.doAs(Subject.java:422)*<\/p>\n<\/blockquote>\n<p>It seems that libhdfs used by mlflow cannot properly authenticate with delegation tokens. Do you know any way to fix or circumvent this problem?<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1633615788157,
        "Question_score":0,
        "Question_tags":"apache-spark|pyspark|kerberos|mlflow|hdp",
        "Question_view_count":102,
        "Owner_creation_time":1633614827870,
        "Owner_last_access_time":1663923745037,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1633622029737,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69482686",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70680222,
        "Question_title":"Does MLflow allow to log artifacts from remote locations like S3?",
        "Question_body":"<h2>My setting<\/h2>\n<p>I have developed an environment for ML experiments that looks like the following: training happens in the AWS cloud with SageMaker Training Jobs. The trained model is stored in the <code>\/opt\/ml\/model<\/code> directory, <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-output.html\" rel=\"nofollow noreferrer\">which is reserved by SageMaker to pack models<\/a> as a <code>.tar.gz<\/code> in SageMaker's own S3 bucket. Several evaluation metrics are computed during training and testing, and recorded to an MLflow infrastructure consisting of an S3-based artifact store (see <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\" rel=\"nofollow noreferrer\">Scenario 4<\/a>). Note that this is a different S3 bucket than SageMaker's.<\/p>\n<p>A very useful feature from MLflow is that any model artifacts can be logged to a training run, so data scientists have access to both metrics and more complex outputs through the UI. These outputs include (but are not limited to) the trained model itself.<\/p>\n<p>A limitation is that, as I understand it, the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"nofollow noreferrer\">MLflow API for logging artifacts<\/a> only accepts as input a local path to the artifact itself, and will always upload it to its artifact store. This is suboptimal when the artifacts are stored somewhere outside MLflow, as you have to store them twice. A transformer model may weigh more than 1GB.<\/p>\n<h2>My questions<\/h2>\n<ul>\n<li>Is there a way to pass an S3 path to MLflow and make it count as an artifact, without having to download it locally first?<\/li>\n<li>Is there a way to avoid pushing a copy of an artifact to the artifact store? If my artifacts already reside in another remote location, it would be ideal to just have a link to such location in MLflow and not a copy in MLflow storage.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1641984552913,
        "Question_score":0,
        "Question_tags":"python|amazon-s3|amazon-sagemaker|mlflow|mlops",
        "Question_view_count":533,
        "Owner_creation_time":1452286548080,
        "Owner_last_access_time":1663928318030,
        "Owner_location":"Madrid, Spain",
        "Owner_reputation":118,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70680222",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59363969,
        "Question_title":"mlflow: problems with pip installation",
        "Question_body":"<p>I read through many threads regarding installation issues using pip. However, I could find a solution to help me fix my problem.\nI installed mlflow with :<\/p>\n\n<pre><code>    pip3 install mlflow\n<\/code><\/pre>\n\n<p>so mlflow is installed in \/usr\/local\/bin\/mlflow<\/p>\n\n<p>Since it is not in \/Users\/xxxx\/opt\/anaconda3\/lib\/python3.7\/site-packages, I get \"ModuleNotFoundError: No module named 'mlflow' error when I try to run code that imports mlflow module. How should I fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1576528631793,
        "Question_score":1,
        "Question_tags":"pip|python-import|python-3.7|importerror|mlflow",
        "Question_view_count":9843,
        "Owner_creation_time":1524783572553,
        "Owner_last_access_time":1639508068437,
        "Owner_location":"San Francisco, CA, USA",
        "Owner_reputation":87,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59363969",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72604450,
        "Question_title":"MLflow load model fails Python",
        "Question_body":"<p>I am trying to build an API using an MLflow model.<\/p>\n<p>the funny thing is it works from one location on my PC and not from another. So, the reason for doing I wanted to change my repo etc.<\/p>\n<p>So, the simple code of<\/p>\n<pre><code>from mlflow.pyfunc import load_model\nMODEL_ARTIFACT_PATH = &quot;.\/model\/model_name\/&quot;\nMODEL = load_model(MODEL_ARTIFACT_PATH)\n<\/code><\/pre>\n<p>now fails with<\/p>\n<pre><code>ERROR:    Traceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 540, in lifespan\n    async for item in self.lifespan_context(app):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 481, in default_lifespan\n    await self.startup()\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 516, in startup\n    await handler()\n  File &quot;\/code\/.\/app\/main.py&quot;, line 32, in startup_load_model\n    MODEL = load_model(MODEL_ARTIFACT_PATH)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 733, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 737, in _load_pyfunc\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 656, in _load_model\n    return PipelineModel.load(model_uri)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 332, in load\n    return cls.read().load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/pipeline.py&quot;, line 258, in load\n    return JavaMLReader(self.cls).load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 282, in load\n    java_obj = self._jread.load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/py4j\/java_gateway.py&quot;, line 1321, in __call__\n    return_value = get_return_value(\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/sql\/utils.py&quot;, line 117, in deco\n    raise converted from None\npyspark.sql.utils.AnalysisException: Unable to infer schema for Parquet. It must be specified manually.\n<\/code><\/pre>\n<p>The model artifacts are already downloaded to the folder \/model folder which has the following structure.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>the load model call is in the main.py file\nAs I mentioned it works from another directory, but there is no reference to any absolute paths. Also, I have made sure that my package references are identical. e,g I have pinned them all down<\/p>\n<pre><code># Model\nmlflow==1.25.1\nprotobuf==3.20.1\npyspark==3.2.1\nscipy==1.6.2\nsix==1.15.0\n<\/code><\/pre>\n<p>also, the same docker file is used both places, which among other things, makes sure that the final resulting folder structure is the same<\/p>\n<pre><code>......other stuffs\n\nCOPY .\/app \/code\/app\nCOPY .\/model \/code\/model\n<\/code><\/pre>\n<p>what can explain it throwing this exception whereas in another location (on my PC), it works (same model artifacts) ?<\/p>\n<p>Since it uses load_model function, it should be able to read the parquet files ?<\/p>\n<p>Any question and I can explain.<\/p>\n<p>EDIT1: I have debugged this a little more in the docker container and it seems the parquet files in the itemFactors folder (listed in my screenshot above) are not getting copied over to my image , even though I have the copy command to copy all files under the model folder. It is copying the _started , _committed and _SUCCESS files, just not the parquet files. Anyone knows why would that be? I DO NOT have a .dockerignore file. Why are those files ignored while copying?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655130099670,
        "Question_score":2,
        "Question_tags":"python|docker|databricks|mlflow",
        "Question_view_count":109,
        "Owner_creation_time":1428654714763,
        "Owner_last_access_time":1664012257383,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Question_last_edit_time":1655134670387,
        "Answer_body":"<p>I found the problem. Like I wrote in the EDIT1 of my post, with further observations, the parquet files were missing in the docker container. That was strange because I was copying the entire folder in my Dockerfile.<\/p>\n<p>I then realized that I was hitting this problem <a href=\"https:\/\/github.com\/moby\/buildkit\/issues\/1366\" rel=\"nofollow noreferrer\">mentioned here<\/a>. File paths exceeding 260 characters, silently fail and do not get copied over to the docker container. This was really frustrating because nothing failed during build and then during run, it gave me that cryptic error of &quot;unable to infer schema for parquet&quot;, essentially because the parquet files were not copied over during docker build.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1655191745993,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1655202841060,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72604450",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67456172,
        "Question_title":"Unable to connect to MLFLOW_TRACKING_URI when running MLflow run in Docker container",
        "Question_body":"<p>I have setup a mlflow server locally at http:\/\/localhost:5000<\/p>\n<p>I followed the instructions at <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker<\/a> and tried to run the example docker with<\/p>\n<pre><code>\/mlflow\/examples\/docker$ mlflow run . -P alpha=0.5\n<\/code><\/pre>\n<p>but I encountered the following error.<\/p>\n<pre><code>2021\/05\/09 17:11:20 INFO mlflow.projects.docker: === Building docker image docker-example:7530274 ===\n2021\/05\/09 17:11:20 INFO mlflow.projects.utils: === Created directory \/tmp\/tmp9wpxyzd_ for downloading remote URIs passed to arguments of type 'path' ===\n2021\/05\/09 17:11:20 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v \/home\/mlf\/mlf\/0\/ae69145133bf49efac22b1d390c354f1\/artifacts:\/home\/mlf\/mlf\/0\/ae69145133bf49efac22b1d390c354f1\/artifacts -e MLFLOW_RUN_ID=ae69145133bf49efac22b1d390c354f1 -e MLFLOW_TRACKING_URI=http:\/\/localhost:5000 -e MLFLOW_EXPERIMENT_ID=0 docker-example:7530274 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID 'ae69145133bf49efac22b1d390c354f1' === \n\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/__init__.py:55: DeprecationWarning: MLflow support for Python 2 is deprecated and will be dropped in a future release. At that point, existing Python 2 workflows that use MLflow will continue to work without modification, but Python 2 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3 - see https:\/\/docs.python.org\/3\/howto\/pyporting.html for a migration guide.\n  &quot;for a migration guide.&quot;, DeprecationWarning)\nTraceback (most recent call last):\n  File &quot;train.py&quot;, line 56, in &lt;module&gt;\n    with mlflow.start_run():\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 122, in start_run\n    active_run_obj = MlflowClient().get_run(existing_run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/client.py&quot;, line 96, in get_run\n    return self._tracking_client.get_run(run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 49, in get_run\n    return self.store.get_run(run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 92, in get_run\n    response_proto = self._call_endpoint(GetRun, req_body)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 32, in _call_endpoint\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 133, in call_endpoint\n    host_creds=host_creds, endpoint=endpoint, method=method, params=json_body)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 70, in http_request\n    url=url, headers=headers, verify=verify, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 51, in request_with_ratelimit_retries\n    response = requests.request(**kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/api.py&quot;, line 58, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py&quot;, line 508, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py&quot;, line 618, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/adapters.py&quot;, line 508, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get?run_uuid=ae69145133bf49efac22b1d390c354f1&amp;run_id=ae69145133bf49efac22b1d390c354f1 (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f5cbd80d690&gt;: Failed to establish a new connection: [Errno 111] Connection refused',))\n2021\/05\/09 17:11:22 ERROR mlflow.cli: === Run (ID 'ae69145133bf49efac22b1d390c354f1') failed ===\n<\/code><\/pre>\n<p>Any ideas how to fix this? I tried adding the following in MLproject file but it doesn't help<\/p>\n<pre><code>environment: [[&quot;network&quot;, &quot;host&quot;], [&quot;add-host&quot;, &quot;host.docker.internal:host-gateway&quot;]]\n<\/code><\/pre>\n<p>Thanks for your help! =)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1620552530280,
        "Question_score":0,
        "Question_tags":"docker|mlflow",
        "Question_view_count":1151,
        "Owner_creation_time":1316620102630,
        "Owner_last_access_time":1643692547643,
        "Owner_location":null,
        "Owner_reputation":1308,
        "Owner_up_votes":177,
        "Owner_down_votes":1,
        "Owner_views":151,
        "Question_last_edit_time":1620554070857,
        "Answer_body":"<p>Run MLflow server such was that it will use your machine IP instead of <code>localhost<\/code>.  Then point the <code>mlflow run<\/code> to that IP instead of <code>http:\/\/localhost:5000<\/code>.   The main reason is that <code>localhost<\/code> of Docker process is its own, not your machine.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1620627546970,
        "Answer_score":1.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67456172",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67835498,
        "Question_title":"MLflow - How to point interface path to show the expected result",
        "Question_body":"<p>I just started MLflow today and fail to display the log result on MLflow ui interface.\nWill appreciate a lot if someone can give me some hint..<\/p>\n<p>tried the sample code below<\/p>\n<pre><code>import os\nfrom random import random, randint\nfrom mlflow import log_metric, log_param, log_artifacts\n\nif __name__ == &quot;__main__&quot;:\n    # Log a parameter (key-value pair)\n    log_param(&quot;param1&quot;, randint(0, 100))\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    # Log an artifact (output file)\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>ran the script above for 3 times and it gave me the result in the following structure. 3 folders representing 3 runs separately:<\/p>\n<pre><code>file:\/\/\/home\/devuser\/project\/mlruns\/0\n0 - 0737fec7d4824384b6320070cd688b78\n    355d57e092a242b7aa263451d280b497 \n    ed2614ffe2fd4f2db991d5d7166635f8  \n    meta.yaml\n<\/code><\/pre>\n<p>with folders\/files <code>artifacts, meta.yaml, metrics, params, tags<\/code> in each folder separately.<\/p>\n<p>I ran <code>mlflow ui<\/code> under <code>file:\/\/\/home\/devuser\/project\/mlruns\/<\/code> but nothing was showed on the interface. tried to look this up but no one has come across this problem with this kind of simple code.<\/p>\n<p>Appreciate a lot if someone could kindly let me know how I can change my setting.. Thank you..<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1622801740880,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":379,
        "Owner_creation_time":1445157877637,
        "Owner_last_access_time":1638455223627,
        "Owner_location":null,
        "Owner_reputation":267,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":111,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You need to run <code>mlflow ui<\/code> in the project directory itself, not inside the <code>mlruns<\/code> - if you look into the <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-ui\" rel=\"nofollow noreferrer\">documentation for <code>mlflow ui<\/code> command<\/a>, it says:<\/p>\n<blockquote>\n<p><code>--default-artifact-root &lt;URI&gt;<\/code><\/p>\n<p>Path to local directory to store artifacts, for new experiments. Note that this flag does not impact already-created experiments. <strong>Default: .\/mlruns<\/strong><\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1622968783720,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67835498",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59887618,
        "Question_title":"Is it possible to use MLFlow and H2o.ai sparkling water in a Scala based project?",
        "Question_body":"<p>I'm solving a Scala data science problem in Intellij using maven. I noticed that MLFlow spark (<a href=\"https:\/\/mvnrepository.com\/artifact\/org.mlflow\/mlflow-spark\/1.5.0\" rel=\"nofollow noreferrer\">https:\/\/mvnrepository.com\/artifact\/org.mlflow\/mlflow-spark\/1.5.0<\/a>) is dependent on scala 2.12 while h2o.ai sparkling water is dependent on scala 2.11 (<a href=\"https:\/\/mvnrepository.com\/artifact\/ai.h2o\/sparkling-water-core\" rel=\"nofollow noreferrer\">https:\/\/mvnrepository.com\/artifact\/ai.h2o\/sparkling-water-core<\/a>). Is there any way to use both of these together using Scala? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1579816453420,
        "Question_score":0,
        "Question_tags":"scala|apache-spark|h2o|sparkling-water|mlflow",
        "Question_view_count":217,
        "Owner_creation_time":1579815947657,
        "Owner_last_access_time":1661917140247,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59887618",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68402406,
        "Question_title":"MLflow webserver returns 400 status, \"Incompatible input types for column X. Can not safely convert float64 to <U0.\"",
        "Question_body":"<p>I am implementing an anomaly detection web service using <code>MLflow<\/code> and <code>sklearn.pipeline.Pipeline()<\/code>. The aim of the model is to detect web crawlers using server log and <code>response_length<\/code> column is one of my features. After serving model, for testing the web service I send below request that contains the 20 first columns of the train data.<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ curl  --location --request POST '127.0.0.1:8000\/invocations'\n        --header 'Content-Type: text\/csv' \\\n        --data-binary 'datasets\/test.csv'\n<\/code><\/pre>\n<p>But response of the web server has status code 400 (BAD REQUEST) and this JSON body:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;error_code&quot;: &quot;BAD_REQUEST&quot;,\n    &quot;message&quot;: &quot;Incompatible input types for column response_length. Can not safely convert float64 to &lt;U0.&quot;\n}\n<\/code><\/pre>\n<p>Here is the model compilation MLflow Tracking component log:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>[Pipeline] ......... (step 1 of 3) Processing transform, total=11.8min\n[Pipeline] ............... (step 2 of 3) Processing pca, total=   4.8s\n[Pipeline] ........ (step 3 of 3) Processing rule_based, total=   0.0s\n2021\/07\/16 04:55:12 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n2021\/07\/16 04:55:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: &quot;\/home\/matin\/workspace\/Rahnema College\/venv\/lib\/python3.8\/site-packages\/mlflow\/models\/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https:\/\/www.mlflow.org\/docs\/latest\/models.html#handling-integers-with-missing-values&gt;`_ for more details.&quot;\nLogged data and model in run: 8843336f5c31482c9e246669944b1370\n\n---------- logged params ----------\n{'memory': 'None',\n 'pca': 'PCAEstimator()',\n 'rule_based': 'RuleBasedEstimator()',\n 'steps': &quot;[('transform', &lt;log_transformer.LogTransformer object at &quot;\n          &quot;0x7f05a8b95760&gt;), ('pca', PCAEstimator()), ('rule_based', &quot;\n          'RuleBasedEstimator())]',\n 'transform': '&lt;log_transformer.LogTransformer object at 0x7f05a8b95760&gt;',\n 'verbose': 'True'}\n\n---------- logged metrics ----------\n{}\n\n---------- logged tags ----------\n{'estimator_class': 'sklearn.pipeline.Pipeline', 'estimator_name': 'Pipeline'}\n\n---------- logged artifacts ----------\n['model\/MLmodel',\n 'model\/conda.yaml',\n 'model\/model.pkl',\n 'model\/requirements.txt']\n<\/code><\/pre>\n<p>Could anyone tell me exactly how I can fix this model serve problem?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1626398499507,
        "Question_score":1,
        "Question_tags":"scikit-learn|webserver|mlflow",
        "Question_view_count":787,
        "Owner_creation_time":1553088438367,
        "Owner_last_access_time":1664054397820,
        "Owner_location":"Tehran, Tehran Province, Iran",
        "Owner_reputation":415,
        "Owner_up_votes":300,
        "Owner_down_votes":2,
        "Owner_views":37,
        "Question_last_edit_time":1657456057947,
        "Answer_body":"<p>The problem caused by <code>mlflow.utils.autologging_utils<\/code> WARNING.<\/p>\n<p>When the model is created, data input signature is saved on the <code>MLmodel<\/code> file with some.\nYou should change <code>response_length<\/code> signature input type from <code>string<\/code> to <code>double<\/code> by replacing<\/p>\n<pre><code>{&quot;name&quot;: &quot;response_length&quot;, &quot;type&quot;: &quot;double&quot;}\n<\/code><\/pre>\n<p>instead of<\/p>\n<pre><code>{&quot;name&quot;: &quot;response_length&quot;, &quot;type&quot;: &quot;string&quot;}\n<\/code><\/pre>\n<p>so it doesn't need to be converted. After serving the model with edited <code>MLmodel<\/code> file, the web server worked as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1626398499507,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68402406",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73620580,
        "Question_title":"Hi everyone, I'm trying to authentication and authorize MLFlow my infra is in AWS and my mlflow will run in eks ? can we do it with mlflow plugin",
        "Question_body":"<p>Do we have any way to do this?<\/p>\n<ol>\n<li>I tried to authenticate using AWS ALB that did not work for me.<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1662460519567,
        "Question_score":0,
        "Question_tags":"kubernetes|mlflow",
        "Question_view_count":26,
        "Owner_creation_time":1562213601020,
        "Owner_last_access_time":1663912595940,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73620580",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67968777,
        "Question_title":"How to get run id from run name in MLflow",
        "Question_body":"<p>To download artifacts from a run, you need run id. I get the run id from the UI as shown below.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FJtAe.png\" rel=\"nofollow noreferrer\">Run id from the UI<\/a><\/p>\n<p>But when I set the run name parameter, run id is not visible in the UI. How to find the run Id of a particular run in MLflow ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1623667148760,
        "Question_score":2,
        "Question_tags":"mlflow",
        "Question_view_count":1492,
        "Owner_creation_time":1585919790787,
        "Owner_last_access_time":1641475609990,
        "Owner_location":null,
        "Owner_reputation":29,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67968777",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64645798,
        "Question_title":"How to log a sklearn pipeline with a Keras step using mlflow.pyfunc.log_model()? TypeError: can't pickle _thread.RLock objects",
        "Question_body":"<p>I would like to log into MlFlow a <code>sklearn<\/code> pipeline with a Keras step.<\/p>\n<p>The pipeline has 2 steps: a <code>sklearn<\/code> StandardScale and a Keras TensorFlow model.<\/p>\n<p>I am using mlflow.pyfunc.log_model() as possible solution, but I am having this error:<\/p>\n<pre><code>TypeError: can't pickle _thread.RLock objects\n---&gt;   mlflow.pyfunc.log_model(&quot;test1&quot;, python_model=wrappedModel, signature=signature)\n<\/code><\/pre>\n<p>Here is my code:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nfrom keras import layers, Input\nfrom keras.wrappers.scikit_learn import KerasRegressor\nimport mlflow.pyfunc\nfrom sklearn.pipeline import Pipeline\nfrom mlflow.models.signature import infer_signature\n\n#toy dataframe\ndf1 = pd.DataFrame([[1,2,3,4,5,6], [10,20,30,40,50,60],[100,200,300,400,500,600]] )\n\n#create train test datasets\nX_train, X_test = train_test_split(df1, random_state=42, shuffle=True)\n\n#scale X_train\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_train_s = pd.DataFrame(X_train_s)\n\n#wrap the keras model to use it inside of sklearn pipeline\ndef create_model(optimizer='adam', loss='mean_squared_error', s = X_train.shape[1]):\n  input_layer = keras.Input(shape=(s,))\n  # &quot;encoded&quot; is the encoded representation of the input\n  encoded = layers.Dense(25, activation='relu')(input_layer)\n  encoded = layers.Dense(2, activation='relu')(encoded)\n\n  # &quot;decoded&quot; is the lossy reconstruction of the input\n  decoded = layers.Dense(2, activation='relu')(encoded)\n  decoded = layers.Dense(25, activation='relu')(encoded)\n  decoded = layers.Dense(s, activation='linear')(decoded)\n  \n  model = keras.Model(input_layer, decoded)\n  model.compile(optimizer, loss)\n  return model\n\n# wrap the model\nmodel = KerasRegressor(build_fn=create_model, verbose=1)\n\n# create the pipeline\npipe = Pipeline(steps=[\n    ('scale', StandardScaler()),\n    ('model',model)\n])\n\n#function to wrap the pipeline to be logged by mlflow\nclass SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n  def __init__(self, model):\n    self.model = model\n    \n  def predict(self, context, model_input):\n    return self.model.predict(model_input)[:,1]\n  \n  \nmlflow.end_run()\nwith mlflow.start_run(run_name='test1'):\n\n  #train the pipeline\n  pipe.fit(X_train, X_train_s, model__epochs=2)\n  \n  #wrap the model for mlflow log\n  wrappedModel = SklearnModelWrapper(pipe)\n\n  # Log the model with a signature that defines the schema of the model's inputs and outputs. \n  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))\n  mlflow.pyfunc.log_model(&quot;test1&quot;, python_model=wrappedModel, signature=signature)\n  \n<\/code><\/pre>\n<p>From what I googled, it seems like this type of error is related to concurrency of threads. It could be then related to the TensorFlow, since it distributes the code during the model training phase.<\/p>\n<p>However, the offending code line is after the training phase. If I remove this line, the rest of the code works, which makes me think that it happens after the concurrency phase of the model training. I have no idea why I am getting this error in this context.\nI am a beginner? Can someone please help me?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1604320799543,
        "Question_score":4,
        "Question_tags":"python|keras|scikit-learn|mlflow",
        "Question_view_count":787,
        "Owner_creation_time":1339148818537,
        "Owner_last_access_time":1616602620223,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1604334305113,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64645798",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61615818,
        "Question_title":"Setting-up MLflow on Google Colab",
        "Question_body":"<p>I frequently use Google Colab to train TF\/PyTorch models as Colab provides me with GPU\/TPU runtime. Besides, I like working with MLflow to store and compare trained models, tracking progress, sharing, etc.  What are the available solutions to use MLflow with Google Colab?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_time":1588689839033,
        "Question_score":7,
        "Question_tags":"google-colaboratory|mlflow|mlops",
        "Question_view_count":6053,
        "Owner_creation_time":1552661046210,
        "Owner_last_access_time":1663946284313,
        "Owner_location":"Paris, France\/ Ternopil, Ukraine",
        "Owner_reputation":1131,
        "Owner_up_votes":55,
        "Owner_down_votes":0,
        "Owner_views":49,
        "Question_last_edit_time":1621937850167,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61615818",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63973530,
        "Question_title":"Convert an instance of xgboost.Booster into a model that implements the scikit-learn API",
        "Question_body":"<p>I am trying to use <code>mlflow<\/code> to save a model and then load it later to make predictions.<\/p>\n<p>I'm using a <code>xgboost.XGBRegressor<\/code> model and its sklearn functions <code>.predict()<\/code> and <code>.predict_proba()<\/code> to make predictions but it turns out that <code>mlflow<\/code> doesn't support models that implements the sklearn API, so when loading the model later from mlflow, mlflow returns an instance of <code>xgboost.Booster<\/code>, and it doesn't implements the <code>.predict()<\/code> or <code>.predict_proba()<\/code> functions.<\/p>\n<p>Is there a way to convert a <code>xgboost.Booster<\/code> back into a <code>xgboost.sklearn.XGBRegressor<\/code> object that implements the sklearn API functions?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1600550858547,
        "Question_score":3,
        "Question_tags":"scikit-learn|save|xgboost|mlflow|xgbclassifier",
        "Question_view_count":1317,
        "Owner_creation_time":1592264086427,
        "Owner_last_access_time":1663962090790,
        "Owner_location":null,
        "Owner_reputation":35,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Have you tried wrapping up your model in custom class, logging and loading it using <code>mlflow.pyfunc.PythonModel<\/code>?\nI put up a simple example and upon loading back the model it correctly shows <code>&lt;class 'xgboost.sklearn.XGBRegressor'&gt;<\/code> as a type.<\/p>\n<p>Example:<\/p>\n<pre><code>import xgboost as xgb\nxg_reg = xgb.XGBRegressor(...)\n\nclass CustomModel(mlflow.pyfunc.PythonModel):\n    def __init__(self, xgbRegressor):\n        self.xgbRegressor = xgbRegressor\n\n    def predict(self, context, input_data):\n        print(type(self.xgbRegressor))\n        \n        return self.xgbRegressor.predict(input_data)\n\n# Log model to local directory\nwith mlflow.start_run():\n     custom_model = CustomModel(xg_reg)\n     mlflow.pyfunc.log_model(&quot;custome_model&quot;, python_model=custom_model)\n\n\n# Load model back\nfrom mlflow.pyfunc import load_model\nmodel = load_model(&quot;\/mlruns\/0\/..\/artifacts\/custome_model&quot;)\nmodel.predict(X_test)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>&lt;class 'xgboost.sklearn.XGBRegressor'&gt;\n[ 9.107417 ]\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1600607182583,
        "Answer_score":4.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63973530",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65316586,
        "Question_title":"get the run id for an mlflow experiment with the name?",
        "Question_body":"<p>I currently created an experiment in mlflow and created multiple runs in the experiment.<\/p>\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport mlflow\n\nexperiment_name=&quot;experiment-1&quot;\nmlflow.set_experiment(experiment_name)\n\nno_of_trees=[100,200,300]\ndepths=[2,3,4]\nfor trees in no_of_trees:\n    for depth in depths:\n        with mlflow.start_run() as run:\n            model=RandomForestRegressor(n_estimators=trees, criterion='mse',max_depth=depth)\n            model.fit(x_train, y_train)\n            predictions=model.predict(x_cv)\n            mlflow.log_metric('rmse',mean_squared_error(y_cv, predictions))\n<\/code><\/pre>\n<p>after creating the runs, I wanted to get the best run_id for this experiment. for now, I can get the best run by looking at the UI of mlflow but how can we do right the program?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1608086727487,
        "Question_score":6,
        "Question_tags":"python|mlflow",
        "Question_view_count":6374,
        "Owner_creation_time":1479190327737,
        "Owner_last_access_time":1660584310400,
        "Owner_location":"R G U K T , basar, Andhra Pradesh, India",
        "Owner_reputation":2470,
        "Owner_up_votes":265,
        "Owner_down_votes":22,
        "Owner_views":251,
        "Question_last_edit_time":null,
        "Answer_body":"<p>we can get the experiment id from the experiment name and we can use python API to get the best runs.<\/p>\n<pre><code>experiment_name = &quot;experiment-1&quot;\ncurrent_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\nexperiment_id=current_experiment['experiment_id']\n<\/code><\/pre>\n<p>By using the experiment id, we can get all the runs and we can sort them based on metrics like below. In the below code, rmse is my metric name (so it may be different for you based on metric name)<\/p>\n<pre><code>df = mlflow.search_runs([experiment_id], order_by=[&quot;metrics.rmse DESC&quot;])\nbest_run_id = df.loc[0,'run_id']\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1608086727487,
        "Answer_score":15.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65316586",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60695933,
        "Question_title":"MLflow: Why can't backend-store-uri be an s3 location?",
        "Question_body":"<p>I'm new to mlflow and I can't figure out why the <code>artifact store<\/code> can't be the same as the <code>backend store<\/code>? <\/p>\n\n<p>The only reason I can think of is to be able to query the experiments with SQL syntax... but since we can interact with the runs using <code>mlflow ui<\/code> I just don't understand why all artifacts and parameters can't go to a same location (which is what happens when using local storage).<\/p>\n\n<p>Can anyone shed some light on this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1584294693613,
        "Question_score":4,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":768,
        "Owner_creation_time":1528574640850,
        "Owner_last_access_time":1663976741153,
        "Owner_location":null,
        "Owner_reputation":133,
        "Owner_up_votes":10,
        "Owner_down_votes":2,
        "Owner_views":76,
        "Question_last_edit_time":null,
        "Answer_body":"<p>MLflow's Artifacts are typically ML models, i.e. relatively large binary files. On the other hand, run data are typically a couple of floats.<\/p>\n<p>In the end it is not a question of what is possible or not (many things are possible if you put enough effort into it), but rather to follow good practices:<\/p>\n<ul>\n<li>storing large binary artifacts in an SQL database is possible but is bound the degrade the performance of the database sooner or later, and this in turn will degrade your user experience.<\/li>\n<li>storing a couple of floats from a SQL database for quick retrieval for display in a front-end or via command line is a robust industry-proven classic<\/li>\n<\/ul>\n<p>It remains true that the documentation of MLflow on the architecture design rationale could be improved (as of 2020)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1611045077983,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60695933",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":55943088,
        "Question_title":"Databricks notebook integrated mlflow artifact location and retention",
        "Question_body":"<ol>\n<li><p>Currently by default in notebook run, it will create an experiment ID, but the Artifact Location would point to something under dbfs:\/databricks\/mlflow\/{experiment id}. If there is a way we may change this in default experiment creation? We like to manage the storage outside databricks.<\/p><\/li>\n<li><p>How long is default TTL for experiment runs and metrics? Is it configurable and how?<\/p><\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1556747098277,
        "Question_score":1,
        "Question_tags":"azure-databricks|mlflow",
        "Question_view_count":587,
        "Owner_creation_time":1458276216763,
        "Owner_last_access_time":1575678794047,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55943088",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72855204,
        "Question_title":"MLflow is taking longer than expected time to finish logging metrics and parameters",
        "Question_body":"<p>I'm running a code where I have to perform multiple iterations for a set of products to select the best performing model. While running multiple iterations for a single product, I need to log details of every single run using mlflow(using mlflow with pandas-udf). While logging for individual iterations are taking around 2 seconds but the parent run under which I'm tracking every iteration details is taking 1.5 hours to finish. Here is the code -<\/p>\n<pre><code>@F.pandas_udf( model_results_schema, F.PandasUDFType.GROUPED_MAP )\ndef get_gam_pe_results( model_input ):\n    ...\n    ...\n    for j, gam_terms in enumerate(term_list[-1]):\n        results_iteration_output_1, results_iteration_output, results_iteration_all = run_gam_model(gam_terms)\n        \n        results_iteration_version = results_iteration_version.append(results_iteration_output)\n        unique_id = uuid.uuid1()\n        metric_list = [&quot;AIC&quot;, &quot;AICc&quot;, &quot;GCV&quot;, &quot;adjusted_R2&quot;, &quot;deviance&quot;, &quot;edof&quot;, &quot;elasticity_in_k&quot;, &quot;loglikelihood&quot;,\n                      &quot;scale&quot;]\n        param_list = [&quot;features&quot;]\n        start_time = str(datetime.now())\n        with mlflow.start_run(run_id=parent_run_id, experiment_id=experiment_id):\n            with mlflow.start_run(run_name=str(model_input['prod_id'].iloc[1]) + &quot;-&quot; + unique_id.hex,\n                                  experiment_id=experiment_id, nested=True):\n                for item in results_iteration_output.columns.values.tolist():\n                        if item in metric_list:\n                            mlflow.log_metric(item, results_iteration_output[item].iloc[0])\n                        if item in param_list:\n                            mlflow.log_param(item, results_iteration_output[item].iloc[0])\n                            \n                end_time = str(datetime.now())\n                mlflow.log_param(&quot;start_time&quot;, start_time)\n                mlflow.log_param(&quot;end_time&quot;, end_time)\n<\/code><\/pre>\n<p>Outside pandas-udf -<\/p>\n<pre><code>current_time = str(datetime.today().replace(microsecond=0))\nrun_id = None\nwith mlflow.start_run(run_name=&quot;MLflow_pandas_udf_testing-&quot;+current_time, experiment_id=experiment_id) as run:\n    run_id = run.info.run_uuid\n    gam_model_output = (Product_data\n                        .withColumn(&quot;run_id&quot;, F.lit(run_id))\n                        .groupby(['prod_id'])\n                        .apply(get_gam_pe_results)\n                       )\n<\/code><\/pre>\n<p>Note - Running this entire code in Databricks(cluster has 8 cores and 28gb ram).<\/p>\n<p>Any idea why this parent run is taking so long to finish while it's only 2 seconds to finish each iterations?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jzqkx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jzqkx.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1656930055540,
        "Question_score":0,
        "Question_tags":"python-3.x|machine-learning|azure-databricks|mlflow|pandas-udf",
        "Question_view_count":76,
        "Owner_creation_time":1452602206603,
        "Owner_last_access_time":1663948894330,
        "Owner_location":"Kolkata, West Bengal, India",
        "Owner_reputation":55,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":1663949207680,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72855204",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73320708,
        "Question_title":"Set run description programmatically in mlflow",
        "Question_body":"<p>Similar to <a href=\"https:\/\/stackoverflow.com\/questions\/57199472\/is-it-possible-to-set-change-mlflow-run-name-after-run-initial-creation#:%7E:text=It%20is%20possible%20to%20edit,you%27d%20like%20to%20edit.&amp;text=There%27s%20currently%20no%20stable%20public,the%20tag%20with%20key%20mlflow.\">this question<\/a>, I'd like to edit\/set the description of a run via code, instead of editing it via UI.<\/p>\n<p>To clarify, I don't want to set the description of my entire experiment, only of a single run.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" alt=\"Image showing what I want to edit\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660221143727,
        "Question_score":1,
        "Question_tags":"python|artificial-intelligence|mlflow",
        "Question_view_count":89,
        "Owner_creation_time":1527525798183,
        "Owner_last_access_time":1664059587093,
        "Owner_location":"Sarajevo, Bosnia and Herzegovina",
        "Owner_reputation":736,
        "Owner_up_votes":829,
        "Owner_down_votes":8,
        "Owner_views":57,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There are two ways to set the description.<\/p>\n<h3>1. <code>description<\/code> parameter<\/h3>\n<p>You can set a description using a markdown string for your run in <code>mlflow.start_run()<\/code> using <code>description<\/code> parameter. Here is an example.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    with mlflow.start_run(description=run_description) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>2. <code>mlflow.note.content<\/code> tag<\/h3>\n<p>You can set\/edit run names by setting the tag with the key <code>mlflow.note.content<\/code>, which is what the UI (currently) does under the hood.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    tags = {\n        'mlflow.note.content': run_description\n    }\n\n    with mlflow.start_run(tags=tags) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>Result<\/h3>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" alt=\"output of the given example\" \/><\/a><\/p>\n<hr \/>\n<p>If you set <code>description<\/code> parameter and <code>mlflow.note.content<\/code> tag in <code>mlflow.start_run()<\/code>, you'll get this error.<\/p>\n<pre><code>Description is already set via the tag mlflow.note.content in tags.\nRemove the key mlflow.note.content from the tags or omit the description.\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1660231264753,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1660307815687,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73320708",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64771247,
        "Question_title":"Logging a PySpark dataframe into a MLFlow Artifact",
        "Question_body":"<p>I am currently writing an MLFlow artifact to the dbfs but I am using pandas using the code below...<\/p>\n<pre><code>temp = tempfile.NamedTemporaryFile(prefix=&quot;*****&quot;, suffix=&quot;.csv&quot;)\ntemp_name = temp.name\ntry:\n  df.to_csv(temp_name, index=False)\n  mlflow.log_artifact(temp_name, &quot;******&quot;)\nfinally:\n  temp.close() # Delete the temp file\n<\/code><\/pre>\n<p>How would I write this if 'df' was a spark dataframe?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_time":1605020000127,
        "Question_score":1,
        "Question_tags":"python|pyspark|mlflow",
        "Question_view_count":810,
        "Owner_creation_time":1593519939237,
        "Owner_last_access_time":1660311748437,
        "Owner_location":null,
        "Owner_reputation":129,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64771247",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68233056,
        "Question_title":"Logging SKLearn Models in the same folder while running multiple models in Pandas UDF",
        "Question_body":"<p>I am trying to run multiple XGBoost models and save the resulting models in the form of experiments. However, when I call the UDF function on my pyspark dataframe the models are being saved in a multiple folders.<\/p>\n<p>It appears that they are being randomly split in smaller batches and stored. Is there a way to ensure that all models are saved in the same run\/ folder such that I can easily load them back later.<\/p>\n<pre><code>def classification_xgb(df):\n  #modeling code\n  mlflow.sklearn.log_model(xgb, model_name)\n\n\ndat_m.groupBy(&quot;Product&quot;).applyInPandas(classification_xgb, schema).show(10000,False)\n<\/code><\/pre>\n<p>I have over 100 products for which I need to create models and save in the same run instance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1625283818387,
        "Question_score":1,
        "Question_tags":"pandas|pyspark|azure-databricks|sklearn-pandas|mlflow",
        "Question_view_count":79,
        "Owner_creation_time":1625282679850,
        "Owner_last_access_time":1641308459047,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1625285948293,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68233056",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58554979,
        "Question_title":"Cannot Start mlflow ui on google cloud platform virtual machine instance",
        "Question_body":"<p>after running mlflow ui on command line\nand  clicking <a href=\"http:\/\/127.0.0.1:5000\/\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000\/<\/a>\ni get site cannot be reached\n127.0.0.1 refused to connect.<\/p>\n<p>I have already updated firewall rules on VPC network in GCP and on my local machine and activated the ports<\/p>\n<blockquote>\n<p>This site can\u2019t be reached127.0.0.1 refused to connect.<\/p>\n<p>Try:<\/p>\n<ul>\n<li>Checking the connection<\/li>\n<li>Checking the proxy and the firewall<\/li>\n<\/ul>\n<p>ERR_CONNECTION_REFUSED<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1571992526673,
        "Question_score":0,
        "Question_tags":"google-cloud-platform|mlflow",
        "Question_view_count":360,
        "Owner_creation_time":1516552952317,
        "Owner_last_access_time":1616233012253,
        "Owner_location":"Haryana, India",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1592644375060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58554979",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66855807,
        "Question_title":"How to add more metrics to a finished MLflow run?",
        "Question_body":"<p>Once an MLflow run is finished, external scripts can access its parameters and metrics using python <code>mlflow<\/code> client and <code>mlflow.get_run(run_id)<\/code> method, but the <code>Run<\/code> object returned by <code>get_run<\/code> seems to be read-only.<\/p>\n<p>Specifically, <code>.log_param<\/code> <code>.log_metric<\/code>, or <code>.log_artifact<\/code> cannot be used on the object returned by <code>get_run<\/code>, raising errors like these:<\/p>\n<pre><code>AttributeError: 'Run' object has no attribute 'log_param'\n<\/code><\/pre>\n<p>If we attempt to run any of the <code>.log_*<\/code> methods on <code>mlflow<\/code>, it would log them into to a new run  with auto-generated run ID in the <code>Default<\/code> experiment.<\/p>\n<p>Example:<\/p>\n<pre><code>final_model_mlflow_run = mlflow.get_run(final_model_mlflow_run_id)\n\nwith mlflow.ActiveRun(run=final_model_mlflow_run) as myrun:    \n    \n    # this read operation uses correct run\n    run_id = myrun.info.run_id\n    print(run_id)\n    \n    # this write operation writes to a new run \n    # (with auto-generated random run ID) \n    # in the &quot;Default&quot; experiment (with exp. ID of 0)\n    mlflow.log_param(&quot;test3&quot;, &quot;This is a test&quot;)\n   \n<\/code><\/pre>\n<p>Note that the above problem exists regardless of the <code>Run<\/code> status (<code>.info.status<\/code> can be both &quot;FINISHED&quot; or &quot;RUNNING&quot;, without making any difference).<\/p>\n<p>I wonder if this read-only behavior is by design (given that immutable modeling runs improve experiments reproducibility)? I can appreciate that, but it also goes against code modularity if everything has to be done within a single monolith like the <code>with mlflow.start_run()<\/code> context...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1617027126043,
        "Question_score":3,
        "Question_tags":"python|databricks|mlflow",
        "Question_view_count":1269,
        "Owner_creation_time":1529411528930,
        "Owner_last_access_time":1664050484457,
        "Owner_location":"EU",
        "Owner_reputation":3260,
        "Owner_up_votes":1100,
        "Owner_down_votes":4,
        "Owner_views":466,
        "Question_last_edit_time":1617040232537,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66855807",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69796285,
        "Question_title":"Artifacts generations for pmml models in mlflow",
        "Question_body":"<p>I generated a sample pmml file which contains lightgbm model, when i am trying to log it and generate artifacts in mlflow i am getting error: 'Model' object has no attribute 'save_model'<\/p>\n<p>The code i used for logging:<\/p>\n<pre><code>import mlflow\n\nfrom pypmml import Model\n\nlr = Model.fromFile('iris.pmml') \n\nmlflow.lightgbm.log_model(lr,&quot;model&quot;)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1635766055407,
        "Question_score":0,
        "Question_tags":"mlflow|pmml",
        "Question_view_count":95,
        "Owner_creation_time":1635765403513,
        "Owner_last_access_time":1642406857823,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1635843903450,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69796285",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71121324,
        "Question_title":"Mlflow registed model version increment in python",
        "Question_body":"<p>I want to keep versions of the model in mlflow but not as version[1,2,3,...]\ninstead, i want to increment model's versions like 1.1 1.2 and when I feel that there is some major change I want increment to 2.0<\/p>\n<p>please let me know how this can be done.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1644901430677,
        "Question_score":0,
        "Question_tags":"python|model|version-control|mlflow",
        "Question_view_count":24,
        "Owner_creation_time":1516006161920,
        "Owner_last_access_time":1645106959933,
        "Owner_location":"Arunachal Pradesh, India",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71121324",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62711259,
        "Question_title":"Customize metric visualization in MLFlow UI when using mlflow.tensorflow.autolog()",
        "Question_body":"<p>I'm trying to integrate MLFlow to my project. Because I'm using <code>tf.keras.fit_generator()<\/code> for my training so I take advantage of <code>mlflow.tensorflow.autolog()<\/code>(<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a> here) to enable automatic logging of metrics and parameters:<\/p>\n<pre><code>    model = Unet()\n    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n\n    metrics = [IOUScore(threshold=0.5), FScore(threshold=0.5)]\n    model.compile(optimizer, customized_loss, metrics)\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(&quot;model.h5&quot;, save_weights_only=True, save_best_only=True, mode='min'),\n        tf.keras.callbacks.TensorBoard(log_dir='.\/logs', profile_batch=0, update_freq='batch'),\n    ]\n\n\n    train_dataset = Dataset(src_dir=SOURCE_DIR)\n\n    train_data_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n\n   \n    with mlflow.start_run():\n        mlflow.tensorflow.autolog()\n        mlflow.log_param(&quot;batch_size&quot;, BATCH_SIZE)\n\n        model.fit_generator(\n            train_data_loader,\n            steps_per_epoch=len(train_data_loader),\n            epochs=EPOCHS,\n            callbacks=callbacks   \n            )\n<\/code><\/pre>\n<p>I expected something like this (just a demonstration taken from the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#visualizing-metrics\" rel=\"nofollow noreferrer\">docs<\/a>):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" alt=\"Visualization on the docs\" \/><\/a><\/p>\n<p>However, after the training finished, this is what I got:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" alt=\"f1_score visualization\" \/><\/a><\/p>\n<p>How can I configure so that the metric plot will update and display its value at each epoch instead of just showing the latest value?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1593764146630,
        "Question_score":2,
        "Question_tags":"tf.keras|mlflow",
        "Question_view_count":1035,
        "Owner_creation_time":1467943515393,
        "Owner_last_access_time":1664083114540,
        "Owner_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Owner_reputation":173,
        "Owner_up_votes":97,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Question_last_edit_time":1594008626393,
        "Answer_body":"<p>After searching around, I found <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2390\" rel=\"nofollow noreferrer\">this issue<\/a> related to my problem above. Actually, all my metrics just logged once each training (instead of each epoch as my intuitive thought). The reason is I didn't specify the <code>every_n_iter<\/code> parameter in <code>mlflow.tensorflow.autolog()<\/code>, which indicates how many 'iterations' must pass before MLflow logs metric executed (see the <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a>). So, changing my code to:<\/p>\n<p><code>mlflow.tensorflow.autolog(every_n_iter=1)<\/code><\/p>\n<p>fixed the problem.<\/p>\n<p>P\/s: Remember that in TF 2.x, an 'iteration' is an epoch (in TF 1.x it's a batch).<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1594008525280,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62711259",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":51064366,
        "Question_title":"Can't run MLflow web-based user interface",
        "Question_body":"<p>I've installed <a href=\"https:\/\/mlflow.org\/\" rel=\"nofollow noreferrer\">MLflow<\/a> on Ubuntu Server 18.04 LTS, in a virtual environment (Python 3), using its <a href=\"https:\/\/mlflow.org\/docs\/latest\/quickstart.html\" rel=\"nofollow noreferrer\">Quickstart documentation<\/a>:<\/p>\n\n<pre><code>$ python3 -m venv mlflow\n$ source \/home\/emre\/mlflow\/bin\/activate\n$ pip install mlflow\n<\/code><\/pre>\n\n<p>that gave the following output during install:<\/p>\n\n<pre><code>Collecting mlflow\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e8\/b3\/cf358e182be34a62fcd6843e5df793f278bd9d24f78f565509cb927c6a22\/mlflow-0.1.0.tar.gz (4.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 323kB\/s\nCollecting Flask (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/e7\/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b\/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 9.4MB\/s\nCollecting awscli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ba\/32\/d6d254f6ccc2ed21f02d81f38709ff06feca9cbdb2e68ea90635fa483a73\/awscli-1.15.46-py2.py3-none-any.whl (1.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3MB 1.0MB\/s\nCollecting boto3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/24\/e0\/a98898b94d8093bbd8fd4576fb2e89620adac1e24a2bfc28d11c4ce29a5b\/boto3-1.7.46-py2.py3-none-any.whl (128kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.8MB\/s\nCollecting click&gt;=6.7 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/34\/c1\/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77\/click-6.7-py2.py3-none-any.whl (71kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 9.3MB\/s\nCollecting databricks-cli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/58\/78\/4bda6f29a091ab7b0ad29efdba2491e5d0b56bd09d608857e6f0b799be48\/databricks-cli-0.7.2.tar.gz\nCollecting gitpython (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ac\/c9\/96d7c86c623cb065976e58c0f4898170507724d6b4be872891d763d686f4\/GitPython-2.1.10-py2.py3-none-any.whl (449kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 2.9MB\/s\nCollecting numpy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/68\/1e\/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2\/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2MB 110kB\/s\nCollecting pandas (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/eb\/6ab533ea8e35e7dd159af6922ac1123d4565d89f3926ad9a6aa46530978f\/pandas-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11.8MB 116kB\/s\nCollecting protobuf (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/fc\/f0\/db040681187496d10ac50ad167a8fd5f953d115b16a7085e19193a6abfd2\/protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7.1MB 177kB\/s\nCollecting pygal (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/5f\/b7\/201c9254ac0d2b8ffa3bb2d528d23a4130876d9ba90bc28e99633f323f17\/pygal-2.4.0-py2.py3-none-any.whl (127kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 9.7MB\/s\nCollecting python-dateutil (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/cf\/f5\/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825\/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 215kB 6.0MB\/s\nCollecting pyyaml (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/10\/7d\/6efe0bd69580fecd40adf47ebaf8d807238308ccb851f0549881fa7605aa\/PyYAML-4.1.tar.gz (153kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 7.8MB\/s\nCollecting querystring_parser (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/64\/3086a9a991ff3aca7b769f5b0b51ff8445a06337ae2c58f215bcee48f527\/querystring_parser-1.2.3.tar.gz\nCollecting requests&gt;=2.17.3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/65\/47\/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda\/requests-2.19.1-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 8.2MB\/s\nCollecting scikit-learn (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/3d\/2d\/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9\/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.4MB 108kB\/s\nCollecting scipy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a8\/0b\/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730\/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 31.2MB 42kB\/s\nCollecting six&gt;=1.10.0 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/67\/4b\/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a\/six-1.11.0-py2.py3-none-any.whl\nCollecting uuid (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ce\/63\/f42f5aa951ebf2c8dac81f77a8edcc1c218640a2a35a03b9ff2d4aa64c3d\/uuid-1.30.tar.gz\nCollecting zipstream (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/1a\/a4\/58f0709cef999db1539960aa2ae77100dc800ebb8abb7afc97a1398dfb2f\/zipstream-1.1.4.tar.gz\nCollecting itsdangerous&gt;=0.24 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/b4\/a60bcdba945c00f6d608d8975131ab3f25b22f2bcfe1dab221165194b2d4\/itsdangerous-0.24.tar.gz (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.4MB\/s\nCollecting Werkzeug&gt;=0.14 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/20\/c4\/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243\/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 4.0MB\/s\nCollecting Jinja2&gt;=2.10 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/ff\/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731\/Jinja2-2.10-py2.py3-none-any.whl (126kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.2MB\/s\nCollecting rsa&lt;=3.5.0,&gt;=3.1.2 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e1\/ae\/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e\/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.5MB\/s\nCollecting botocore==1.10.46 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b4\/04\/ddaad5574f70a539d106e8d53b4685e3de4387de7a16884a95459f8c7691\/botocore-1.10.46-py2.py3-none-any.whl (4.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4MB 314kB\/s\nCollecting s3transfer&lt;0.2.0,&gt;=0.1.12 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/d7\/14\/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d\/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.6MB\/s\nCollecting colorama&lt;=0.3.9,&gt;=0.2.5 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/db\/c8\/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf\/colorama-0.3.9-py2.py3-none-any.whl\nCollecting docutils&gt;=0.10 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/36\/fa\/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d\/docutils-0.14-py3-none-any.whl (543kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 552kB 2.5MB\/s\nCollecting jmespath&lt;1.0.0,&gt;=0.7.1 (from boto3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b7\/31\/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365\/jmespath-0.9.3-py2.py3-none-any.whl\nCollecting configparser&gt;=0.3.5 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/69\/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c\/configparser-3.5.0.tar.gz\nCollecting tabulate&gt;=0.7.7 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/12\/c2\/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc\/tabulate-0.8.2.tar.gz (45kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 7.9MB\/s\nCollecting gitdb2&gt;=2.0.0 (from gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e0\/95\/c772c13b7c5740ec1a0924250e6defbf5dfdaee76a50d1c47f9c51f1cabb\/gitdb2-2.0.3-py2.py3-none-any.whl (63kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 11.2MB\/s\nCollecting pytz&gt;=2011k (from pandas-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/83\/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2\/pytz-2018.4-py2.py3-none-any.whl (510kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 512kB 421kB\/s\nRequirement already satisfied: setuptools in .\/mlflow\/lib\/python3.6\/site-packages (from protobuf-&gt;mlflow)\nCollecting chardet&lt;3.1.0,&gt;=3.0.2 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bc\/a9\/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.7MB\/s\nCollecting idna&lt;2.8,&gt;=2.5 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4b\/2a\/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165\/idna-2.7-py2.py3-none-any.whl (58kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.3MB\/s\nCollecting urllib3&lt;1.24,&gt;=1.21.1 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bd\/c9\/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb\/urllib3-1.23-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.3MB\/s\nCollecting certifi&gt;=2017.4.17 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/e6\/92ad559b7192d846975fc916b65f667c7b8c3a32bea7372340bfe9a15fa5\/certifi-2018.4.16-py2.py3-none-any.whl (150kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 8.0MB\/s\nCollecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.10-&gt;Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4d\/de\/32d741db316d8fdb7680822dd37001ef7a448255de9699ab4bfcbdf4172b\/MarkupSafe-1.0.tar.gz\nCollecting pyasn1&gt;=0.1.3 (from rsa&lt;=3.5.0,&gt;=3.1.2-&gt;awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a0\/70\/2c27740f08e477499ce19eefe05dbcae6f19fdc49e9e82ce4768be0643b9\/pyasn1-0.4.3-py2.py3-none-any.whl (72kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 10.9MB\/s\nCollecting smmap2&gt;=2.0.0 (from gitdb2&gt;=2.0.0-&gt;gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e3\/59\/4e22f692e65f5f9271252a8e63f04ce4ad561d4e06192478ee48dfac9611\/smmap2-2.0.3-py2.py3-none-any.whl\nBuilding wheels for collected packages: mlflow, databricks-cli, pyyaml, querystring-parser, uuid, zipstream, itsdangerous, configparser, tabulate, MarkupSafe\n  Running setup.py bdist_wheel for mlflow ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/mlflow\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp10fdrz2ypip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for mlflow\n  Running setup.py clean for mlflow\n  Running setup.py bdist_wheel for databricks-cli ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/databricks-cli\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpy_2acqi3pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for databricks-cli\n  Running setup.py clean for databricks-cli\n  Running setup.py bdist_wheel for pyyaml ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/pyyaml\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp4bs2fwrtpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for pyyaml\n  Running setup.py clean for pyyaml\n  Running setup.py bdist_wheel for querystring-parser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/querystring-parser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp_cnm9w_tpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for querystring-parser\n  Running setup.py clean for querystring-parser\n  Running setup.py bdist_wheel for uuid ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/uuid\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpenr2igaxpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for uuid\n  Running setup.py clean for uuid\n  Running setup.py bdist_wheel for zipstream ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/zipstream\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpnzsjh5e2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for zipstream\n  Running setup.py clean for zipstream\n  Running setup.py bdist_wheel for itsdangerous ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/itsdangerous\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp7imi3zv2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for itsdangerous\n  Running setup.py clean for itsdangerous\n  Running setup.py bdist_wheel for configparser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/configparser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpyk9qtmi1pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for configparser\n  Running setup.py clean for configparser\n  Running setup.py bdist_wheel for tabulate ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/tabulate\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpjim2qr00pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for tabulate\n  Running setup.py clean for tabulate\n  Running setup.py bdist_wheel for MarkupSafe ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/MarkupSafe\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpsdpdd8ulpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for MarkupSafe\n  Running setup.py clean for MarkupSafe\nFailed to build mlflow databricks-cli pyyaml querystring-parser uuid zipstream itsdangerous configparser tabulate MarkupSafe\nInstalling collected packages: click, itsdangerous, Werkzeug, MarkupSafe, Jinja2, Flask, pyasn1, rsa, jmespath, six, python-dateutil, docutils, botocore, s3transfer, colorama, pyyaml, awscli, boto3, configparser, chardet, idna, urllib3, certifi, requests, tabulate, databricks-cli, smmap2, gitdb2, gitpython, numpy, pytz, pandas, protobuf, pygal, querystring-parser, scikit-learn, scipy, uuid, zipstream, mlflow\n  Running setup.py install for itsdangerous ... done\n  Running setup.py install for MarkupSafe ... done\n  Running setup.py install for pyyaml ... done\n  Running setup.py install for configparser ... done\n  Running setup.py install for tabulate ... done\n  Running setup.py install for databricks-cli ... done\n  Running setup.py install for querystring-parser ... done\n  Running setup.py install for uuid ... done\n  Running setup.py install for zipstream ... done\n  Running setup.py install for mlflow ... done\nSuccessfully installed Flask-1.0.2 Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 awscli-1.15.46 boto3-1.7.46 botocore-1.10.46 certifi-2018.4.16 chardet-3.0.4 click-6.7 colorama-0.3.9 configparser-3.5.0 databricks-cli-0.7.2 docutils-0.14 gitdb2-2.0.3 gitpython-2.1.10 idna-2.7 itsdangerous-0.24 jmespath-0.9.3 mlflow-0.1.0 numpy-1.14.5 pandas-0.23.1 protobuf-3.6.0 pyasn1-0.4.3 pygal-2.4.0 python-dateutil-2.7.3 pytz-2018.4 pyyaml-4.1 querystring-parser-1.2.3 requests-2.19.1 rsa-3.4.2 s3transfer-0.1.13 scikit-learn-0.19.1 scipy-1.1.0 six-1.11.0 smmap2-2.0.3 tabulate-0.8.2 urllib3-1.23 uuid-1.30 zipstream-1.1.4\n<\/code><\/pre>\n\n<p>After that I checked the following didn't give any errors:<\/p>\n\n<pre><code>import os\nfrom mlflow import log_metric, log_param, log_artifact\n<\/code><\/pre>\n\n<p>But when I try to run the web-based user interface, I get the following errors:<\/p>\n\n<pre><code>$ mlflow ui\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 574, in _build_master\n    ws.require(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 892, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/bin\/mlflow\", line 6, in &lt;module&gt;\n    from pkg_resources import load_entry_point\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3088, in &lt;module&gt;\n    @_call_aside\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3072, in _call_aside\n    f(*args, **kwargs)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3101, in _initialize_master_working_set\n    working_set = WorkingSet._build_master()\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 576, in _build_master\n    return cls._build_from_requirements(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 589, in _build_from_requirements\n    dists = ws.resolve(reqs, Environment())\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n<\/code><\/pre>\n\n<p>Any ideas how I can fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1530106954863,
        "Question_score":0,
        "Question_tags":"python|python-3.x|pip|mlflow",
        "Question_view_count":791,
        "Owner_creation_time":1261400320737,
        "Owner_last_access_time":1663928633650,
        "Owner_location":"Antwerp, Belgium",
        "Owner_reputation":7876,
        "Owner_up_votes":4051,
        "Owner_down_votes":47,
        "Owner_views":924,
        "Question_last_edit_time":1530112131487,
        "Answer_body":"<p>Apparently I had to install the <code>wheel<\/code> module inside my virtual environment. I deleted the virtual environment, re-created it, and then installed the <code>wheel<\/code> module:<\/p>\n\n<pre><code>pip install wheel\n<\/code><\/pre>\n\n<p>after that <code>pip install mlflow<\/code>, as well as <code>mlflow ui<\/code> worked successfully.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1530109158067,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51064366",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65145994,
        "Question_title":"Saving an Matlabplot as an MLFlow artifact",
        "Question_body":"<p>I am using DataBricks and Spark 7.4ML,<\/p>\n<p>The following code successfully logs the params and metrics, and I can see the ROCcurve.png in the MLFLOW gui (just the item in the tree below the model). But the actually plot is blank. Why?<\/p>\n<pre><code>with mlflow.start_run(run_name=&quot;logistic-regression&quot;) as run:\n  pipeModel = pipe.fit(trainDF)\n  mlflow.spark.log_model(pipeModel, &quot;model&quot;)\n  predTest = pipeModel.transform(testDF)\n  predTrain = pipeModel.transform(trainDF)\n  evaluator=BinaryClassificationEvaluator(labelCol=&quot;arrivedLate&quot;)\n  trainROC = evaluator.evaluate(predTrain)\n  testROC = evaluator.evaluate(predTest)\n  print(f&quot;Train ROC: {trainROC}&quot;)\n  print(f&quot;Test ROC: {testROC}&quot;)\n  mlflow.log_param(&quot;Dataset Name&quot;, &quot;Flights &quot; + datasetName)\n  mlflow.log_metric(key=&quot;Train ROC&quot;, value=trainROC)\n  mlflow.log_metric(key=&quot;Test ROC&quot;, value=testROC)\n\n  lrModel = pipeModel.stages[3]\n  trainingSummary = lrModel.summary\n  roc = trainingSummary.roc.toPandas()\n  plt.plot(roc['FPR'],roc['TPR'])\n  plt.ylabel('False Positive Rate')\n  plt.xlabel('True Positive Rate')\n  plt.title('ROC Curve')\n  plt.show()\n  plt.savefig(&quot;ROCcurve.png&quot;)\n  mlflow.log_artifact(&quot;ROCcurve.png&quot;)\n  plt.close()\n  \n  display(predTest.select(stringCols + [&quot;arrivedLate&quot;, &quot;prediction&quot;]))\n<\/code><\/pre>\n<p>What the notebook shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What the MLFlow shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1607094596640,
        "Question_score":8,
        "Question_tags":"apache-spark|matplotlib|pyspark|databricks|mlflow",
        "Question_view_count":5219,
        "Owner_creation_time":1316705139197,
        "Owner_last_access_time":1663085821243,
        "Owner_location":"Boston, MA",
        "Owner_reputation":6711,
        "Owner_up_votes":353,
        "Owner_down_votes":3,
        "Owner_views":819,
        "Question_last_edit_time":1607191847983,
        "Answer_body":"<p>Put <code>plt.show()<\/code> after <code>plt.savefig()<\/code> - <code>plt.show()<\/code> will remove your plot because it is shown already.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1607094854147,
        "Answer_score":7.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65145994",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63515370,
        "Question_title":"How to add coefficients, p-values and relevant variable name in mlflow?",
        "Question_body":"<p>I am running a linear regression model and I would like to add the coefficients and P-values of each variable and the variable name in to the metrics of the mlflow output. I am new to using mlflow and not very familiar in doing this. Below is an example of part of my code<\/p>\n<pre><code>with mlflow.start_run(run_name=p_key + '_' + str(o_key)):\n    \n    lr = LinearRegression(\n      featuresCol = 'features',\n      labelCol = target_var,\n      maxIter = 10,\n      regParam = 0.0,\n      elasticNetParam = 0.0,\n      solver=&quot;normal&quot;\n        )\n    \n    lr_model_item = lr.fit(train_model_data)\n    lr_coefficients_item = lr_model_item.coefficients\n    lr_coefficients_intercept = lr_model_item.intercept\n    \n    lr_predictions_item = lr_model_item.transform(train_model_data)\n    lr_predictions_item_oos = lr_model_item.transform(test_model_data)\n    \n    rsquared = lr_model_item.summary.r2\n    \n    # Log mlflow attributes for mlflow UI\n    mlflow.log_metric(&quot;rsquared&quot;, rsquared)\n    mlflow.log_metric(&quot;intercept&quot;, lr_coefficients_intercept)\n    for i in lr_coefficients_item:\n      mlflow.log_metric('coefficients', lr_coefficients_item[i])\n<\/code><\/pre>\n<p>Would like to know whether this is possible? In the final output I should have the intercept, coefficients, p-values and the relevant variable name.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1597974389493,
        "Question_score":1,
        "Question_tags":"databricks|mlflow",
        "Question_view_count":242,
        "Owner_creation_time":1557281764547,
        "Owner_last_access_time":1621398878877,
        "Owner_location":null,
        "Owner_reputation":129,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":29,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63515370",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73808627,
        "Question_title":"Can't get model inference using mlflow.pytorch.log_model, but could get it with mlflow.pyfunc.log_model",
        "Question_body":"<p>I've used <code>mlflow.pyfunc.log_model<\/code> and I was able to get model inference with this, but not with<code>mlflow.pytorch.log_model<\/code>. The error was Verify that the serialized input Dataframe is compatible with the model for inference.<\/p>\n<pre><code>    data = torch.randn(10, 3, 224, 224)  # shape: [bs, channel, size, size]\n    model_input = {\n                &quot;inputs&quot;: { \n                    &quot;x&quot;: data.tolist() }\n                }\n    request = json.dumps(model_input)\n    headers = {&quot;content-type&quot;: &quot;application\/json&quot;}\n    response = requests.post(URL, data=request, headers=headers) # to mlflow\n    response = response.json() \n    print(response)\n<\/code><\/pre>\n<p>The very same input to the model, but I could get inference on one but not the other? Am I missing something here? I would like to use <code>mlflow.pytorch.log_model<\/code> so I don't have to do a model wrapper for generalisation with <code>mlflow.pyfunc.log_model<\/code>.<\/p>\n<p>Can anyone help me with this please.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663812765467,
        "Question_score":0,
        "Question_tags":"rest|deployment|pytorch|mlflow|serving",
        "Question_view_count":14,
        "Owner_creation_time":1487831504143,
        "Owner_last_access_time":1664005735500,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1663812910113,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73808627",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68722437,
        "Question_title":"Azure : Ansible role for deploying ML model integrated over databricks",
        "Question_body":"<p>I have developed ML predictive model on historical data in Azure Databricks using python notebook.\nWhich means i have done data extraction, preparation, feature engineering and model training everything done in Databricks using python notebook.\nI have almost completed development part of it, now we want to deploy ML model into production using ansible roles.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1628579607800,
        "Question_score":1,
        "Question_tags":"deployment|databricks|mlflow|mlmodel",
        "Question_view_count":128,
        "Owner_creation_time":1605508510493,
        "Owner_last_access_time":1638163317803,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1628663676903,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68722437",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68887243,
        "Question_title":"Autolog metrics mlflow",
        "Question_body":"<p>I have a question about autologging. I use it and I want to record another metrics.\nCan I change the recorded metrics for autologging?<\/p>\n<p>I found a class in the documentation <code>_AutologgingMetricsManager<\/code> but I don't know how can I use it.<\/p>\n<p>Thanks,\nIrina<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1629692108827,
        "Question_score":1,
        "Question_tags":"metrics|mlflow",
        "Question_view_count":54,
        "Owner_creation_time":1629691503070,
        "Owner_last_access_time":1657106037790,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1629701490177,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68887243",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72660569,
        "Question_title":"mlflow UI server doesn't start",
        "Question_body":"<p>When I run mlflow UI inside my repository and environment (anaconda), I receive the following error<\/p>\n<pre><code>Cannot open C:\\Users\\XXX\\Anaconda3\\envs\\haea\\Scripts\\waitress-serve-script.py\nRunning the mlflow server failed. Please see the logs above for details\n<\/code><\/pre>\n<p>When I checked the anaconda environment folder, I don't see a waitress-serve-script there, that might be the reason, but I can't find other online resources for the issue. Any recommendations would help.<\/p>\n<p><em>What I have tried so far<\/em><\/p>\n<ol>\n<li>Reinstalling mlflow<\/li>\n<li>Creating a new environment<\/li>\n<li>Manually install waitress (pip install waitress)<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1655474363667,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":158,
        "Owner_creation_time":1466863372793,
        "Owner_last_access_time":1658241993080,
        "Owner_location":"Michigan",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72660569",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71612603,
        "Question_title":"How does one invert an encoded prediction in Keras for model serving?",
        "Question_body":"<p>I have a Keras model in which i have successfully added a <code>StringLookUp<\/code> pre-processing step as part of the model definition. This is generally a good practice because i can then feed it the raw data to get back a prediction.<\/p>\n<p>I am feeding the model string words that are mapped to an integer. The Y values are also string words that have been mapped to an integer.<\/p>\n<p>Here is the implementation of the encoder and decoders:<\/p>\n<pre><code>#generate the encoder and decoders\nencoder = tf.keras.layers.StringLookup(vocabulary=vocab, )\ndecoder = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode=&quot;int&quot;, invert=True)\n<\/code><\/pre>\n<p>Here is the some of the code that makes the inference model<\/p>\n<pre><code># For inference, you can export a model that accepts strings as input\ninputs = Input(shape=(6,), dtype=&quot;string&quot;)\nx = encoder(inputs)\noutputs = keras_model(x)\ninference_model = Model(inputs, outputs)\n\ninference_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \ninference_model.summary()\n<\/code><\/pre>\n<p>The <code>encoder<\/code> above is just a function that implements <code>tf.keras.layers.StringLookup<\/code><\/p>\n<p>Now, inside the notebook, I can easily convert the predictions back to the Original String representations by using a <code>decoder<\/code> which implements the reverse of <code>StringLookUp<\/code>.<\/p>\n<p><em><strong>Here's my problem<\/strong><\/em>\nWhile this works fine inside the notebook, this isn't very practical for deploying the model as a REST API because the calling program has no way of knowing how the encoded integer maps back to the original string representation.<\/p>\n<p><em><strong>So the question is what strategy should I use to implement the keras predict so that it returns the original string which I can then serialize using mlflow &amp; cloudpickle to deploy it as a servable model in databricks<\/strong><\/em><\/p>\n<p>Any guidance would be very much appreciated. I've seen a lot of example of Keras, but none that show how to do enact this kind of behavior for model deployment.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1648186526013,
        "Question_score":0,
        "Question_tags":"tensorflow|keras|deep-learning|mlflow",
        "Question_view_count":176,
        "Owner_creation_time":1427492676943,
        "Owner_last_access_time":1663998407850,
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":18,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71612603",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68319208,
        "Question_title":"Unable to import mlflow, getting ModuleNotFoundError: No module named 'mlflow'",
        "Question_body":"<p>Unable to import <code>mlflow<\/code> in a .py script.<\/p>\n<pre><code>ModuleNotFoundError: No module named 'mlflow'\n<\/code><\/pre>\n<p>The script runs in a <code>python:3.7-stretch Docker<\/code> container<\/p>\n<p>Use <code>requirements.txt<\/code> to pip install packages.<\/p>\n<pre><code>(...)\nsqlalchemy==1.4.1\npsycopg2==2.8.6\nmlflow==1.18.0\n<\/code><\/pre>\n<pre><code>RUN pip3 install --default-timeout=5000 --use-deprecated=legacy-resolver -r \/root\/requirements.txt\n<\/code><\/pre>\n<p>Can see that it is installed.<\/p>\n<pre><code>root@abc:~# pip uninstall mlflow\nFound existing installation: mlflow 1.18.0\nUninstalling mlflow-1.18.0:\n  Would remove:\n    \/usr\/local\/bin\/mlflow\n    \/usr\/local\/lib\/python3.7\/site-packages\/mlflow-1.18.0.dist-info\/*\n    \/usr\/local\/lib\/python3.7\/site-packages\/mlflow\/*\nProceed (y\/n)? n\n<\/code><\/pre>\n<p>Can do an import from python shell.<\/p>\n<pre><code>root@abc:~# python\nPython 3.7.10 (default, Feb 16 2021, 19:46:13)\n[GCC 6.3.0 20170516] on linux\nType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; import mlflow\n&gt;&gt;&gt;\n<\/code><\/pre>\n<p>But no joy when running from .py script.<\/p>\n<p>Other packages installed from <code>requirements.txt<\/code> can be imported.<\/p>\n<p>Any ideas what is wrong ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1625844282463,
        "Question_score":0,
        "Question_tags":"python-3.x|docker|machine-learning|python-module|mlflow",
        "Question_view_count":814,
        "Owner_creation_time":1461829551257,
        "Owner_last_access_time":1663945644783,
        "Owner_location":null,
        "Owner_reputation":375,
        "Owner_up_votes":241,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Question_last_edit_time":1650287875787,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68319208",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63232368,
        "Question_title":"Storing mlflow artifacts to s3, while having SQL databse as backend",
        "Question_body":"<p>When using a SQL database as backend for <code>mlflow<\/code> are the artifacts stored in the same database or in default <code>.\/mlruns<\/code> directory?<\/p>\n<p>Is it possible to store them in different location as in AWS S3?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1596468560843,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":610,
        "Owner_creation_time":1596468107063,
        "Owner_last_access_time":1624957000150,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1596534279300,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63232368",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56851463,
        "Question_title":"How do I specify mlflow MLproject with zero parameters?",
        "Question_body":"<p>I tried to create MLproject with zero parameters as:<\/p>\n\n<pre><code>name: test\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    parameters:\n    command: \"python test.py\"\n<\/code><\/pre>\n\n<p>when I get an error:<\/p>\n\n<pre><code>  Traceback (most recent call last):\n File \"\/home\/ubuntu\/.local\/bin\/mlflow\", line 11, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/cli.py\", line 137, in run\n    run_id=run_id,\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\n    use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/__init__.py\", line 85, in _run\n    project = _project_spec.load_project(work_dir)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/_project_spec.py\", line 40, in load_project\n    entry_points[name] = EntryPoint(name, parameters, command)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/_project_spec.py\", line 87, in __init__\n    self.parameters = {k: Parameter(k, v) for (k, v) in parameters.items()}\nAttributeError: 'NoneType' object has no attribute 'items'\n<\/code><\/pre>\n\n<p>Am I missing something or mlflow does not allow project with  zero parameters?<\/p>\n\n<p>I have also posted this at my public repo of: <a href=\"https:\/\/github.com\/sameermahajan\/mlflow-try\" rel=\"nofollow noreferrer\">https:\/\/github.com\/sameermahajan\/mlflow-try<\/a> if someone would like to try out:<\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/sameermahajan\/mlflow-try.git\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1562066976100,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":353,
        "Owner_creation_time":1384343462317,
        "Owner_last_access_time":1663916912330,
        "Owner_location":"Pune, Maharashtra, India",
        "Owner_reputation":478,
        "Owner_up_votes":65,
        "Owner_down_votes":4,
        "Owner_views":118,
        "Question_last_edit_time":null,
        "Answer_body":"<p>For this, you completely drop the 'parameters' section as below:<\/p>\n\n<pre><code>name: test\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    command: \"python test.py\"\n<\/code><\/pre>\n\n<p>(I thought I had tried it earlier but I was trying too many different ways to may be miss out on this one)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1562240543613,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56851463",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59401800,
        "Question_title":"MLFlow run passing Google Application credentials",
        "Question_body":"<p>I want to pass my <code>GOOGLE_APPLICATION_CREDENTIALS<\/code> environmental variable when I run <code>mlflow run<\/code> using a Docker container:<\/p>\n\n<p>This is my current <code>docker run<\/code> when using mlflow run:<\/p>\n\n<pre><code> Running command 'docker run --rm -e MLFLOW_RUN_ID=f18667e37ecb486cac4631cbaf279903 -e MLFLOW_TRACKING_URI=http:\/\/3.1.1.11:5000 -e MLFLOW_EXPERIMENT_ID=0 mlflow_gcp:33156ee python -m trainer.task --job-dir \/tmp\/ \\\n    --num-epochs 10 \\\n    --train-steps 1000 \\\n    --eval-steps 1 \\\n    --train-files gs:\/\/cloud-samples-data\/ml-engine\/census\/data\/adult.data.csv \\\n    --eval-files gs:\/\/cloud-samples-data\/ml-engine\/census\/data\/adult.test.csv \\\n    --batch-size 128\n<\/code><\/pre>\n\n<p>This is how I would normally pass it:<\/p>\n\n<pre><code>docker run \\\n   -p 9090:${PORT} \\\n   -e PORT=${PORT} \\\n   -e GOOGLE_APPLICATION_CREDENTIALS=\/tmp\/keys\/[FILE_NAME].json\n<\/code><\/pre>\n\n<p>What is the best way to option to pass this value to mlflow? I'm writing files in GCS and Docker requires access to GCP.<\/p>\n\n<p>MLproject contents<\/p>\n\n<pre><code>name: mlflow_gcp\ndocker_env:\n  image: mlflow-gcp-example\nentry_points:\n  main:\n    parameters:\n      job_dir:\n        type: string\n        default: '\/tmp\/'\n      num_epochs:\n        type: int\n        default: 10\n      train_steps:\n        type: int\n        default: 1000\n      eval_steps:\n        type: int\n        default: 1\n      batch_size:\n        type: int\n        default: 64\n      train_files:\n        type: string\n        default: 'gs:\/\/cloud-samples-data\/ml-engine\/census\/data\/adult.data.csv'\n      eval_files:\n        type: string\n        default: 'gs:\/\/cloud-samples-data\/ml-engine\/census\/data\/adult.test.csv'\n      mlflow_tracking_uri:\n        type: uri\n        default: ''\n\n    command: |\n        python -m trainer.task --job-dir {job_dir} \\\n            --num-epochs {num_epochs} \\\n            --train-steps {train_steps} \\\n            --eval-steps {eval_steps} \\\n            --train-files {train_files} \\\n            --eval-files {eval_files} \\\n            --batch-size {batch_size} \\\n            --mlflow-tracking-uri {mlflow_tracking_uri}\n\n<\/code><\/pre>\n\n<p>I already tried in Python file and fails since Docker has no access to local file system:<\/p>\n\n<pre><code>import os\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\/Users\/user\/key.json\"\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1576715118127,
        "Question_score":2,
        "Question_tags":"docker|mlflow",
        "Question_view_count":243,
        "Owner_creation_time":1264671735677,
        "Owner_last_access_time":1664082395287,
        "Owner_location":"San Francisco, CA",
        "Owner_reputation":8619,
        "Owner_up_votes":1916,
        "Owner_down_votes":102,
        "Owner_views":1286,
        "Question_last_edit_time":1576715456443,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59401800",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58306468,
        "Question_title":"Gridsearch on an experiment in Sacred",
        "Question_body":"<p>I'm trying to see some ways to store my ML experiments and I came across some python libraries like Sacred, ModelChimp, MLFlow, ....<\/p>\n\n<p>The one I like the most is Sacred, but I would like to know how to save the <code>GridSearchCV<\/code> sklearn object the way ModelChimp does, for example. Is there any way to include each of the tests that the <code>GridSearchCV<\/code> object does in Sacred like ModelChimp does?<\/p>\n\n<p>Additionally I would like to be able to visualize an interactive map of the folium library (which I would simply export to HTML), but I haven't seen that any of these libraries accept objects to visualize beyond an image.<\/p>\n\n<p>Are Sacred or ModelChimp good options? The little I've seen of MLflow or other libraries hasn't convinced me either but I'm open to suggestions. <a href=\"https:\/\/www.reddit.com\/r\/MachineLearning\/comments\/bx0apm\/d_how_do_you_manage_your_machine_learning\/\" rel=\"nofollow noreferrer\">Here<\/a> are a few more alternatives. Which one do you use?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1570631306603,
        "Question_score":1,
        "Question_tags":"python|machine-learning|folium|mlflow|python-sacred",
        "Question_view_count":205,
        "Owner_creation_time":1550233102177,
        "Owner_last_access_time":1663835213537,
        "Owner_location":null,
        "Owner_reputation":621,
        "Owner_up_votes":87,
        "Owner_down_votes":26,
        "Owner_views":103,
        "Question_last_edit_time":1571068502090,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58306468",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73769728,
        "Question_title":"What is a 'XGBoostLabelEncoder' object?",
        "Question_body":"<p>I'm trying to load a model from an mlflow run. When I do that I get an 'XGBoostLabelEncoder' object, an object with no attributes like predict or predict_proba. I don't really know what you can do with it.<\/p>\n<p>I've googled around but can't find any information about what an 'XGBoostLabelEncoder' object is.<\/p>\n<p>Anybody who knows?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663571938730,
        "Question_score":0,
        "Question_tags":"python|scikit-learn|xgboost|mlflow",
        "Question_view_count":25,
        "Owner_creation_time":1503559541763,
        "Owner_last_access_time":1664083799790,
        "Owner_location":"Malm\u00f6, Sverige",
        "Owner_reputation":796,
        "Owner_up_votes":605,
        "Owner_down_votes":4,
        "Owner_views":136,
        "Question_last_edit_time":1663573301817,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73769728",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68622242,
        "Question_title":"Copying Experiments from a MLFlow server to another MLFlow server",
        "Question_body":"<p>I have a user in a Linux machine and I run a mlflow server from this user. Artifacts are stored in local mlruns folder. Lets call this user as user A. Then I run another mlflow server from another Linux user and call this user as user B. I wanted to move older experiments that resides in mlruns directory of user A to mlflow that run in user B. I simply moved mlruns directory of user A to the home directory of user B and run mlflow from there again. When I accessed to mlflow UI by browser I saw that artifact location is configured correctly to mlruns folder of user B, but I couldn't see the experiments that moved from user A's mlruns directory. How can I see them in the UI too?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1627910044223,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":303,
        "Owner_creation_time":1533205766067,
        "Owner_last_access_time":1663159397120,
        "Owner_location":"\u0130stanbul, T\u00fcrkiye",
        "Owner_reputation":275,
        "Owner_up_votes":167,
        "Owner_down_votes":2,
        "Owner_views":85,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68622242",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58666136,
        "Question_title":"How can I set run_name in mlflow command line?",
        "Question_body":"<p>MLFlow version: 1.4.0\nPython version: 3.7.4<\/p>\n\n<p>I'm running the UI as <code>mlflow server...<\/code> with all the required command line options. <\/p>\n\n<p>I am logging to MLFlow as an MLFlow project, with the appropriate <code>MLproject.yaml<\/code> file. The project is being run on a Docker container, so the CMD looks like this: <\/p>\n\n<p><code>mlflow run . -P document_ids=${D2V_DOC_IDS} -P corpus_path=...  --no-conda --experiment-name=${EXPERIMENT_NAME}<\/code><\/p>\n\n<p>Running the experiment like this results in a blank run_name. I know there's a run_id but I'd also like to see the run_name and set it in my code -- either in the command line, or in my code as <code>mlflow.log....<\/code>.  <\/p>\n\n<p>I've looked at <a href=\"https:\/\/stackoverflow.com\/questions\/57199472\/is-it-possible-to-set-change-mlflow-run-name-after-run-initial-creation\">Is it possible to set\/change mlflow run name after run initial creation?<\/a> but I want to programmatically set the run name instead of changing it manually on the UI.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1572643824847,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":2230,
        "Owner_creation_time":1364599762503,
        "Owner_last_access_time":1649458568280,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Question_last_edit_time":null,
        "Answer_body":"<p>One of the parameters to <code>mlflow.start_run()<\/code> is <code>run_name<\/code>.  This would give you programmatic access to set the run name with each iteration. See the docs <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.start_run\" rel=\"nofollow noreferrer\">here<\/a>. <\/p>\n\n<p>Here's an example:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from datetime import datetime\n\n## Define the name of our run\nname = \"this run is gonna be bananas\" + datetime.now()\n\n## Start a new mlflow run and set the run name\nwith mlflow.start_run(run_name = name):\n\n    ## ...train model, log metrics\/params\/model...\n\n    ## End the run\n    mlflow.end_run()\n<\/code><\/pre>\n\n<p>If you want to include set the name as part of an MLflow Project, you'll have to specify it as a parameter in the entry points to the project.  This is located in in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/projects.html#mlproject-file\" rel=\"nofollow noreferrer\">MLproject file<\/a>.  Then you can pass those values into the <code>mlflow.start_run()<\/code> function from the command line.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1573412741883,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58666136",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58198968,
        "Question_title":"mlflow not work after installation (Ubuntu 16, Centos 7)",
        "Question_body":"<p><img src=\"https:\/\/i.stack.imgur.com\/5DC76.png\" alt=\"enter link description here\"><\/p>\n\n<p>I try to install and run the web-based interface mlflow on VM Azure Ubuntu 16 and Centos 7.\nAfter running the command:\nsudo mlflow ui<\/p>\n\n<p>I can not get access url, either through the dns (mydomain.com:5000), or by IP: <a href=\"http:\/\/123.456.789.123:5000\/\" rel=\"nofollow noreferrer\">http:\/\/123.456.789.123:5000\/<\/a><\/p>\n\n<p>Executing on the server:<\/p>\n\n<p>wget <a href=\"http:\/\/localhost:5000\" rel=\"nofollow noreferrer\">http:\/\/localhost:5000<\/a><\/p>\n\n<p>I get the html-page mlflow, ie the server is running, but then why can not I connect to it in a browser? - Error:The connection has timed out<\/p>\n\n<p>p.s. Firewall disabled on this VM.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570009106153,
        "Question_score":0,
        "Question_tags":"ubuntu|centos|gunicorn|mlflow",
        "Question_view_count":218,
        "Owner_creation_time":1554820347590,
        "Owner_last_access_time":1652262856667,
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":1570173908487,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58198968",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73716706,
        "Question_title":"Using MLFlow for commercial use",
        "Question_body":"<p>It seems that from April 2020, we cannot use anaconda for &quot;commercial use&quot; meaning for example (organizations with more than 200 employees for example)<\/p>\n<p>Since MLFlow seems to use yaml files that contain allusions to conda, how is the situation with MLFlow?<\/p>\n<p>Can MLFlow be used for commercial use?<\/p>\n<p>Note: This question <em>is<\/em> about programming since I intend to use MLFlow in our programs and I have to decide if we can or not<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663157783360,
        "Question_score":0,
        "Question_tags":"anaconda|mlflow",
        "Question_view_count":21,
        "Owner_creation_time":1421198269333,
        "Owner_last_access_time":1664010554427,
        "Owner_location":null,
        "Owner_reputation":5585,
        "Owner_up_votes":792,
        "Owner_down_votes":53,
        "Owner_views":1350,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73716706",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59415473,
        "Question_title":"Why is the MLFlow UI different on installation?",
        "Question_body":"<p>My MLFlow installation results in a significantly different UI experience  that does not neatly stack the Parameters and Metrics columns as in the QuickStart. <\/p>\n\n<p>Here's what my UI looks like after logging some basic information: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/L7xEe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/L7xEe.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Whereas every other example of MLFlow I've come across online looks like this (image taken from MLFlow website quickstart): \n<a href=\"https:\/\/i.stack.imgur.com\/N4d6d.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/N4d6d.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The other thing that's missing is the toggle between \"list\" and \"table\" views. Below is what MLFlow documentation says I should see: \n<a href=\"https:\/\/i.stack.imgur.com\/K5VI9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/K5VI9.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Whereas here's what I see in my installation: \n<a href=\"https:\/\/i.stack.imgur.com\/bgFKt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bgFKt.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>My environments are as follows: <\/p>\n\n<ol>\n<li>Ubuntu 16.04, Docker + pip installation of MLFlow<\/li>\n<li>Mac OS, \n\n<ol>\n<li>Conda + pip installation of MLFlow<\/li>\n<li>Brew installation of Python, then pip3 installation of MLFlow<\/li>\n<\/ol><\/li>\n<\/ol>\n\n<p>I've tried tweaking the following: <\/p>\n\n<ol>\n<li>Version of MLFlow from 1.3 to 1.4<\/li>\n<li>Version of Python from 3.7 to 3.8 <\/li>\n<li>Brand new installation vs. existing upgrade <\/li>\n<\/ol>\n\n<p>I'm out of ideas at this point as to why my UI looks so different. It doesn't necessarily affect my usage of MLFlow, but I'm trying to sell it to my colleagues as a good experiment tracking system and I want the UI to be the best possible representation. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1576781811567,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":403,
        "Owner_creation_time":1364599762503,
        "Owner_last_access_time":1649458568280,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59415473",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60398594,
        "Question_title":"mlflow artifact storage to AWS s3 artifacts",
        "Question_body":"<p>Is there anyway to store the logs stored by mlflow to AWS S3? <\/p>\n\n<pre><code>mlflow server \\\n    --backend-store-uri \/mnt\/persistent-disk \\\n    --default-artifact-root s3:\/\/my-mlflow-bucket\/ \\\n    --host 0.0.0.0\n<\/code><\/pre>\n\n<p>Is it possible to only provide the default-artifact-root instead of providing both backend-store-uri and default-artifact-root? <\/p>\n\n<p>Also is there anyway to set default-artifact-root programatically from MlFlowClient or MlFlowContext instead of running mlflow server command line? <\/p>\n\n<p>FYI, I have already defined all AWS_ACCESS_KEY and AWS_SECRET_KEY in my environment variables, and exported ENDPOINTS to S3.<\/p>\n\n<p>Is logArtifacts from ActiveRun class a correct method to set the artifact_uri which points to AWS s3 bucket?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1582646236957,
        "Question_score":1,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":5057,
        "Owner_creation_time":1579635994630,
        "Owner_last_access_time":1583333598867,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1582655395240,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60398594",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68745216,
        "Question_title":"Curl returning single output for multiple string inputs",
        "Question_body":"<p>I logged a sentiment-analysis model in <code>Mlflow<\/code> with the custom signature, everything is working fine but as soon as I serve the model and hit it with the curl command, then for my multiple inputs it's returning a single output, please help if someone can point to the issue<\/p>\n<p>Curl command i am using :<\/p>\n<pre><code>curl http:\/\/127.0.0.1:2000\/invocations -H 'Content-Type: application\/json' -d '{&quot;columns&quot;: [&quot;text&quot;],&quot;data&quot;: [[&quot;Its a Bad day&quot;],[&quot;what are you&quot;]]}'\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[&quot;negative&quot;]\n<\/code><\/pre>\n<p>Expected Output:<\/p>\n<pre><code>[&quot;negative&quot;,&quot;neutral&quot;]\n<\/code><\/pre>\n<p>Here is the model signature :<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/iNZHX.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iNZHX.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I have tried two different models, both of them are giving the same issue and if I am trying a model which takes integer values then it's working as expected.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1628696944257,
        "Question_score":0,
        "Question_tags":"python|curl|mlflow",
        "Question_view_count":65,
        "Owner_creation_time":1594195651540,
        "Owner_last_access_time":1663919696387,
        "Owner_location":"India",
        "Owner_reputation":857,
        "Owner_up_votes":83,
        "Owner_down_votes":5,
        "Owner_views":35,
        "Question_last_edit_time":1628697805627,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68745216",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71795643,
        "Question_title":"Error when loading ML model from the remote MLflow instance",
        "Question_body":"<p>I tried to load a model from the remote MLflow instance, using <code>load_model<\/code> function:<\/p>\n<pre><code>import mlflow\n\nmodel = mlflow.pyfunc.load_model(&quot;http:\/\/remote_IP_address:5000\/runs:\/&lt;run_id&gt;\/model&quot;)\n<\/code><\/pre>\n<p>I found the run_id by using the REST API:<\/p>\n<pre><code>import requests\n\nrequests.get(&quot;http:\/\/remote_IP_address:5000\/api\/2.0\/preview\/mlflow\/runs\/search&quot;,params={&quot;experiment_ids&quot;:[0,1]})\n<\/code><\/pre>\n<p>But I am receiving an error:<\/p>\n<pre><code>ValueError: not enough values to unpack (expected 2, got 1)\n<\/code><\/pre>\n<p>I suppose the error is in the URI that I am using. Can you tell me the correct way to access the remote Mlflow instance and load the model?<\/p>\n<p>p.s.\nI also tried:<\/p>\n<pre><code>mlflow.pyfunc.load_model(&quot;http:\/\/remote_Ip_address:5000\/models:\/&lt;model_name&gt;\/production&quot;)\n<\/code><\/pre>\n<p>but I received the same error.<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1649414682147,
        "Question_score":0,
        "Question_tags":"python|jupyter-notebook|mlflow",
        "Question_view_count":286,
        "Owner_creation_time":1528365488027,
        "Owner_last_access_time":1663858441063,
        "Owner_location":null,
        "Owner_reputation":499,
        "Owner_up_votes":167,
        "Owner_down_votes":1,
        "Owner_views":59,
        "Question_last_edit_time":1649415164790,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71795643",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72723433,
        "Question_title":"Does MLflow support darknet framework?",
        "Question_body":"<p>I am learning yolov4 with darknet and using that model for service development.<\/p>\n<p>However, I want to track and manage the performance metric of the model.<\/p>\n<p>So, I've heard of MLflow Tracking and am looking into it.<\/p>\n<p>Does MLflow support darknet?<\/p>\n<p>If so, is there a tracking management tool for using darknet?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1655945856957,
        "Question_score":0,
        "Question_tags":"yolo|mlflow|darknet",
        "Question_view_count":85,
        "Owner_creation_time":1546387948563,
        "Owner_last_access_time":1662079308337,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72723433",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72280328,
        "Question_title":"MLflow artifacts on S3 but not in UI",
        "Question_body":"<p>I'm running mlflow on my local machine and logging everything through a remote tracking server with my artifacts going to an S3 bucket.  I've confirmed that they are present in S3 after a run but when I look at the UI the artifacts section is completely blank.  There's no error, just empty space.  <a href=\"https:\/\/i.stack.imgur.com\/ZeHJ8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZeHJ8.png\" alt=\"enter image description here\" \/><\/a>\nAny idea why this is?  I've included a picture from the UI.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_time":1652819462347,
        "Question_score":1,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":502,
        "Owner_creation_time":1639614248310,
        "Owner_last_access_time":1663891212383,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1659109833417,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72280328",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59856641,
        "Question_title":"How can I throw an exception from within an MLflow project?",
        "Question_body":"<p>I have an Mlflow project that raises an exception. I execute that function using <code>mlflow.run<\/code>, but I get <code>mlflow.exceptions.ExecutionException(\"Run (ID '&lt;run_id&gt;') failed\")<\/code>. <\/p>\n\n<p>Is there any way I could get the exception that is being raised where I am executing <code>mlflow.run<\/code>? <\/p>\n\n<p>Or is it possible to send an <code>mlflow.exceptions.ExecutionException<\/code> with custom message set from within the project?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1579686060327,
        "Question_score":0,
        "Question_tags":"python|exception|mlflow",
        "Question_view_count":428,
        "Owner_creation_time":1472932425400,
        "Owner_last_access_time":1623748857057,
        "Owner_location":"Pune, Maharashtra, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Unfortunately not at the moment. mlflow run starts a new process and there is no protocol for exception passing right now. In general the other project does not even have to be in the same language. <\/p>\n\n<p>One workaround I can think of is to pass the exception via mlflow by setting run tag. E.g.:<\/p>\n\n<pre><code>try:\n    ...\nexcept Exception as ex:\n    mlflow.set_tag(\"exception\", str(ex))\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1579719419647,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1579728648287,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59856641",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69554275,
        "Question_title":"MLFLow: Install github-package dependency via pip and 1 building-job",
        "Question_body":"<p>I want to use MLFlow and I have to specify a Github python package as a pip dependency in the yaml-file.\nThe problem is, that I need to force pip to only use 1 job to build it (otherwise it would run out of memory).\nHow can I do this?<\/p>\n<p>I tried already: mlflow run hello_ml -n 1\nBut n is no option. Nether j (job).<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1634122665053,
        "Question_score":0,
        "Question_tags":"python|pip|mlflow",
        "Question_view_count":26,
        "Owner_creation_time":1582009662117,
        "Owner_last_access_time":1652282252807,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69554275",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70169519,
        "Question_title":"How can I save more metadata on an MLFlow model",
        "Question_body":"<p>I am trying to save a model to MLFlow, but as I have a custom prediction pipeline to retrieve data, I need to save extra metadata into the model.<\/p>\n<p>I tried using my custom signature class, which It does the job correctly and saves the model with the extra metadata in the MLModel file (YAML format). But when want to load the model from the MLFlow registry, the signature is not easy accesible.<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, signature = signature)\n<\/code><\/pre>\n<p>I've also tried to save an extra dictionary at the log_model function, but it saves it in the conda.yaml file:<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, {&quot;metadata1&quot;:&quot;value1&quot;, &quot;metadata2&quot;:&quot;value2&quot;})\n<\/code><\/pre>\n<p>Should I make my own flavour? Or my own Model inheritance? I've seen <a href=\"https:\/\/github1s.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/pyfunc\/__init__.py\" rel=\"nofollow noreferrer\">here<\/a> that the PyFuncModel recieves some metadata class and an implementation to solve this, but I don't know where should I pass my own implementations to PyFuncModel on an experiment script. Here's a minimal example:<\/p>\n<pre><code>import mlflow\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nmetadata_dic = {&quot;metadata1&quot;: &quot;value1&quot;, \n                &quot;metadata2&quot;: &quot;value2&quot;}\n\nX = np.array([[-2, -1, 0, 1, 2, 1],[-2, -1, 0, 1, 2, 1]]).T\ny = np.array([0, 0, 1, 1, 1, 0])\n\nX = pd.DataFrame(X, columns=[&quot;X1&quot;, &quot;X2&quot;])\ny = pd.DataFrame(y, columns=[&quot;y&quot;])\n\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1638276045390,
        "Question_score":3,
        "Question_tags":"python|scikit-learn|mlflow|mlops",
        "Question_view_count":323,
        "Owner_creation_time":1550233102177,
        "Owner_last_access_time":1663835213537,
        "Owner_location":null,
        "Owner_reputation":621,
        "Owner_up_votes":87,
        "Owner_down_votes":26,
        "Owner_views":103,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Finally, I made a class that contains every metadata and saved it as an model argument:<\/p>\n<pre><code>model = LogisticRegression()\nmodel.fit(X, y)\nmodel.metadata = ModelMetadata(**metadata_dic)\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>\n<p>Here I lost the customizable <code>predict<\/code> process, but after reading the <code>MLFlow<\/code> documentation is not very clear how to proceed.<\/p>\n<p>If anyone finds a good approach It would be very appreciated.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1638361888373,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70169519",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56967364,
        "Question_title":"Keep track of all the parameters of spark-submit",
        "Question_body":"<p>I have a team where many member has permission to submit Spark tasks to YARN (the resource management) by command line. It's hard to track who is using how much cores, who is using how much memory...e.g. Now I'm looking for a software, framework or something could help me monitor the parameters that each member used. It will be a bridge between client and YARN. Then I could used it to filter the submit commands.<\/p>\n\n<p>I did take a look at <a href=\"http:\/\/www.mlflow.org\" rel=\"nofollow noreferrer\">mlflow<\/a> and I really like the MLFlow Tracking but it was designed for ML training process. I wonder if there is an alternative for my purpose? Or there is any other solution for the problem.<\/p>\n\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1562750084187,
        "Question_score":0,
        "Question_tags":"apache-spark|parameters|hadoop-yarn|spark-submit|mlflow",
        "Question_view_count":93,
        "Owner_creation_time":1413431014113,
        "Owner_last_access_time":1566529894493,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":"<p>My recommendation would be to build such a tool yourself as its not too complicated,\nhave a wrapper script to spark submit which logs the usage in a DB and after the spark job finishes the wrapper will know to release information. could be done really easily.\nIn addition you can even block new spark submits if your team already asked for too much information.<\/p>\n\n<p>And as you build it your self its really flexible as you can even create \"sub teams\" or anything you want.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1562766864887,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56967364",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72416831,
        "Question_title":"mlflow: saving signature gives me warning",
        "Question_body":"<p>I am using mlflow with sqlite backend. started the server with:<\/p>\n<pre><code>mlflow server --backend-store-uri sqlite:\/\/\/mlruns_db\/mlruns.db --default-artifact-root $PWD\/mlruns --host 0.0.0.0 -p 5000\n<\/code><\/pre>\n<p>in the code, I log the model with signature as such<\/p>\n<pre><code>...\nsignature = infer_signature(X, y)\nmlflow.sklearn.log_model(model, model_name, signature=signature)\n...\n<\/code><\/pre>\n<p>then I get warnings<\/p>\n<blockquote>\n<p>2022\/05\/26 19:52:17 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under .\/mlruns\/1\/d4c8f611d3f24986a32d19c7d8b03f06\/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above.<\/p>\n<\/blockquote>\n<p>I am using <code>mlflow, version 1.24.0<\/code>, though.<\/p>\n<p>I see that the signature is correctly logged inside <code>MLmodel<\/code> file, but the nice rendering of mlflow ui is lost.<\/p>\n<ol>\n<li><p>with logging signature\n<a href=\"https:\/\/i.stack.imgur.com\/r2FwI.png\" rel=\"nofollow noreferrer\">mlflow ui with logging signature<\/a><\/p>\n<\/li>\n<li><p>without logging signature\n<a href=\"https:\/\/i.stack.imgur.com\/9nQ8w.png\" rel=\"nofollow noreferrer\">mlflow ui without logging signature<\/a><\/p>\n<\/li>\n<\/ol>\n<p>Does this have any consequence later when serving models with signature enforcement?\nAlso, I see many blog examples with postgres instead of sqlite, and sftp\/minio instead of filestore. maybe changing to those setups will solve this?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1653750895023,
        "Question_score":1,
        "Question_tags":"postgresql|sqlite|metadata|mlflow",
        "Question_view_count":194,
        "Owner_creation_time":1653748227087,
        "Owner_last_access_time":1661359833540,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72416831",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65330061,
        "Question_title":"working directory changes to \/tmp\/ when python script runs with mlflow",
        "Question_body":"<p>I have a strange issue with python working directory when running with mlflow run -e build .\nThe script running successfully locally\/using IDE, but when running it with mlflow the problem is that the working directory changes to \/tmp folders instead of the correct working directory where the script resides (I have some path dependencies that certain folders should be present in .\/* so thats why my process fails.<\/p>\n<p>I had a feeling that something with the working directory messed up so I did os.getcwd() prints and saw the issue with temp folders.<\/p>\n<p>I had a similar project that I configured in a similar manner before and didn't have these issues.<\/p>\n<p>any idea what might be the issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1608147574247,
        "Question_score":0,
        "Question_tags":"python|path|mlflow",
        "Question_view_count":286,
        "Owner_creation_time":1511185810877,
        "Owner_last_access_time":1644828875333,
        "Owner_location":null,
        "Owner_reputation":174,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":62,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65330061",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71610688,
        "Question_title":"Is it possible to change the legend of the plot chart in mlflow metrics?",
        "Question_body":"<p>Thanks for the development of mlflow. I love it very much.<\/p>\n<p>I want to compare several runs with different hyper parameters, but I found that it is very difficult to differenciate these runs from the legend (some random numbers as the run ID) as shown in the screenshot.<\/p>\n<p>I hope the legend could be set to the hyper parameters in which these runs have different values. For instance, the legend could be set to different <code>patch size<\/code>, or different <code>learning rate<\/code>, etc.<\/p>\n<p>So is it possible for the current mlflow? If not, do you have the plan to develop this feature?<\/p>\n<p>This question is similar with this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/5523\" rel=\"nofollow noreferrer\">issue<\/a>. But the issue proposed to use the customed <code>name<\/code> as the legend, while I think it is better to set it as the different hyperparemeters. Or it is best to let users to choose how to set the legend.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/0Wagl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0Wagl.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1648165795930,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":68,
        "Owner_creation_time":1516197597947,
        "Owner_last_access_time":1663970048630,
        "Owner_location":"Leiden, \u8377\u5170",
        "Owner_reputation":908,
        "Owner_up_votes":568,
        "Owner_down_votes":12,
        "Owner_views":151,
        "Question_last_edit_time":1648167115347,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71610688",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73015639,
        "Question_title":"Issues with deploying spark and mlflow to sagemaker",
        "Question_body":"<p>My goal is to deploy a spark\/mlflow to sagemaker with the following command:<\/p>\n<pre><code>    mlflow sagemaker deploy .. \n<\/code><\/pre>\n<p>I've successfully pushed a image to EC2 with<\/p>\n<pre><code>mlflow sagemaker build-and-push-container\n<\/code><\/pre>\n<p>I encounter errors when attempting to run mlflow sagemaker deploy:<\/p>\n<pre><code>[error] 446#446: *69 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 10.32.0.2, server: , request: &quot;GET \/ping HTTP\/1.1&quot;, upstream: &quot;http:\/\/127.0.0.1:8000\/ping&quot;, host: &quot;model.aws.local:8080&quot;\njava.io.IOException: Failed to connect to model.aws.local\/172.17.0.2:34473\n<\/code><\/pre>\n<p>Therefore, I added the following as I thought I was mishandling pyspark in sagemaker:<\/p>\n<pre><code>classpath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars()) \nspark = SparkSession.builder.config( &quot;spark.driver.extraClassPath&quot;, classpath ).appName('audit-risk-predictor-training').getOrCreate()          \n<\/code><\/pre>\n<p>However this outputted the following error:<\/p>\n<pre><code>Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org\/apache\/commons\/configuration\/Configuration\n    at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.&lt;init&gt;(DefaultMetricsSystem.java:38)\n    at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.&lt;clinit&gt;(DefaultMetricsSystem.java:36)\n    at org.apache.hadoop.security.UserGroupInformation$UgiMetrics.create(UserGroupInformation.java:134)\n    at org.apache.hadoop.security.UserGroupInformation.&lt;clinit&gt;(UserGroupInformation.java:254)\n    at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2487)\n    at scala.Option.getOrElse(Option.scala:189)\n    at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2487)\n    at org.apache.spark.SecurityManager.&lt;init&gt;(SecurityManager.scala:79)\n    at org.apache.spark.deploy.SparkSubmit.secMgr$lzycompute$1(SparkSubmit.scala:368)\n    at org.apache.spark.deploy.SparkSubmit.secMgr$1(SparkSubmit.scala:368)\n    at org.apache.spark.deploy.SparkSubmit.$anonfun$prepareSubmitEnvironment$8(SparkSubmit.scala:376)\n    at scala.Option.map(Option.scala:230)\n    at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:376)\n    at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n    at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n    at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n    at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n    at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)\n    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)\n    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.lang.ClassNotFoundException: org.apache.commons.configuration.Configuration\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n    ... 20 more\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\nInput In [7], in &lt;cell line: 3&gt;()\n      1 # Create Spark Session\n      2 classpath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars()) \n----&gt; 3 spark = SparkSession.builder.config( &quot;spark.driver.extraClassPath&quot;, classpath ).appName('audit-risk-predictor-training').getOrCreate()\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/sql\/session.py:228, in SparkSession.Builder.getOrCreate(self)\n    226         sparkConf.set(key, value)\n    227     # This SparkContext may be an existing one.\n--&gt; 228     sc = SparkContext.getOrCreate(sparkConf)\n    229 # Do not update `SparkConf` for existing `SparkContext`, as it's shared\n    230 # by all sessions.\n    231 session = SparkSession(sc)\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:384, in SparkContext.getOrCreate(cls, conf)\n    382 with SparkContext._lock:\n    383     if SparkContext._active_spark_context is None:\n--&gt; 384         SparkContext(conf=conf or SparkConf())\n    385     return SparkContext._active_spark_context\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:144, in SparkContext.__init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\n    139 if gateway is not None and gateway.gateway_parameters.auth_token is None:\n    140     raise ValueError(\n    141         &quot;You are trying to pass an insecure Py4j gateway to Spark. This&quot;\n    142         &quot; is not allowed as it is a security risk.&quot;)\n--&gt; 144 SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n    145 try:\n    146     self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n    147                   conf, jsc, profiler_cls)\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:331, in SparkContext._ensure_initialized(cls, instance, gateway, conf)\n    329 with SparkContext._lock:\n    330     if not SparkContext._gateway:\n--&gt; 331         SparkContext._gateway = gateway or launch_gateway(conf)\n    332         SparkContext._jvm = SparkContext._gateway.jvm\n    334     if instance:\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/java_gateway.py:108, in launch_gateway(conf, popen_kwargs)\n    105     time.sleep(0.1)\n    107 if not os.path.isfile(conn_info_file):\n--&gt; 108     raise Exception(&quot;Java gateway process exited before sending its port number&quot;)\n    110 with open(conn_info_file, &quot;rb&quot;) as info:\n    111     gateway_port = read_int(info)\n\nException: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>Any insight on where I'm going wrong? Is spark capable of running in sagemaker?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1658095201223,
        "Question_score":0,
        "Question_tags":"python|apache-spark|deployment|amazon-sagemaker|mlflow",
        "Question_view_count":59,
        "Owner_creation_time":1642068779037,
        "Owner_last_access_time":1663949787333,
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73015639",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73153142,
        "Question_title":"Mlflow UI can't show artifacts",
        "Question_body":"<p>I have mlflow running on an azure VM and connected to Azure Blob as the artifact storage.<\/p>\n<p>After uploading artifacts to the storage from the Client.<\/p>\n<p>I tried the MLflow UI and successfully was able to show the uploaded file.<\/p>\n<p>The problem happens when I try to run MLFLOW with Docker, I get the error:\n<strong>Unable to list artifacts stored under <code>{artifactUri}<\/code> for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory<\/strong><\/p>\n<p>Dockerfile:<\/p>\n<pre><code>FROM python:3.7-slim-buster\n# Install python packages\nRUN pip install mlflow pymysql\n\nRUN pip install azure-storage-blob\n\nENV AZURE_STORAGE_ACCESS_KEY=&quot;#########&quot;\nENV AZURE_STORAGE_CONNECTION_STRING=&quot;#######&quot;\n<\/code><\/pre>\n<p>docker-compose.yml<\/p>\n<pre><code>web:\n        restart: always\n        build: .\/mlflow_server\n        image: mlflow_server\n        container_name: mlflow_server\n        expose:\n            - &quot;5000&quot;\n        networks:\n            - frontend\n            - backend\n        environment:\n            - AZURE_STORAGE_ACCESS_KEY=&quot;#####&quot;\n            - AZURE_STORAGE_CONNECTION_STRING=&quot;#####&quot;\n        command: mlflow server --backend-store-uri mysql+pymysql:\/\/mlflow_user:123456@db:3306\/mlflow --default-artifact-root wasbs:\/\/etc..\n<\/code><\/pre>\n<p>I tried multiple solutions:<\/p>\n<ol>\n<li>Making sure that boto3 is installed (Didn't do anything)<\/li>\n<li>Adding Environment Variables in the Dockerfile so the command runs after they're set<\/li>\n<li>I double checked the url of the storage blob<\/li>\n<\/ol>\n<p>And MLFLOW doesn't show any logs it just kills the process and restarts again.<\/p>\n<p>Anyone got any idea what might be the solution or how can i access the logs<\/p>\n<p>here're the docker logs of the container:<\/p>\n<pre><code>[2022-07-28 12:23:33 +0000] [10] [INFO] Starting gunicorn 20.1.0\n[2022-07-28 12:23:33 +0000] [10] [INFO] Listening at: http:\/\/0.0.0.0:5000 (10)\n[2022-07-28 12:23:33 +0000] [10] [INFO] Using worker: sync\n[2022-07-28 12:23:33 +0000] [13] [INFO] Booting worker with pid: 13\n[2022-07-28 12:23:33 +0000] [14] [INFO] Booting worker with pid: 14\n[2022-07-28 12:23:33 +0000] [15] [INFO] Booting worker with pid: 15\n[2022-07-28 12:23:33 +0000] [16] [INFO] Booting worker with pid: 16\n[2022-07-28 12:24:24 +0000] [10] [CRITICAL] WORKER TIMEOUT (pid:14)\n[2022-07-28 12:24:24 +0000] [14] [INFO] Worker exiting (pid: 14)\n[2022-07-28 12:24:24 +0000] [21] [INFO] Booting worker with pid: 21\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1659012211500,
        "Question_score":0,
        "Question_tags":"docker|docker-compose|azure-blob-storage|mlflow",
        "Question_view_count":97,
        "Owner_creation_time":1659010615837,
        "Owner_last_access_time":1663625482013,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73153142",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71950167,
        "Question_title":"What is the use of git commits in mlflow?",
        "Question_body":"<p>Why mlflow tracks git commits, we already have run_id for tracking experiment. Can we use those commits to go back to previous commit like we do in git.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1650524426890,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":161,
        "Owner_creation_time":1608194065657,
        "Owner_last_access_time":1662033766403,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71950167",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56984854,
        "Question_title":"fcntl error with \u201cmlflow ui\u201d on windows - mlflow 1.0",
        "Question_body":"<p>I am getting the following error message when trying mlflow examples and running 'mlflow ui'.<\/p>\n\n<p><strong>Error:<\/strong><\/p>\n\n<blockquote>\n  <p>ModuleNotFoundError: No module named 'fcntl' Running the mlflow server\n  failed. Please see the logs above for details<\/p>\n<\/blockquote>\n\n<p>Is anyone aware of a solution to this issue?<\/p>\n\n<p>I have tried the solutions suggested at <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/1080\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/pull\/1080<\/a><\/p>\n\n<p>without success. Replacing the modified files in mlflow source code, it raises other issues for not finding what it is looking for with the following:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\thesis_mlflow\\Scripts\\mlflow.exe\\__main__.py\", line 9, in &lt;module&gt;\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\click\\core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\click\\core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\click\\core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\click\\core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\click\\core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\mlflow\\cli.py\", line 198, in ui\n    _run_server(backend_store_uri, default_artifact_root, \"127.0.0.1\", port, None, 1)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\mlflow\\server\\__init__.py\", line 90, in _run_server\n    exec_cmd(full_command, env=env_map, stream_output=True)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\site-packages\\mlflow\\utils\\process.py\", line 34, in exec_cmd\n    stdin=subprocess.PIPE, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\subprocess.py\", line 729, in __init__\n    restore_signals, start_new_session)\n  File \"c:\\programdata\\anaconda3\\envs\\thesis_mlflow\\lib\\subprocess.py\", line 1017, in _execute_child\n    startupinfo)\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1562833873410,
        "Question_score":1,
        "Question_tags":"python|windows|mlflow",
        "Question_view_count":725,
        "Owner_creation_time":1529408888483,
        "Owner_last_access_time":1649930832187,
        "Owner_location":"London, UK",
        "Owner_reputation":79,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":1562909693510,
        "Answer_body":"<p>Just solved the issue: for some reason, waitress was not installed in the running environment. After installing it, everything seems working fine with the solution #1080 linked above in the question.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1562919127687,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56984854",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61975133,
        "Question_title":"Run mlflow project on multiple remote servers?",
        "Question_body":"<p>Can <code>MLflow<\/code> be used to dispatch <strong>projects<\/strong> to multiple remote servers?(not aws,azure etc.) from a local tracking server?<br>\nI have the following scenario-<Br>\nMultiple servers, where I would like to dispatch the <code>mlflow<\/code> project to all with different parameters, and let them \"report\" back to the current <strong>tracking server:<\/strong><\/p>\n\n<pre><code>for ip in servers_ips:\n    start_remote_mlflow(entry_point=GITHUBPATH,tracking_server=this_server_ip,hparams)\n<\/code><\/pre>\n\n<p>I see one can dispatch <code>mlflow<\/code> projects to aws or azure by specifying the ip or the remote machine. Can it be done with desktops as well?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1590251060187,
        "Question_score":2,
        "Question_tags":"python|remote-server|mlflow",
        "Question_view_count":221,
        "Owner_creation_time":1476768953033,
        "Owner_last_access_time":1664082143130,
        "Owner_location":"Israel",
        "Owner_reputation":2057,
        "Owner_up_votes":201,
        "Owner_down_votes":2,
        "Owner_views":269,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61975133",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70099987,
        "Question_title":"Setting Mlflow region in Python script",
        "Question_body":"<p>Hi all I deployed my minio on my localhost using Kuberenetes @ url: mlflow-minio.local<\/p>\n<p>I also deployed my mlflow server <a href=\"http:\/\/mlflow-server.local\" rel=\"nofollow noreferrer\">http:\/\/mlflow-server.local<\/a> and set the parameters as below in my python script<\/p>\n<pre><code>def savemlflow(lm, output, test_size, random_state, coeff_df):\n    mlflow.set_tracking_uri('http:\/\/mlflow-server.local')\n    os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/mlflow-minio.local\/'\n    os.environ['AWS_ACCESS_KEY_ID'] = 'minio'\n    os.environ['AWS_SECRET_ACCESS_KEY'] = 'minio'\n    with mlflow.start_run():\n        mlflow.sklearn.log_model(lm, &quot;model&quot;)\n        mlflow.log_metric(&quot;MAE&quot;, metrics.mean_absolute_error(output[&quot;ACTUAL_SPEND&quot;], output[&quot;PREDICTED_SPEND&quot;]))\n        mlflow.log_metric(&quot;MSE&quot;, metrics.mean_squared_error(output[&quot;ACTUAL_SPEND&quot;], output[&quot;PREDICTED_SPEND&quot;]))\n        mlflow.log_metric(&quot;RMSE&quot;, np.sqrt(metrics.mean_squared_error(output[&quot;ACTUAL_SPEND&quot;], output[&quot;PREDICTED_SPEND&quot;])))\n<\/code><\/pre>\n<p>However, I keep getting a <code>boto3.exceptions.S3UploadFailedError: Failed to upload \/var\/folders\/xw\/6jppt2490z30qk9pz1fxm2c80000gp\/T\/tmpjen_w4gh\/model\/requirements.txt to mlflow\/0\/adf90c9806e64f64aaf14c4513a00dbf\/artifacts\/model\/requirements.txt: An error occurred (InvalidRegion) when calling the PutObject operation: Region does not match.<\/code><\/p>\n<p>Im guessing I need to set the region somehow for my minio in my python. But how do i do know what is the current region so I can be able to set it?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1637772817887,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":62,
        "Owner_creation_time":1381186868793,
        "Owner_last_access_time":1664071153520,
        "Owner_location":null,
        "Owner_reputation":1069,
        "Owner_up_votes":43,
        "Owner_down_votes":0,
        "Owner_views":178,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70099987",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62841162,
        "Question_title":"How can I password protect my mlflow portal",
        "Question_body":"<p>I have installed my mlflow on centos7 and hosting it at a port 5000.\nI followed this article for reference: <a href=\"https:\/\/medium.com\/analytics-vidhya\/setup-mlflow-in-production-d72aecde7fef\" rel=\"nofollow noreferrer\">Install MLFlow with postgres<\/a><\/p>\n<p>I am looking to secure my mlflow UI with username and password. Any authentication method should be fine, however, Single Sign On is preferred.<\/p>\n<p>I looked at this article: <a href=\"https:\/\/karimlahrichi.com\/2020\/03\/13\/add-authentication-to-mlflow\/\" rel=\"nofollow noreferrer\">Add Authentication to MLFlow<\/a> It allows me to secure all the traffic going from port 80. After successful authentication I will be redirected to port 5000 where my MLFlow application is running. However, if I directly go to host:5000 my mlflow doesn't ask me for any authentication.\nPlease help me understand how I can enable mandatory authentication before you can reach the mlflow dashboard.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1594409600090,
        "Question_score":1,
        "Question_tags":"python|authentication|nginx|centos7|mlflow",
        "Question_view_count":1682,
        "Owner_creation_time":1490818955347,
        "Owner_last_access_time":1619802281030,
        "Owner_location":null,
        "Owner_reputation":175,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62841162",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70968664,
        "Question_title":"How to run data bricck notebook with mlflow in azure data factory pipeline?",
        "Question_body":"<p>My colleagues and I are facing an issue when trying to run my databricks notebook in Azure Data Factory and the error is coming from MLFlow.<\/p>\n<p>The command that is failing is the following:<\/p>\n<pre><code># Take the parent notebook path to use as path for the experiment\ncontext = json.loads(dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson())\nnb_base_path = context['extraContext']['notebook_path'][:-len(&quot;00_training_and_validation&quot;)]\n\nexperiment_path = nb_base_path + 'trainings'\nmlflow.set_experiment(experiment_path)\nexperiment = mlflow.get_experiment_by_name(experiment_path)\nexperiment_id = experiment.experiment_id\n\nrun = mlflow.start_run(experiment_id=experiment_id, run_name=f&quot;run_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}&quot;)\n<\/code><\/pre>\n<p>And the error that is throwing is:<\/p>\n<p>An exception was thrown from a UDF: 'mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: No experiment ID was specified. An experiment ID must be specified in Databricks Jobs and when logging to the MLflow server from outside the Databricks workspace. If using the Python fluent API, you can set an active experiment under which to create runs by calling mlflow.set_experiment(&quot;\/path\/to\/experiment\/in\/workspace&quot;) at the start of your program.', from , line 32.<\/p>\n<p>The pipeline just runs the notebook from ADF, it does not have any other step and the cluster we are using is type 7.3 ML.<\/p>\n<p>Could you please help us?<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1643880182260,
        "Question_score":0,
        "Question_tags":"azure-data-factory|databricks|mlflow",
        "Question_view_count":392,
        "Owner_creation_time":1586330708360,
        "Owner_last_access_time":1643881412287,
        "Owner_location":"Madrid, Spain",
        "Owner_reputation":35,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70968664",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69175969,
        "Question_title":"Data bricks:- Cannot display the predicted output by using ml flow registered model",
        "Question_body":"<p>I have created a model using diabetes dataset for prediction. I have trained, evaluated, logged and registered it as a new model in ML flow. Now I am trying to load the registered model and trying to predict on new data. All though I was able to predict the results. I am not able to display it. When I try to display using command <code>.show()<\/code> or <code>display()<\/code> it is throwing an error. What is the cause of the error? and How do I display the results?<\/p>\n<p>Note: I have programmed using pure pyspark and all the ML flow operation was done on Data bricks<\/p>\n<p>Code:-<\/p>\n<pre><code>model_details = mlflow.tracking.MlflowClient().get_latest_versions('model1',stages=['staging'])[0]\nmodel = mlflow.pyfunc.spark_udf(spark,model_details.source)\ninput_df = sdf.drop('progression')\ncolumns = list(map(lambda c: f&quot;{c}&quot;, input_df.columns))\ndf = input_df.withColumn(&quot;progression&quot;, model(*columns))\ndf.show(truncate=False)\n<\/code><\/pre>\n<p>Error :-<\/p>\n<pre><code>PythonException: An exception was thrown from a UDF: 'Exception: Java gateway process exited before sending its port number'. Full traceback below:\nPythonException                           Traceback (most recent call last)\n&lt;command-1343735193245452&gt; in &lt;module&gt;\n     34 df = input_df.withColumn(&quot;progression&quot;, model(*columns))\n     35 \n---&gt; 36 df.show(truncate=False)\n\n\/databricks\/spark\/python\/pyspark\/sql\/dataframe.py in show(self, n, truncate, vertical)\n    441             print(self._jdf.showString(n, 20, vertical))\n    442         else:\n--&gt; 443             print(self._jdf.showString(n, int(truncate), vertical))\n    444 \n    445     def __repr__(self):\n\n\/databricks\/spark\/python\/lib\/py4j-0.10.9-src.zip\/py4j\/java_gateway.py in __call__(self, *args)\n   1303         answer = self.gateway_client.send_command(command)\n   1304         return_value = get_return_value(\n-&gt; 1305             answer, self.gateway_client, self.target_id, self.name)\n   1306 \n   1307         for temp_arg in temp_args:\n\n\/databricks\/spark\/python\/pyspark\/sql\/utils.py in deco(*a, **kw)\n    131                 # Hide where the exception came from that shows a non-Pythonic\n    132                 # JVM exception message.\n--&gt; 133                 raise_from(converted)\n    134             else:\n    135                 raise\n\n\/databricks\/spark\/python\/pyspark\/sql\/utils.py in raise_from(e)\n\nPythonException: An exception was thrown from a UDF: 'Exception: Java gateway process exited before sending its port number'. Full traceback below:\nTraceback (most recent call last):\n  File &quot;\/databricks\/spark\/python\/pyspark\/worker.py&quot;, line 654, in main\n    process()\n  File &quot;\/databricks\/spark\/python\/pyspark\/worker.py&quot;, line 646, in process\n    serializer.dump_stream(out_iter, outfile)\n  File &quot;\/databricks\/spark\/python\/pyspark\/sql\/pandas\/serializers.py&quot;, line 281, in dump_stream\n    timely_flush_timeout_ms=self.timely_flush_timeout_ms)\n  File &quot;\/databricks\/spark\/python\/pyspark\/sql\/pandas\/serializers.py&quot;, line 97, in dump_stream\n    for batch in iterator:\n  File &quot;\/databricks\/spark\/python\/pyspark\/sql\/pandas\/serializers.py&quot;, line 271, in init_stream_yield_batches\n    for series in iterator:\n  File &quot;\/databricks\/spark\/python\/pyspark\/worker.py&quot;, line 467, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &quot;\/databricks\/spark\/python\/pyspark\/worker.py&quot;, line 467, in &lt;genexpr&gt;\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &quot;\/databricks\/spark\/python\/pyspark\/worker.py&quot;, line 111, in &lt;lambda&gt;\n    verify_result_type(f(*a)), len(a[0])), arrow_return_type)\n  File &quot;\/databricks\/spark\/python\/pyspark\/util.py&quot;, line 109, in wrapper\n    return f(*args, **kwargs)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 827, in predict\n    model = SparkModelCache.get_or_load(archive_path)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/spark_model_cache.py&quot;, line 64, in get_or_load\n    SparkModelCache._models[archive_path] = load_pyfunc(temp_dir)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/utils\/annotations.py&quot;, line 43, in deprecated_func\n    return func(*args, **kwargs)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 693, in load_pyfunc\n    return load_model(model_uri, suppress_warnings)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 667, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/databricks\/python\/lib\/python3.7\/site-packages\/mlflow\/spark.py&quot;, line 707, in _load_pyfunc\n    .master(&quot;local[1]&quot;)\n  File &quot;\/databricks\/spark\/python\/pyspark\/sql\/session.py&quot;, line 189, in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\n  File &quot;\/databricks\/spark\/python\/pyspark\/context.py&quot;, line 384, in getOrCreate\n    SparkContext(conf=conf or SparkConf())\n  File &quot;\/databricks\/spark\/python\/pyspark\/context.py&quot;, line 134, in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n  File &quot;\/databricks\/spark\/python\/pyspark\/context.py&quot;, line 333, in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n  File &quot;\/databricks\/spark\/python\/pyspark\/java_gateway.py&quot;, line 105, in launch_gateway\n    raise Exception(&quot;Java gateway process exited before sending its port number&quot;)\nException: Java gateway process exited before sending its port number\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1631614691113,
        "Question_score":1,
        "Question_tags":"pyspark|apache-spark-sql|user-defined-functions|databricks|mlflow",
        "Question_view_count":168,
        "Owner_creation_time":1628599797537,
        "Owner_last_access_time":1637600430000,
        "Owner_location":null,
        "Owner_reputation":111,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":18,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69175969",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70539698,
        "Question_title":"MlFlow - Unable to run with S3 as default-artifact-root",
        "Question_body":"<p>I am trying to store my model artifacts using mlflow to s3. In the API services, we use <code>MLFLOW_S3_ENDPOINT_URL<\/code> as the s3 bucket. In the mlflow service, we pass it as an environment variable. But, the mlflow container servicer fails with the below exception:<\/p>\n<pre><code>mflow_server  | botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: Not supported URL scheme s3\n<\/code><\/pre>\n<p>docker-compose file as below:<\/p>\n<pre><code>version: &quot;3.3&quot;\nservices:\n  prisim-api:\n    image: prisim-api:latest\n    container_name: prisim-api\n    expose:\n      - &quot;8000&quot;\n    environment: \n    - S3_URL=s3:\/\/mlflow-automation-artifacts\/\n    - MLFLOW_SERVER=http:\/\/mlflow:5000\n    - AWS_ID=xyz+\n    - AWS_KEY=xyz\n\n    networks:\n      - prisim \n    depends_on:\n      - mlflow\n    links:\n            - mlflow\n    volumes:\n      - app_data:\/usr\/data\n  mlflow:\n    image: mlflow_server:latest\n    container_name: mflow_server\n    ports:\n      - &quot;5000:5000&quot;    \n    environment:\n      - AWS_ACCESS_KEY_ID=xyz+\n      - AWS_SECRET_ACCESS_KEY=xyz\n      - MLFLOW_S3_ENDPOINT_URL=s3:\/\/mlflow-automation-artifacts\/\n    healthcheck:\n      test: [&quot;CMD&quot;, &quot;echo&quot;, &quot;mlflow server is running&quot;]\n      interval: 1m30s\n      timeout: 10s\n      retries: 3\n    networks:\n       - prisim \nnetworks:\n prisim:\nvolumes:\n  app_data:\n<\/code><\/pre>\n<p>Why the scheme s3 is not supported?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1640933189943,
        "Question_score":1,
        "Question_tags":"amazon-s3|docker-compose|mlflow",
        "Question_view_count":932,
        "Owner_creation_time":1310893185210,
        "Owner_last_access_time":1663988189020,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I found the solution.<\/p>\n<p>I have added <code>[&quot;AWS_DEFAULT_REGION&quot;]<\/code> to the environment variables and it worked.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641275216080,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70539698",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73040570,
        "Question_title":"How to share models in a multitenant enviroment with Mlflow?",
        "Question_body":"<p>The company I work for are using Databricks with Azure as a storage service. My group is trying to create a centralized model registry that allows us to push and pull models into different instances of Databricks. We are aware that we can share models within the same subscription (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/machine-learning\/manage-model-lifecycle\/multiple-workspaces\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/machine-learning\/manage-model-lifecycle\/multiple-workspaces<\/a>) however we have multiple subscriptions so this wont work for us. From what I've read there are two solutions for this. Use Azure blob storage or an SQL solution. Unfortunately I cant find much info online. Anyone have any idea how I can implement this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1658248426997,
        "Question_score":0,
        "Question_tags":"azure|azure-blob-storage|databricks|mlflow",
        "Question_view_count":49,
        "Owner_creation_time":1632199544943,
        "Owner_last_access_time":1664060085030,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73040570",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66566031,
        "Question_title":"MLFLow artifact logging and retrieve on remote server",
        "Question_body":"<p>I am trying to setup a MLFlow tracking server on a remote machine as a systemd service.\nI have a sftp server running and created a SSH key pair.<\/p>\n<p>Everything seems to work fine except the artifact logging. MLFlow seems to not have permissions to list the artifacts saved in the <code>mlruns<\/code> directory.<\/p>\n<p>I create an experiment and log artifacts in this way:<\/p>\n<pre><code>uri = 'http:\/\/192.XXX:8000' \nmlflow.set_tracking_uri(uri)\n\nmlflow.create_experiment('test', artifact_location='sftp:\/\/192.XXX:_path_to_mlruns_folder_')\n\nexperiment=mlflow.get_experiment_by_name('test')\nwith mlflow.start_run(experiment_id=experiment.experiment_id, run_name=run_name) as run:\n       mlflow.log_param(_parameter_name_, _parameter_value_)     \n       mlflow.log_artifact(_an_artifact_, _artifact_folder_name_)\n<\/code><\/pre>\n<p>I can see the metrics in the UI and the artifacts in the correct destination folder on the remote machine. However, in the UI I receive this message when trying to see the artifacts:<\/p>\n<blockquote>\n<p>Unable to list artifacts stored\nunder sftp:\/\/192.XXX:<em>path_to_mlruns_folder<\/em>\/<em>run_id<\/em>\/artifacts\nfor the current run. Please contact your tracking server administrator\nto notify them of this error, which can happen when the tracking\nserver lacks permission to list artifacts under the current run's root\nartifact directory.<\/p>\n<\/blockquote>\n<p>I cannot figure out why as the <code>mlruns<\/code> folder has <code>drwxrwxrwx<\/code> permissions and all the subfolders have <code>drwxrwxr-x<\/code>. What am I missing?<\/p>\n<hr \/>\n<p>UPDATE\nLooking at it with fresh eyes, it seems weird that it tries to list files through <code>sftp:\/\/192.XXX:<\/code>, it should just look in the folder <code>_path_to_mlruns_folder_\/_run_id_\/artifacts<\/code>. However, I still do not know how to circumvent that.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1615383956893,
        "Question_score":3,
        "Question_tags":"python|mlflow",
        "Question_view_count":2283,
        "Owner_creation_time":1403084852693,
        "Owner_last_access_time":1664082389037,
        "Owner_location":null,
        "Owner_reputation":2210,
        "Owner_up_votes":1124,
        "Owner_down_votes":117,
        "Owner_views":262,
        "Question_last_edit_time":1615451686850,
        "Answer_body":"<p>The problem seems to be that by default the systemd service is run by root.\nSpecifying a user and creating a ssh key pair for that user to access the same remote machine worked.<\/p>\n<pre><code>[Unit]\n\nDescription=MLflow server\n\nAfter=network.target \n\n[Service]\n\nRestart=on-failure\n\nRestartSec=20\n\nUser=_user_\n\nGroup=_group_\n\nExecStart=\/bin\/bash -c 'PATH=_yourpath_\/anaconda3\/envs\/mlflow_server\/bin\/:$PATH exec mlflow server --backend-store-uri postgresql:\/\/mlflow:mlflow@localhost\/mlflow --default-artifact-root sftp:\/\/_user_@192.168.1.245:_yourotherpath_\/MLFLOW_SERVER\/mlruns -h 0.0.0.0 -p 8000' \n\n[Install]\n\nWantedBy=multi-user.target\n<\/code><\/pre>\n<p><code>_user_<\/code> and <code>_group_<\/code> should be the same listed by <code>ls -la<\/code> in the <code>mlruns<\/code> directory.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1615544206663,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66566031",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68918223,
        "Question_title":"Databricks: Migrate a registered model from one workspace to another?",
        "Question_body":"<p>We have multiple Databricks Workspaces on Azure. On one of them we trained multiple models and registered them in the MLflow registry. Our goal is to move those model from one databricks workspace to another and so far, i could not find a straight forwared way to do this except running the training script again on the new databricks workspace.<\/p>\n<p>Downloading the model an registering them in the new workspace didn't work so far. Should I create a &quot;dummy&quot; training script, that just loads the model, does nothing with it and then logs it away in the new workspace?<\/p>\n<p>Seems to me like databricks never anticipated, that someone might want to migrate ML models?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1629874787863,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|migration|databricks|mlflow",
        "Question_view_count":588,
        "Owner_creation_time":1485121974840,
        "Owner_last_access_time":1659449289970,
        "Owner_location":null,
        "Owner_reputation":188,
        "Owner_up_votes":0,
        "Owner_down_votes":1,
        "Owner_views":22,
        "Question_last_edit_time":1629877329853,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68918223",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56701139,
        "Question_title":"Model-logging for \"hybrid models\" (e.g. SKlearn Pipeline including KerasWrapper) possible?",
        "Question_body":"<p>I have wrapped my keras-tf-model into a Sklearn Pipeline, which also does some pre- and postprocessing. I want to serialize this model and capture its dependencies via MLflow.<\/p>\n\n<p>I have tried <code>mlflow.keras.save_model()<\/code>, which seems not appropriate. (it's not a \"pure\" keras model and as no <code>save()<\/code> attribute)<\/p>\n\n<p>I also tried <code>mlflow.sklearn.save_model()<\/code> and <code>mlflow.pyfunc.save_model()<\/code>, which both lead my to the same error: <\/p>\n\n<p><code>NotImplementedError: numpy() is only available when eager execution is enabled.<\/code><\/p>\n\n<p>(This error seems to stem from a clash between python and tensorflow, maybe?)<\/p>\n\n<p>I wonder, should it already\/ generally be possible to serialize these kind of \"hybrid\" models with mlflow?<\/p>\n\n<h3>Please finde a minimal example below<\/h3>\n\n<pre><code># In[1]:\n\n\nfrom mlflow.sklearn import save_model\nimport mlflow.sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\n\nfrom tensorflow.keras.models import Sequential\n\nimport numpy as np\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n\n# ### Save Keras Model\n\n# In[2]:\n\n\niris_data = load_iris() \n\nx = iris_data.data\ny_ = iris_data.target.reshape(-1, 1)\n\n# One Hot encode the class labels\nencoder = OneHotEncoder(sparse=False)\ny = encoder.fit_transform(y_)\n\n# Split the data for training and testing\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n\n# Build the model\nmodel = Sequential()\n\nmodel.add(Dense(10, input_shape=(4,), activation='relu', name='fc1'))\nmodel.add(Dense(10, activation='relu', name='fc2'))\nmodel.add(Dense(3, activation='softmax', name='output'))\n\noptimizer = Adam(lr=0.001)\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_x, train_y, verbose=2, batch_size=5, epochs=20)\n\n\n# In[3]:\n\n\nimport mlflow.keras\n\nmlflow.keras.save_model(model, \"modelstorage\/model40\")\n\n\n# ### Save Minimal SKlearn-Pipeline (with Keras)\n\n# In[4]:\n\n\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\n# In[5]:\n\n\ndef define_model():\n    \"\"\"\n    Create fully connected network with given parameters.\n    \"\"\"\n    keras_model = Sequential()\n\n    keras_model.add(Dense(10, input_shape=(4,), activation='relu', name='fc1'))\n    keras_model.add(Dense(10, activation='relu', name='fc2'))\n    keras_model.add(Dense(3, activation='softmax', name='output'))\n\n    optimizer = Adam(lr=0.001)\n    keras_model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# In[6]:\n\n\n# target_encoder = TargetEncoder() \nscaler = StandardScaler()\nkeras_model = KerasClassifier(define_model, batch_size=5, epochs=20)\n\n\n# In[7]:\n\n\npipeline = Pipeline([\n#     ('encoding', target_encoder),\n    ('scaling', scaler),\n    ('modeling', keras_model)\n])\n\n\n# In[8]:\n\n\npipeline.fit(train_x, train_y)\n\n\n# In[9]:\n\n\nmlflow.keras.save_model(pipeline, \"modelstorage\/model42\")   #not working\n\n\n# In[10]:\n\n\nimport mlflow.sklearn\n\nmlflow.sklearn.save_model(pipeline, \"modelstorage\/model43\")\n\nOutput from modelstorage\/model43\/conda.yaml:\n\n======================\nchannels:\n- defaults\ndependencies:\n- python=3.6.7\n- scikit-learn=0.21.2\n- pip:\n  - mlflow\n  - cloudpickle==1.2.1\nname: mlflow-env\n======================\n\nDoesn't seem to capture Tensorflow.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1561111222150,
        "Question_score":2,
        "Question_tags":"python|keras|scikit-learn|mlflow",
        "Question_view_count":1470,
        "Owner_creation_time":1336936830510,
        "Owner_last_access_time":1663079651823,
        "Owner_location":null,
        "Owner_reputation":948,
        "Owner_up_votes":592,
        "Owner_down_votes":1,
        "Owner_views":132,
        "Question_last_edit_time":1561122889067,
        "Answer_body":"<p>You can add extra dependencies when you save your model, for example if you have a keras step in your pipeline you can add keras &amp; tensorflow:<\/p>\n\n<pre><code>  conda_env = mlflow.sklearn.get_default_conda_env()\n  conda_env[\"dependencies\"] = ['keras==2.2.4', 'tensorflow==1.14.0'] + conda_env[\"dependencies\"]\n  mlflow.sklearn.log_model(pipeline, \"modelstorage\/model43\", conda_env = conda_env)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1572628704763,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56701139",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73562615,
        "Question_title":"MlflowException: API request (Caused by ResponseError('too many 503 error responses'))",
        "Question_body":"<p>I am using mlflow to register my model. I try to use 'Scenario 4' when artifacts load to S3 bucket from local.<\/p>\n<ol>\n<li><p>Add credentials of S3 bucket to .aws\/credentials<\/p>\n<\/li>\n<li><p>Set endpoint and mlflow URI:<\/p>\n<p>os.environ[&quot;MLFLOW_S3_ENDPOINT_URL&quot;]='https:\/\/storage.yandexcloud.net'\nos.environ[&quot;MLFLOW_TRACKING_URI&quot;]='http:\/\/:8000'<\/p>\n<\/li>\n<li><p>Log model to S3 via mlflow:<\/p>\n<p>import mlflow\nimport mlflow.sklearn\nmlflow.set_experiment(&quot;my&quot;)\n...\nmlflow.sklearn.log_model(model, artifact_path=&quot;models_mlflow&quot;)<\/p>\n<\/li>\n<\/ol>\n<p>But get error:<\/p>\n<pre><code>MlflowException: API request to http:\/\/&lt;IP&gt;:8000\/api\/2.0\/mlflow-artifacts\/artifacts\/6\/95972bcc493c4a8cbd8432fea4cc8bac\/artifacts\/models_mlflow\/model.pkl failed with exception HTTPConnectionPool(host='62.84.121.234', port=8000): Max retries exceeded with url: \/api\/2.0\/mlflow-artifacts\/artifacts\/6\/95972bcc493c4a8cbd8432fea4cc8bac\/artifacts\/models_mlflow\/model.pkl (Caused by ResponseError('too many 503 error responses'))\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1661985677113,
        "Question_score":0,
        "Question_tags":"python|amazon-s3|mlflow|mlops|yandexcloud",
        "Question_view_count":38,
        "Owner_creation_time":1396864721170,
        "Owner_last_access_time":1663931830007,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":75,
        "Owner_up_votes":105,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73562615",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58611088,
        "Question_title":"Is there a way to manage permissions at an experiment level in MLflow?",
        "Question_body":"<p>Is there a way to manage permissions at an experiment level in MLflow?  We would like to have a shared server but would like to be able to manage permissions at an experiment level - e.g. admin can view all experiments, user_group1 can manage experiment1 - perhaps different groups can see results vs post results.<\/p>\n\n<p>It looks like it is possible in databricks: <a href=\"https:\/\/docs.databricks.com\/administration-guide\/access-control\/workspace-acl.html#experiment-permissions\" rel=\"nofollow noreferrer\">https:\/\/docs.databricks.com\/administration-guide\/access-control\/workspace-acl.html#experiment-permissions<\/a>  but I can't find anything in the opensource APIdocs.<\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1572364657393,
        "Question_score":4,
        "Question_tags":"mlflow",
        "Question_view_count":1567,
        "Owner_creation_time":1487332729157,
        "Owner_last_access_time":1663766140707,
        "Owner_location":null,
        "Owner_reputation":289,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58611088",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68034523,
        "Question_title":"How to download artifacts from mlflow in python",
        "Question_body":"<p>I am creating an mlflow experiment which logs a logistic regression model together with a metric and an artifact.<\/p>\n<pre><code>import mlflow\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\n\nwith mlflow.start_run(run_name=run_name, experiment_id=experiment_id):\n\n        logreg = LogisticRegression()\n        logreg.fit(x_train, y_train)\n        print('training over', flush=True)\n        y_pred = logreg.predict(x_test)\n        mlflow.sklearn.log_model(logreg, &quot;model&quot;)\n   \n        mlflow.log_metric(&quot;f1&quot;, precision_recall_fscore_support(y_test, y_pred, average='weighted')[2])\n        mlflow.log_artifact(x_train.to_csv('train.csv')\n<\/code><\/pre>\n<p>for some data (<code>x_train, y_train, x_test, y_test<\/code>)<\/p>\n<p>Is there any way to access the artifacts for that specific experiment_id for this run_name and read the <code>train.csv<\/code> and also read the <code>model<\/code> ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1624016436840,
        "Question_score":3,
        "Question_tags":"python|python-3.x|mlflow",
        "Question_view_count":5182,
        "Owner_creation_time":1454338460480,
        "Owner_last_access_time":1664044608790,
        "Owner_location":null,
        "Owner_reputation":3527,
        "Owner_up_votes":352,
        "Owner_down_votes":6,
        "Owner_views":440,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There is a <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.download_artifacts\" rel=\"noreferrer\">download_artifacts function<\/a> that allows you to get access to the logged artifact:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>local_path = client.download_artifacts(run_id, &quot;train.csv&quot;, local_dir)\n<\/code><\/pre>\n<p>The model artifact could either downloaded using the same function (there should be the object called <code>model\/model.pkl<\/code> (for scikit-learn, or something else), or you can load model by run:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>loaded_model = mlflow.pyfunc.load_model(f&quot;runs:\/{run_id}\/model&quot;)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1624022186893,
        "Answer_score":5.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68034523",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72341647,
        "Question_title":"MLFlow -> ModuleNotFoundError: No module named 'sqlalchemy.future'",
        "Question_body":"<p>It seems to use MLFlow Model Registry locally, one option is to build my own backend database with SQLite.<\/p>\n<p>I've found a site, which advised to run:<\/p>\n<pre><code>mlflow server --backend-store-uri sqlite:\/\/\/mlflow.db --default-artifact-root .\/artifacts --host 0.0.0.0 --port 5000\n<\/code><\/pre>\n<p>When running the command above, I get the following error message:<\/p>\n<pre><code>2022\/05\/22 23:08:58 ERROR mlflow.cli: Error initializing backend store\n2022\/05\/22 23:08:58 ERROR mlflow.cli: No module named 'sqlalchemy.future'\nTraceback (most recent call last):\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/cli.py&quot;, line 426, in server\n    initialize_backend_stores(backend_store_uri, default_artifact_root)\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py&quot;, line 259, in initialize_backend_stores\n    _get_tracking_store(backend_store_uri, default_artifact_root)\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py&quot;, line 244, in _get_tracking_store\n    _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py&quot;, line 39, in get_store\n    return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py&quot;, line 49, in _get_store_with_resolved_uri\n    return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py&quot;, line 110, in _get_sqlalchemy_store\n    from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore\n  File &quot;\/home\/username\/.local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py&quot;, line 11, in &lt;module&gt;\n    from sqlalchemy.future import select\nModuleNotFoundError: No module named 'sqlalchemy.future'\n<\/code><\/pre>\n<p>This seems odd, because if I run <code>pip freeze<\/code>, the sqlalchemy shows up, or if I do <code>from sqlalchemy.future import select<\/code> in a notebook, I get no error.<\/p>\n<p>I think this may related to using a virtual environment. The current one I'm using is in <code>\/home\/username\/folder\/mlflow\/.mlflow<\/code> but mlflow seems to be looking elsewhere for the file...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1653257749153,
        "Question_score":1,
        "Question_tags":"python|sqlalchemy|mlflow",
        "Question_view_count":274,
        "Owner_creation_time":1396288958297,
        "Owner_last_access_time":1664053410610,
        "Owner_location":null,
        "Owner_reputation":714,
        "Owner_up_votes":128,
        "Owner_down_votes":6,
        "Owner_views":251,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72341647",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71738738,
        "Question_title":"How to set custom path for databricks mlflow artifacts on s3",
        "Question_body":"<p>I've created an empty experiments from databricks experiments console and given the path for my artifacts on s3 i.e. s3:\/\/\/. When i run the scripts, the artifacts are stored at<\/p>\n<pre><code>s3:\/\/&lt;bucket&gt;\/\/&lt;32 char id&gt;\/artifacts\/model-Elasticnet\/model.pkl\n<\/code><\/pre>\n<p>I want to replace \/\/&lt;32 char id&gt;\/artifacts\/ with \/datetime\/artifacts\/ so something like<\/p>\n<pre><code>s3:\/\/&lt;bucket&gt;\/&lt;datetime&gt;\/artifacts\/model-Elasticnet\/model.pkl\n<\/code><\/pre>\n<p>Is there any way i could achieve that?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wUDcE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wUDcE.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Note: experiment_id is from databricks experiment console<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1649081553880,
        "Question_score":2,
        "Question_tags":"databricks|mlflow|aws-databricks|mlops",
        "Question_view_count":140,
        "Owner_creation_time":1526140623120,
        "Owner_last_access_time":1664008621693,
        "Owner_location":"Berlin, Germany",
        "Owner_reputation":962,
        "Owner_up_votes":106,
        "Owner_down_votes":9,
        "Owner_views":128,
        "Question_last_edit_time":1649316095153,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71738738",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67786052,
        "Question_title":"Log Pickle files as a part of Mlflow run",
        "Question_body":"<p>I am running an MLflow experiment as a part of it I would like to log a few artifacts as a python pickle.<\/p>\n<p>Ex: Trying out different categorical encoders, so wanted to log the encoder objects as a pickle file.<\/p>\n<p>Is there a way to achieve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1622538922663,
        "Question_score":3,
        "Question_tags":"python|databricks|azure-databricks|mlflow",
        "Question_view_count":1843,
        "Owner_creation_time":1411361217027,
        "Owner_last_access_time":1662192778187,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":569,
        "Owner_up_votes":41,
        "Owner_down_votes":3,
        "Owner_views":123,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There are two functions for there:<\/p>\n<ol>\n<li><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"nofollow noreferrer\">log_artifact<\/a> - to log a local file or directory as an artifact<\/li>\n<li><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifacts\" rel=\"nofollow noreferrer\">log_artifacts<\/a> - to log a contents of a local directory<\/li>\n<\/ol>\n<p>so it would be as simple as:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with mlflow.start_run():\n    mlflow.log_artifact(&quot;encoder.pickle&quot;)\n<\/code><\/pre>\n<p>And you will need to use the <a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">custom MLflow model<\/a> to use that pickled file, something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow.pyfunc\n\nclass my_model(mlflow.pyfunc.PythonModel):\n    def __init__(self, encoders):\n        self.encoders = encoders\n\n    def predict(self, context, model_input):\n        _X = ...# do encoding using self.encoders.\n        return str(self.ctx.predict([_X])[0])\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1622542563553,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67786052",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72250896,
        "Question_title":"PowerShell Get request with body",
        "Question_body":"<p>I am trying <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#search-modelversions\" rel=\"nofollow noreferrer\">this api endpoint<\/a>.\nI can call this in python, no problem, like the below<\/p>\n<pre><code>get_model_versions={\n    &quot;filter&quot;:&quot;name='model_name'&quot;,\n    &quot;order_by&quot;:[&quot;version DESC&quot;],\n    &quot;max_results&quot;:1\n}\n\ninit_get = requests.get(&quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search&quot;,headers=header_read,json=get_model_versions)\n<\/code><\/pre>\n<p>However, I just can't seem to find a way to make it work in Powershell.<\/p>\n<p>First the powershell &quot;get&quot; Invoke-RestMethod does not accept a body<\/p>\n<p>and then I can't seem to find a way to append it in Powershell as a query string.<\/p>\n<p>I have tried (among other failed attempts), the following<\/p>\n<pre><code>$get_model_versions=([PSCustomObject]@{\n  filter = &quot;name=`'model_name`'&quot;\n  order_by = @(&quot;version desc&quot;)\n} | ConvertTo-Json)\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get -Body $get_model_versions\n<\/code><\/pre>\n<p>But that gives me an error that body can't be used with a get method<\/p>\n<p>trying to append it as a query string (like if I even just keep the name filter and remove the others), also fails<\/p>\n<pre><code>$searchuri= &quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search?filter=&quot;&quot;name==model_name&quot;&quot;&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get\n<\/code><\/pre>\n<p>fails with<\/p>\n<pre><code>{&quot;error_code&quot;:&quot;INVALID_PARAMETER_VALUE&quot;,&quot;message&quot;:&quot;Unsupported filter query : `\\&quot;name==model_name\\&quot;`. Unsupported operator.&quot;}\n<\/code><\/pre>\n<p>How can I mimic the same behaviour in Powershell, as I do in Python?<\/p>\n<p>EDIT 1: I did try to encode the query param (maybe I did it wrong), but here's how my failed attempt looked like<\/p>\n<pre><code>$encodedvalue = [System.Web.HttpUtility]::UrlEncode(&quot;`&quot;name='model_name'`&quot;&quot;)\n$searchuri= &quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search?filter=$encodedvalue&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get\n<\/code><\/pre>\n<p>But that too gives me<\/p>\n<pre><code>&quot;Unsupported filter query : `\\&quot;name='model_name'\\&quot;`. Unsupported operator.&quot;\n<\/code><\/pre>\n<p>I have also tried it successfully in Postman by passing a raw json body (the same as python) and when I look at the generated PowerShell code in Postman I see this<\/p>\n<pre><code>$headers = New-Object &quot;System.Collections.Generic.Dictionary[[String],[String]]&quot;\n$headers.Add(&quot;Authorization&quot;, &quot;Bearer token&quot;)\n$headers.Add(&quot;Content-Type&quot;, &quot;application\/json&quot;)\n\n$body = &quot;{\n`n    `&quot;filter`&quot;:`&quot;name='model_name'`&quot;,\n`n    `&quot;order_by`&quot;:[`&quot;version DESC`&quot;],\n`n    `&quot;max_results`&quot;:1\n`n}\n`n&quot;\n\n$response = Invoke-RestMethod 'baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search' -Method 'GET' -Headers $headers -Body $body\n$response | ConvertTo-Json\n<\/code><\/pre>\n<p>But of course that fails (if you copy that in an powershell editor and run it<\/p>\n<pre><code>Invoke-RestMethod : Cannot send a content-body with this verb-type\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1652637573657,
        "Question_score":1,
        "Question_tags":"powershell|rest|python-requests|mlflow",
        "Question_view_count":281,
        "Owner_creation_time":1428654714763,
        "Owner_last_access_time":1664012257383,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Question_last_edit_time":1652640935860,
        "Answer_body":"<p>Finally, after struggling for a long time, I found the answer !<\/p>\n<p>The crux is in the documentation <a href=\"https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.utility\/invoke-restmethod?view=powershell-7.2\" rel=\"nofollow noreferrer\">here<\/a>.\nEspecially this section<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/h0gwk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/h0gwk.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>So, if you want to pass on a body for your &quot;get&quot; method in powershell, pass it as a hashtable.<\/p>\n<p>So, finally the answer is<\/p>\n<pre><code>$query=@{&quot;filter&quot;=&quot;name='model_name'&quot;;&quot;order_by&quot;=@(&quot;version DESC&quot;); &quot;max_results&quot;=1};\n$searchuri=&quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get -Body $query\n<\/code><\/pre>\n<p>Hope this helps someone looking for something similar.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1652649592320,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72250896",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73501103,
        "Question_title":"Getting Bad request while searching run in mlflow",
        "Question_body":"<p>Training a ml model with mlflow in azure environment.<\/p>\n<pre><code>import mlflow\nfrom mlflow import MlflowClient\nfrom azureml.core import Experiment, Workspace\n\nexperiment_name = 'housing-lin-mlflow'\n\nexperiment = Experiment(ws, experiment_name)\n\nruns = mlflow.search_runs(experiment_ids=[ experiment.id ])\n\n<\/code><\/pre>\n<p>While fetching runs from search_runs getting this error :<\/p>\n<pre><code>RestException: BAD_REQUEST: For input string: &quot;5b649b3c-3b8f-497a-bb4f&quot;\n<\/code><\/pre>\n<p>MLflow version : 1.28.0\nIn Azure studio jobs have been created and successfully run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1661517215980,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|mlflow",
        "Question_view_count":56,
        "Owner_creation_time":1582101477803,
        "Owner_last_access_time":1663953873503,
        "Owner_location":"Delhi, India",
        "Owner_reputation":171,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1661625379893,
        "Answer_body":"<p>The bad request in MLFlow after successful running the job is because of not giving proper API permissions for the application.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Search for <strong>MLFLOW<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Scroll down<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/s50AL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/s50AL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Click on View API Permissions<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Under API permissions, assign the permissions according to the application running region and requirements. Checkout the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models-mlflow\" rel=\"nofollow noreferrer\">document<\/a> for further information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1661603882123,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73501103",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":51335594,
        "Question_title":"Error with \"mlflow ui\" when trying to run it on MS Windows",
        "Question_body":"<p>When I run <code>mlflow ui<\/code> the following error occurred:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\Scripts\\gunicorn.exe\\__main__.py\", line 5, in &lt;module&gt;\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\app\\wsgiapp.py\", line 9, in &lt;module&gt;\n    from gunicorn.app.base import Application\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\app\\base.py\", line 12, in &lt;module&gt;\n    from gunicorn import util\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\util.py\", line 9, in &lt;module&gt;\n    import fcntl\nModuleNotFoundError: No module named 'fcntl'\nTraceback (most recent call last):\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\Scripts\\mlflow.exe\\__main__.py\", line 9, in &lt;module&gt;\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 722, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 697, in main\n    rv = self.invoke(ctx)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 895, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 535, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\cli.py\", line 131, in ui\n    mlflow.server._run_server(file_store, file_store, host, port, 1)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\server\\__init__.py\", line 48, in _run_server\n    env=env_map, stream_output=True)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\utils\\process.py\", line 38, in exec_cmd\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\n<\/code><\/pre>\n\n<p>I used anaconda + python 3.6.5 and I installed git and set path with <code>C:\\Program Files\\Git\\bin\\git.exe<\/code> and <code>C:\\Program Files\\Git\\cmd<\/code>.<\/p>\n\n<p>I installed <code>mlflow<\/code> whit <code>pip install mlflow<\/code> and its version is 0.2.1.<\/p>\n\n<p>I set a variable with name <code>GIT_PYTHON_GIT_EXECUTABLE<\/code> and value <code>C:\\Program Files\\Git\\bin\\git.exe<\/code> in Environment Variables. <\/p>\n\n<p>How can I solve this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1531546446273,
        "Question_score":1,
        "Question_tags":"python|windows|fcntl|mlflow",
        "Question_view_count":4688,
        "Owner_creation_time":1308552848513,
        "Owner_last_access_time":1664030809627,
        "Owner_location":null,
        "Owner_reputation":1177,
        "Owner_up_votes":24,
        "Owner_down_votes":0,
        "Owner_views":144,
        "Question_last_edit_time":1531837117033,
        "Answer_body":"<p><a href=\"https:\/\/github.com\/databricks\/mlflow\" rel=\"nofollow noreferrer\">mlflow documentation<\/a> already says that <\/p>\n\n<blockquote>\n  <p>Note 2: We <strong>do not currently support running MLflow on Windows<\/strong>.\n  Despite this, we would appreciate any contributions to make MLflow\n  work better on Windows.<\/p>\n<\/blockquote>\n\n<p>You're hitting <code>fcntl<\/code> problem: it's not available on MS Windows platform because it's a \"wrapper\" around the <a href=\"http:\/\/man7.org\/linux\/man-pages\/man2\/fcntl.2.html\" rel=\"nofollow noreferrer\">fcntl function<\/a> that's available on POSIX-compatible systems. (See <a href=\"https:\/\/stackoverflow.com\/a\/1422436\/236007\">https:\/\/stackoverflow.com\/a\/1422436\/236007<\/a> for more details.)<\/p>\n\n<p>Solving this requires modifying the source code of mlflow accordingly. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1531837039907,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51335594",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70098779,
        "Question_title":"How to connect to MLFlow tracking server that has auth?",
        "Question_body":"<p>I want to connect to remote tracking server (<a href=\"http:\/\/123.456.78.90\" rel=\"nofollow noreferrer\">http:\/\/123.456.78.90<\/a>) that requires authentication<\/p>\n<p>When I do this:<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>import mlflow\nmlflow.set_tracking_uri(\"http:\/\/123.456.78.90\")\nmlflow.set_experiment(\"my-experiment\")<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>I get an error<\/p>\n<p><em>MlflowException: API request to endpoint \/api\/2.0\/mlflow\/experiments\/list failed with error code 401 != 200.\nResponse body: 401 Authorization Required<\/em><\/p>\n<p>I understand that I need to log in first but I have no idea how to do it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1637767811310,
        "Question_score":1,
        "Question_tags":"authorization|tracking|mlflow",
        "Question_view_count":2102,
        "Owner_creation_time":1637766437853,
        "Owner_last_access_time":1663839694783,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":"<p><a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#logging-to-a-tracking-server\" rel=\"nofollow noreferrer\">MLflow documentation<\/a> says:<\/p>\n<blockquote>\n<p><code>MLFLOW_TRACKING_USERNAME<\/code> and <code>MLFLOW_TRACKING_PASSWORD<\/code> - username and password to use with HTTP Basic authentication. To use Basic authentication, you must set both environment variables.<\/p>\n<\/blockquote>\n<p>So you just need to set these variables in your code using <code>os.environ<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>os.environ['MLFLOW_TRACKING_USERNAME'] = 'name'\nos.environ['MLFLOW_TRACKING_PASSWORD'] = 'pass'\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1637773273483,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70098779",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73241326,
        "Question_title":"Can't see artifact ui in mlflow dashboard",
        "Question_body":"<p>mlflow server <br \/>\n--host 0.0.0.0 <br \/>\n--port 5000 <br \/>\n--backend-store-uri sqlite:\/\/\/\/tmp\/test.db <br \/>\n--artifacts-destination s3:\/\/mlflow <br \/>\n--serve-artifacts<\/p>\n<p>Using minio as S3\nAnd env. Variable as secret key &amp; access key<\/p>\n<p>#mlflow #artifactui #proxyartifact<a href=\"https:\/\/i.stack.imgur.com\/Q3h0B.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1659641244373,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":65,
        "Owner_creation_time":1542045989230,
        "Owner_last_access_time":1663926597850,
        "Owner_location":"Gandhinagar, Gujarat, India",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1660023754677,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73241326",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70377991,
        "Question_title":"Setting tracking and artifact locations",
        "Question_body":"<p>I read the documentation for setting the tracking and artifact location. For tracking URI, the options are:<\/p>\n<ol>\n<li>set the <code>MLFLOW_TRACKING_URI<\/code> in bash or the environment I use<\/li>\n<li>set the location with <code>mlflow.set_tracking_uri<\/code> inside the python code<\/li>\n<li>Start a server and then set the above parameters to reflect the server information.<\/li>\n<\/ol>\n<p>How can I set the tracking uri in MLproject? I want to use minimal external code in my project. One way I think of is to use the environment section of the MLproject file environment, like <code>[[&quot;NEW_ENV_VAR&quot;, &quot;new_var_value&quot;]<\/code> Is this correct? Or is there any other way to do it? I could find no example for this except under docker section.<\/p>\n<p>Secondly, same for the artifact registry. Can this be set somewhere in the MLproject file?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1639653097383,
        "Question_score":0,
        "Question_tags":"tracking|artifact|mlflow",
        "Question_view_count":146,
        "Owner_creation_time":1462427517847,
        "Owner_last_access_time":1646398883960,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1639662138947,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70377991",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61258979,
        "Question_title":"EKS Docker Image Pull CrashLoopBackOff",
        "Question_body":"<p>I'm trying to deploy a Docker image from ECR to my EKS. When attempting to deploy my docker image to a pod, I get the following events from a CrashLoopBackOff:<\/p>\n\n<pre><code>Events:\n  Type     Reason                  Age               From                                   Message\n  ----     ------                  ----              ----                                   -------\n  Normal   Scheduled               62s               default-scheduler                      Successfully assigned default\/mlflow-tracking-server to &lt;EC2 IP&gt;.internal\n  Normal   SuccessfulAttachVolume  60s               attachdetach-controller                AttachVolume.Attach succeeded for volume \"&lt;PVC&gt;\"\n  Normal   Pulling                 56s               kubelet, &lt;IP&gt;.ec2.internal             Pulling image \"&lt;ECR Image UI&gt;\"\n  Normal   Pulled                  56s               kubelet, &lt;IP&gt;.ec2.internal             Successfully pulled image \"&lt;ECR Image UI&gt;\"\n  Normal   Created                 7s (x4 over 56s)  kubelet, &lt;IP&gt;.ec2.internal             Created container mlflow-tracking-server\n  Normal   Pulled                  7s (x3 over 54s)  kubelet, &lt;IP&gt;.ec2.internal             Container image \"&lt;ECR Image UI&gt;\" already present on machine\n  Normal   Started                 6s (x4 over 56s)  kubelet, &lt;IP&gt;.ec2.internal             Started container mlflow-tracking-server\n  Warning  BackOff                 4s (x5 over 52s)  kubelet, &lt;IP&gt;.ec2.internal             Back-off restarting failed container\n<\/code><\/pre>\n\n<p>I don't understand why it keeps looping like this and failing. Would anyone know why this is happening?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1587067011163,
        "Question_score":1,
        "Question_tags":"docker|amazon-eks|mlflow",
        "Question_view_count":604,
        "Owner_creation_time":1417012835813,
        "Owner_last_access_time":1628782664573,
        "Owner_location":null,
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Question_last_edit_time":null,
        "Answer_body":"<p><code>CrashLoopBackError<\/code> can be related to these possible reasons:<\/p>\n\n<ul>\n<li><p>the application inside your pod is not starting due to an error;<\/p><\/li>\n<li><p>the image your pod is based on is not present in the registry, or the\nnode where your pod has been scheduled cannot pull from the registry;<\/p><\/li>\n<li><p>some parameters of the pod has not been configured correctly.<\/p><\/li>\n<\/ul>\n\n<p>In your case it seems an application error, inside the container.\nTry to view the logs with:<\/p>\n\n<pre><code>kubectl logs &lt;your_pod&gt; -n &lt;namespace&gt;\n<\/code><\/pre>\n\n<p>For more info on how to troubleshoot this kind of error refer to:<\/p>\n\n<p><a href=\"https:\/\/pillsfromtheweb.blogspot.com\/2020\/05\/troubleshooting-kubernetes.html\" rel=\"nofollow noreferrer\">https:\/\/pillsfromtheweb.blogspot.com\/2020\/05\/troubleshooting-kubernetes.html<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1588674359533,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61258979",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57987999,
        "Question_title":"Delete a run in the experiment of mlflow from the UI so the run does not exist in backend store",
        "Question_body":"<p>I found deleting a <code>run<\/code> only change the state from <code>active<\/code> to <code>deleted<\/code>, because the run is still visible in the UI if searching by <code>deleted<\/code>. <\/p>\n\n<p>Is it possible to remove a <code>run<\/code> from the UI to save the space? \nWhen removing a run, does the artifact correspond to the run is also removed?<\/p>\n\n<p>If not, can the run be removed through rest call?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1568794247973,
        "Question_score":6,
        "Question_tags":"mlflow",
        "Question_view_count":3582,
        "Owner_creation_time":1408370821673,
        "Owner_last_access_time":1663216838707,
        "Owner_location":"Berlin, Germany",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Question_last_edit_time":1568796468593,
        "Answer_body":"<p>You can't do it via the web UI but you can from a python terminal<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmlflow.delete_experiment(69)\n<\/code><\/pre>\n\n<p>Where 69 is the experiment ID<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1569793174477,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57987999",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73619538,
        "Question_title":"geting artifacts from mlflow GridSearch run",
        "Question_body":"<p>I'm running a sklearn pipeline with hyperparameter search (let's say GridSearch). Now, I am logging artifacts such as test results and whole-dataset predictions. I'd like to retrieve these artifacts but the mlflow API is getting in the way...<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmlflow.set_tracking_uri(&quot;sqlite:\/\/\/mlruns\/mlruns.db&quot;)\nmlflow.set_registry_uri(&quot;.\/mlruns\/&quot;)\n\nrun_ids = [r.run_id for r in mlflow.list_run_infos(mlflow.get_experiment_by_name(&quot;My Experiment&quot;).experiment_id)]\n<\/code><\/pre>\n<p>With the above code, I can retrieve all runs but I have no way of telling which one is a toplevel run with artifacts logged or a sub-run spawned by the GridSearch procedure.<\/p>\n<p>Is there some way of querying only for <strong>parent<\/strong> runs, so I can retrieve these csv files in order to plot the results? I can of course go to the web api and manually select the run then copy the URI for the file, but I'd like to do it programmatically instead of opening a tab and clicking things.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1662455773517,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":10,
        "Owner_creation_time":1467887362327,
        "Owner_last_access_time":1663866285120,
        "Owner_location":"Spain",
        "Owner_reputation":624,
        "Owner_up_votes":56,
        "Owner_down_votes":2,
        "Owner_views":76,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73619538",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69484727,
        "Question_title":"Pyspark: How to save and apply IndexToString to convert labels back to original values in a new predicted dataset",
        "Question_body":"<p>I am using pyspark.ml.RandomForestClassifier and one of the steps here involves <strong>StringIndexer<\/strong> on the training data target variable to convert it into labels.<\/p>\n<pre><code>indexer = StringIndexer(inputCol = target_variable_name, outputCol = 'label').fit(df)\ndf = indexer.transform(df)\n<\/code><\/pre>\n<p>After fitting the final model I am saving it using mlflow.spark.log_model(). So, when applying the model on a new dataset in future, I just load the model again and apply to the new data:<\/p>\n<pre><code>model = mlflow.sklearn.load_model(&quot;models:\/RandomForest_model\/None&quot;)\npredictions = rfModel.transform(new_data)\n<\/code><\/pre>\n<p>In the new_data the prediction will come as <strong>labels<\/strong> and not in original value. So, if I have to get the original values I have to use <strong>IndexToString<\/strong><\/p>\n<pre><code>labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,labels=indexer.labels)\npredictions = labelConverter.transform(predictions)\n<\/code><\/pre>\n<p>So, the question is, my model doesn't save the <strong>indexer.labels<\/strong> as only the model gets saved. How do, I save and use the indexer.labels from my training dataset on any new dataset. Can this be saved and retrived in mlflow ?<\/p>\n<p>Apologies, if Iam sounding na\u00efve here . But, getting back the original values in the new dataset is really getting me confused.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1633624197133,
        "Question_score":1,
        "Question_tags":"pyspark|databricks|random-forest|apache-spark-mllib|mlflow",
        "Question_view_count":115,
        "Owner_creation_time":1501160366927,
        "Owner_last_access_time":1663743894843,
        "Owner_location":null,
        "Owner_reputation":459,
        "Owner_up_votes":100,
        "Owner_down_votes":0,
        "Owner_views":61,
        "Question_last_edit_time":1633676810887,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69484727",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61879913,
        "Question_title":"ModuleNotFoundError: No module named 'pyspark.dbutils' while running multiple.py file\/notebook on job clusters in databricks",
        "Question_body":"<p>I am working in TravisCI, MlFlow and Databricks environment where .tavis.yml sits at git master branch and detects any change in <code>.py<\/code> file and whenever it gets updated, It will run mlflow command to run .py file in databricks environment. \nmy MLProject file looks as following:<\/p>\n\n<pre><code>name: mercury_cltv_lib\nconda_env: conda-env.yml\n\n\nentry_points:    \n  main:\n    command: \"python3 run-multiple-notebooks.py\"\n<\/code><\/pre>\n\n<p>Workflow is as following:\nTravisCI detects change in master branch-->triggers build which will run MLFlow command and it'll spin up a job cluster in databricks to run .py file from repo.<\/p>\n\n<p>It worked fine with one .py file but when I tried to run multiple notebook using dbutils, it is throwing <\/p>\n\n<pre><code>  File \"run-multiple-notebooks.py\", line 3, in &lt;module&gt;\n    from pyspark.dbutils import DBUtils\nModuleNotFoundError: No module named 'pyspark.dbutils'\n<\/code><\/pre>\n\n<p>Please find below the relevant code section from run-multiple-notebooks.py<\/p>\n\n<pre><code>  def get_spark_session():\n    from pyspark.sql import SparkSession\n    return SparkSession.builder.getOrCreate()\n\n  def get_dbutils(self, spark = None):\n    try:\n        if spark == None:\n            spark = spark\n\n        from pyspark.dbutils import DBUtils #error line\n        dbutils = DBUtils(spark) #error line\n    except ImportError:\n        import IPython\n        dbutils = IPython.get_ipython().user_ns[\"dbutils\"]\n    return dbutils\n\n  def submitNotebook(notebook):\n    print(\"Running notebook %s\" % notebook.path)\n    spark = get_spark_session()\n    dbutils = get_dbutils(spark)\n<\/code><\/pre>\n\n<p>I tried all the options and tried <\/p>\n\n<pre><code>https:\/\/stackoverflow.com\/questions\/61546680\/modulenotfounderror-no-module-named-pyspark-dbutils\n<\/code><\/pre>\n\n<p>as well. It is not working :(<\/p>\n\n<p>Can someone please suggest if there is fix for the above-mentioned error while running .py in job cluster. My code works fine inside databricks local notebook but running from outside using TravisCI and MLFlow isn't working which is must requirement for pipeline automation.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1589840102237,
        "Question_score":2,
        "Question_tags":"pyspark|travis-ci|databricks|mlflow|dbutils",
        "Question_view_count":401,
        "Owner_creation_time":1555347036127,
        "Owner_last_access_time":1663694487237,
        "Owner_location":"Minnesota, USA",
        "Owner_reputation":352,
        "Owner_up_votes":27,
        "Owner_down_votes":1,
        "Owner_views":88,
        "Question_last_edit_time":1589982476477,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61879913",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68547133,
        "Question_title":"Using pytorch_lightning.loggers.MLFlowLogger with azure machine learning studio raises exception mlflow.exceptions.RestException: BAD_REQUEST",
        "Question_body":"<p>I'm trying to locally train pytorch_lightning model and log metrics using  pytorch_lightning.loggers.MLFlowLogger.<\/p>\n<p>It was working fine until last weekend. Now training crashes with error:<\/p>\n<pre><code>mlflow.exceptions.RestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Metric once published using sync API should always use sync API to publish following metrics', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '', 'request': ''}, 'Environment': 'northeurope', 'Location': 'northeurope', 'Time': '2021-07-27T14:06:23.7035319+00:00', 'ComponentName': 'run-history', 'error_code': 'BAD_REQUEST'}\n<\/code><\/pre>\n<p>How to fix this issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1627397531183,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|mlflow|pytorch-lightning",
        "Question_view_count":176,
        "Owner_creation_time":1625582525933,
        "Owner_last_access_time":1656680057217,
        "Owner_location":"Krak\u00f3w, Poland",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68547133",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73321771,
        "Question_title":"Mlflow authorization with spnego",
        "Question_body":"<p>I saw this topic about Kerberos authntication - <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2678\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/2678<\/a> . It was in 2020 . Our team trying to do authentication with kerberos by spnego. We did spnego on nginx server and it is fine - and get code 200 when we do curl to mlflow http uri . BUT we can't do it with mlflow environment variable .<\/p>\n<p>The question is - Does mlflow has some feature to make authentication with spnego or not? Or it has just these environment variables for authentication and such methods :<\/p>\n<ul>\n<li>MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD - username and password to use with HTTP Basic authentication. To use Basic authentication, you must set both environment variables .<\/li>\n<li>MLFLOW_TRACKING_TOKEN - token to use with HTTP Bearer authentication. Basic authentication takes precedence if set.<\/li>\n<li>MLFLOW_TRACKING_INSECURE_TLS - If set to the literal true, MLflow does not verify the TLS connection, meaning it does not validate certificates or hostnames for https:\/\/ tracking URIs. This flag is not recommended for production environments. If this is set to true then MLFLOW_TRACKING_SERVER_CERT_PATH must not be set.<\/li>\n<li>MLFLOW_TRACKING_SERVER_CERT_PATH - Path to a CA bundle to use. Sets the verify param of the requests.request function (see <a href=\"https:\/\/requests.readthedocs.io\/en\/master\/api\/\" rel=\"nofollow noreferrer\">https:\/\/requests.readthedocs.io\/en\/master\/api\/<\/a>). When you use a self-signed server certificate you can use this to verify it on client side. If this is set MLFLOW_TRACKING_INSECURE_TLS must not be set (false).<\/li>\n<li>MLFLOW_TRACKING_CLIENT_CERT_PATH - Path to ssl client cert file (.pem). Sets the cert param of the requests.request function (see <a href=\"https:\/\/requests.readthedocs.io\/en\/master\/api\/\" rel=\"nofollow noreferrer\">https:\/\/requests.readthedocs.io\/en\/master\/api\/<\/a>). This can be used to use a (self-signed) client certificate.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660225498580,
        "Question_score":1,
        "Question_tags":"authentication|kerberos|mlflow|spnego",
        "Question_view_count":25,
        "Owner_creation_time":1536337420893,
        "Owner_last_access_time":1662282588817,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73321771",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65627039,
        "Question_title":"MLflow stores tags but does not return them",
        "Question_body":"<p>I am running the below code to store tags and then to retrieve them. As you can see below, Mlflow is storing one set of tags and returning another.<\/p>\n<pre><code>import mlflow\nwith mlflow.start_run() as active_run:\n    tw = { &quot;run_id&quot;: 1}\n    mlflow.set_tags(tw)            \n    print(&quot;Tags are &quot;, active_run.data.tags)\n    print(type(active_run.data.tags))\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>Tags are  {'mlflow.source.name': '\/media\/Space\/AI\/anaconda4\/lib\/python3.7\/site-packages\/ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'adeel'}\n<\/code><\/pre>\n<p>Looking at the stored tags through mlflow ui, I can see that the tag &quot;run_id&quot; set by the code is actually stored in the run. However, only the header information of the run seems to be getting returned by active_run.data.tags.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1610100575263,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":173,
        "Owner_creation_time":1445990517173,
        "Owner_last_access_time":1663982428387,
        "Owner_location":"Sydney, New South Wales, Australia",
        "Owner_reputation":689,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":87,
        "Question_last_edit_time":1611139529420,
        "Answer_body":"<p>At the moment, you have to query your run again in MLflow to get the run with all the info that you logged. In the example below, I call <code>mlflow.get_run(&lt;run_id&gt;)<\/code> to achieve this.<\/p>\n<pre><code>import mlflow\n\n\nwith mlflow.start_run() as active_run:\n  tags = { &quot;my_tag&quot;: 1}\n  mlflow.set_tags(tags)            \n  # Keep track of the run ID of the active run\n  run_id = active_run.info.run_id\n\nrun = mlflow.get_run(run_id)\nprint(&quot;The tags are &quot;, run.data.tags)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1610128097450,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65627039",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69088149,
        "Question_title":"MlFlow: Can't find runs using api",
        "Question_body":"<p>I try get list of runs, but get empty list.<\/p>\n<p>There are my runs:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/v8uF2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/v8uF2.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But if I try get it using api:\nI expect(<a href=\"https:\/\/mlflow.org\/docs\/latest\/rest-api.html#get-experiment\" rel=\"nofollow noreferrer\">by API<\/a>) that I also watch &quot;runs&quot;, but watch &quot;experiment&quot; only<\/p>\n<pre><code>http:\/\/localhost:5000\/api\/2.0\/mlflow\/experiments\/get?experiment_id=0\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/78a3Y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/78a3Y.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I read in doc, that &quot;This field is deprecated. Please use the \u201cSearch Runs\u201d API to fetch runs within an experiment.&quot;, Ok, I try \u201cSearch Runs\u201d<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/EExIn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EExIn.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Nothing again.<\/p>\n<p>But I try get run by id(from ui):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4eHB7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4eHB7.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I need get list of run ids by experiment id. How can I do it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1631017253323,
        "Question_score":0,
        "Question_tags":"python|api|mlflow",
        "Question_view_count":306,
        "Owner_creation_time":1525702055273,
        "Owner_last_access_time":1664047417137,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":155,
        "Owner_up_votes":34,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69088149",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60667610,
        "Question_title":"How to deploy mlflow model with data preprocessing(text data)",
        "Question_body":"<p>I have developed keras text classification model. I have preprocessed data(tokenization). I have logged trained model successfully(mlflow.keras.log_model). I have served model using mlflow serve. Now while doing prediction on text data I need to do preprocessing using same tokenizer object used for training.\nHow to preprocess test data and get predictions from served model.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1584090517703,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":1996,
        "Owner_creation_time":1498470936987,
        "Owner_last_access_time":1614914388693,
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can log a custom python model: \n<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1584552358667,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60667610",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63806335,
        "Question_title":"How to migrate MlFlow experiments from one Databricks workspace to another with registered models?",
        "Question_body":"<p>so unfortunatly we have to redeploy our Databricks Workspace in which we use the MlFlow functonality with the Experiments and the registering of Models.<\/p>\n<p>However if you export the user folder where the eyperiment is saved with a DBC and import it into the new workspace, the Experiments are not migrated and are just missing.<\/p>\n<p>So the easiest solution did not work. The next thing I tried was to create a new experiment in the new workspace. Copy all the experiment data from the dbfs of the old workspace (with dbfs cp -r dbfs:\/databricks\/mlflow source, and then the same again to upload it to the new workspace) to the new one. And then just reference the location of the data to the experiment like in the following picture:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/emgGs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/emgGs.png\" alt=\"Create Experiment with existing path\" \/><\/a><\/p>\n<p>This is also not working, no run is visible, although the path is already existing.<\/p>\n<p>The next idea was that the registred models are the most important one so at least those should be there and accessible. For that I used the documentation here: <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/model-registry.html\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/model-registry.html<\/a>.<\/p>\n<p>With the following code you get a list of the registred models on the old workspace with the reference on the run_id and location.<\/p>\n<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\nfor rm in client.list_registered_models():\n    pprint(dict(rm), indent=4)\n<\/code><\/pre>\n<p>And with this code you can add models to a model registry with a reference to the location of the artifact data (on the new workspace):<\/p>\n<pre><code># first the general model must be defined\nclient.create_registered_model(name='MyModel')\n\n# and then the run of the model you want to registre will be added to the model as version one\nclient.create_model_version( name='MyModel', run_id='9fde022012046af935fe52435840cf1', source='dbfs:\/databricks\/mlflow\/experiment_id\/run_id\/artifacts\/model')\n<\/code><\/pre>\n<p>But that did also not worked out. if you go into the Model Registry you get a message like this: <a href=\"https:\/\/i.stack.imgur.com\/Ham4y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ham4y.png\" alt=\"error message of the registred model\" \/><\/a>.<\/p>\n<p>And I really checked, at the given path (the source) there the data is really uploaded and also a model is existing.<\/p>\n<p>Do you have any new ideas to migrate those models in Databricks?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1599634821840,
        "Question_score":4,
        "Question_tags":"migration|databricks|azure-databricks|mlflow",
        "Question_view_count":1704,
        "Owner_creation_time":1437927419340,
        "Owner_last_access_time":1655189509997,
        "Owner_location":null,
        "Owner_reputation":416,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":90,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63806335",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73469166,
        "Question_title":"Can we print the configurations on which the MLflow server has started?",
        "Question_body":"<p>I am using the following command to start the MLflow server:<\/p>\n<pre><code>mlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow@localhost\/mlflow  --artifacts-destination &lt;S3 bucket location&gt; --serve-artifacts  -h 0.0.0.0 -p 8000\n<\/code><\/pre>\n<p>Before production deployment, we have a requirement that we need to print or fetch the under what configurations the server is running. For example, the above command uses localhost postgres connection and S3 bucket.<\/p>\n<p>Is there a way to achieve this?<\/p>\n<p>Also, how do I set the server's environment as &quot;production&quot;? So finally I should see a log like this:<\/p>\n<pre><code>[LOG] Started MLflow server:\nEnv: production\npostgres: localhost:5432\nS3: &lt;S3 bucket path&gt;\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1661326653987,
        "Question_score":0,
        "Question_tags":"machine-learning|mlflow|model-management",
        "Question_view_count":17,
        "Owner_creation_time":1484504952247,
        "Owner_last_access_time":1664042089473,
        "Owner_location":"Mumbai, India",
        "Owner_reputation":4433,
        "Owner_up_votes":121,
        "Owner_down_votes":31,
        "Owner_views":885,
        "Question_last_edit_time":1661327087603,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73469166",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72443352,
        "Question_title":"How to save summary of pyGAM using MLflow?",
        "Question_body":"<p>Getting None in return while trying to save output of pyGAM summary function in a variable or file to log it using MLflow .<\/p>\n<pre><code>gam = LinearGAM(s(0, n_splines=20) + s(1) + s(2)+ s(3)+s(4)+s(5)+s(6)+s(7)+s(8)+s(9)+s(10)+s(11)+s(12)+s(13)+s(14)+s(15)+s(16)+s(17)).fit(X_GAM, Y_GAM)\ngam.summary()\noutput = gam.summary()\ntype(output)\n<\/code><\/pre>\n<p><strong>Output:<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ub0Gs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ub0Gs.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>NoneType<\/p>\n<p>Is there any efficient way to store pyGAM summary output using MLflow?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1653979981097,
        "Question_score":0,
        "Question_tags":"python-3.x|machine-learning|mlflow|pygam",
        "Question_view_count":28,
        "Owner_creation_time":1452602206603,
        "Owner_last_access_time":1663948894330,
        "Owner_location":"Kolkata, West Bengal, India",
        "Owner_reputation":55,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":1653981428130,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72443352",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72473826,
        "Question_title":"When to use mlflow.set_tag() vs mlflow.log_params()?",
        "Question_body":"<p>I am confused about the usecase of mlflow.set_tag() vs mlflow.log_params() as both takes key and value pair. Currently, I use mlflow.set_tag() to set tags for data version, code version, etc and mlflow.log_params() to set model training parameters like loss, accuracy, optimizer, etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1654161812087,
        "Question_score":1,
        "Question_tags":"machine-learning|mlflow",
        "Question_view_count":77,
        "Owner_creation_time":1473408279707,
        "Owner_last_access_time":1663860023897,
        "Owner_location":"Germany",
        "Owner_reputation":620,
        "Owner_up_votes":49,
        "Owner_down_votes":1,
        "Owner_views":101,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72473826",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69573565,
        "Question_title":"How to configure artifact store of mlflow tracking service to connect to minio S3 using minio STS generated acces_key, secret_key and session_token",
        "Question_body":"<ul>\n<li><p>Minio is configured with LDAP and am generating credentials of user\nwith AssumeRoleWithLDAPIdentity using STS API (<a href=\"https:\/\/docs.min.io\/minio\/baremetal\/security\/ad-ldap-external-identity-management\/AssumeRoleWithLDAPIdentity.html#assumerolewithldapidentity\" rel=\"nofollow noreferrer\">reference<\/a>)<\/p>\n<\/li>\n<li><p>From above values, I'm setting the variables AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_SESSION_TOKEN (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#amazon-s3-and-s3-compatible-storage\" rel=\"nofollow noreferrer\">reference<\/a>)<\/p>\n<\/li>\n<\/ul>\n<p>I'm getting error when am trying to push model to mlflow to store in minio artifact<\/p>\n<pre><code>S3UploadFailedError: Failed to upload \/tmp\/tmph68xubhm\/model\/MLmodel to mlflow\/1\/xyz\/artifacts\/model\/MLmodel: An error occurred (InvalidTokenId) when calling the PutObject operation: The security token included in the request is invalid\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1634225910190,
        "Question_score":2,
        "Question_tags":"amazon-s3|minio|mlflow|mlops",
        "Question_view_count":255,
        "Owner_creation_time":1496203946490,
        "Owner_last_access_time":1664009984060,
        "Owner_location":null,
        "Owner_reputation":838,
        "Owner_up_votes":89,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69573565",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72239105,
        "Question_title":"MLFlow Webhook calling Azure DevOps pipeline - retrieve body",
        "Question_body":"<p>I am using the MLFlow Webhooks , mentioned <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-registry-webhooks\" rel=\"nofollow noreferrer\">here<\/a>. I am using that to queue an Azure Devops Pipeline.<\/p>\n<p>However, I can't seem to to find a way to retrieve the payload variables inside my pipeline.<\/p>\n<p>E.g. during transition of models, according to the document, such a payload is passed<\/p>\n<pre><code>POST\n\/your\/endpoint\/for\/event\/model-versions\/stage-transition\n--data {\n  &quot;event&quot;: &quot;MODEL_VERSION_TRANSITIONED_STAGE&quot;,\n  &quot;webhook_id&quot;: &quot;c5596721253c4b429368cf6f4341b88a&quot;,\n  &quot;event_timestamp&quot;: 1589859029343,\n  &quot;model_name&quot;: &quot;Airline_Delay_SparkML&quot;,\n  &quot;version&quot;: &quot;8&quot;,\n  &quot;to_stage&quot;: &quot;Production&quot;,\n  &quot;from_stage&quot;: &quot;None&quot;,\n  &quot;text&quot;: &quot;Registered model 'someModel' version 8 transitioned from None to Production.&quot;\n}\n<\/code><\/pre>\n<p>My webhook is created like this:<\/p>\n<pre><code>mlflow_webhook_triggerDevOps={\n  &quot;events&quot;: [&quot;TRANSITION_REQUEST_CREATED&quot;, &quot;REGISTERED_MODEL_CREATED&quot;],\n  &quot;description&quot;: &quot;Integration with Azure DevOps&quot;,\n  &quot;status&quot;: &quot;ACTIVE&quot;,\n  &quot;http_url_spec&quot;: {\n                    &quot;url&quot;: &quot;https:\/\/dev.azure.com\/orgname\/ProjectName\/_apis\/build\/builds?definitionId=742&amp;api-version=6.0&quot;,\n                    &quot;authorization&quot;: &quot;Basic &quot; + base64_message\n                    }\n }\n\nmlflow_createwebhook=requests.post('https:\/\/databricksurl\/api\/2.0\/mlflow\/registry-webhooks\/create', headers=header, proxies=proxies, json=mlflow_webhook_body)\n<\/code><\/pre>\n<p>How do I then retrieve the payload variable e.g. model_name, inside my pipeline definition in Azure Devops?.<\/p>\n<p>I looked at <a href=\"https:\/\/stackoverflow.com\/questions\/50838651\/vsts-use-api-to-set-build-parameters-at-queue-time\">this post<\/a>, but I can't seem to see any payload information (like mentioned above) under the Network-payload tab (or I am not using properly).<\/p>\n<p>Right now, I can trigger the pipeline, but can't seem to find a way to retrieve the payload.<\/p>\n<p>Is it possible? Am I missing something?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1652522121283,
        "Question_score":1,
        "Question_tags":"azure-devops|databricks|webhooks|azure-databricks|mlflow",
        "Question_view_count":125,
        "Owner_creation_time":1428654714763,
        "Owner_last_access_time":1664012257383,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72239105",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67472983,
        "Question_title":"Can MLFlow log new metrics in a terminated run?",
        "Question_body":"<p>I would like to use MLFlow (with Python) to log time series with time interval equal to 1 day.\nMy idea would be to create a new run with a certain ID and to use function <code>log_metric<\/code> every day (say, with a cron job) with a new value. Once my run is terminated, can I &quot;reopen&quot; it and log a new metric ?\nWhat I have in mind is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># Day 1\nimport mlflow\n\ntracking_uri = &quot;my_uri&quot;\nmlflow.set_tracking_uri(tracking_uri)\nxp_id = 0\nmlflow.start_run(run_name=&quot;test&quot;, experiment_id=xp_id)\nmlflow.log_metric(&quot;test_metric&quot;, 1)\nmlflow.end_run()\n<\/code><\/pre>\n<p>And the following days:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\ndef log_daily_metric(daily_value_metric):\n  tracking_uri = &quot;my_uri&quot;\n  mlflow.set_tracking_uri(tracking_uri)\n  xp_id = 0\n  mlflow.restart_run(run_name=&quot;test&quot;, experiment_id=xp_id)  # \/!\\ function mlflow.restart does not exist\n  mlflow.log_metric(&quot;test_metric&quot;, daily_value_metric)\n  mlflow.end_run()\n<\/code><\/pre>\n<p>so that run <code>&quot;test&quot;<\/code> would have new metrics logged every day.<\/p>\n<p>Any idea to achieve this ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1620659322073,
        "Question_score":2,
        "Question_tags":"python-3.x|time-series|mlflow",
        "Question_view_count":274,
        "Owner_creation_time":1539181664153,
        "Owner_last_access_time":1663922812787,
        "Owner_location":"Nice, France",
        "Owner_reputation":1247,
        "Owner_up_votes":690,
        "Owner_down_votes":9,
        "Owner_views":191,
        "Question_last_edit_time":1620662360137,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67472983",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70962095,
        "Question_title":"what is the difference between Duration, TT (Training Time), RunTime on ML Performance Report of mlflow",
        "Question_body":"<p>I compared the performance of machine learning algorithms by applying pycaret and k-fold on a data and reported it on mlflow. There are three time columns in the report, these are duration, TT(training time) and runtime. When I look at these times, they are all different from each other. I know the training time, but what are the other times?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1643831868733,
        "Question_score":0,
        "Question_tags":"machine-learning|classification|mlflow|pycaret",
        "Question_view_count":54,
        "Owner_creation_time":1642027182437,
        "Owner_last_access_time":1648553902727,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1643835272060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70962095",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70792868,
        "Question_title":"Serving MLFlow artifacts through `--serve-artifacts` without passing credentials",
        "Question_body":"<p>A new version of MLFlow (1.23) provided a <code>--serve-artifacts<\/code> option (via <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/5045\" rel=\"nofollow noreferrer\">this<\/a> pull request) along with some example code. This <em>should<\/em> allow me to simplify the rollout of a server for data scientists by only needing to give them one URL for the tracking server, rather than a URI for the tracking server, URI for the artifacts server, and a username\/password for the artifacts server. At least, that's how I understand it.<\/p>\n<p>A complication that I have is that I need to use <code>podman<\/code> instead of <code>docker<\/code> for my containers (and without relying on <code>podman-compose<\/code>). I ask that you keep those requirements in mind; I'm aware that this is an odd situation.<\/p>\n<p>What I did before this update (for MLFlow 1.22) was to create a kubernetes play yaml config, and I was successfully able to issue a <code>podman play kube ...<\/code> command to start a pod and from a different machine successfully run an experiment and save artifacts after setting the appropriate four env variables. I've been struggling with getting things working with the newest version.<\/p>\n<p>I am following the <code>docker-compose<\/code> example provided <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/mlflow_artifacts\" rel=\"nofollow noreferrer\">here<\/a>. I am trying a (hopefully) simpler approach. The following is my kubernetes play file defining a pod.<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>apiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: &quot;2022-01-14T19:07:15Z&quot;\n  labels:\n    app: mlflowpod\n  name: mlflowpod\nspec:\n  containers:\n  - name: minio\n    image: quay.io\/minio\/minio:latest\n    ports:\n    - containerPort: 9001\n      hostPort: 9001\n    - containerPort: 9000\n      hostPort: 9000\n    resources: {}\n    tty: true\n    volumeMounts:\n    - mountPath: \/data\n      name: minio-data\n    args:\n    - server\n    - \/data\n    - --console-address\n    - :9001\n\n  - name: mlflow-tracking\n    image: localhost\/mlflow:latest\n    ports:\n    - containerPort: 80\n      hostPort: 8090\n    resources: {}\n    tty: true\n    env:\n      - name: MLFLOW_S3_ENDPOINT_URL\n        value: http:\/\/127.0.0.1:9000\n      - name: AWS_ACCESS_KEY_ID\n        value: minioadmin\n      - name: AWS_SECRET_ACCESS_KEY\n        value: minioadmin\n    command: [&quot;mlflow&quot;]\n    args:\n      - server\n      - -p \n      - 80\n      - --host \n      - 0.0.0.0\n      - --backend-store-uri \n      - sqlite:\/\/\/root\/store.db\n      - --serve-artifacts\n      - --artifacts-destination \n      - s3:\/\/mlflow\n      - --default-artifact-root \n      - mlflow-artifacts:\/\n#      - http:\/\/127.0.0.1:80\/api\/2.0\/mlflow-artifacts\/artifacts\/experiments\n      - --gunicorn-opts \n      - &quot;--log-level debug&quot;\n    volumeMounts:\n    - mountPath: \/root\n      name: mlflow-data  \n\n  volumes:\n  - hostPath:\n      path: .\/minio\n      type: Directory\n    name: minio-data\n  - hostPath:\n      path: .\/mlflow\n      type: Directory\n    name: mlflow-data\nstatus: {}\n<\/code><\/pre>\n<p>I start this with <code>podman play kube mlflowpod.yaml<\/code>. On the same machine (or a different one, it doesn't matter), I have cloned and installed <code>mlflow<\/code> into a virtual environment. From that virtual environment, I set an environmental variable <code>MLFLOW_TRACKING_URI<\/code> to <code>&lt;name-of-server&gt;:8090<\/code>. I then run the <code>example.py<\/code> file in the <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/mlflow_artifacts\" rel=\"nofollow noreferrer\"><code>mlflow_artifacts<\/code><\/a> example directory. I get the following response:<\/p>\n<pre><code>....\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>\n<p>Which seems like the client needs the server credentials to minIO, which I thought the proxy was supposed to take care of.<\/p>\n<p>If I also provide the env variables<\/p>\n<pre><code>$env:MLFLOW_S3_ENDPOINT_URL=&quot;http:\/\/&lt;name-of-server&gt;:9000\/&quot; \n$env:AWS_ACCESS_KEY_ID=&quot;minioadmin&quot;\n$env:AWS_SECRET_ACCESS_KEY=&quot;minioadmin&quot;\n<\/code><\/pre>\n<p>Then things work. But that kind of defeats the purpose of the proxy...<\/p>\n<p>What is it about the proxy setup via kubernates play yaml and podman that is going wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1642709711853,
        "Question_score":1,
        "Question_tags":"kubernetes|mlflow|podman",
        "Question_view_count":773,
        "Owner_creation_time":1321286030420,
        "Owner_last_access_time":1642791786807,
        "Owner_location":null,
        "Owner_reputation":428,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Question_last_edit_time":1642710219863,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70792868",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56088195,
        "Question_title":"mlflow can't find .py file",
        "Question_body":"<p>I'm trying to learn to use <code>mlflow<\/code> by creating a very simple project and log it.<\/p>\n\n<p>I've tried following <code>mlflow<\/code>'s example and my code runs properly when running the main.py as a normal bash command.<\/p>\n\n<p>I couldn't make it run using the <code>mlflow<\/code> CLI using project and a simple file.\nI got the following error.<\/p>\n\n<pre><code>(rlearning) yair@pc2016:~\/reinforced_learning101$ mlflow run src\/main.py \n2019\/05\/11 10:21:41 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===\n(rlearning) yair@pc2016:~\/reinforced_learning101$ mlflow run .\n2019\/05\/11 10:40:25 INFO mlflow.projects: === Created directory \/tmp\/tmpe26oernf for downloading remote URIs passed to arguments of type 'path' ===\n2019\/05\/11 10:40:25 INFO mlflow.projects: === Running command 'source activate mlflow-21497056aed7961402b515847613ed9f950fa9fc &amp;&amp; python src\/main.py 1.0' in run with ID 'ed51446de4c44903ab891d09cfe10e49' === \nbash: activate: No such file or directory\n2019\/05\/11 10:40:25 ERROR mlflow.cli: === Run (ID 'ed51446de4c44903ab891d09cfe10e49') failed ===\n\n<\/code><\/pre>\n\n<p>Needless to say my main has a <code>.py<\/code> suffix.<\/p>\n\n<p>Is there anything wrong that causes this issue?<\/p>\n\n<p>My main.py is:<\/p>\n\n<pre><code>import sys\n\nimport gym\nimport mlflow\n\n\nif __name__ == '__main__':\n    env = gym.make(\"CartPole-v0\")\n    right_percent = float(sys.argv[1]) if len(sys.argv) &gt; 1 else 1.0\n    with mlflow.start_run():\n        obs = env.reset()\n        print(env.action_space)\n        action = 1  # accelerate right\n        print(obs)\n        mlflow.log_param(\"right percent\", right_percent)\n        mlflow.log_metric(\"mean score\", 1)\n        mlflow.log_metric(\"std score\", 0)\n<\/code><\/pre>\n\n<p>conda_env.yaml<\/p>\n\n<pre><code>name: rlearning\nchannels:\n  - defaults\ndependencies:\n  - python=3.7\n  - numpy\n  - pandas\n  - tensorflow-gpu\n  - pip:\n      - mlflow\n      - gym\n<\/code><\/pre>\n\n<p>MLproject<\/p>\n\n<pre><code>name: reinforced learning\n\nconda_env: files\/config\/conda_environment.yaml\n\nentry_points:\n  main:\n    parameters:\n      right_percent: {type: float, default: 1.0}\n    command: \"python src\/main.py {right_percent}\"\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1557559963290,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":1263,
        "Owner_creation_time":1435222208620,
        "Owner_last_access_time":1662621569283,
        "Owner_location":"London, UK",
        "Owner_reputation":91,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Question_last_edit_time":1557560675393,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56088195",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58917918,
        "Question_title":"How to make predictions using a model that requires an input shape with more than two dimensions using MLflow?",
        "Question_body":"<p>I'm trying to implement a tensorflow (keras) based model into mlflow while learning how it works and if it suite our needs. I'm trying to implement the Fashion MNIST example from tensorflow website <a href=\"https:\/\/www.tensorflow.org\/tutorials\/keras\/classification?hl=it\" rel=\"nofollow noreferrer\">Here the link<\/a><\/p>\n\n<p>I was able to train and to log the model successfully into mlflow using this code:<\/p>\n\n<pre><code>import mlflow\nimport mlflow.tensorflow\nimport mlflow.keras\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\nfashion_mnist = keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\nclass_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\ntrain_images = train_images \/ 255.0\n\ntest_images = test_images \/ 255.0\n\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n\nif __name__ == \"__main__\":\n\n    model.fit(train_images, train_labels, epochs=10)\n    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n    print('\\nTest accuracy:', test_acc)\n\n    mlflow.log_metric(\"validation accuracy\", float(test_acc))\n    mlflow.log_metric(\"validation loss\", float(test_loss))\n    mlflow.keras.log_model(model, \n                        \"model\", \n                        registered_model_name = \"Fashion MNIST\")\n<\/code><\/pre>\n\n<p>Then I'm now serving it with the models serve subcommand<\/p>\n\n<pre><code>$ mlflow models serve -m [model_path_here] -p 1234\n<\/code><\/pre>\n\n<p>The problem is that I'm not able to make predictions:<\/p>\n\n<pre><code>fashion_mnist = keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\ntrain_images = train_images \/ 255.0\ntest_images = test_images \/ 255.0\nlabels = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nurl = \"http:\/\/127.0.0.1:1234\/invocations\"\n\nto_predict = test_images[0]\n\ndata = {\n    \"data\": [to_predict.tolist()]\n}\nheaders = {'Content-type': 'application\/json', 'Accept': 'text\/plain'}\nr = requests.post(url, data=json.dumps(data), headers=headers)\nres = r.json()\n<\/code><\/pre>\n\n<p>I'm getting this error:<\/p>\n\n<pre><code>{'error_code': 'BAD_REQUEST', 'message': 'Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.', 'stack_trace': 'Traceback (most recent call last):\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\", line 196, in transformation\\n    raw_predictions = model.predict(data)\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/mlflow\/keras.py\", line 298, in predict\\n    predicted = pd.DataFrame(self.keras_model.predict(dataframe))\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/engine\/training.py\", line 909, in predict\\n    use_multiprocessing=use_multiprocessing)\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/engine\/training_arrays.py\", line 715, in predict\\n    x, check_steps=True, steps_name=\\'steps\\', steps=steps)\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/engine\/training.py\", line 2472, in _standardize_user_data\\n    exception_prefix=\\'input\\')\\n  File \"\/home\/ferama\/.local\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/engine\/training_utils.py\", line 564, in standardize_input_data\\n    \\'with shape \\' + str(data_shape))\\nValueError: Error when checking input: expected flatten_input to have 3 dimensions, but got array with shape (1, 28)\\n'}\n<\/code><\/pre>\n\n<p>That code above worked fine with a one dimension model<\/p>\n\n<p>The error seems to me related to the fact that a pandas DataFrame is a two dimensional data structure and the model instead requires a three dimensional input.<\/p>\n\n<p>The latest words from the error \"...but got array with shape (1, 28)\". The input shape should be (1, 28, 28) instead<\/p>\n\n<p>There is a way to use this kind of models with mlflow? There is a way to serialize and send numpy arrays directly as input instead of pandas dataframes?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1574090895563,
        "Question_score":3,
        "Question_tags":"python|tensorflow|keras|mlflow",
        "Question_view_count":1221,
        "Owner_creation_time":1293720910407,
        "Owner_last_access_time":1641627502447,
        "Owner_location":null,
        "Owner_reputation":503,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58917918",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64354220,
        "Question_title":"Permission denied writing artifacts to an NFS-mounted PVC",
        "Question_body":"<p>I'm attempting to write MLflow artifacts to an NFS-mounted PVC. It's a new PVC mounting at <code>\/opt\/mlflow<\/code>, but MLflow seems to have permission writing to it. The specific error I'm getting is<\/p>\n<pre><code>PermissionError: [Errno 13] Permission denied: '\/opt\/mlflow'\n<\/code><\/pre>\n<p>I ran the same deployment with an S3-backed artifact store, and that worked just fine. That was on my home computer though, and I don't have the ability to do that at work. The MLflow documentation seems to indicate that I don't need any special syntax for NFS mounts.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1602681645387,
        "Question_score":1,
        "Question_tags":"kubernetes|mlflow|kubernetes-pvc",
        "Question_view_count":432,
        "Owner_creation_time":1586788742313,
        "Owner_last_access_time":1607609300903,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1607049416233,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64354220",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62865250,
        "Question_title":"How to serve AI models in a multi-tenant environment in scale?",
        "Question_body":"<p>I have a servers cluster, each server gets real-time authentication events as requests, and returns a risk score for the incoming event, based on AI models that sits in S3.<\/p>\n<p>This cluster serves multiple customers. Each customer has its own AI model in S3.\nEach AI model file in S3 size is ~50MB in size.<\/p>\n<p><strong>The problem:<\/strong><\/p>\n<p>Let's say this cluster consists of 10 servers, and it serves 20 customers. Respectively, there are 20 AI models in S3.<\/p>\n<p>In a naive solution, each server in the cluster might end up loading all the 20 models from S3 to the server memory.\n20(servers in the cluster)*50MB(model size in S3) = 1GB.\nIt takes long time to download the model and load it to memory, and the amount of memory is limited to the memory capacity of the server.\nAnd of course - these problems get bigger with scale.<\/p>\n<p>So what are my options?\nI know that there are out of the box products for model life cycle management, such as: MlFlow, KubeFlow, ...\nDo these products have a solution to the problem I raised?<\/p>\n<p>Maybe use Redis as a cache layer?<\/p>\n<p>Maybe use Redis as a cache layer in combination with MlFlow and KubeFlow?<\/p>\n<p>Any other solution?<\/p>\n<p><strong>Limitation:<\/strong>\nI can't have sticky session between the servers in that cluster, so I can't ensure all the requests of the same customer will end up in the same server.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1594579872523,
        "Question_score":0,
        "Question_tags":"artificial-intelligence|scalability|mlflow|kubeflow",
        "Question_view_count":504,
        "Owner_creation_time":1289286902413,
        "Owner_last_access_time":1663763347283,
        "Owner_location":null,
        "Owner_reputation":1806,
        "Owner_up_votes":104,
        "Owner_down_votes":3,
        "Owner_views":148,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62865250",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68501612,
        "Question_title":"MLflow saves models to relative place instead of tracking_uri",
        "Question_body":"<p>sorry if my question is too basic, but cannot solve it.\nI am experimenting with mlflow currently and facing the following issue:<\/p>\n<p>Even if I have set the <em>tracking_uri<\/em>, the mlflow artifacts are saved to the <em>.\/mlruns\/...<\/em> folder relative to the path from where I run <code>mlfow run path\/to\/train.py<\/code> (in command line). The mlflow server searches for the artifacts following the <em>tracking_uri<\/em> (<code>mlflow server --default-artifact-root here\/comes\/the\/same\/tracking_uri<\/code>).<\/p>\n<p>Through the following example it will be clear what I mean:<\/p>\n<p>I set the following in the training script before the <code>with mlflow.start_run() as run:<\/code><\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;file:\/\/\/home\/@myUser\/@SomeFolders\/mlflow_artifact_store\/mlruns\/&quot;)\n<\/code><\/pre>\n<p>My expectation would be that mlflow saves all the artifacts to the place I gave in the registry uri. Instead, it saves the artifacts relative to place from where I run <code>mlflow run path\/to\/train.py<\/code>, i.e. running the following<\/p>\n<pre><code>\/home\/@myUser\/ mlflow run path\/to\/train.py\n<\/code><\/pre>\n<p>creates the structure:<\/p>\n<pre><code>\/home\/@myUser\/mlruns\/@experimentID\/@runID\/artifacts\n\/home\/@myUser\/mlruns\/@experimentID\/@runID\/metrics\n\/home\/@myUser\/mlruns\/@experimentID\/@runID\/params\n\/home\/@myUser\/mlruns\/@experimentID\/@runID\/tags\n<\/code><\/pre>\n<p>and therefore it doesn't find the run artifacts in the tracking_uri, giving the error message:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;train.py&quot;, line 59, in &lt;module&gt;\n    with mlflow.start_run() as run:\n  File &quot;\/home\/@myUser\/miniconda3\/envs\/mlflow-ff56d6062d031d43990effc19450800e72b9830b\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 204, in start_run\n    active_run_obj = client.get_run(existing_run_id)\n  File &quot;\/home\/@myUser\/miniconda3\/envs\/mlflow-ff56d6062d031d43990effc19450800e72b9830b\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py&quot;, line 151, in get_run\n    return self._tracking_client.get_run(run_id)\n  File &quot;\/home\/@myUser\/miniconda3\/envs\/mlflow-ff56d6062d031d43990effc19450800e72b9830b\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 57, in get_run\n    return self.store.get_run(run_id)\n  File &quot;\/home\/@myUser\/miniconda3\/envs\/mlflow-ff56d6062d031d43990effc19450800e72b9830b\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py&quot;, line 524, in get_run\n    run_info = self._get_run_info(run_id)\n  File &quot;\/home\/@myUser\/miniconda3\/envs\/mlflow-ff56d6062d031d43990effc19450800e72b9830b\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/file_store.py&quot;, line 544, in _get_run_info\n    &quot;Run '%s' not found&quot; % run_uuid, databricks_pb2.RESOURCE_DOES_NOT_EXIST\nmlflow.exceptions.MlflowException: Run '788563758ece40f283bfbf8ba80ceca8' not found\n2021\/07\/23 16:54:16 ERROR mlflow.cli: === Run (ID '788563758ece40f283bfbf8ba80ceca8') failed ===\n<\/code><\/pre>\n<p>Why is that so? How can I change the place where the artifacts are stored, this directory structure is created? I have tried <code>mlflow run --storage-dir here\/comes\/the\/path<\/code>, setting the <em>tracking_uri<\/em>, <em>registry_uri<\/em>. If I run the <code>\/home\/path\/to\/tracking\/uri mlflow run path\/to\/train.py<\/code> it works, but I need to run the scripts remotely.<\/p>\n<p>My endgoal would be to change the artifact uri to an NFS drive, but even in my local computer I cannot do the trick.<\/p>\n<p>Thanks for reading it, even more thanks if you suggest a solution! :)\nHave a great day!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1627054156107,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":785,
        "Owner_creation_time":1512572031753,
        "Owner_last_access_time":1655968570680,
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68501612",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59827478,
        "Question_title":"How to get current run_id inside of mlflow.start_run()?",
        "Question_body":"<p><code>mlflow.active_run()<\/code> returns nothing so I can't just use\n<code>current_rui_id = mlflow.active_run().info.run_id<\/code><\/p>\n\n<p>I have to get <strong>run_id<\/strong> inside of this construction for being able to continue logging parameters,  metrics and artifacts inside of another block but for the same model:<\/p>\n\n<pre><code>with mlflow.start_run(run_name=\"test_ololo\"):\n\n    \"\"\" \n       fitting a model here ...\n    \"\"\"\n\n    for name, val in metrics:\n        mlflow.log_metric(name, np.float(val))\n\n    # Log our parameters into mlflow\n    for k, v in params.items():\n        mlflow.log_param(key=k, value=v)\n\n    pytorch.log_model(learn.model, f'model')\n    mlflow.log_artifact('.\/outputs\/fig.jpg')\n<\/code><\/pre>\n\n<p>I have to get current <strong>run_id<\/strong> to continue training inside the same run<\/p>\n\n<pre><code>with mlflow.start_run(run_id=\"215d3a71925a4709a9b694c45012988a\"):\n\n    \"\"\"\n       fit again\n       log_metrics\n    \"\"\"\n\n    pytorch.log_model(learn.model, f'model')\n    mlflow.log_artifact('.\/outputs\/fig2.jpg')\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1579537993127,
        "Question_score":4,
        "Question_tags":"python|mlflow",
        "Question_view_count":6042,
        "Owner_creation_time":1443627469260,
        "Owner_last_access_time":1663849445573,
        "Owner_location":null,
        "Owner_reputation":863,
        "Owner_up_votes":100,
        "Owner_down_votes":2,
        "Owner_views":22,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59827478",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67677780,
        "Question_title":"MLFlow run: Pass parameters in a file instead of key\/value pairs",
        "Question_body":"<p>Usually when running an MLProject, I would use something similar to:<\/p>\n<pre><code>mlflow run . -P alpha=0.1 -P l1_ratio=0.9\n<\/code><\/pre>\n<p>Is it possible to pass a file containing the key\/value pairs instead ? so something like:<\/p>\n<pre><code>mlflow run . --file .\/parametrs\n<\/code><\/pre>\n<p>where .\/parameters contains the key\/value pairs (like an env file or something)<\/p>\n<p>One way I thought of is to make a seperate bash script that accept the file and extracts the key\/value pairs to be included in the run command, but I wonder if there's a way more native to mlflow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1621883888327,
        "Question_score":1,
        "Question_tags":"python|machine-learning|mlflow|mlops",
        "Question_view_count":222,
        "Owner_creation_time":1540654775053,
        "Owner_last_access_time":1663859840653,
        "Owner_location":"Tunisia",
        "Owner_reputation":606,
        "Owner_up_votes":42,
        "Owner_down_votes":8,
        "Owner_views":69,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It's not supported functionality according to <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-run\" rel=\"nofollow noreferrer\">documentation<\/a>, and <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/cli.py#L124\" rel=\"nofollow noreferrer\">source code<\/a>, so you'll need to add your own wrapper to read parameters from file &amp; pass them explicitly.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1621931875960,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67677780",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65992591,
        "Question_title":"send post request using curl to mlflow api to multiple records",
        "Question_body":"<p>I have served an mlflow model and am sending POST requests in this format:<\/p>\n<pre><code>curl -X POST -H &quot;Content-Type:application\/json; format=pandas-split&quot; \n--data '{&quot;columns&quot;:[&quot;alcohol&quot;, &quot;chlorides&quot;, &quot;citric acid&quot;, &quot;density&quot;, \n&quot;fixed acidity&quot;, &quot;free sulfur dioxide&quot;, &quot;pH&quot;, &quot;residual sugar&quot;, &quot;sulphates&quot;, \n&quot;total sulfur dioxide&quot;, &quot;volatile acidity&quot;],&quot;data&quot;:[[12.8, 0.029, 0.48, 0.98, \n6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' \nhttp:\/\/127.0.0.1:1234\/invocations\n<\/code><\/pre>\n<p>It is getting scored. However for my particular project, the input to rest api for scoring will always be multiple records in dataframe\/csv format instead of a single record. Can someone point me to how to achieve this ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1612181841393,
        "Question_score":1,
        "Question_tags":"curl|post|deployment|mlflow|serving",
        "Question_view_count":407,
        "Owner_creation_time":1573739890560,
        "Owner_last_access_time":1663922252563,
        "Owner_location":null,
        "Owner_reputation":115,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65992591",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70005957,
        "Question_title":"Logging the git_sha as a parameter on Mlflow using Kedro hooks",
        "Question_body":"<p>I would like to log the git_sha parameter on Mlflow as shown in the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/07_extend_kedro\/02_hooks.html?highlight=run_params#add-metrics-tracking-to-your-model\" rel=\"nofollow noreferrer\">documentation<\/a>. What appears to me here, is that simply running the following portion of code should be enough to get git_sha logged in the Mlflow UI. Am I right ?<\/p>\n<pre><code>@hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n<\/code><\/pre>\n<p>But this does not work as I get all but the git_sha parameter. And when I look at the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/_modules\/kedro\/framework\/hooks\/specs.html?highlight=run_params#\" rel=\"nofollow noreferrer\">hooks specs<\/a>, it seems that this param is not part of run_params (anymore?)<\/p>\n<p>Is there a way I could get the git sha (maybe from the context journal ?) and add it to the logged parameters ?<\/p>\n<p>Thank you in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1637158421443,
        "Question_score":0,
        "Question_tags":"python|mlflow|kedro|mlops",
        "Question_view_count":172,
        "Owner_creation_time":1586517832390,
        "Owner_last_access_time":1660328393330,
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":1637158766987,
        "Answer_body":"<p>Whilst it's heavily encouraged to use git with Kedro it's not required and as such no part of Kedro (except <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro-starters\" rel=\"nofollow noreferrer\">kedro-starters<\/a> if we're being pedantic) is 'aware' of git.<\/p>\n<p>In your <code>before_pipeline_hook<\/code> there it is pretty easy for you to retrieve the info <a href=\"https:\/\/stackoverflow.com\/questions\/14989858\/get-the-current-git-hash-in-a-python-script\">via the techniques documented here<\/a>. It seems trivial for the whole codebase, a bit more involved if you want to say provide pipeline specific hashes.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1637159193837,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70005957",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61427012,
        "Question_title":"can I use mlflow python API to register a spark UDF & then use the UDF in Spark scala code?",
        "Question_body":"<p>I'm trying to use mlflow to do the machine learning work. I register the ML model as UDF using the following python code. The question is how can I use the UDF(test_predict) in my scala code? The reason is that our main code is in Scala. The problem is that UDF created below is a temporary UDF and SparkSession scoped. thanks!<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport mlflow\nfrom mlflow import pyfunc\nimport numpy as np\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark import SQLContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\n\nsc=SparkContext()\nspark = SparkSession.builder.appName(\"Python UDF example\").getOrCreate()\npyfunc_udf=mlflow.pyfunc.spark_udf(spark=spark, model_uri=\".\/sk\",result_type=\"float\")\nspark.udf.register(\"test_predict\",pyfunc_udf)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1587824105457,
        "Question_score":2,
        "Question_tags":"python|apache-spark|pyspark|user-defined-functions|mlflow",
        "Question_view_count":617,
        "Owner_creation_time":1553506414607,
        "Owner_last_access_time":1614866413497,
        "Owner_location":null,
        "Owner_reputation":129,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Question_last_edit_time":1588065231427,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61427012",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57980954,
        "Question_title":"when using python open() on mac, getting \"[Errno 2] no such file or directory: 'file:\/\/\/absolute\/path\/' \", path generated from MLflow",
        "Question_body":"<p>I imagine this has been answered, but I could not find.<\/p>\n\n<p>I am attempting to use:<\/p>\n\n<pre><code>with open('file:\/\/\/absolute\/path\/to\/file') as fn:\n     csv-stuff\n<\/code><\/pre>\n\n<p>however, I am getting Error : <\/p>\n\n<blockquote>\n  <p>\"[Errno 2] No such file or directory: 'file:\/\/\/absolute\/path\/to\/file'\"<\/p>\n<\/blockquote>\n\n<p>The absolute file path is being generated within the following commands from os and mlflow:<\/p>\n\n<pre><code>data_uri = os.path.join(run.info.artifact_uri, \"data\")\n<\/code><\/pre>\n\n<p>where \"data\" was logged without a artifact_path specified with:<\/p>\n\n<pre><code>mlflow.log_artifact(tempfile_path,\"data\")\n<\/code><\/pre>\n\n<p>I have been stuck on this for a few days and have not figured out the issue yet. Thanks for the help!<\/p>\n\n<p>P.S. This is my first post, feel free to tell me if I am doing something wrong. Thanks.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1568748928353,
        "Question_score":1,
        "Question_tags":"python-3.x|macos|mlflow|nosuchfileexception",
        "Question_view_count":30,
        "Owner_creation_time":1551311642383,
        "Owner_last_access_time":1643120523147,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":1568750990320,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57980954",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60616879,
        "Question_title":"Logging Artifacts from MlFlow on GCS Bucket",
        "Question_body":"<p>I have a running MlFlow server on GCS VM instance. I have created a bucket to log the artifacts.\nThis is the command I'm running to start the server and for specifying bucket path-<\/p>\n\n<pre><code>mlflow server --default-artifact-root gs:\/\/gcs_bucket\/artifacts --host x.x.x.x\n<\/code><\/pre>\n\n<p>But facing this error:<\/p>\n\n<pre><code>TypeError: stat: path should be string, bytes, os.PathLike or integer, not ElasticNet\n<\/code><\/pre>\n\n<p>Note- The mlflow server is running fine with the specified host alone. The problem is in the way when I'm specifying the storage bucket path.\nI have given permission of storage api by using these commands:<\/p>\n\n<pre><code>gcloud auth application-default login\ngcloud auth login\n<\/code><\/pre>\n\n<p>Also, on printing the artifact URI, this is what I'm getting:<\/p>\n\n<pre><code>mlflow.get_artifact_uri()\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>gs:\/\/gcs_bucket\/artifacts\/0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts\n<\/code><\/pre>\n\n<p>So in the above path from where this is coming <code>0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts<\/code> and why it's not getting auto-created at <code>gs:\/\/gcs_bucket\/artifacts<\/code><\/p>\n\n<p>After debugging more, why it's not able to get the local path from VM:\n<a href=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And this error I'm getting on VM:<\/p>\n\n<pre><code>ARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\nTraceback (most recent call last):\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 197, in list_experiments\n   experiment = self._get_experiment(exp_id, view_type)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 256, in _get_experiment\n   meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/utils\/file_utils.py\", line 160, in read_yaml\n   raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\nmlflow.exceptions.MissingConfigException: Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\n<\/code><\/pre>\n\n<p>Can I get a solution to this and what I'm missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_time":1583840420677,
        "Question_score":4,
        "Question_tags":"python|google-cloud-platform|google-cloud-storage|mlflow",
        "Question_view_count":2153,
        "Owner_creation_time":1451124057623,
        "Owner_last_access_time":1664026764720,
        "Owner_location":"India",
        "Owner_reputation":736,
        "Owner_up_votes":69,
        "Owner_down_votes":2,
        "Owner_views":234,
        "Question_last_edit_time":1583922371777,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60616879",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56791931,
        "Question_title":"Not able to save pyspark iforest model using pyspark",
        "Question_body":"<p>Using iforest as described here : <a href=\"https:\/\/github.com\/titicaca\/spark-iforest\" rel=\"nofollow noreferrer\">https:\/\/github.com\/titicaca\/spark-iforest<\/a>\nBut model.save() is throwing exception.<\/p>\n\n<p>Followed the code snippet mentioned under \"Python API\" section on mentioned git page.<\/p>\n\n<p>from pyspark.ml.feature import VectorAssembler\nimport os\nimport tempfile\nfrom pyspark_iforest.ml.iforest import *<\/p>\n\n<p>col_1:integer\ncol_2:integer\ncol_3:integer<\/p>\n\n<p>assembler = VectorAssembler(inputCols=in_cols, outputCol=\"features\")\nfeaturized = assembler.transform(df)<\/p>\n\n<p>iforest = IForest(contamination=0.5, maxDepth=2)\nmodel=iforest.fit(df)<\/p>\n\n<p>model.save(\"model_path\")\nException:\nscala.NotImplementedError: The default jsonEncode only supports string, vector and matrix. org.apache.spark.ml.param.Param must override jsonEncode for java.lang.Double.<\/p>\n\n<p>Below is the output dataframe I'm getting after executing \"model.transform(df)\". model.save() should be able to save model-files.\ncol_1:integer\ncol_2:integer\ncol_3:integer\nfeatures:udt\nanomalyScore:double\nprediction:double<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1561641462687,
        "Question_score":0,
        "Question_tags":"machine-learning|pyspark|mlflow",
        "Question_view_count":372,
        "Owner_creation_time":1433235101097,
        "Owner_last_access_time":1663928002773,
        "Owner_location":"India",
        "Owner_reputation":779,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":132,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56791931",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73368271,
        "Question_title":"Pycaret MlFlow authentication",
        "Question_body":"<p>How can I use <code>log_environment = True<\/code> in Pycaret <code>setup<\/code> with<\/p>\n<p><code> import os import mlflow mlflow.set_tracking_uri(&quot;https:\/\/dagshub.com\/BexTuychiev\/pet_pawpularity.mlflow&quot;) os.environ[&quot;MLFLOW_TRACKING_USERNAME&quot;] = &quot;MLFLOW_TRACKING_USERNAME&quot; os.environ[&quot;MLFLOW_TRACKING_PASSWORD&quot;] = &quot;MLFLOW_TRACKING_PASSWORD&quot;<\/code><\/p>\n<p>Without getting  <code>RestException: INTERNAL_ERROR: Response: {'error': 'not found'} <\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660618090423,
        "Question_score":0,
        "Question_tags":"google-colaboratory|mlflow|pycaret|dagshub",
        "Question_view_count":35,
        "Owner_creation_time":1481730456640,
        "Owner_last_access_time":1663945777720,
        "Owner_location":"Kansas",
        "Owner_reputation":675,
        "Owner_up_votes":54,
        "Owner_down_votes":0,
        "Owner_views":1816,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73368271",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73643715,
        "Question_title":"ValueError: Enum ErrorCode has no value defined for name '403' in mlflow.set_experiment()",
        "Question_body":"<p>I am trying to run some code to train a model, while logging my results to MLflow on Databricks. I keep getting the following error when I try to make a call to <code>mlflow.set_experiment()<\/code>,<\/p>\n<pre><code>    raise ValueError('Enum {} has no value defined for name {!r}'.format(\nValueError: Enum ErrorCode has no value defined for name '403'\n<\/code><\/pre>\n<p>What exactly is going on here?<\/p>\n<p>I am using Databricks Connect to run my code and the section where the error pops up looks like this,<\/p>\n<pre><code>    # set remote tracking server URI\n    mlflow.set_tracking_uri(remote_server_uri)\n\n    # create the MLflow client\n    client = MlflowClient(remote_server_uri)\n\n    # set experiment to log mlflow runs\n    mlflow.set_experiment(experiment_name)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1662611126990,
        "Question_score":1,
        "Question_tags":"python|mlflow|databricks-connect",
        "Question_view_count":68,
        "Owner_creation_time":1521856385820,
        "Owner_last_access_time":1664037995903,
        "Owner_location":"Sri Lanka",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Question_last_edit_time":1662625313963,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73643715",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61871515,
        "Question_title":"MLflow Artifacts Storing But Not Listing In UI",
        "Question_body":"<p>I've run into an issue using MLflow server. When I first ran the command to start an mlflow server on an ec2 instance, everything worked fine. Now, although logs and artifacts are being stored to postgres and s3, the UI is not listing the artifacts. Instead, the artifact section of the UI shows:<\/p>\n\n<pre><code>Loading Artifacts Failed\nUnable to list artifacts stored under &lt;s3-location&gt; for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.\n<\/code><\/pre>\n\n<p>But when I check in s3, I see the artifact in the s3 location that the error shows. What could possibly have started causing this as it used to work not too long ago and nothing was changed on the ec2 that is hosting mlflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1589810994053,
        "Question_score":9,
        "Question_tags":"amazon-s3|amazon-ec2|artifact|mlflow",
        "Question_view_count":3949,
        "Owner_creation_time":1417012835813,
        "Owner_last_access_time":1628782664573,
        "Owner_location":null,
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61871515",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63640567,
        "Question_title":"Error using set MLFLOW_TRACKING_URI='http:\/\/0.0.0.0:5000' for serve models",
        "Question_body":"<p>Hi i need to run a command like this<\/p>\n<pre><code>mlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow@localhost:5433\/mlflow --default-artifact-root file:D:\/artifact_root --host 0.0.0.0 --port 5000\n<\/code><\/pre>\n<p>for start my serve and i have not problem with this but when i try to run a example\nin the route of project from github python<\/p>\n<pre><code>mlflow\/examples\/sklearn_elasticnet_diabetes\/linux\/train_diabetes.py 0.1 0.9 \n<\/code><\/pre>\n<p>i get this error<\/p>\n<pre><code>  _model_registry_store_registry.register_entrypoints()\nElasticnet model (alpha=0.100000, l1_ratio=0.900000):\n  RMSE: 71.98302888908191\n  MAE: 60.5647520017933\n  R2: 0.21655161434654602\n&lt;function get_tracking_uri at 0x0000017F3AE885E8&gt;\nurl 'http:\/\/0.0.0.0:8001'\nurl2 'http|\/\/0.0.0.0|8001'\nTraceback (most recent call last):\n  File &quot;train_diabetes.py&quot;, line 90, in &lt;module&gt;\n    mlflow.log_param(&quot;alpha&quot;, alpha)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\fluent.py&quot;, line 210, in log_param\n    run_id = _get_or_start_run().info.run_id\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\fluent.py&quot;, line 508, in _get_or_start_run\n    return start_run()\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\fluent.py&quot;, line 148, in start_run\n    active_run_obj = MlflowClient().create_run(\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\client.py&quot;, line 44, in __init__\n    self._tracking_client = TrackingServiceClient(final_tracking_uri)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py&quot;, line 32, in __init__       \n    self.store = utils._get_store(self.tracking_uri)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py&quot;, line 126, in _get_store     \n    return _tracking_store_registry.get_store(store_uri, artifact_uri)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py&quot;, line 37, in get_store    \n    return builder(store_uri=store_uri, artifact_uri=artifact_uri)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py&quot;, line 81, in _get_file_store \n    return FileStore(store_uri, store_uri)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py&quot;, line 100, in __init__\n    self.root_directory = local_file_uri_to_path(root_directory or _default_root_dir())\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\site-packages\\mlflow\\utils\\file_utils.py&quot;, line 387, in local_file_uri_to_path\n    return urllib.request.url2pathname(path)\n  File &quot;C:\\Users\\kevin.sanchez\\Miniconda3\\envs\\env_mlflow\\lib\\nturl2path.py&quot;, line 35, in url2pathname\n    raise OSError(error)\nOSError: Bad URL: 'http|\/\/0.0.0.0|8001'\n<\/code><\/pre>\n<p>before running the python code i run this command to set the env tracking uri for the execution set MLFLOW_TRACKING_URI='http:\/\/0.0.0.0:5000'<\/p>\n<p>i don\u00b4t know why mlflow replace the : for | i need help. Before this option worked but now it is failing<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1598646868280,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":895,
        "Owner_creation_time":1598646307000,
        "Owner_last_access_time":1603930318483,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1598647185303,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63640567",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72516775,
        "Question_title":"I expose ports in docker but it does not connect",
        "Question_body":"<p>I have a simple docker image (I post the Dockerfile at the end) and I run it with<\/p>\n<pre><code>docker run -p 8888:8888 -p 5000:5000 -v $(pwd):\/workfolder -it --rm stockpred\n<\/code><\/pre>\n<p>I am expecting to expose the ports 8888 and 5000.<\/p>\n<p>Inside the container I do:<\/p>\n<pre><code>(base) root@41131b74043f:\/workfolder# mlflow ui\n[2022-06-06 10:59:24 +0000] [26] [INFO] Starting gunicorn 20.1.0\n[2022-06-06 10:59:24 +0000] [26] [INFO] Listening at: http:\/\/127.0.0.1:5000 (26)\n[2022-06-06 10:59:24 +0000] [26] [INFO] Using worker: sync\n[2022-06-06 10:59:24 +0000] [27] [INFO] Booting worker with pid: 27\n<\/code><\/pre>\n<p>so I go and open that address in my browser but I got<\/p>\n<p>The connection was reset<\/p>\n<blockquote>\n<p>The connection to the server was reset while the page was loading.<\/p>\n<pre><code>The site could be temporarily unavailable or too busy. Try again in a few moments.\nIf you are unable to load any pages, check your computer\u2019s network connection.\nIf your computer or network is protected by a firewall or proxy, make sure that Firefox is permitted to access the Web.\n<\/code><\/pre>\n<\/blockquote>\n<p>I thought that I could open the page externally. It must be something I am missing but what am I doing wrong?<\/p>\n<pre><code>FROM continuumio\/miniconda3\n\nRUN pip install mlflow&gt;=1.18.0 \\\n    &amp;&amp; pip install numpy \\\n    &amp;&amp; pip install scipy \\\n    &amp;&amp; pip install pandas \\\n    &amp;&amp; pip install scikit-learn \\\n    &amp;&amp; pip install cloudpickle \\\n    &amp;&amp; pip install pandas_datareader==0.10.0 \\\n    &amp;&amp; pip install yfinance\n<\/code><\/pre>\n<p>EDIT:<\/p>\n<p>It worked when I did<\/p>\n<pre><code>docker run --network=&quot;host&quot; -p 8888:8888 -p 5000:5000 -v $(pwd):\/workfolder -it --rm stockpred\n<\/code><\/pre>\n<p>Notice that I did not expose the ports in the Dockerfile.<\/p>\n<p>Can someone explain me why this is working like this?<\/p>\n<p>(I also tried exposing the ports in the Dockerfile and running like originally but it didn't work)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1654513786370,
        "Question_score":0,
        "Question_tags":"docker|mlflow",
        "Question_view_count":121,
        "Owner_creation_time":1421198269333,
        "Owner_last_access_time":1664010554427,
        "Owner_location":null,
        "Owner_reputation":5585,
        "Owner_up_votes":792,
        "Owner_down_votes":53,
        "Owner_views":1350,
        "Question_last_edit_time":1654516610190,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72516775",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57033896,
        "Question_title":"How to use MLfLow with private git repositories?",
        "Question_body":"<p>I tested <code>MLflow<\/code> experiment when the source code is stored in public a git repository. Example command looks like this<\/p>\n\n<pre><code>mlflow run  https:\/\/github.com\/amesar\/mlflow-fun.git#examples\/hello_world \\\n --experiment-id=2019 \\\n -Palpha=100 -Prun_origin=GitRun -Plog_artifact=True\n<\/code><\/pre>\n\n<p>However, when I provide an internal (private) git repository link instead of public- MLflow redirects to login url, and then execution fails like this.<\/p>\n\n<pre><code>git.exc.GitCommandError: Cmd('git') failed due to: exit code(128)\ncmdline: git fetch -v origin\nstderr: 'fatal: unable to update url base from redirection:\nasked for: https:\/\/gitlab-master.companyname.com\/myusername\/project_name\n\/tree\/master\/models\/myclassifier\/info\/refs?service=git-upload-pack\nredirect: https:\/\/gitlab-master.company.com\/users\/sign_in'\n<\/code><\/pre>\n\n<p>Is there any way to commmunicate credentials of git account to MLflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1563170204117,
        "Question_score":2,
        "Question_tags":"git|gitlab|databricks|mlflow",
        "Question_view_count":1278,
        "Owner_creation_time":1401104228227,
        "Owner_last_access_time":1663944731387,
        "Owner_location":"Santa Clara, CA, USA",
        "Owner_reputation":4031,
        "Owner_up_votes":79,
        "Owner_down_votes":6,
        "Owner_views":244,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57033896",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62686181,
        "Question_title":"MLflow - How can I run python code using a REST API",
        "Question_body":"<p>I'am a newbie on MachineLearning. Just a simple question, how can I run python code using REST API?\nHere is the documentation\n<a href=\"https:\/\/mlflow.org\/docs\/latest\/rest-api.html\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/rest-api.html<\/a>\nBut there are no examples for REST API.\nI just created an experiment, but I cant create python run?\nAny examples like this? &quot;This is create just a experiment&quot;\ncurl -X POST http:\/\/localhost:5000\/api\/2.0\/preview\/mlflow\/experiments\/create -d '{&quot;name&quot;:&quot;TEST&quot;}'<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1593642122807,
        "Question_score":2,
        "Question_tags":"machine-learning|artificial-intelligence|mlflow",
        "Question_view_count":494,
        "Owner_creation_time":1593641319837,
        "Owner_last_access_time":1663184903993,
        "Owner_location":"Turkey",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1593642521280,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62686181",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56604989,
        "Question_title":"How to install mlflow using pip install",
        "Question_body":"<p>I'm working on a Window 10 machine and trying to pip install mlflow but I'm getting the following error message.<\/p>\n\n<pre><code>THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\nmlflow from https:\/\/files.pythonhosted.org\/packages\/01\/ec\/8c9448968d4662e8354b9c3a62e635f8929ed507a45af3d9fdb84be51270\/mlflow-1.0.0-py3-none-any.whl#sha256=0f2f116a377b9da538642eaf688caa0a7166ee1ede30c8734830eb9e789574b4:\n    Expected sha256 0f2f116a377b9da538642eaf688caa0a7166ee1ede30c8734830eb9e789574b4\n         Got        eb34ea16ecfe02d474ce50fd1f88aba82d56dcce9e8fdd30193ab39edf32ac9e\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1560545573400,
        "Question_score":1,
        "Question_tags":"pip|mlflow",
        "Question_view_count":365,
        "Owner_creation_time":1355343131933,
        "Owner_last_access_time":1649125560750,
        "Owner_location":null,
        "Owner_reputation":5655,
        "Owner_up_votes":73,
        "Owner_down_votes":3,
        "Owner_views":629,
        "Question_last_edit_time":1560799785057,
        "Answer_body":"<p>It is trying to check cache for packages. They were likely compiled in linux or some other OS and you are trying to install them in Windows.<\/p>\n\n<p>This should fix your issue:<\/p>\n\n<pre><code>pip install --no-cache-dir mlflow\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1560545869140,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56604989",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65744496,
        "Question_title":"MLFlow Model Registry ENDPOINT_NOT_FOUND: No API found for ERROR",
        "Question_body":"<p>I'm currently using MLFlow in Azure Databricks and trying to load a model from the Model Registry. Currently referencing the version, but will want to reference the stage 'Production' (I get the same error when referencing the stage as well)<\/p>\n<p>I keep encountering an error:<\/p>\n<pre><code>ENDPOINT_NOT_FOUND: No API found for 'POST \/mlflow\/model-versions\/get-download-uri'\n<\/code><\/pre>\n<p>My artifacts are stored in the dbfs filestore.<\/p>\n<p>I have not been able to identify why this is happening.<\/p>\n<p>Code:<\/p>\n<pre><code>from mlflow.tracking.client import MlflowClient\nfrom mlflow.entities.model_registry.model_version_status import ModelVersionStatus\n\nimport mlflow.pyfunc\n\nmodel_name = &quot;model_name&quot;\n\nmodel_version_uri = &quot;models:\/{model_name}\/4&quot;.format(model_name=model_name)\n\nprint(&quot;Loading registered model version from URI: '{model_uri}'&quot;.format(model_uri=model_version_uri))\nmodel_version_4 = mlflow.pyfunc.load_model(model_version_uri)\n\nmodel_production_uri = &quot;models:\/{model_name}\/production&quot;.format(model_name=model_name)\n\nprint(&quot;Loading registered model version from URI: '{model_uri}'&quot;.format(model_uri=model_production_uri))\nmodel_production = mlflow.pyfunc.load_model(model_production_uri)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1610750609033,
        "Question_score":1,
        "Question_tags":"azure|databricks|mlflow",
        "Question_view_count":387,
        "Owner_creation_time":1581292138330,
        "Owner_last_access_time":1614304868413,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1610964132683,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65744496",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70383800,
        "Question_title":"How can I run Tensorboard with MLFlow's logs?",
        "Question_body":"<p>I use MLFlow with autolog to keep track of my Tensorflow models:<\/p>\n<pre><code>mlflow.tensorflow.autolog(every_n_iter=1)\nwith mlflow.start_run():\n  model = ...\n  model.compile(...)\n  model.fit(...)\n<\/code><\/pre>\n<p>and then I want to use my tensorboard logs located in the artifacts.\nBut when I run:<\/p>\n<pre><code>%tensorboard --logdir=&lt;logs_path&gt;\n<\/code><\/pre>\n<p>I have the error message:\n&quot;No dashboards are active for the current data set.\nProbable causes:<\/p>\n<p>You haven\u2019t written any data to your event files.\nTensorBoard can\u2019t find your event files.&quot;<\/p>\n<p>I work on Databricks, so log_path is something like:<\/p>\n<pre><code>\/dbfs\/databricks\/mlflow-tracking\/..\n<\/code><\/pre>\n<p>Any ideas?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1639678545067,
        "Question_score":1,
        "Question_tags":"tensorflow|databricks|tensorboard|mlflow",
        "Question_view_count":501,
        "Owner_creation_time":1639677790923,
        "Owner_last_access_time":1663854761243,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70383800",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70296350,
        "Question_title":"Mlflow log_model, not able to predict with spark_udf but with python works",
        "Question_body":"<p>I was wondering to log a model on mlflow, once I do it, I'm able to predict probabilities with python loaded model but not with spark_udf. The thing is, I still need to have a preprocessing function inside the model. Here is a toy reproductible example for you to see when it fails:<\/p>\n<pre><code>import mlflow\nfrom mlflow.models.signature import infer_signature\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_classes=2, shuffle=True, random_state=1995)\nX, y = pd.DataFrame(X), pd.DataFrame(y,columns=[&quot;target&quot;])\n# geerate column names\nX.columns = [f&quot;col_{idx}&quot; for idx in range(len(X.columns))]\nX[&quot;categorical_column&quot;] = np.random.choice([&quot;a&quot;,&quot;b&quot;,&quot;c&quot;], size=len(X) )\n\n\ndef encode_catcolumn(X):\n  X = X.copy()\n  # replace cat values [a,b,c] for [-10,0,35] respectively\n  X['categorical_column'] = np.select([X[&quot;categorical_column&quot;] == &quot;a&quot;, X[&quot;categorical_column&quot;] == &quot;b&quot;, X[&quot;categorical_column&quot;] == &quot;c&quot;],  [-10, 0,35] ) \n  return X\n\n# with catcolumn encoded; i need to use custom encoding , we'll do this within mlflow later\nX_encoded = encode_catcolumn(X)\n\n<\/code><\/pre>\n<p>Now let's create a wrapper for the model to encode the function within the model. Please see that the function encode_catcolumn within the class and the one outside the class presented before are the same.<\/p>\n<pre><code>class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n  def __init__(self, model):\n    self.model = model\n  def encode_catcolumn(self,X):\n    X = X.copy()\n    # replace cat values [a,b,c] for [-10,0,35] respectively\n    X['categorical_column'] = np.select([X[&quot;categorical_column&quot;] == &quot;a&quot;, X[&quot;categorical_column&quot;] == &quot;b&quot;, X[&quot;categorical_column&quot;] == &quot;c&quot;],  [-10, 0,35] ) \n    return X \n  def predict(self, context, model_input):\n    # encode catvariable\n    model_input = self.encode_catcolumn(model_input)\n    # predict probabilities\n    predictions = self.model.predict_proba(model_input)[:,1]\n    return predictions\n<\/code><\/pre>\n<p>Now let's log the model<\/p>\n<pre><code>with mlflow.start_run(run_name=&quot;reproductible_example&quot;) as run:\n  clf = RandomForestClassifier()\n  clf.fit(X_encoded,y)\n  # wrappmodel with pyfunc, does the encoding inside the class \n  wrappedModel = SklearnModelWrapper(clf)\n  # When the model is deployed, this signature will be used to validate inputs.\n  mlflow.pyfunc.log_model(&quot;reproductible_example_model&quot;, python_model=wrappedModel)\n\nmodel_uuid = run.info.run_uuid\nmodel_path = f'runs:\/{model_uuid}\/reproductible_example_model'\n<\/code><\/pre>\n<p>Do the inference without spark and works perfectly:<\/p>\n<pre><code>model_uuid = run.info.run_uuid\nmodel_path = f'runs:\/{model_uuid}\/reproductible_example_model'\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(model_path)\n# predictions without spark , encodes the variables INSIDE; this WORKS\nloaded_model.predict(X)\n<\/code><\/pre>\n<p>Now do the inference with spark_udf and get an error:<\/p>\n<pre><code># create spark dataframe to test it on spark\nX_spark = spark.createDataFrame(X)\n# Load model as a Spark UDF.\nloaded_model_spark = mlflow.pyfunc.spark_udf(spark, model_uri=model_path)\n\n# Predict on a Spark DataFrame.\ncolumns = list(X_spark.columns)\n# this does not work\nX_spark.withColumn('predictions', loaded_model_spark(*columns)).collect()\n<\/code><\/pre>\n<p>The error is:<\/p>\n<pre><code>PythonException: An exception was thrown from a UDF: 'KeyError: 'categorical_column'', from &lt;command-908038&gt;, line 7. Full traceback below:\n<\/code><\/pre>\n<p>I need to some how encode the variables and preprocess within the class. Is there any solution to this or any workaround to make this code able to woork with spark?\nWhat I've tried so far:<\/p>\n<ol>\n<li>Incorporate the encode_catcolumn within a sklearn Pipeline (with a custom encoder sklearn) -&gt; Fails;<\/li>\n<li>Create a function within the sklearn wrapper class (this example) -&gt; Fails\n3 ) Use the log_model and then create a pandas_udf in order to do it with spark as well --&gt; works but that's not what I want. I would like to be able to run the model on spark with just calling .predict() method or something like that.<\/li>\n<li>When a remove the preprocessing function and do it outside the class --&gt;  this actually works but this is not what<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1639081909030,
        "Question_score":0,
        "Question_tags":"apache-spark|pyspark|scikit-learn|mlflow|mlops",
        "Question_view_count":730,
        "Owner_creation_time":1588098542797,
        "Owner_last_access_time":1664026048063,
        "Owner_location":"Buenos Aires, Argentina",
        "Owner_reputation":391,
        "Owner_up_votes":44,
        "Owner_down_votes":2,
        "Owner_views":26,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70296350",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71531665,
        "Question_title":"How to get `run_id` when using MLflow Project",
        "Question_body":"<p>When using MLflow Projects (via an <code>MLproject<\/code> file) I get this message at starting time:<\/p>\n<pre><code>INFO mlflow.projects.backend.local: \n=== Running command 'source \/anaconda3\/bin\/..\/etc\/profile.d\/conda.sh &amp;&amp; \nconda activate mlflow-4736797b8261ec1b3ab764c5060cae268b4c8ffa 1&gt;&amp;2 &amp;&amp; \npython3 main.py' in run with ID 'e2f0e8c670114c5887963cd6a1ac30f9' === \n<\/code><\/pre>\n<p>I want to access the <code>run_id<\/code> shown above (<strong>e2f0e8c670114c5887963cd6a1ac30f9<\/strong>) from inside the main script.<\/p>\n<p>I expected a run to be active but:<\/p>\n<pre><code>mlflow.active_run()\n&gt; None\n<\/code><\/pre>\n<p>Initiating a run inside the main script does give me access the correct <code>run_id<\/code>, although any subsequent runs will have a different <code>run_id<\/code>.<\/p>\n<pre><code># first run inside the script - correct run_id\nwith mlflow.start_run():\n   print(mlflow.active_run().info.run_id)\n&gt; e2f0e8c670114c5887963cd6a1ac30f9\n\n# second run inside the script - wrong run_id\nwith mlflow.start_run():\n   print(mlflow.active_run().info.run_id)\n&gt; 417065241f1946b98a4abfdd920239b1\n<\/code><\/pre>\n<p>Seems like a strange behavior, and I was wondering if there's another way to access the <code>run_id<\/code> assigned at the beginning of the <code>MLproject<\/code> run?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1647628142007,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":143,
        "Owner_creation_time":1527686643970,
        "Owner_last_access_time":1663364883530,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71531665",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73808171,
        "Question_title":"What is the difference between deploying models in MLflow and Sagemaker?",
        "Question_body":"<p>I could do\n<code>mlflow model serve -m &lt;RUN_ID&gt; --p 1234 --no-conda<\/code><\/p>\n<p>and<\/p>\n<p><code>mlflow sagemaker run-local -m &lt;MODEL_PATH&gt; -p 1234<\/code><\/p>\n<p>Are they not the same anyway as both can do model serving so what's the hassle deploying it to Sagemaker?<\/p>\n<p>I'm a beginner at this so if anyone can help me out with my understanding that will be great. Thank you so much in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663806620887,
        "Question_score":0,
        "Question_tags":"rest|deployment|amazon-sagemaker|endpoint|mlflow",
        "Question_view_count":26,
        "Owner_creation_time":1487831504143,
        "Owner_last_access_time":1664005735500,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73808171",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72365934,
        "Question_title":"Running mlflow ui in AWS Sagemaker",
        "Question_body":"<p>I want to run mlflow UI in sagemaker but it simply does not work, When it outputs the http address going to it results in a &quot;this site cannot be reached&quot;<\/p>\n<p>Here is the code:<\/p>\n<pre><code>def mlflow_test(server_uri, experiment_name):\n    mlflow.set_tracking_uri(server_uri)\n    mlflow.set_experiment(experiment_name)\n    with mlflow.start_run():\n        params = {\n            &quot;n-estimators&quot;: 100,\n            &quot;min-samples-leaf&quot;: 10,\n            &quot;features&quot;: 'feature_test'\n        }\n        mlflow.log_params(params)\n        mlflow.log_metric('foo', 5)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>running that code will return:<\/p>\n<pre><code>[2022-05-24 15:48:44 +0000] [27820] [INFO] Starting gunicorn 20.1.0\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Listening at: http:\/\/127.0.0.1:5000 (27820)\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Using worker: sync\n[2022-05-24 15:48:44 +0000] [27823] [INFO] Booting worker with pid: 27823\n<\/code><\/pre>\n<p>Going to the <a href=\"http:\/\/127.0.0.1:5000\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000<\/a> link won't work. Anyone know how to get mlflow ui running in sagemaker? There's not much info on this that's at an easy to understand level. I just want to log my metrics and params in sagemaker and view them using the mlflow ui<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1653407649377,
        "Question_score":0,
        "Question_tags":"python|amazon-web-services|amazon-sagemaker|mlflow",
        "Question_view_count":93,
        "Owner_creation_time":1615994492347,
        "Owner_last_access_time":1657796021117,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72365934",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62754017,
        "Question_title":"Save customized function inside function in MLFlow log_model",
        "Question_body":"<p>I would like to do something with MLFlow but I do not find any solution on Internet. I am working with MLFlow and R, and I want to save a regression model. The thing is that by the time I want to predict the testing data, I want to do some transformation of that data. Then I have:<\/p>\n<pre class=\"lang-r prettyprint-override\"><code>data &lt;- #some data with numeric regressors and dependent variable called 'y'\n\n# Divide into train and test\nind &lt;- sample(nrow(data), 0.8*nrow(data), replace = FALSE)\ndataTrain &lt;- data[ind,]\ndataTest &lt;- data[-ind,]\n\n# Run model in the mlflow framework\nwith(mlflow_start_run(), {\n   model &lt;- lm(y ~ ., data = dataTrain)\n   \n   predict_fun &lt;- function(model, data_to_predict){\n       data_to_predict[,3] &lt;- data_to_predict[,3]\/2\n       data_to_predict[,4] &lt;- data_to_predict[,4] + 1\n\n       return(predict(model, data_to_predict))\n       }\n\n   predictor &lt;- crate(~predict_fun(model,dataTest),model)\n\n   ### Some code to use the predictor to get the predictions and measure the accuracy as a log_metric\n   ##################\n   ##################\n   ##################\n\n   mlflow_log_model(predictor,'model')\n}\n<\/code><\/pre>\n<p>As you can notice, my prediction function not only consists in predict the new data you are evaluating, but it also makes some transformations in the third and fourth columns. All examples I saw on the web use the function predict in the <em>crate<\/em> as the default function of R.<\/p>\n<p>Once I save this model, when I run it in another notebook with some Test data, I get the error: <em>&quot;predict_fun&quot; doesn't exist<\/em>. That is because my algorithm has not saved this specific function. Do you know what can I do to save and specific prediction function that I have created instead of the default functions that are in R?<\/p>\n<p>This is not the real example I am working with, but it is an approximation of it. The fact is that I want to save extra functions apart from the model itself.<\/p>\n<p>Thank you very much!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1594030946863,
        "Question_score":1,
        "Question_tags":"r|predict|mlflow",
        "Question_view_count":140,
        "Owner_creation_time":1568015757070,
        "Owner_last_access_time":1642423173287,
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62754017",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72835208,
        "Question_title":"Can't access the blob folder but files inside it are able to download",
        "Question_body":"<p>I have azure storage where I am using containers to store blobs. I am trying to download the blob from this container. But either using python SDK or rest, I am getting error &quot;The specified blob does not exist.&quot; but when I giving the full path with the final file such as .txt or whatever instead of root folder, it is able to download it.<\/p>\n<p>For example:\nfollowing URL gives error <strong><a href=\"https:\/\/mlflowsmodeltorage.blob.core.windows.net\/mlflow-test\/110\/63e7b9f2482b45e29b8c2983fa9522ef\/artifacts\/models\" rel=\"nofollow noreferrer\">https:\/\/mlflowsmodeltorage.blob.core.windows.net\/mlflow-test\/110\/63e7b9f2482b45e29b8c2983fa9522ef\/artifacts\/models<\/a><\/strong> The specified blob does not exist.<\/p>\n<p>but the URL <strong><a href=\"https:\/\/mlflowsmodeltorage.blob.core.windows.net\/mlflow-test\/110\/63e7b9f2482b45e29b8c2983fa9522ef\/artifacts\/models\/conda.yaml\" rel=\"nofollow noreferrer\">https:\/\/mlflowsmodeltorage.blob.core.windows.net\/mlflow-test\/110\/63e7b9f2482b45e29b8c2983fa9522ef\/artifacts\/models\/conda.yaml<\/a><\/strong> able to download the file.<\/p>\n<p>Same thing happens with the python SDK. But I want to download the whole folder rather than the files inside it.<\/p>\n<p>How can I achieve it.<\/p>\n<p>Below is the code I am using to access the blob using pytohn SDK<\/p>\n<pre><code>from azure.storage.blob import BlobServiceClient\n\nSTORAGEACCOUNTURL = &quot;https:\/\/mlflowsmodeltorage.blob.core.windows.net&quot;\nSTORAGEACCOUNTKEY = &quot;xxxxxxxxxxxxxx&quot;\nCONTAINERNAME = &quot;mlflow-test&quot;\nBLOBNAME = &quot;110\/63e7b9f2482b45e29b8c2983fa9522ef\/artifacts\/models\/&quot;\n\nblob_service_client_instance = BlobServiceClient(\n    account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY,\n\n)\n\nblob_client_instance = blob_service_client_instance.get_blob_client(\n    CONTAINERNAME, BLOBNAME, snapshot=None)\n\nblob_data = blob_client_instance.download_blob()\ndata = blob_data.readall()\nprint(data)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1656715374267,
        "Question_score":0,
        "Question_tags":"azure-blob-storage|azure-storage|mlflow|azure-storage-account",
        "Question_view_count":141,
        "Owner_creation_time":1626523396117,
        "Owner_last_access_time":1664042694257,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1656886891087,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72835208",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62296590,
        "Question_title":"MLFlow and Hydra causing crash when used together",
        "Question_body":"<p>I'm trying to utilize Hydra with MLFlow, so I wrote the bare minimum script to see if they worked together (importing etc.). Both work fine on their own, but when put together I get a weird outcome.<\/p>\n\n<p>I have the script below:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import hydra\nfrom omegaconf import DictConfig\nfrom mlflow import log_metric, log_param, log_artifact,start_run\n\n@hydra.main(config_path=\"config.yaml\")\ndef my_app(cfg : DictConfig):\n    # print(cfg.pretty())\n    # print(cfg['coordinates']['x0'])\n    log_param(\"a\",2)\n    log_metric(\"b\",3)\n\nif __name__ == \"__main__\":\n    my_app()\n<\/code><\/pre>\n\n<p>However when ran, I get the error below:<\/p>\n\n<pre><code>ilknull@nurmachine:~\/Files\/Code\/Python\/MLFlow_test$ python3 hydra_temp.py \nError in atexit._run_exitfuncs:\nTraceback (most recent call last):\n  File \"\/home\/ilknull\/.local\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py\", line 164, in end_run\n    MlflowClient().set_terminated(_active_run_stack[-1].info.run_id, status)\n  File \"\/home\/ilknull\/.local\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 311, in set_terminated\n    self._tracking_client.set_terminated(run_id, status, end_time)\n  File \"\/home\/ilknull\/.local\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 312, in set_terminated\n    end_time=end_time)\n  File \"\/home\/ilknull\/.local\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 377, in update_run_info\n    run_info = self._get_run_info(run_id)\n  File \"\/home\/ilknull\/.local\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/file_store.py\", line 442, in _get_run_info\n    databricks_pb2.RESOURCE_DOES_NOT_EXIST)\nmlflow.exceptions.MlflowException: Run '9066793c02604a6783d081ed965d5eff' not found\n<\/code><\/pre>\n\n<p>Again, they work perfectly fine when used separately, but together they cause this error. Any ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591767515617,
        "Question_score":4,
        "Question_tags":"python|docker|exception|mlflow|fb-hydra",
        "Question_view_count":718,
        "Owner_creation_time":1583072555673,
        "Owner_last_access_time":1663970229957,
        "Owner_location":null,
        "Owner_reputation":301,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Thanks for reporting this. I was not aware of this issue.<\/p>\n\n<p>This is because Hydra is changing your current working directory for each run.<\/p>\n\n<p>I did some digging, this is what you can do:<\/p>\n\n<ol>\n<li>Set the MLFLOW_TRACKING_URI environment variable:<\/li>\n<\/ol>\n\n<pre><code>MLFLOW_TRACKING_URI=file:\/\/\/$(pwd)\/.mlflow  python3 hydra_temp.py\n<\/code><\/pre>\n\n<ol start=\"2\">\n<li>Call set_tracking_url() before hydra.main() starts:<\/li>\n<\/ol>\n\n<pre><code>import hydra\nfrom omegaconf import DictConfig\nfrom mlflow import log_metric, log_param, set_tracking_uri\nimport os\n\nset_tracking_uri(f\"file:\/\/\/{os.getcwd()}\/.mlflow\")\n\n@hydra.main(config_name=\"config\")\ndef my_app(cfg: DictConfig):\n    log_param(\"a\", 2)\n    log_metric(\"b\", 3)\n\n\nif __name__ == \"__main__\":\n    my_app()\n<\/code><\/pre>\n\n<ol start=\"3\">\n<li>Wait for my <a href=\"https:\/\/github.com\/facebookresearch\/hydra\/issues\/664\" rel=\"nofollow noreferrer\">new issue<\/a> to get resolved, then there will have a proper plugin to integrate with mlflow.\n(This will probably take a while).<\/li>\n<\/ol>\n\n<p>By the way, Hydra 1.0 has new support for setting environment variables:<\/p>\n\n<p>This <em>ALMOST<\/em> works:<\/p>\n\n<pre class=\"lang-yaml prettyprint-override\"><code>hydra:\n  job:\n    env_set:\n      MLFLOW_TRACKING_DIR: file:\/\/${hydra:runtime.cwd}\/.mlflow\n      MLFLOW_TRACKING_URI: file:\/\/${hydra:runtime.cwd}\/.mlflow\n<\/code><\/pre>\n\n<p>Unfortunately Hydra is cleaning up the env variables when your function exits, and MLFlow is making the final save when the process exits so the env variable is no longer set.\nMLFlow also keeps re-initializing the FileStore object used to store the experiments data. If they would have initialized it just once and reused the same object the above should would have worked.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1591773861797,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1591782103620,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62296590",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72569496,
        "Question_title":"In mlflow, is it possible to track an artifact without having mlflow store it separately?",
        "Question_body":"<p>I am new to mlflow. I am trying to track\/log some artifacts (a directory of images output by my model) such that they are affiliated with the run that generated them, and so that I can view them in the mlflow UI along with all the other tracked information.<\/p>\n<p>This directory of images is generated in a custom folder path location (with a unique identifier for each run). My goal is to point mlflow to this directory so that it can recognize that these images are artifacts to track.<\/p>\n<p>Is this possible? From my understanding, the mlflow.log_artifact() function will simply create a duplicate of this image and store it within mlflow's default artifact path (ie, something like <em>mydrive1\/mlflow\/0\/\/artifacts\/<\/em>). I do not want to create a duplicate; I want to keep these images where I originally saved them.<\/p>\n<p>Example of file tree:<br \/>\nmydrive1\/<br \/>\n--\/train.py<br \/>\n--\/mlflow\/<br \/>\n----\/0\/<br \/>\n------\/meta.yaml<br \/>\n------\/[random char sequence]<br \/>\n--------\/artifacts\/<br \/>\n--------\/meta.yaml<\/p>\n<p>mydrive2\/<br \/>\n--\/output\/<br \/>\n----\/my_experiment0\/<br \/>\n------\/images\/<br \/>\n--------\/image1.png<br \/>\n--------\/image2.png<\/p>\n<p>I have found that if I manually edit the <em>artifact_uri<\/em> variable (in the meta.yaml file of the relevant run) to point to the relevant directory of images (ie, <em>mydrive2\/my_experiment0\/images\/<\/em>), all those images will show up in the artifact viewer in the mlflow UI. Is there a way to edit the <em>artifact_uri<\/em> variable via the mlflow API (or some other principled way)?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1654839245583,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":164,
        "Owner_creation_time":1560804109483,
        "Owner_last_access_time":1664065617013,
        "Owner_location":"Tokyo, Japan",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72569496",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69227917,
        "Question_title":"Connect MLflow server to minio in local",
        "Question_body":"<p>I am trying to connect mlflow with Minio server, both are running on my local machine, I am able to connect my client code to minio by adding the below lines to the code,<\/p>\n<pre><code>os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] =&quot;xxxx&quot;\nos.environ['AWS_SECRET_ACCESS_KEY'] =&quot;xxxxxx&quot; \nos.environ['MLFLOW_TRACKING_URI'] = 'http:\/\/localhost:5000'\n<\/code><\/pre>\n<p>But the mlflow server is not getting connected to Minio. To run Mlflow server, command I use:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 -p 5000 --default-artifact-root s3:\/\/mlbucket --backend-store-uri sqlite:\/\/\/mlflow.db\n<\/code><\/pre>\n<p>The mlflow server runs, but while accessing the artifacts page the server, it throws the error:<\/p>\n<pre><code>raise NoCredentialsError()\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>\n<p>So how can I pass the credentials of the Minio to the mlflow server command?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_time":1631902626293,
        "Question_score":1,
        "Question_tags":"python|minio|mlflow",
        "Question_view_count":1136,
        "Owner_creation_time":1310893185210,
        "Owner_last_access_time":1663988189020,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Just add the below environment variables:<\/p>\n<pre><code>export AWS_ACCESS_KEY_ID=&lt;your-aws-access-key-id&gt;\nexport AWS_SECRET_ACCESS_KEY = &lt;your-aws-secret-access-key&gt;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1634743751773,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69227917",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69479488,
        "Question_title":"Hi. I am very new to MLFlow, and want to implement MLFlow project on my own ML model. However I am getting \"\"Could not find main among entry points\"\"",
        "Question_body":"<p>The full error message is as below:<\/p>\n<pre><code>ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===\n\n<\/code><\/pre>\n<p>I also try the solutions suggested here <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/1094<\/code>, but the result is the same.<\/p>\n<p>Below I provide all the required files to run <code>MLflow<\/code> project.<\/p>\n<p>The <code>conda.yaml<\/code> file<\/p>\n<pre><code>name: lightgbm-example\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.6\n  - pip\n  - pip:\n      - mlflow&gt;=1.6.0\n      - lightgbm\n      - pandas\n      - numpy\n<\/code><\/pre>\n<p>The MLProject file<\/p>\n<pre><code>name: lightgbm-example\nconda_env: ~\/Desktop\/MLflow\/conda.yaml\nentry-points:\n    main:\n      parameters:\n        learning_rate: {type: float, default: 0.1}\n        colsample_bytree: {type: float, default: 1.0}\n        subsample: {type: float, default: 1.0} \n      command: |\n          python3 ~\/Desktop\/MLflow\/Test.py \\\n            --learning-rate={learning_rate} \\\n            --colsample-bytree={colsample_bytree} \\\n            --subsample={subsample}\n<\/code><\/pre>\n<p>My Test.py file<\/p>\n<pre><code>import pandas as pd\nimport lightgbm as lgb\nimport numpy as np\nimport mlflow\nimport mlflow.lightgbm\nimport argparse\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=&quot;LightGBM example&quot;)\n    parser.add_argument(\n        &quot;--learning-rate&quot;,\n        type=float,\n        default=0.1,\n        help=&quot;learning rate to update step size at each boosting step (default: 0.3)&quot;,\n    )\n    parser.add_argument(\n        &quot;--colsample-bytree&quot;,\n        type=float,\n        default=1.0,\n        help=&quot;subsample ratio of columns when constructing each tree (default: 1.0)&quot;,\n    )\n    parser.add_argument(\n        &quot;--subsample&quot;,\n        type=float,\n        default=1.0,\n        help=&quot;subsample ratio of the training instances (default: 1.0)&quot;,\n    )\n    return parser.parse_args()\n\ndef find_specificity(c_matrix):\n    specificity = c_matrix[1][1]\/(c_matrix[1][1]+c_matrix[0][1])\n    return specificity\n    \n    \ndef main():\n\n    args = parse_args()\n\n    df = pd.read_csv('~\/Desktop\/MLflow\/Churn_demo.csv')\n    train_df = df.sample(frac=0.8, random_state=25)\n    test_df = df.drop(train_df.index)\n\n\n        \n    train_df.drop(['subscriberid'], axis = 1, inplace = True)\n    test_df.drop(['subscriberid'], axis = 1, inplace = True)\n\n    TrainX = train_df.iloc[:,:-1]\n    TrainY = train_df.iloc[:,-1]\n\n    TestX = test_df.iloc[:,:-1]\n    TestY = test_df.iloc[:,-1]\n    \n    mlflow.lightgbm.autolog()\n    \n    dtrain = lgb.Dataset(TrainX, label=TrainY)\n    dtest = lgb.Dataset(TestX, label=TestY)\n    \n    with mlflow.start_run():\n\n        parameters = {\n            'objective': 'binary',\n            'device':'cpu',\n            'num_threads': 6,\n            'num_leaves': 127,\n            'metric' : 'binary',\n            'lambda_l2':5,\n            'max_bin': 63,\n            'bin_construct_sample_cnt' :2*1000*1000,\n            'learning_rate': args.learning_rate,\n            'colsample_bytree': args.colsample_bytree,\n            'subsample': args.subsample,\n            'verbose': 1\n        }\n\n\n\n        model = lgb.train(parameters,\n                       dtrain,\n                       valid_sets=dtest,\n                       num_boost_round=10000,\n                       early_stopping_rounds=10)\n                       \n               \n        y_proba=model.predict(TestX)\n        pred=np.where(y_proba&gt;0.25,1,0) \n        conf_matrix = confusion_matrix(TestY,pred)\n        \n        specificity = find_specificity(conf_matrix)\n        acc = accuracy_score(TestY,pred)\n        \n        mlflow.log_metric({&quot;specificity&quot; : specificity, &quot;accuracy&quot; : acc})\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n        \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1633602279323,
        "Question_score":2,
        "Question_tags":"python|yaml|mlflow",
        "Question_view_count":418,
        "Owner_creation_time":1583491811220,
        "Owner_last_access_time":1663774319043,
        "Owner_location":"Baku, Azerbaijan",
        "Owner_reputation":23,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Fortunately, I have been resolved my problem. I list some solutions for the same error which can help you in the future if you face the same problem.<\/p>\n<ol>\n<li>File names. The file names should be the same suggested in MLFlow docs <code>https:\/\/mlflow.org\/ <\/code>. For example not <code>conda.yamp<\/code>, but <code>conda.yaml<\/code>, as there was such problem in <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/3856<\/code><\/li>\n<li>The <code>conda.yaml<\/code> file does not support Tab, please consider using spaces instead<\/li>\n<li>In the MLProject file name 'P' should be the upper case before MLFlow 1.4. But the later versions it does not matter as explained there <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/1094<\/code><\/li>\n<li>(In my case) MLProject file is space sensitive. Let the <code> https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples<\/code> GitHub examples guide you.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1633946464143,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69479488",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72454747,
        "Question_title":"Problem when loading a xgboost model from mlflow registry",
        "Question_body":"<p>I create a xgboost classifier:<\/p>\n<pre><code>   xg_reg = xgb.XGBClassifier(objective ='reg:squarederror',  learning_rate = 0.1,\n                max_depth = 20, alpha = 10, n_estimators = 50, use_label_encoder=False)\n<\/code><\/pre>\n<p>After training the model, I am logging it to the MLFLow registry:<\/p>\n<pre><code>   mlflow.xgboost.log_model(\n        xgb_model = xg_reg, \n        artifact_path = &quot;xgboost-models&quot;,\n        registered_model_name = &quot;xgb-regression-model&quot;\n    )\n<\/code><\/pre>\n<p>In the remote UI, I can see the logged model:<\/p>\n<pre><code>artifact_path: xgboost-models\nflavors:\n  python_function:\n    data: model.xgb\n    env: conda.yaml\n    loader_module: mlflow.xgboost\n    python_version: 3.7.9\n  xgboost:\n    code: null\n    data: model.xgb\n    model_class: xgboost.sklearn.XGBClassifier\n    xgb_version: 1.5.2\nmlflow_version: 1.25.1\nmodel_uuid: 5fd42554cf184d8d96afae34dbb96de2\nrun_id: acdccd9f610b4c278b624fca718f76b4\nutc_time_created: '2022-05-17 17:54:53.039242\n<\/code><\/pre>\n<p>Now, on the server side, to load the logged model:<\/p>\n<pre><code>   model = mlflow.xgboost.load_model(model_uri=model_path)\n<\/code><\/pre>\n<p>which loads OK, but the model type is<\/p>\n<blockquote>\n<p>&lt;xgboost.core.Booster object at 0x00000234DBE61D00&gt;<\/p>\n<\/blockquote>\n<p>and the predictions are numpy.float32 (eg 0.5) instead of int64 (eg 0, 1) for the original model.<\/p>\n<p>Any ideas what can be wrong? Many thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1654036554297,
        "Question_score":1,
        "Question_tags":"python|xgboost|mlflow",
        "Question_view_count":163,
        "Owner_creation_time":1369252294280,
        "Owner_last_access_time":1663789810223,
        "Owner_location":null,
        "Owner_reputation":324,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It turns out this was caused by using different versions of mlflow. The model was uploaded to registry with the newest version but was loaded with a previous one. When updated the server to load it, it now works! :)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1655934198727,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72454747",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68753631,
        "Question_title":"Combine MLflow projects with docker-compose",
        "Question_body":"<p>I face the following situation:<\/p>\n<p>We train our models within docker container, which is build by running a docker-compose file. I have implemented MLflow to work with docker-compose (by doing something similar to e.g. this post: <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039<\/a>), creating two more containers (one for the server and one for the postgresql backend).<\/p>\n<p>However, the story doesn't end here. Our goal is to implement a full ML pipeline, which includes data creation, preprocessing steps and so on. I know, that ML projects is something which helps to create such pipeline. I have seen that it is designed to work with docker images (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/projects.html\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/projects.html<\/a>), but I don't get it, how one could use it with docker-compose.<\/p>\n<p>Could you help me in that by giving any tipps, guidelines, documentations, etc?<\/p>\n<p>Or in general, any advice, how a full machine learning pipeline could be implemented using mlflow?<\/p>\n<p>Thanks a lot!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1628755106943,
        "Question_score":1,
        "Question_tags":"machine-learning|docker-compose|pipeline|mlflow",
        "Question_view_count":1007,
        "Owner_creation_time":1512572031753,
        "Owner_last_access_time":1655968570680,
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Question_last_edit_time":1628775110070,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68753631",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69689266,
        "Question_title":"How to set a tag at the experiment level in MLFlow",
        "Question_body":"<p>I can see that an experiment in MLFlow can have tags (like runs can have tags).\nI'm able to set a run's tag using <code>mlflow.set_tag<\/code>, but how do I set it for an experiment?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1635000756820,
        "Question_score":2,
        "Question_tags":"python|mlflow",
        "Question_view_count":1047,
        "Owner_creation_time":1244984040077,
        "Owner_last_access_time":1663968051750,
        "Owner_location":"New York, NY",
        "Owner_reputation":13408,
        "Owner_up_votes":306,
        "Owner_down_votes":12,
        "Owner_views":687,
        "Question_last_edit_time":1635005765867,
        "Answer_body":"<p>If you look into the Python API, the very <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html\" rel=\"nofollow noreferrer\">first example<\/a> in <code>mlflow.tracking package<\/code> that shows how to create the <code>MLflowClient<\/code> is really showing how to tag experiment using the <code>client.set_experiment_tag<\/code> function (<a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.tracking.MlflowClient.set_experiment_tag\" rel=\"nofollow noreferrer\">doc<\/a>):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from mlflow.tracking import MlflowClient\n\n# Create an experiment with a name that is unique and case sensitive.\nclient = MlflowClient()\nexperiment_id = client.create_experiment(&quot;Social NLP Experiments&quot;)\nclient.set_experiment_tag(experiment_id, &quot;nlp.framework&quot;, &quot;Spark NLP&quot;)\n<\/code><\/pre>\n<p>you can also set it for model version with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.client.MlflowClient.set_model_version_tag\" rel=\"nofollow noreferrer\">set_model_version_tag<\/a> function, and for registered model with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.tracking.MlflowClient.set_registered_model_tag\" rel=\"nofollow noreferrer\">set_registered_model_tag<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1635012053310,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1663958792437,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69689266",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70030903,
        "Question_title":"Error while loading MLFlow model in python 3.7",
        "Question_body":"<p>I am saving the MLFlow model using databricks. Below are the details:<\/p>\n<pre><code>artifact_path: model\ndatabricks_runtime: 8.4.x-gpu-ml-scala2.12\nflavors:\n  python_function:\n    data: data\n    env: conda.yaml\n    loader_module: mlflow.pytorch\n    pickle_module_name: mlflow.pytorch.pickle_module\n    python_version: 3.8.8\n  pytorch:\n    model_data: data\n    pytorch_version: 1.9.0+cu102\n<\/code><\/pre>\n<p><strong>I am not able to locally load the model using Python 3.7<\/strong>, whereas it works well with Python 3.9.<\/p>\n<p>Any idea what could be the possible resolution to this?<\/p>\n<p>Error Trace:<\/p>\n<pre><code>  File &quot;\/Users\/danishm\/opt\/miniconda3\/envs\/py37\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 714, in load_model\n    return _load_model(path=torch_model_artifacts_path, **kwargs)\n  File &quot;\/Users\/danishm\/opt\/miniconda3\/envs\/py37\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 626, in _load_model\n    return torch.load(model_path, **kwargs)\n  File &quot;\/Users\/danishm\/opt\/miniconda3\/envs\/py37\/lib\/python3.7\/site-packages\/torch\/serialization.py&quot;, line 607, in load\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n  File &quot;\/Users\/danishm\/opt\/miniconda3\/envs\/py37\/lib\/python3.7\/site-packages\/torch\/serialization.py&quot;, line 882, in _load\n    result = unpickler.load()\nTypeError: code() takes at most 15 arguments (16 given)\n<\/code><\/pre>\n<p>I have tried specifying the pickle module name explicitly as <code>mlflow.pytorch.load_model(ML_MODEL_PATH,pickle_module=mlflow.pytorch.pickle_module)<\/code><\/p>\n<p>But still getting the same error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1637304792843,
        "Question_score":0,
        "Question_tags":"python-3.x|pickle|torch|mlflow",
        "Question_view_count":477,
        "Owner_creation_time":1637303950900,
        "Owner_last_access_time":1663585014760,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70030903",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69738859,
        "Question_title":"Multiple values for a single parameter in the mlflow run command",
        "Question_body":"<p>I just started learning mlflow and wanted to know how to pass multiple values to  each parameter in the mlflow run command.<\/p>\n<p>The objective is to pass a dictionary to GridSearchCV as a param_grid to perform cross validation.<\/p>\n<p>In my main code, I retrieve the command line parameters using argparse. And by adding nargs='+' in the add_argument(), I can write spaced values for each hyper parameter and then applying vars() to create the dictionary. See code below:<\/p>\n<pre><code>import argparse\n\n# Build the parameters for the command-line\nparam_names = list(RandomForestClassifier().get_params().keys())\n\n# Param types in the same order they appear in param_names by using get_params()\nparam_types = [bool, float, dict, str, int, float, int, float, float, float,\n               float, float, float, int, int, bool, int, int, bool]\n\n# Allow for only optional command-line arguments\nparser = argparse.ArgumentParser()\ngrid_group = parser.add_argument_group('param_grid_group')\nfor i, p in enumerate(param_names):\n    grid_group.add_argument(f'--{p}', type=param_types[i], nargs='+')\n#Create a param_grid to be passed to GridSearchCV\nparam_grid_unprocessed = vars(parser.parse_args())\n<\/code><\/pre>\n<p>This works well with the classic python command :<\/p>\n<pre><code>python my_code.py --max_depth 2 3 4 --n_estimators 400 600 1000\n<\/code><\/pre>\n<p>As I said, here I can just write spaced values for each hyper-parameter and the code above does the magic by grouping the values inside a list and returning the dictionary below that I can then pass to GridSearchCV :<\/p>\n<pre><code>{'max_depth':[2, 3, 4], 'n_estimators':[400, 600, 1000]}\n<\/code><\/pre>\n<p>However with the mlflow run command, I can't get it right so far as it only accepts one value for each parameter. Here's my MLproject file :<\/p>\n<pre><code>name: mlflow_project\n\nconda_env: conda.yml\n\nentry_points:\n\n  main:\n    parameters:\n      max_depth: int\n      n_estimators: int\n    command: &quot;python my_code.py --max_depth {max_depth} --n_estimators {n_estimators}&quot;\n<\/code><\/pre>\n<p>So this works :<\/p>\n<pre><code>mlflow run . -P max_depth=2 -P n_estimators=400\n<\/code><\/pre>\n<p>But not this :<\/p>\n<pre><code> mlflow run . -P max_depth=[2, 3, 4] -P n_estimators=[400, 600, 1000]\n<\/code><\/pre>\n<p>In the <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-run\" rel=\"nofollow noreferrer\">documentation<\/a>, it seems that it's impossible to do it. So, is there is any hack to overcome this problem ?<\/p>\n<p>Thank you in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1635338354137,
        "Question_score":2,
        "Question_tags":"python|gridsearchcv|mlflow",
        "Question_view_count":356,
        "Owner_creation_time":1586517832390,
        "Owner_last_access_time":1660328393330,
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69738859",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71568975,
        "Question_title":"Custom MLFlow scoring_server for model serving",
        "Question_body":"<p>I would like to know if MLflow currently does support any kind of customization of it's scoring_serving that would allow the ability to register new endpoints to the published Rest API.<\/p>\n<p>By default the scoring server provides \/ping and \/invocations endpoint, but i would like to include more endpoints in addition to those.<\/p>\n<p>I've seen some resources that allow that kind of behaviour using custom WSGI implementations but i would like to know if extension of the provided mlflow scoring_server is possible in any way, so the default supporty provided by mlflow generated docker images and the deployment management is not lost.<\/p>\n<p>I explored existing official and unofficial documentation, and explored existing github issues and the mlflow codebase in it's github repository.<\/p>\n<p>Also i've explored some alternatives such as using custom WSGI server configuration for starting the Rest API.<\/p>\n<p>Any kind of resource\/documentation is greatly appreciated.<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1647937847000,
        "Question_score":2,
        "Question_tags":"rest|mlflow|serving|mlops",
        "Question_view_count":96,
        "Owner_creation_time":1370003358430,
        "Owner_last_access_time":1655743101593,
        "Owner_location":"A Coru\u00f1a",
        "Owner_reputation":303,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71568975",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65887231,
        "Question_title":"Use mlflow to serve a custom python model for scoring",
        "Question_body":"<p>I am using Python code generated from an ml software with mlflow to read a dataframe, perform some table operations and output a dataframe. I am able to run the code successfully and save the new dataframe as an artifact. However I am unable to log the model using log_model because it is not a lr or classifier model where we train and fit. I want to log a model for this so that it can be served with new data and deployed with a rest API<\/p>\n<pre><code>df = pd.read_csv(r&quot;\/home\/xxxx.csv&quot;)\n\n\nwith mlflow.start_run():\n    def getPrediction(row):\n        \n        perform_some_python_operaions \n\n        return [Status_prediction, Status_0_probability, Status_1_probability]\n    columnValues = []\n    for column in columns:\n        columnValues.append([])\n\n    for index, row in df.iterrows():\n        results = getPrediction(row)\n        for n in range(len(results)):\n            columnValues[n].append(results[n])\n\n    for n in range(len(columns)):\n        df[columns[n]] = columnValues[n]\n\n    df.to_csv('dataset_statistics.csv')\n    mlflow.log_artifact('dataset_statistics.csv')\n   \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1611586824463,
        "Question_score":4,
        "Question_tags":"python|deployment|mlflow|mlops",
        "Question_view_count":3026,
        "Owner_creation_time":1573739890560,
        "Owner_last_access_time":1663922252563,
        "Owner_location":null,
        "Owner_reputation":115,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Question_last_edit_time":null,
        "Answer_body":"<p>MLflow supports <a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#custom-python-models\" rel=\"nofollow noreferrer\">custom models<\/a> of mlflow.pyfunc flavor.  You can create a custom  class  inherited from the <code>mlflow.pyfunc.PythonModel<\/code>, that needs to provide function <code>predict<\/code> for performing predictions, and optional <code>load_context<\/code> to load the necessary artifacts, like this (adopted from the docs):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class MyModel(mlflow.pyfunc.PythonModel):\n\n    def load_context(self, context):\n        # load your artifacts\n\n    def predict(self, context, model_input):\n        return my_predict(model_input.values)\n<\/code><\/pre>\n<p>You can log to MLflow whatever artifacts you need for your models, define Conda environment if necessary, etc.<br \/>\nThen you can use <code>save_model<\/code> with your class to save your implementation, that could be loaded with <code>load_model<\/code> and do the <code>predict<\/code> using your model:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.pyfunc.save_model(\n        path=mlflow_pyfunc_model_path, \n        python_model=MyModel(), \n        artifacts=artifacts)\n\n# Load the model in `python_function` format\nloaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1611592914947,
        "Answer_score":9.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":1634187940523,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65887231",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73386272,
        "Question_title":"How to log metrics to Azure ML Metrics Tab",
        "Question_body":"<p>I have the following train.py file<\/p>\n<pre><code>import argparse\nimport os\nimport numpy as np\nimport glob\n# import joblib\nimport mlflow\nimport logging\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport pandas as pd \n\nfrom matplotlib import pyplot as plt\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.dataset import Dataset\nfrom azureml.train.automl import AutoMLConfig\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nimport lightgbm as lgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\n\n\n# let user feed in 2 parameters, the dataset to mount or download,\n# and the regularization rate of the logistic regression model\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    &quot;--tablename&quot;, type=str, dest=&quot;tablename&quot;, help=&quot;Table name&quot;\n)\nargs = parser.parse_args()\n\ntablename = args.tablename\n\n\nsubscription_id = ''\nresource_group = 'mlplayground'\nworkspace_name = 'mlplayground'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\ndataset = Dataset.get_by_name(workspace, name=tablename)\ndata = dataset.to_pandas_dataframe()\n\n# use mlflow autologging\nmlflow.autolog()\n\ndata.drop(['postal_code','Column1','province','region','lattitude','longitude'], axis=1, inplace=True)\none_hot_state_of_the_building=pd.get_dummies(data.state_of_the_building) \none_hot_city = pd.get_dummies(data.city_name, prefix='city')\n\n#removing categorical features \ndata.drop(['city_name','state_of_the_building'],axis=1,inplace=True)  \n\n#Merging one hot encoded features with our dataset 'data' \ndata=pd.concat([data,one_hot_city,one_hot_state_of_the_building,],axis=1) \n\ndata['pricepersqm'] = data.price \/ data.house_area\n\nx=data.drop('price',axis=1) \ny=data.price \n\nX_df = DataFrame(x, columns= data.columns)\nX_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.20)\n\n#Converting the data into proper LGB Dataset Format\nd_train=lgb.Dataset(X_train, label=y_train)\n\n\n#Declaring the parameters\nparams = {\n    'task': 'train', \n    'boosting': 'gbdt',\n    'objective': 'regression',\n    'num_leaves': 10,\n    'learning_rate': 0.01,\n    'metric': {'l2','l1'},\n    'verbose': -1\n}\n\nprint(&quot;Train a LightGBM Regression model&quot;)\nclf=lgb.train(params,d_train,1000)\n\n#model prediction on X_test\nprint(&quot;Predict the test set&quot;)\ny_pred=clf.predict(X_test)\n\n#using RMSE error metric\nmse =mean_squared_error(y_pred,y_test)\nprint(&quot;RMSE: &quot;, mse**0.5)\nmlflow.log_metric(&quot;RMSE&quot;, mse**0.5)\n<\/code><\/pre>\n<p>And then from a notebook file I use the following:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core import Experiment\n\n# connect to your workspace\nws = Workspace.from_config()\n\nexperiment_name = &quot;get-started-with-jobsubmission-tutorial-andlightgbm&quot;\nexp = Experiment(workspace=ws, name=experiment_name)\n\n\n\nfrom azureml.core.environment import Environment\n\n# use a curated environment that has already been built for you\n\nenv = Environment.get(workspace=ws, \n                      name=&quot;AzureML-sklearn-1.0-ubuntu20.04-py38-cpu&quot;, \n                      version=1)\n\nfrom azureml.core import ScriptRunConfig\n\nargs = [&quot;--tablename&quot;, &quot;BelgiumRealEstate&quot;]\n\nsrc = ScriptRunConfig(\n    source_directory=&quot;&quot;,\n    script=&quot;train.py&quot;,\n    arguments=args,\n    compute_target=&quot;local&quot;,\n    environment=env,\n)\n\nrun = exp.submit(config=src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>As you can see in the train.py file I am logging the RMSE, however the metric does not appear on the metrics tab.<\/p>\n<p>What should I do?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660729490553,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|mlflow",
        "Question_view_count":40,
        "Owner_creation_time":1302030303093,
        "Owner_last_access_time":1663332147473,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73386272",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71001833,
        "Question_title":"Accessing Delta Lake Table in Databricks via Spark in MLflow project",
        "Question_body":"<p>I am currently accessing deltalake table from databricks notebook using spark. However now I need to access delta tables from MLflow project. MLflow spark api only allows logging and loading of SparkML models. Any idea on how can I accomplish this?<\/p>\n<p>Currently I am trying to access spark via this code in MLflow project:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>\nspark = pyspark.sql.SparkSession._instantiatedSession\nif spark is None:\n  # NB: If there is no existing Spark context, create a new local one.\n  # NB: We're disabling caching on the new context since we do not need it and we want to\n  # avoid overwriting cache of underlying Spark cluster when executed on a Spark Worker\n  # (e.g. as part of spark_udf).\n  spark = ( pyspark.sql.SparkSession.builder \\\n   .config(&quot;spark.python.worker.reuse&quot;, True)\n   .config(&quot;spark.databricks.io.cache.enabled&quot;, False)\n   # In Spark 3.1 and above, we need to set this conf explicitly to enable creating\n   # a SparkSession on the workers\n   .config(&quot;spark.executor.allowSparkContext&quot;, &quot;true&quot;)\n   .master(&quot;local[*]&quot;)\n   .appName(&quot;MLflow Project&quot;)\n   .getOrCreate()\n  )\n<\/code><\/pre>\n<p>But I am getting this error:<\/p>\n<pre><code>py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1644092503000,
        "Question_score":1,
        "Question_tags":"apache-spark|pyspark|databricks|delta-lake|mlflow",
        "Question_view_count":282,
        "Owner_creation_time":1477235384120,
        "Owner_last_access_time":1663896021600,
        "Owner_location":null,
        "Owner_reputation":71,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":1644169913797,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71001833",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72425907,
        "Question_title":"How to log a tensorflow model with mlflow.tensorflow.log_model (error module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants')",
        "Question_body":"<p>I am trying to log a trained model with MLFlow using mlflow.tensorflow.log_model.<\/p>\n<p>After training a simple sequential tf model<\/p>\n<pre><code>history = binary_model.fit(train_ds, validation_data=val_ds, epochs=num_epochs)\n<\/code><\/pre>\n<p>I am trying to log it:<\/p>\n<pre><code>    from tensorflow.python.saved_model import signature_constants\n    tag=[tf.saved_model.tag_constants.SERVING]\n    key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n\n    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n                                tf_meta_graph_tags=tag,\n                                tf_signature_def_key=key,\n                                artifact_path=&quot;tf-models&quot;,\n                                registered_model_name=model_name)\n<\/code><\/pre>\n<p>but I get the error:<\/p>\n<pre><code>    AttributeError                            Traceback (most recent call last)\n    \/var\/folders\/2k\/g7p7j2gx6v54vkwv3v401h2m0000gn\/T\/ipykernel_73638\/562549064.py in &lt;module&gt;\n          1 from tensorflow.python.saved_model import signature_constants\n    ----&gt; 2 tag=[tf.saved_model.tag_constants.SERVING]\n          3 key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n          4 \n          5 mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n\n    AttributeError: module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants'\n<\/code><\/pre>\n<p>Any idea how to get the tags and keys correctly from the model to log it in MLFlow?<\/p>\n<p>Many thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1653845789630,
        "Question_score":1,
        "Question_tags":"python|tensorflow|mlflow",
        "Question_view_count":319,
        "Owner_creation_time":1369252294280,
        "Owner_last_access_time":1663789810223,
        "Owner_location":null,
        "Owner_reputation":324,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The <code>tag_constants<\/code> is in <code>tf.compat.v1.saved_model<\/code>.<\/p>\n<p>To resolve the error replace this line<\/p>\n<pre><code>tag=[tf.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>with this<\/p>\n<pre><code>tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>Please refer <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/compat\/v1\/saved_model\/tag_constants\" rel=\"nofollow noreferrer\">this<\/a> for more details.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1655094569433,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72425907",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62271624,
        "Question_title":"Access databricks secrets in pyspark\/python job",
        "Question_body":"<p>Databricks secrets can be accessed within notebooks using dbutils, however since dbutils is not available outside notebooks how can one access secrets in pyspark\/python jobs, especially if they are run using mlflow.<\/p>\n\n<p>I have already tried <a href=\"https:\/\/stackoverflow.com\/questions\/51885332\/how-to-load-databricks-package-dbutils-in-pyspark?rq=1\">How to load databricks package dbutils in pyspark<\/a><\/p>\n\n<p>which does not work for remote jobs or mlflow project runs.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591652446997,
        "Question_score":1,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":1369,
        "Owner_creation_time":1497525776727,
        "Owner_last_access_time":1615138462217,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":481,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":49,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62271624",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62720044,
        "Question_title":"No Artifacts Recorded MLFlow",
        "Question_body":"<p>I am unable to store, view, and retrieve the artifacts in MLFlow. The artifact folder is empty irrespective of creating a new experiment and assign proper experiment name and location.<\/p>\n<p>Server: mlflow server --backend-store-uri mlruns\/ --default-artifact-root mlruns\/ --host 0.0.0.0 --port 5000<\/p>\n<p>Create an Experiment: mlflow.create_experiment(exp_name, artifact_location='mlruns\/')<\/p>\n<pre><code>with mlflow.start_run():\n    mlflow.log_metric(&quot;mse&quot;, float(binary))\n    mlflow.log_artifact(data_path, &quot;data&quot;)\n    # log model\n    mlflow.keras.log_model(model, &quot;models&quot;)\n<\/code><\/pre>\n<p>The code compiles and runs but does not have any artifacts recorded. It has mlflow.log-model.history file but not the model.h5<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1593796777153,
        "Question_score":4,
        "Question_tags":"python-3.x|machine-learning|keras|mlflow",
        "Question_view_count":2676,
        "Owner_creation_time":1536570133123,
        "Owner_last_access_time":1601678349240,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":89,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62720044",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":54773795,
        "Question_title":"Accessing MLFlow UI with a folder name different than mlruns",
        "Question_body":"<p>I set the <code>tracking_uri<\/code> to a folder name different than <code>mlruns<\/code>. <\/p>\n\n<p>Is there a way I can open the <strong>MLFlow UI<\/strong> pointing to the new folder name for mlruns? <\/p>\n\n<p>I know I can rename the folder back to <code>mlruns<\/code>, which gets me access to all of my metrics and parameters for each experiment, but the artifacts are not accessible, since they were logged to a different folder name than mlruns. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1550605267453,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":1521,
        "Owner_creation_time":1550605103667,
        "Owner_last_access_time":1575604038253,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1550609420313,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54773795",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60641337,
        "Question_title":"mlflow R installation MLFLOW_PYTHON_BIN",
        "Question_body":"<p>I am trying to install mlflow in R and im getting this error message saying <\/p>\n\n<blockquote>\n  <p>mlflow::install_mlflow()\n  Error in mlflow_conda_bin() :\n    Unable to find conda binary. Is Anaconda installed?\n    If you are not using conda, you can set the environment variable MLFLOW_PYTHON_BIN to the path of yourpython executable.<\/p>\n<\/blockquote>\n\n<p>I have tried the following<\/p>\n\n<pre><code>export MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\" \nsource ~\/.bashrc\necho $MLFLOW_PYTHON_BIN  -&gt; this prints the \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>or in R,<\/p>\n\n<pre><code>sys.setenv(MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\")\nsys.getenv() -&gt; prints MLFLOW_PYTHON_BIN is set to \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>however, it still does not work<\/p>\n\n<p>I do not want to use conda environment.<\/p>\n\n<p>how to I get past this error?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1583947052940,
        "Question_score":5,
        "Question_tags":"r|mlflow|system-variable",
        "Question_view_count":1141,
        "Owner_creation_time":1539211301843,
        "Owner_last_access_time":1663982305137,
        "Owner_location":null,
        "Owner_reputation":117,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":1584403666973,
        "Answer_body":"<p>The install_mlflow command only works with conda right now, sorry about the confusing message. You can either:<\/p>\n<ul>\n<li>install conda - this is the recommended way of installing and using mlflow<\/li>\n<\/ul>\n<p>or<\/p>\n<ul>\n<li>install mlflow python package yourself via pip<\/li>\n<\/ul>\n<p>To install mlflow yourself, pip install correct (matching the the R package) python version of mlflow and set the MLFLOW_PYTHON_BIN environment variable as well as MLFLOW_BIN evn variable: e.g.<\/p>\n<pre><code>library(mlflow)\nsystem(paste(&quot;pip install -U mlflow==&quot;, mlflow:::mlflow_version(), sep=&quot;&quot;))\nSys.setenv(MLFLOW_BIN=system(&quot;which mlflow&quot;))\nSys.setenv(MLFLOW_PYTHON_BIN=system(&quot;which python&quot;))\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1584554585177,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1624202175903,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60641337",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69703225,
        "Question_title":"Can I change the port of my MLflow tracking server?",
        "Question_body":"<p>I would like to know if I can change the port of my MLflow server.<\/p>\n<p>By default it is running on port 5000, but my company's VPN only allows HTTP (port 80) and HTTPS (port 443) traffic.<\/p>\n<p>This might be a very beginner's question, but is it possible, and if yes, is there any problem on running the MLflow server on port 83 (HTTP) ?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1635139632427,
        "Question_score":1,
        "Question_tags":"http|port|mlflow",
        "Question_view_count":540,
        "Owner_creation_time":1561106497313,
        "Owner_last_access_time":1661059074150,
        "Owner_location":null,
        "Owner_reputation":133,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Yes, you can do that by passing the <code>-p port_number<\/code> command-line switch when starting MLflow server (see <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#cmdoption-mlflow-server-p\" rel=\"nofollow noreferrer\">docs<\/a>). Please note, that to be able to use ports below 1024, the server needs to be run as root.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1635152056290,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69703225",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56647549,
        "Question_title":"MLflow Error while deploying the Model to local REST server",
        "Question_body":"<blockquote>\n  <p><strong>System Details:<\/strong><\/p>\n  \n  <p>Operating System: Ubuntu 19.04<\/p>\n  \n  <p>Anaconda version: 2019.03<\/p>\n  \n  <p>Python version: 3.7.3<\/p>\n  \n  <p>mlflow version: 1.0.0<\/p>\n<\/blockquote>\n\n<p><strong>Steps to Reproduce:<\/strong> <a href=\"https:\/\/mlflow.org\/docs\/latest\/tutorial.html\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tutorial.html<\/a><\/p>\n\n<p><strong>Error at line\/command:<\/strong> <code>mlflow models serve -m [path_to_model] -p 1234<\/code><\/p>\n\n<p><strong>Error:<\/strong>\nCommand 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1>&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1<\/p>\n\n<p><strong>Terminal Log:<\/strong><\/p>\n\n<pre><code>(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# mlflow models serve -m $(pwd) -p 1234\n2019\/06\/18 16:15:16 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2019\/06\/18 16:15:17 INFO mlflow.pyfunc.backend: === Running command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app'\nbash: activate: No such file or directory\nTraceback (most recent call last):\n  File \"\/root\/anaconda3\/envs\/mlflow\/bin\/mlflow\", line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 43, in serve\n    host=host)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 76, in serve\n    command_env=command_env)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 147, in _execute_in_conda_env\n    command, rc\nException: Command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1\n(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1560855399150,
        "Question_score":0,
        "Question_tags":"python-3.x|deployment|mlflow",
        "Question_view_count":1840,
        "Owner_creation_time":1504001058090,
        "Owner_last_access_time":1630952509900,
        "Owner_location":null,
        "Owner_reputation":2101,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Following the steps mentioned in the GitHub Issue <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">1507<\/a> (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/1507<\/a>) I was able to resolve this issue.<\/p>\n\n<p>In reference to this post, the \"<strong>anaconda\/bin\/<\/strong>\" directory is never added to the list of environment variables i.e. PATH variable. In order to resolve this issue, add the \"<strong>else<\/strong>\" part of conda initialize code block from ~\/.bashrc file to your PATH variable.<\/p>\n\n<pre><code># &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'conda init' !!\n__conda_setup=\"$('\/home\/atulk\/anaconda3\/bin\/conda' 'shell.bash' 'hook' 2&gt; \/dev\/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\" ]; then\n        . \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\"\n    else\n        export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n<\/code><\/pre>\n\n<p>In this case, I added <strong>export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"<\/strong> to the PATH variable. However, this is just a temporary fix until the issue is fixed in the project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1561730574530,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56647549",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72206086,
        "Question_title":"Can't log MLflow artifacts to S3 with docker-based tracking server",
        "Question_body":"<p>I'm trying to set up a simple MLflow tracking server with docker that uses a mysql backend store and S3 bucket for artifact storage.  I'm using a simple docker-compose file to set this up on a server and supplying all of the credentials through a .env file.  When I try to run the sklearn_elasticnet_wine example from the mlflow repo here: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine<\/a> using<code>TRACKING_URI = &quot;http:\/\/localhost:5005<\/code> from the machine hosting my tracking server, the run fails with the following error: <code>botocore.exceptions.NoCredentialsError: Unable to locate credentials<\/code>.  I've verified that my environment variables are correct and available in my mlflow_server container. The runs show up in my backend store so the run only seems to be failing at the artifact logging step.  I'm not sure why this isn't working.  I've seen a examples of how to set up a tracking server online, including: <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039<\/a>.  Some use minio also but others just specify their s3 location as I have.  I'm not sure what I'm doing wrong at this point. Do I need to explicitly set the ARTIFACT_URI as well?  Should I be using Minio?  Eventually, I'll be logging runs to the server from another machine, hence the nginx container.  I'm pretty new to all of this so I'm hoping it's something really obvious and easy to fix but so far the Google has failed me.  TIA.<\/p>\n<pre><code>version: '3'\n\nservices:\n  app: \n    restart: always\n    build: .\/mlflow\n    image: mlflow_server\n    container_name: mlflow_server\n    expose:\n      - 5001\n    ports:\n      - &quot;5001:5001&quot;\n    networks:\n      - internal \n    environment:\n      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\n      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}\n      - AWS_S3_BUCKET=${AWS_S3_BUCKET}\n      - DB_USER=${DB_USER}\n      - DB_PASSWORD=${DB_PASSWORD}\n      - DB_PORT=${DB_PORT}\n      - DB_NAME=${DB_NAME}\n    command: &gt;\n      mlflow server \n      --backend-store-uri mysql+pymysql:\/\/${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}\/${DB_NAME} \n      --default-artifact-root s3:\/\/${AWS_S3_BUCKET}\/mlruns\/\n      --host 0.0.0.0 \n      --port 5001\n\n  nginx: \n    restart: always\n    build: .\/nginx\n    image: mlflow_nginx\n    container_name: mlflow_nginx\n    ports:\n      - &quot;5005:80&quot; \n    networks:\n      - internal \n    depends_on:\n      - app\n\nnetworks:\n  internal:\n    driver: bridge\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1652294436513,
        "Question_score":2,
        "Question_tags":"docker|amazon-s3|docker-compose|boto3|mlflow",
        "Question_view_count":620,
        "Owner_creation_time":1639614248310,
        "Owner_last_access_time":1663891212383,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1652296959877,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72206086",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72688726,
        "Question_title":"Can you edit the tags of a registered model version after the fact using mlflow api?",
        "Question_body":"<p>I am trying to use the mlflow model registry. My plan is to have a monthly scheduled retraining pipeline. I know from reading the documentation that so long as I set the model name to the same string if I save a model\/use create_model_version it will create a new version of the model. I also saw from the documentation that I can set the tags associated with a version using create_model_version as well. I want to set tags for valid_to_date and valid_from_date for each version so that if I want to go back in time and backfill predictions with the correct version <em>as of<\/em> when the data is from I am using the correct model. My initial thought was every time I create a new model version I set the valid_from_date as the date of that model version creation and the valid_to_date as 1-1-2099. Then when I train a new version edit the tag of the previous version valid_to_date from 1-1-2099 to the date it was superceded by a new version. Is that something that can be done using the mlflow python api?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655735663570,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":108,
        "Owner_creation_time":1333388796950,
        "Owner_last_access_time":1663959988533,
        "Owner_location":null,
        "Owner_reputation":335,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72688726",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59003752,
        "Question_title":"adbazureml not supported by mlflow",
        "Question_body":"<p>We've been following the latest Microsoft webinar about deploying the ML model from Azure Databricks to Azure ML using the MLFlow, and we get the following error when trying to run the experiment from Databricks notebook using the following code:<\/p>\n\n<pre><code>experimentName=\"someExperimentName\"\nmlflow.set_experiment(experimentName)\n<\/code><\/pre>\n\n<p>the error message:<\/p>\n\n<blockquote>\n  <p>UnsupportedModelRegistryStoreURIException: Unsupported URI\n  'adbazureml:\/\/westus.experiments.azureml.net\/history\/v1.0\/subscriptions\/cemrecdsap-t10us-20180830\/resourceGroups\/2f5a718e-7c56-4dd3-aa7b-03a19b70667\/providers\/Microsoft.MachineLearningServices\/workspaces\/cemrecdsap-mlservice'\n  for model registry store. Supported schemes are: ['', 'file',\n  'sqlite', 'https', 'databricks', 'postgresql', 'mysql', 'http',\n  'mssql']<\/p>\n<\/blockquote>\n\n<p>Init script we use as suggested in Microsoft MLflow webinar:\n(it was available here, but now it's removed - <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/azure-databricks\/linking\/azureml-cluster-init.sh\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/azure-databricks\/linking\/azureml-cluster-init.sh<\/a>)<\/p>\n\n<pre><code>#!\/bin\/bash\n\n############## START CONFIGURATION #################\n# Provide the required *AzureML* workspace information\nregion=\"westus\" \nsubscriptionId=\"bcb65f42-f234-4bff-91cf-9ef816cd9936\" \nresourceGroupName=\"dev-rg\"\nworkspaceName=\"myazuremlws\"\n# Optional config directory\nconfigLocation=\"\/databricks\/config.json\"\n############### END CONFIGURATION #################\n\n# Drop the workspace configuration on the cluster\nsudo touch $configLocation\nsudo echo {\\\\\"subscription_id\\\\\": \\\\\"${subscriptionId}\\\\\", \\\\\"resource_group\\\\\": \\\\\"${resourceGroupName}\\\\\", \\\\\"workspace_name\\\\\": \\\\\"${workspaceName}\\\\\"} &gt; $configLocation\n\n# Set the MLflow Tracking URI\ntrackingUri=\"adbazureml:\/\/${region}.experiments.azureml.net\/history\/v1.0\/subscriptions\/${subscriptionId}\/resourceGroups\/${resourceGroupName}\/providers\/Microsoft.MachineLearningServices\/workspaces\/${workspaceName}\"\nsudo echo export MLFLOW_TRACKING_URI=${trackingUri} &gt;&gt; \/databricks\/spark\/conf\/spark-env.sh \n<\/code><\/pre>\n\n<p>We use the latest MLFlow version, 1.4<\/p>\n\n<p>Is there a chance that the <strong>adbazureml<\/strong> protocol that was used in the webinar is not supported yet by MLFlow?\nOr we missed something else?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1574472436810,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":430,
        "Owner_creation_time":1502581315743,
        "Owner_last_access_time":1576191685887,
        "Owner_location":"Israel",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59003752",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69944447,
        "Question_title":"How to change the directory of mlflow logs?",
        "Question_body":"<p>I am using MLflow to log the metrics but I want to change the default saving logs directory. So, instead of writing log files besides my main file, I want to store them to <code>\/path\/outputs\/lg <\/code>. I don't know how to change it. I use it without in the <code>Model<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nfrom time import time\n\nimport mlflow\nimport numpy as np\nimport torch\nimport tqdm\n\n# from segmentation_models_pytorch.utils import metrics\nfrom AICore.emergency_landing.metrics import IoU, F1\nfrom AICore.emergency_landing.utils import AverageMeter\nfrom AICore.emergency_landing.utils import TBLogger\n\n\nclass Model:\n    def __init__(self, model, num_classes=5, ignore_index=0, optimizer=None, scheduler=None, criterion=None,\n                 device=None, epochs=30, train_loader=None, val_loader=None, tb_logger: TBLogger = None,\n                 logger=None,\n                 best_model_path=None,\n                 model_check_point_path=None,\n                 load_from_best_model=None,\n                 load_from_model_checkpoint=None,\n                 early_stopping=None,\n                 debug=False):\n\n        self.debug = debug\n\n        self.early_stopping = {\n            'init': early_stopping,\n            'changed': 0\n        }\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.criterion = criterion\n        self.device = device\n        self.epochs = epochs\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.model = model.to(device)\n\n        self.tb_logger = tb_logger\n        self.logger = logger\n\n        self.best_loss = np.Inf\n\n        if not os.path.exists(best_model_path):\n            os.makedirs(best_model_path)\n        self.best_model_path = best_model_path\n\n        if not os.path.exists(model_check_point_path):\n            os.makedirs(model_check_point_path)\n        self.model_check_point_path = model_check_point_path\n\n        self.load_from_best_model = load_from_best_model\n        self.load_from_model_checkpoint = load_from_model_checkpoint\n\n        if self.load_from_best_model is not None:\n            self.load_model(path=self.load_from_best_model)\n        if self.load_from_model_checkpoint is not None:\n            self.load_model_checkpoint(path=self.load_from_model_checkpoint)\n\n        self.train_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.val_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.test_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n\n        self.train_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.val_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.test_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n\n    def metrics(self, is_train=True):\n        if is_train:\n            train_losses = AverageMeter('Training Loss', ':.4e')\n            train_iou = AverageMeter('Training iou', ':6.2f')\n            train_f_score = AverageMeter('Training F_score', ':6.2f')\n\n            return train_losses, train_iou, train_f_score\n        else:\n            val_losses = AverageMeter('Validation Loss', ':.4e')\n            val_iou = AverageMeter('Validation mean iou', ':6.2f')\n            val_f_score = AverageMeter('Validation F_score', ':6.2f')\n\n            return val_losses, val_iou, val_f_score\n\n    def fit(self):\n\n        self.logger.info(&quot;\\nStart training\\n\\n&quot;)\n        start_training_time = time()\n\n        with mlflow.start_run():\n            for e in range(self.epochs):\n                start_training_epoch_time = time()\n                self.model.train()\n                train_losses_avg, train_iou_avg, train_f_score_avg = self.metrics(is_train=True)\n                with tqdm.tqdm(self.train_loader, unit=&quot;batch&quot;) as tepoch:\n                    tepoch.set_description(f&quot;Epoch {e}&quot;)\n                    for image, target in tepoch:\n                        # Transfer Data to GPU if available\n                        image = image.to(self.device)\n                        target = target.to(self.device)\n                        # Clear the gradients\n                        self.optimizer.zero_grad()\n                        # Forward Pass\n                        # out = self.model(image)['out']\n                        # if unet == true =&gt; remove ['out']\n                        out = self.model(image)\n                        # Find the Loss\n                        loss = self.criterion(out, target)\n                        # Calculate Loss\n                        train_losses_avg.update(loss.item(), image.size(0))\n                        # Calculate gradients\n                        loss.backward()\n                        # Update Weights\n                        self.optimizer.step()\n\n                        iou = self.train_iou(out.cpu(), target.cpu()).item()\n                        train_iou_avg.update(iou)\n\n                        f1_score = self.train_f1(out.cpu(), target.cpu()).item()\n                        train_f_score_avg.update(f1_score)\n\n                        tepoch.set_postfix(loss=train_losses_avg.avg,\n                                           iou=train_iou_avg.avg,\n                                           f_score=train_f_score_avg.avg)\n                        if self.debug:\n                            break\n\n                self.tb_logger.log(log_type='criterion\/training', value=train_losses_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='iou\/training', value=train_iou_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='f_score\/training', value=train_f_score_avg.avg, epoch=e)\n\n                mlflow.log_metric('criterion\/training', train_losses_avg.avg, step=e)\n                mlflow.log_metric('iou\/training', train_iou_avg.avg, step=e)\n                mlflow.log_metric('f_score\/training', train_f_score_avg.avg, step=e)\n\n                end_training_epoch_time = time() - start_training_epoch_time\n                print('\\n')\n                self.logger.info(\n                    f'Training Results - [{end_training_epoch_time:.3f}s] Epoch: {e}:'\n                    f' f_score: {train_f_score_avg.avg:.3f},'\n                    f' IoU: {train_iou_avg.avg:.3f},'\n                    f' Loss: {train_losses_avg.avg:.3f}')\n\n                # validation step\n                val_loss = self.evaluation(e)\n                # apply scheduler\n                if self.scheduler:\n                    self.scheduler.step()\n                # early stopping\n                if self.early_stopping['init'] &gt;= self.early_stopping['changed']:\n                    self._early_stopping_model(val_loss=val_loss)\n                else:\n                    print(f'The model can not learn more, Early Stopping at epoch[{e}]')\n                    break\n\n                # save best model\n                if self.best_model_path is not None:\n                    self._best_model(val_loss=val_loss, path=self.best_model_path)\n\n                # model check points\n                if self.model_check_point_path is not None:\n                    self.save_model_check_points(path=self.model_check_point_path, epoch=e, net=self.model,\n                                                 optimizer=self.optimizer, loss=self.criterion,\n                                                 avg_loss=train_losses_avg.avg)\n\n                # log mlflow\n                if self.scheduler:\n                    mlflow.log_param(&quot;get_last_lr&quot;, self.scheduler.get_last_lr())\n                    mlflow.log_param(&quot;scheduler&quot;, self.scheduler.state_dict())\n\n                self.tb_logger.flush()\n                if self.debug:\n                    break\n\n            end_training_time = time() - start_training_time\n            print(f'Finished Training after {end_training_time:.3f}s')\n            self.tb_logger.close()\n\n    def evaluation(self, epoch):\n        print('Validating...')\n        start_validation_epoch_time = time()\n        self.model.eval()  # Optional when not using Model Specific layer\n        with torch.no_grad():\n            val_losses_avg, val_iou_avg, val_f_score_avg = self.metrics(is_train=False)\n            with tqdm.tqdm(self.val_loader, unit=&quot;batch&quot;) as tepoch:\n                for image, target in tepoch:\n                    # Transfer Data to GPU if available\n                    image = image.to(self.device)\n                    target = target.to(self.device)\n                    # out = self.model(image)['out']\n                    # if unet == true =&gt; remove ['out']\n                    out = self.model(image)\n                    # Find the Loss\n                    loss = self.criterion(out, target)\n                    # Calculate Loss\n                    val_losses_avg.update(loss.item(), image.size(0))\n\n                    iou = self.val_iou(out.cpu(), target.cpu()).item()\n                    val_iou_avg.update(iou)\n\n                    f1_score = self.val_f1(out.cpu(), target.cpu()).item()\n                    val_f_score_avg.update(f1_score)\n\n                    tepoch.set_postfix(loss=val_losses_avg.avg,\n                                       iou=val_iou_avg.avg,\n                                       f_score=val_f_score_avg.avg)\n                    if self.debug:\n                        break\n            print('\\n')\n            self.tb_logger.log(log_type='criterion\/validation', value=val_losses_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='iou\/validation', value=val_iou_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='f_score\/validation', value=val_f_score_avg.avg, epoch=epoch)\n\n            mlflow.log_metric('criterion\/validation', val_losses_avg.avg, step=epoch)\n            mlflow.log_metric('iou\/validation', val_iou_avg.avg, step=epoch)\n            mlflow.log_metric('f_score\/validation', val_f_score_avg.avg, step=epoch)\n\n            end_validation_epoch_time = time() - start_validation_epoch_time\n            self.logger.info(\n                f'validation Results - [{end_validation_epoch_time:.3f}s] Epoch: {epoch}:'\n                f' f_score: {val_f_score_avg.avg:.3f},'\n                f' IoU: {val_iou_avg.avg:.3f},'\n                f' Loss: {val_losses_avg.avg:.3f}')\n            print('\\n')\n            return val_losses_avg.avg\n\n    def _save_model(self, name, path, params):\n        torch.save(params, path)\n\n    def _early_stopping_model(self, val_loss):\n        if self.best_loss &lt; val_loss:\n            self.early_stopping['changed'] += 1\n        else:\n            self.early_stopping['changed'] = 0\n\n    def _best_model(self, val_loss, path):\n        if self.best_loss &gt; val_loss:\n            self.best_loss = val_loss\n            name = f'\/best_model_loss_{self.best_loss:.2f}'.replace('.', '_')\n            self._save_model(name, path=f'{path}\/{name}.pt', params={\n                'model_state_dict': self.model.state_dict(),\n            })\n\n            print(f'The best model is saved with criterion: {self.best_loss:.2f}')\n\n    def save_model_check_points(self, path, epoch, net, optimizer, loss, avg_loss):\n        name = f'\/model_epoch_{epoch}_loss_{avg_loss:.2f}'.replace('.', '_')\n        self._save_model(name, path=f'{path}\/{name}.pt', params={\n            'epoch': epoch,\n            'model_state_dict': net.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'criterion': loss,\n        })\n        print(f'model checkpoint is saved at model_epoch_{epoch}_loss_{avg_loss:.2f}')\n\n    def load_model_checkpoint(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        epoch = checkpoint['epoch']\n        self.criterion = checkpoint['criterion']\n\n        return epoch\n\n    def load_model(self, path):\n        best_model = torch.load(path)\n        self.model.load_state_dict(best_model['model_state_dict'])\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1636727119830,
        "Question_score":0,
        "Question_tags":"machine-learning|deep-learning|pytorch|mlflow",
        "Question_view_count":436,
        "Owner_creation_time":1410333105327,
        "Owner_last_access_time":1662489968593,
        "Owner_location":"Turin, Metropolitan City of Turin, Italy",
        "Owner_reputation":477,
        "Owner_up_votes":133,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Question_last_edit_time":1636755379243,
        "Answer_body":"<p>The solution is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(uri=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nexp = mlflow.get_experiment_by_name(name='Emegency_landing')\nif not exp:\n    experiment_id = mlflow.create_experiment(name='Emegency_landing',\n                                                 artifact_location=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nelse:\n    experiment_id = exp.experiment_id\n<\/code><\/pre>\n<p>And then you should pass the experiment Id to:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with mlflow.start_run(experiment_id=experiment_id):\n     pass \n<\/code><\/pre>\n<p>If you don't mention the <code>\/path\/mlruns<\/code>, when you run the command of <code>mlflow ui<\/code>, it will create another folder automatically named <code>mlruns<\/code>. so, pay attention to this point to have the same name as <code>mlruns<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1636732235590,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1636755540677,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69944447",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67959892,
        "Question_title":"Log experiments with MLflow to DAGsHub tracking server",
        "Question_body":"<p>I'm trying to use MLflow and log my experiments to DAGsHub's remote-tracking server but I get this error message:<\/p>\n<p><code>WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object has no attribute 'info' <\/code> with a lot of HTML text.<\/p>\n<p>When I check my DAGsHub repo, no new experiment is created.<\/p>\n<p>What am I'm doing wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1623598028067,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":95,
        "Owner_creation_time":1620133604910,
        "Owner_last_access_time":1641927869990,
        "Owner_location":"New York, NY, USA",
        "Owner_reputation":53,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67959892",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72663925,
        "Question_title":"Failure on importing mlflow to Azure Databricks 7.3 LTS ML Runtime",
        "Question_body":"<p>I am having trouble trying to import mlflow to Azure databricks. I'm currently using 7.3 LTS ML Runtime, which already have mlflow==1.11.0. I am a developing data scientist and I have no clue how to solve this issue. Have already tried to reinstall and didn't suceed. Any thoughts?<\/p>\n<p>This is the error message:<\/p>\n<pre><code>Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.8.0.post1 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('azureml-core~=1.19.0'), {'azureml-telemetry'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-core 1.8.0.post1 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('azureml-core~=1.19.0'), {'azureml-telemetry'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.8.0.post1 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('azureml-core~=1.19.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.8.0.post1 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('azureml-core~=1.19.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.8.0.post1 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('azureml-core~=1.19.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (msrest 0.6.18 (\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages), Requirement.parse('msrest&gt;=0.6.21'), {'azure-mgmt-containerregistry'}).\nCould not import from mlflow. Please upgrade to Mlflow 1.4.0 or higher.\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py:123: UserWarning: Failure attempting to register store for scheme &quot;adbazureml&quot;: No module named 'mlflow.store.rest_store'\n  _tracking_store_registry.register_entrypoints()\nCould not import from mlflow. Please upgrade to Mlflow 1.4.0 or higher.\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/utils.py:123: UserWarning: Failure attempting to register store for scheme &quot;azureml&quot;: No module named 'mlflow.store.rest_store'\n  _tracking_store_registry.register_entrypoints()\nCould not import from mlflow. Please upgrade to Mlflow 1.4.0 or higher.\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_model_registry\/utils.py:106: UserWarning: Failure attempting to register store for scheme &quot;azureml&quot;: No module named 'mlflow.store.rest_store'\n  _model_registry_store_registry.register_entrypoints()\nCould not import from mlflow. Please upgrade to Mlflow 1.4.0 or higher.\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py:89: UserWarning: Failure attempting to register artifact repository for scheme &quot;adbazureml&quot;: No module named 'mlflow.store.rest_store'\n  _artifact_repository_registry.register_entrypoints()\nCould not import from mlflow. Please upgrade to Mlflow 1.4.0 or higher.\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repository_registry.py:89: UserWarning: Failure attempting to register artifact repository for scheme &quot;azureml&quot;: No module named 'mlflow.store.rest_store'\n  _artifact_repository_registry.register_entrypoints()\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/tensorflow\/python\/data\/ops\/iterator_ops.py:546: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n  class IteratorBase(collections.Iterator, trackable.Trackable,\n\/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-818c9387-555f-4b61-a142-d3c244a68503\/lib\/python3.7\/site-packages\/tensorflow\/python\/autograph\/utils\/testing.py:21: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n\npip list\n\nazure-common              1.1.28           \nazure-core                1.24.1           \nazure-graphrbac           0.61.1           \nazure-identity            1.4.1            \nazure-mgmt-authorization  0.61.0           \nazure-mgmt-containerregistry 10.0.0        \nazure-mgmt-core           1.3.1            \nazure-mgmt-keyvault       2.2.0            \nazure-mgmt-network        10.2.0           \nazure-mgmt-resource       11.0.0           \nazure-mgmt-storage        11.2.0           \nazure-storage-blob        12.4.0           \nazureml-automl-core       1.19.0           \nazureml-core              1.8.0.post1      \nazureml-dataprep          2.6.6            \nazureml-dataprep-native   26.0.0           \nazureml-dataprep-rslex    1.4.0            \nazureml-dataset-runtime   1.19.0.post1     \nazureml-mlflow            1.8.0            \nazureml-pipeline          1.19.0           \nazureml-pipeline-core     1.19.0           \nazureml-pipeline-steps    1.19.0           \nazureml-sdk               1.19.0           \nazureml-telemetry         1.19.0           \nazureml-train             1.19.0           \nazureml-train-automl-client 1.19.0         \nazureml-train-core        1.19.0           \nazureml-train-restclients-hyperdrive 1.19.0\nmlflow                    1.11.0\npip                       20.0.2\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655493728417,
        "Question_score":0,
        "Question_tags":"python|azure-databricks|mlflow",
        "Question_view_count":102,
        "Owner_creation_time":1647266372287,
        "Owner_last_access_time":1655579594010,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72663925",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72053762,
        "Question_title":"How to create seperate mlflow custom models for training and prediction?",
        "Question_body":"<p>My requirement is to create separate Mlflow custom models for training and prediction.\nI want to create training model and use those training model in prediction model<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1651214518370,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":45,
        "Owner_creation_time":1651212627497,
        "Owner_last_access_time":1663746029710,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72053762",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71408963,
        "Question_title":"Getting `dtype of input object does not match expected dtype <U0` when invoking MLflow-deployed NLP model in SageMaker",
        "Question_body":"<p>I deployed a Huggingface Transformer model in SageMaker using MLflow's <code>sagemaker.deploy()<\/code>.<\/p>\n<p>When logging the model I used <code>infer_signature(np.array(test_example), loaded_model.predict(test_example))<\/code> to infer input and output signatures.<\/p>\n<p>Model is deployed successfully. When trying to query the model I get <code>ModelError<\/code> (full traceback below).<\/p>\n<p>To query the model, I am using precisely the same <code>test_example<\/code> that I used for <code>infer_signature()<\/code>:<\/p>\n<p><code>test_example = [['This is the subject', 'This is the body']]<\/code><\/p>\n<p>The only difference is that when querying the deployed model, I am not wrapping the test example in <code>np.array()<\/code> as that is not <code>json<\/code>-serializeable.<\/p>\n<p>To query the model I tried two different approaches:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\n\nSAGEMAKER_REGION = 'us-west-2'\nMODEL_NAME = '...'\n\nclient = boto3.client(&quot;sagemaker-runtime&quot;, region_name=SAGEMAKER_REGION)\n\n# Approach 1\nclient.invoke_endpoint(\n                EndpointName=MODEL_NAME,\n                Body=json.dumps(test_example),\n                ContentType=&quot;application\/json&quot;,\n            )\n\n# Approach 2\nclient.invoke_endpoint(\n                EndpointName=MODEL_NAME,\n                Body=pd.DataFrame(test_example).to_json(orient=&quot;split&quot;),\n                ContentType=&quot;application\/json; format=pandas-split&quot;,\n            )\n<\/code><\/pre>\n<p>but they result in the same error.<\/p>\n<p>Will be grateful for your suggestions.<\/p>\n<p>Thank you!<\/p>\n<p>Note: I am using Python 3 and all <strong>strings are unicode<\/strong>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>---------------------------------------------------------------------------\nModelError                                Traceback (most recent call last)\n&lt;ipython-input-89-d09862a5f494&gt; in &lt;module&gt;\n      2                 EndpointName=MODEL_NAME,\n      3                 Body=test_example,\n----&gt; 4                 ContentType=&quot;application\/json; format=pandas-split&quot;,\n      5             )\n\n~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\n    393                     &quot;%s() only accepts keyword arguments.&quot; % py_operation_name)\n    394             # The &quot;self&quot; in this scope is referring to the BaseClient.\n--&gt; 395             return self._make_api_call(operation_name, kwargs)\n    396 \n    397         _api_call.__name__ = str(py_operation_name)\n\n~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\n    723             error_code = parsed_response.get(&quot;Error&quot;, {}).get(&quot;Code&quot;)\n    724             error_class = self.exceptions.from_code(error_code)\n--&gt; 725             raise error_class(parsed_response, operation_name)\n    726         else:\n    727             return parsed_response\n\nModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message &quot;{&quot;error_code&quot;: &quot;BAD_REQUEST&quot;, &quot;message&quot;: &quot;dtype of input object does not match expected dtype &lt;U0&quot;}&quot;. See https:\/\/us-west-2.console.aws.amazon.com\/cloudwatch\/home?region=us-west-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/bec-sagemaker-model-test-app in account 543052680787 for more information.\n<\/code><\/pre>\n<p>Environment info:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{'channels': ['defaults', 'conda-forge', 'pytorch'],\n 'dependencies': ['python=3.6.10',\n  'pip==21.3.1',\n  'pytorch=1.10.2',\n  'cudatoolkit=10.2',\n  {'pip': ['mlflow==1.22.0',\n    'transformers==4.17.0',\n    'datasets==1.18.4',\n    'cloudpickle==1.3.0']}],\n 'name': 'bert_bec_test_env'}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1646826989870,
        "Question_score":0,
        "Question_tags":"amazon-web-services|nlp|amazon-sagemaker|mlflow",
        "Question_view_count":61,
        "Owner_creation_time":1490275561927,
        "Owner_last_access_time":1663878457720,
        "Owner_location":"Tel Aviv",
        "Owner_reputation":83,
        "Owner_up_votes":30,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Question_last_edit_time":1646837087963,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71408963",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70445997,
        "Question_title":"MLflow run within a docker container - Running with \"docker_env\" in MLflow project file",
        "Question_body":"<p>We are trying to develop an MLflow pipeline. We have our developing environment in a series of dockers (no local python environment &quot;whatsoever&quot;). This means that we have set up a docker container with MLflow and all requirements necessary to run pipelines. The issue we have is that when we write our MLflow project file we need to use &quot;docker_env&quot; to specify the environment. This figure illustrates what we want to achieve:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1tLuw.jpg\" rel=\"nofollow noreferrer\">MLflow run dind<\/a><\/p>\n<p>MLflow inside the docker needs to access the docker daemon\/service so that it can either use the &quot;docker-image&quot; in the MLflow project file or pull it from docker hub. We are aware of the possibility of using &quot;conda_env&quot; in the MLflow project file but wish to avoid this.<\/p>\n<p>Our question is,<\/p>\n<p>Do we need to set some sort of &quot;docker in docker&quot; solution to achieve our goal?<\/p>\n<p>Is it possible to set up the docker container in which MLflow is running so that it can access the &quot;host machine&quot; docker daemon?<\/p>\n<p>I have been all over Google and MLflow's documentation but I can seem to find anything that can guide us. Thanks a lot in advance for any help or pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_time":1640160788793,
        "Question_score":1,
        "Question_tags":"docker|mlflow|docker-in-docker",
        "Question_view_count":779,
        "Owner_creation_time":1546431264350,
        "Owner_last_access_time":1663848875057,
        "Owner_location":"Norway",
        "Owner_reputation":31,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1640184686953,
        "Answer_body":"<p>I managed to create my pipeline using docker and docker_env in MLflow. It is not necessary to run d-in-d, the &quot;sibling approach&quot; is sufficient. This approach is described here:<\/p>\n<p><a href=\"https:\/\/jpetazzo.github.io\/2015\/09\/03\/do-not-use-docker-in-docker-for-ci\/\" rel=\"nofollow noreferrer\">https:\/\/jpetazzo.github.io\/2015\/09\/03\/do-not-use-docker-in-docker-for-ci\/<\/a><\/p>\n<p>and it is the preferred method to avoid d-in-d.<\/p>\n<p>One needs to be very careful when mounting volumes within the primary and secondary docker environments: all volume mounts happen in the host machine.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1640385689187,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70445997",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73591190,
        "Question_title":"MLFlow & Conda: store envs in project dir instead of ~\/opt\/anaconda3\/envs",
        "Question_body":"<p>As per conda's <a href=\"https:\/\/docs.conda.io\/projects\/conda\/en\/latest\/user-guide\/tasks\/manage-environments.html#id3\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<blockquote>\n<p>You can control where a conda environment lives by providing a path to a target directory when creating the environment. [...]:\n<code>conda create --prefix .\/envs jupyterlab=3.2 matplotlib=3.5 numpy=1.21<\/code><\/p>\n<\/blockquote>\n<p>Is it possible to modify how mlflow invoques <code>conda create<\/code> when generating all the components' environments, in order save those at the root of the project instead of the default <code>...\/anaconda3\/envs<\/code> ?<\/p>\n<p>Many thanks in advance for your help,<br \/>\nKind regards<br \/>\nMarc<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1662198074837,
        "Question_score":0,
        "Question_tags":"conda|mlflow|anaconda3",
        "Question_view_count":18,
        "Owner_creation_time":1598781108953,
        "Owner_last_access_time":1664084623343,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1662198174733,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73591190",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66282143,
        "Question_title":"Sagemaker Train Job can't connect to ec2 instance",
        "Question_body":"<p>I have MLFlow server running on ec2 instance, port 5000.<\/p>\n<p>This ec2 instance has security group with opened TCP connection on port 5000 to another security group designated for SageMaker.<\/p>\n<p>ec2 instance inbound rules:\n<a href=\"https:\/\/i.stack.imgur.com\/VXwid.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VXwid.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>SageMaker outbound rules:\n<a href=\"https:\/\/i.stack.imgur.com\/ZUzek.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZUzek.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>These 2 security groups are in the same VPC<\/p>\n<p>Now, I try to run SageMaker training job with designated security group, so that the training script will log metrics to ec2 server via internal IP address. (As answered <a href=\"https:\/\/stackoverflow.com\/questions\/45416882\/aws-security-group-include-another-security-group\">here<\/a>), but connection fails<\/p>\n<p>SageMaker job init:<\/p>\n<pre><code>   role = &quot;ml_sagemaker&quot;\n   security_group_ids = ['sg-04868acca16e81183']\n   bucket = sagemaker_session.default_bucket()  \n   out_path = f&quot;s3:\/\/{bucket}\/{project_name}&quot;\n\n   estimator = PyTorch(entry_point='run_train.py',\n                       source_dir='.',\n                       sagemaker_session=sagemaker_session,\n                       instance_type=instance_type,\n                       instance_count=1,\n                       framework_version='1.5.0',\n                       py_version='py3',\n                       role=role,\n                       security_group_ids=security_group_ids,\n                       hyperparameters={},\n                       )\n   ....\n\n<\/code><\/pre>\n<p>Inside <code>run_train.py<\/code>:<\/p>\n<pre><code>import mlflow\ntracking_uri = &quot;http:\/\/172.31.77.137:5000&quot;  # &lt;- this is internal ec2 IP\nmlflow.set_tracking_uri(tracking_uri)\nmlflow.log_param(&quot;test_param&quot;, 3)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>File &quot;\/opt\/conda\/lib\/python3.6\/site-packages\/urllib3\/util\/connection.py&quot;, line 74, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 110] Connection timed out\n<\/code><\/pre>\n<p><strong>However<\/strong>, when when I create SageMaker Notebook instance with the same security group and the same IAM role, I am able to successfully connect to ec2 and log metrics from within the Notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/YYHlO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YYHlO.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Here is SageMaker Notebook configurations:<\/p>\n<img src=\"https:\/\/i.stack.imgur.com\/bslu8.png\" width=\"300\" \/>\n<p>How can I connect to ec2 instance from SageMaker Training Job?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1613755129957,
        "Question_score":1,
        "Question_tags":"amazon-ec2|amazon-vpc|amazon-sagemaker|aws-security-group|mlflow",
        "Question_view_count":608,
        "Owner_creation_time":1438098365740,
        "Owner_last_access_time":1663853069297,
        "Owner_location":null,
        "Owner_reputation":653,
        "Owner_up_votes":216,
        "Owner_down_votes":1,
        "Owner_views":76,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66282143",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57237388,
        "Question_title":"MLFlow project run fails during conda env creation",
        "Question_body":"<p>I am trying to get mlflow mlproject working.<\/p>\n\n<p>When i run the mlflow run with repo name<\/p>\n\n<pre><code>mlflow run  git@gitlabe2.xx.yy.zz:name\/mlflow-example.git\n<\/code><\/pre>\n\n<p>The execution fails with the below error<\/p>\n\n<pre><code>File \"\/home\/example\/miniconda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 265, in run\nuse_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\nFile \"\/home\/example\/miniconda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 144, in _run\nconda_env_name = _get_or_create_conda_env(project.conda_env_path)\nFile \"\/home\/example\/miniconda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 144, in _run\nconda_env_name = _get_or_create_conda_env(project.conda_env_path)\nFile \"\/home\/example\/miniconda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/projects\/__init__.py\", line 498, in _get_or_create_conda_env\nconda_env_path], stream_output=True)\nFile \"\/home\/example\/miniconda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/utils\/process.py\", line 38, in exec_cmd\nraise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\n<\/code><\/pre>\n\n<p>Any pointers on where I should look ?<\/p>\n\n<p>The suspect the conda.yaml file has some issues especially the conda env name.\nI have different names for the environment where the project is created and where the project is being run. Does it matter ?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1564278857600,
        "Question_score":1,
        "Question_tags":"conda|mlflow",
        "Question_view_count":917,
        "Owner_creation_time":1466129156870,
        "Owner_last_access_time":1664082712907,
        "Owner_location":"Chengdu, Sichuan, China",
        "Owner_reputation":2087,
        "Owner_up_votes":31,
        "Owner_down_votes":1,
        "Owner_views":87,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57237388",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68718719,
        "Question_title":"How can I retrive the model.pkl in the experiment in Databricks",
        "Question_body":"<p>I want to retrieve the pickle off my trained model, which I know is in the run file inside my experiments in Databricks.<\/p>\n<p>It seems that the <code>mlflow.pyfunc.load_model<\/code> can only do the <code>predict<\/code> method.<\/p>\n<p>There is an option to directly access the pickle?<\/p>\n<p>I also tried to use the path in the run using the <code>pickle.load(path)<\/code> (example of path: dbfs:\/databricks\/mlflow-tracking\/20526156406\/92f3ec23bf614c9d934dd0195\/artifacts\/model\/model.pkl).<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1628544411170,
        "Question_score":1,
        "Question_tags":"python|azure|databricks|datastore|mlflow",
        "Question_view_count":3081,
        "Owner_creation_time":1522076554450,
        "Owner_last_access_time":1663901377960,
        "Owner_location":"S\u00e3o Paulo, State of S\u00e3o Paulo, Brazil",
        "Owner_reputation":96,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I recently found the solution which can be done by the following two approaches:<\/p>\n<ol>\n<li>Use the customized predict function at the moment of saving the model (check <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">databricks<\/a> documentation for more details).<\/li>\n<\/ol>\n<p>example give by Databricks<\/p>\n<pre><code>class AddN(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, n):\n        self.n = n\n\n    def predict(self, context, model_input):\n        return model_input.apply(lambda column: column + self.n)\n# Construct and save the model\nmodel_path = &quot;add_n_model&quot;\nadd5_model = AddN(n=5)\nmlflow.pyfunc.save_model(path=model_path, python_model=add5_model)\n\n# Load the model in `python_function` format\nloaded_model = mlflow.pyfunc.load_model(model_path)\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Load the model artefacts as we are downloading the artefact:<\/li>\n<\/ol>\n<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\ntmp_path = client.download_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path='model\/model.pkl')\n\nf = open(tmp_path,'rb')\n\nmodel = pickle.load(f)\n\nf.close()\n\n \n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;&quot;)\n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;model&quot;)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1629748421287,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1643054905513,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68718719",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56120016,
        "Question_title":"Is it possible to specify MLflow project Environment through a Dockerfile (instead of an image)?",
        "Question_body":"<p>To my understanding, currently (May 2019) mlflow support running project in docker environment; however, it needs the docker image already been built. This leaves the docker image building to be a separate workflow. What is the suggested way to run a mlflow project from Dockerfile? <\/p>\n\n<p>Is there plans to support targeting Dockerfile natively in mlflow? What are the considerations about using image vs Dockerfile? Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1557782434943,
        "Question_score":2,
        "Question_tags":"docker|machine-learning|artificial-intelligence|databricks|mlflow",
        "Question_view_count":631,
        "Owner_creation_time":1386735502123,
        "Owner_last_access_time":1663974468663,
        "Owner_location":null,
        "Owner_reputation":3405,
        "Owner_up_votes":641,
        "Owner_down_votes":8,
        "Owner_views":1094,
        "Question_last_edit_time":1557791232507,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56120016",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73399640,
        "Question_title":"Track input transformation for keras-flavored mlflow models",
        "Question_body":"<p><strong>TL\/DR:<\/strong> How to track and serve the input transformation for keras-flavored mlflow models?<\/p>\n<p>Neural network training usually involves preprocessing steps in which<\/p>\n<ul>\n<li>continuous variables are scaled and shifted to have unit width and zero mean,<\/li>\n<li>categorical variables (integer or string) are transformed to one-hot encoding.<\/li>\n<\/ul>\n<p>When the model is applied to new data, the scaling weights and the category-to-index association needs to be known.<\/p>\n<p>In keras there are generally two options to perform preprocessing:<\/p>\n<ul>\n<li><strong>Option 1:<\/strong> Using <a href=\"https:\/\/keras.io\/guides\/preprocessing_layers\/\" rel=\"nofollow noreferrer\">preprocessing layers<\/a>, or<\/li>\n<li><strong>Option 2:<\/strong> perform the transformation before the training when the dataset is loaded.<\/li>\n<\/ul>\n<p>With <strong>Option 1<\/strong>, the transformation is part of the model and will be automatically applied when the network is used and served as a <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html\" rel=\"nofollow noreferrer\">mlflow model<\/a>.<\/p>\n<p>My question concerns <strong>Option 2<\/strong>: What is the recommended way<\/p>\n<ul>\n<li>to keep track of the input transformation in mlflow for different experiments,<\/li>\n<li>and how to apply the same transformations when the model is served, e.g. with <code>mlflow model serve<\/code>?<\/li>\n<\/ul>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1660810680010,
        "Question_score":1,
        "Question_tags":"keras|mlflow",
        "Question_view_count":49,
        "Owner_creation_time":1302064833600,
        "Owner_last_access_time":1663871200727,
        "Owner_location":null,
        "Owner_reputation":3635,
        "Owner_up_votes":460,
        "Owner_down_votes":7,
        "Owner_views":424,
        "Question_last_edit_time":1660979496130,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73399640",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57078147,
        "Question_title":"How should I mount docker volumes in mlflow project?",
        "Question_body":"<p>I use <code>mlflow<\/code> in a docker environment as described in this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">example<\/a> and I start my runs with <code>mlflow run .<\/code>.<\/p>\n\n<p>I get output like this<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>2019\/07\/17 16:08:16 INFO mlflow.projects: === Building docker image mlflow-myproject-ab8e0e4 ===\n2019\/07\/17 16:08:18 INFO mlflow.projects: === Created directory \/var\/folders\/93\/xt2vz36s7jd1fh9bkhkk9sgc0000gn\/T\/tmp1lxyqqw9 for downloading remote URIs passed to arguments of type 'path' ===\n2019\/07\/17 16:08:18 INFO mlflow.projects: === Running command 'docker run \n--rm -v \/Users\/foo\/bar\/mlruns:\/mlflow\/tmp\/mlruns -e \nMLFLOW_RUN_ID=ef21de61d8a6436b97b643e5cee64ae1 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 mlflow-myproject-ab8e0e4 python train.py' in run with ID 'ef21de61d8a6436b97b643e5cee64ae1' ===\n<\/code><\/pre>\n\n<p>I would like to mount a docker volume named <code>my_docker_volume<\/code> to the container\n at \nthe path <code>\/data<\/code>. So instead of the <code>docker run<\/code> shown above, I would like to\n use<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>docker run --rm --mount source=my_docker_volume,target=\/data -v \/Users\/foo\/bar\/mlruns:\/mlflow\/tmp\/mlruns -e MLFLOW_RUN_ID=ef21de61d8a6436b97b643e5cee64ae1 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 mlflow-myproject-ab8e0e4 python train.py\n<\/code><\/pre>\n\n<p>I see that I could in principle run it once without mounted volume and then \ncopy the <code>docker run ...<\/code> and add <code>--mount source=my_volume,target=\/data<\/code> but\n I'd rather use something like<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>mlflow run --mount source=my_docker_volume,target=\/data .\n<\/code><\/pre>\n\n<p>but this obviously doesn't work because --mount is not a parameter for \n<code>mlflow run<\/code>.\nWhat's the recommened way of mounting a docker volume then?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1563373349400,
        "Question_score":4,
        "Question_tags":"docker|mlflow",
        "Question_view_count":1301,
        "Owner_creation_time":1375955724343,
        "Owner_last_access_time":1664025245257,
        "Owner_location":"Freiburg im Breisgau, Germany",
        "Owner_reputation":191,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1564754919900,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57078147",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69551533,
        "Question_title":"Error can't get attribute Net when saving PyTorch model with MLFlow",
        "Question_body":"<p>After installing MLFlow using <a href=\"https:\/\/github.com\/artefactory\/one-click-mlflow\" rel=\"nofollow noreferrer\">one-click-mlflow<\/a> I save a pytorch model using the default command that I found in the user guide. You can find the command bellow:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.pytorch.log_model(net, artifact_path=&quot;model&quot;, pickle_module=pickle)\n<\/code><\/pre>\n<p>The neural network saved is very simple, this is basically a two layer neural network with Xavier initialization and hyperbolic tangent as activation function.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Net(T.nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        self.hid1 = T.nn.Linear(n_features, 10)\n        self.hid2 = T.nn.Linear(10, 10)\n        self.oupt = T.nn.Linear(10, 1)\n        T.nn.init.xavier_uniform_(self.hid1.weight) \n        T.nn.init.zeros_(self.hid1.bias)\n        T.nn.init.xavier_uniform_(self.hid2.weight)\n        T.nn.init.zeros_(self.hid2.bias)\n        T.nn.init.xavier_uniform_(self.oupt.weight)\n        T.nn.init.zeros_(self.oupt.bias)\n        \n    def forward(self, x):\n        z = T.tanh(self.hid1(x))\n        z = T.tanh(self.hid2(z))\n        z = self.oupt(z)\n        return z\n<\/code><\/pre>\n<p>Every things is runing fine in the Jupyter Notebook. I can log metrics and other artifact but when I save the model I got the following error message:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>2021\/10\/13 09:21:00 WARNING mlflow.utils.requirements_utils: Found torch version (1.9.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2021\/10\/13 09:21:00 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2021\/10\/13 09:21:01 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: \/tmp\/tmpnl9dsoye\/model\/data, flavor: pytorch)\nTraceback (most recent call last):\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/environment.py&quot;, line 212, in infer_pip_requirements\n    return _infer_requirements(model_uri, flavor)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 263, in _infer_requirements\n    modules = _capture_imported_modules(model_uri, flavor)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 221, in _capture_imported_modules\n    _run_command(\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 173, in _run_command\n    raise MlflowException(msg)\nmlflow.exceptions.MlflowException: Encountered an unexpected error while running ['\/home\/ucsky\/.virtualenv\/mymodel\/bin\/python', '\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py', '--model-path', '\/tmp\/tmpnl9dsoye\/model\/data', '--flavor', 'pytorch', '--output-file', '\/tmp\/tmplyj0w2fr\/imported_modules.txt', '--sys-path', '[&quot;\/home\/ucsky\/project\/ofi-ds-research\/incubator\/ofi-pe-fr\/notebook\/guillaume-simon\/06-modelisation-pytorch&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/git\/ext\/gitdb&quot;, &quot;\/usr\/lib\/python39.zip&quot;, &quot;\/usr\/lib\/python3.9&quot;, &quot;\/usr\/lib\/python3.9\/lib-dynload&quot;, &quot;&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/IPython\/extensions&quot;, &quot;\/home\/ucsky\/.ipython&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/gitdb\/ext\/smmap&quot;]']\nexit status: 1\nstdout: \nstderr: Traceback (most recent call last):\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py&quot;, line 125, in &lt;module&gt;\n    main()\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py&quot;, line 118, in main\n    importlib.import_module(f&quot;mlflow.{flavor}&quot;)._load_pyfunc(model_path)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 723, in _load_pyfunc\n    return _PyTorchWrapper(_load_model(path, **kwargs))\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 626, in _load_model\n    return torch.load(model_path, **kwargs)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 607, in load\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 882, in _load\n    result = unpickler.load()\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 875, in find_class\n    return super().find_class(mod_name, name)\nAttributeError: Can't get attribute 'Net' on &lt;module '__main__' from '\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py'&gt;\n<\/code><\/pre>\n<p>Can somebody explain me what is wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1634111089723,
        "Question_score":2,
        "Question_tags":"python|pytorch|virtualenv|mlflow|mlops",
        "Question_view_count":343,
        "Owner_creation_time":1263142631610,
        "Owner_last_access_time":1661432787853,
        "Owner_location":null,
        "Owner_reputation":382,
        "Owner_up_votes":248,
        "Owner_down_votes":3,
        "Owner_views":61,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69551533",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64099250,
        "Question_title":"MLFlow in docker - unable to store artifacts in sftp server (atmoz)",
        "Question_body":"<p>I would like to run MLflow &quot;entirely offline&quot; using docker (i.e. no cloud storage like S3 or blob). So I followed <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">this guide<\/a> and tried to set the artifact store to the <a href=\"https:\/\/github.com\/atmoz\/sftp\" rel=\"nofollow noreferrer\">atmoz<\/a> sftp server running inside another docker container. As suggested in the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#sftp-server\" rel=\"nofollow noreferrer\">MLFlow docs<\/a>, I try to auth with host keys, however, when I try to register my artifact I receive the following error <code>pysftp.exceptions.CredentialException: No password or key specified.<\/code><\/p>\n<p>I guess, there's something wrong with my hostkey setup. I also tried to follow <a href=\"https:\/\/towardsdatascience.com\/setup-mlflow-in-production-d72aecde7fef\" rel=\"nofollow noreferrer\">this guide<\/a> (mentioned in <a href=\"https:\/\/towardsdatascience.com\/setup-mlflow-in-production-d72aecde7fef\" rel=\"nofollow noreferrer\">this question<\/a>), but unfortunately it didn't have enough details for my - limited - knowledge of containers, sftp servers and pub-priv-key setups. My docker-compose looks like this...<\/p>\n<pre><code>services:\ndb:\n    restart: always\n    image: mysql\/mysql-server:5.7.28\n    container_name: mlflow_db\n    expose:\n        - &quot;3306&quot;\n    networks:\n        - backend\n    environment:\n        - MYSQL_DATABASE=${MYSQL_DATABASE}\n        - MYSQL_USER=${MYSQL_USER}\n        - MYSQL_PASSWORD=${MYSQL_PASSWORD}\n        - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\n    volumes:\n        - dbdata:\/var\/lib\/mysql\n\nmlflow-sftp:\n    image: atmoz\/sftp\n    container_name: mlflow-sftp\n    ports:\n        - &quot;2222:22&quot;\n    volumes:\n        - .\/storage\/sftp:\/home\/foo\/storage\n        - .\/ssh_host_ed25519_key:\/home\/foo\/.ssh\/ssh_host_ed25519_key.pub:ro\n        - .\/ssh_host_rsa_key:\/home\/foo\/.ssh\/ssh_host_rsa_key.pub:ro\n    command: foo::1001\n    networks:\n        - backend\n    \nweb:\n    restart: always\n    build: .\/mlflow\n    depends_on:\n        - mlflow-sftp\n    image: mlflow_server\n    container_name: mlflow_server\n    expose:\n        - &quot;5000&quot;\n    networks:\n        - frontend\n        - backend\n    volumes:\n        - .\/ssh_host_ed25519_key:\/root\/.ssh\/ssh_host_ed25519_key:ro\n        - .\/ssh_host_rsa_key:\/root\/.ssh\/ssh_host_rsa_key:ro\n    command: &gt;\n        bash -c &quot;sleep 3\n        &amp;&amp; ssh-keyscan -H mlflow-sftp &gt;&gt; ~\/.ssh\/known_hosts\n        &amp;&amp; mlflow server --backend-store-uri mysql+pymysql:\/\/${MYSQL_USER}:${MYSQL_PASSWORD}@db:3306\/${MYSQL_DATABASE} --default-artifact-root sftp:\/\/foo@localhost:2222\/storage --host 0.0.0.0&quot;\n    \nnginx:\n    restart: always\n    build: .\/nginx\n    image: mlflow_nginx\n    container_name: mlflow_nginx\n    ports:\n        - &quot;80:80&quot;\n    networks:\n        - frontend\n    depends_on:\n        - web\n<\/code><\/pre>\n<p>networks:\nfrontend:\ndriver: bridge\nbackend:\ndriver: bridge<\/p>\n<p>volumes:\ndbdata:<\/p>\n<p>... and in my python script I create a new mlflow experiment as follows.<\/p>\n<pre><code>remote_server_uri = &quot;http:\/\/localhost:80&quot; \nmlflow.set_tracking_uri(remote_server_uri)\nEXPERIMENT_NAME = &quot;test43&quot;\nmlflow.create_experiment(EXPERIMENT_NAME) #, artifact_location=ARTIFACT_URI)\nmlflow.set_experiment(EXPERIMENT_NAME)\nEXPERIMENT_NAME = &quot;test43&quot;\nmlflow.create_experiment(EXPERIMENT_NAME) #, artifact_location=ARTIFACT_URI)\nmlflow.set_experiment(EXPERIMENT_NAME)\nwith mlflow.start_run():\n    print(mlflow.get_artifact_uri())\n    print(mlflow.get_registry_uri())\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n    lr.fit(train_x, train_y)\n\n    predicted_qualities = lr.predict(test_x)\n\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n    print(&quot;Elasticnet model (alpha=%f, l1_ratio=%f):&quot; % (alpha, l1_ratio))\n    print(&quot;  RMSE: %s&quot; % rmse)\n    print(&quot;  MAE: %s&quot; % mae)\n    print(&quot;  R2: %s&quot; % r2)\n\n    mlflow.log_param(&quot;alpha&quot;, alpha)\n    mlflow.log_param(&quot;l1_ratio&quot;, l1_ratio)\n    mlflow.log_metric(&quot;rmse&quot;, rmse)\n    mlflow.log_metric(&quot;r2&quot;, r2)\n    mlflow.log_metric(&quot;mae&quot;, mae)\n\n    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n\n    if tracking_url_type_store != &quot;file&quot;:\n        mlflow.sklearn.log_model(lr, &quot;model&quot;, registered_model_name=&quot;ElasticnetWineModel&quot;)\n    else:\n        mlflow.sklearn.log_model(lr, &quot;model&quot;)\n<\/code><\/pre>\n<p>I haven't modified the dockerfiles of the first mentioned guide i.e. you'll be able to see them <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">here<\/a>. My guess is that I messed something up with the host keys, maybe put them in a wrong directory, but after several hours of brute-force experimenting I hope someone can help me with a pointer in the right direction. Let me know if there's anything missing to reproduce the error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1601284508343,
        "Question_score":4,
        "Question_tags":"python|docker|public-key|mlflow",
        "Question_view_count":874,
        "Owner_creation_time":1517932915310,
        "Owner_last_access_time":1662728503583,
        "Owner_location":"Germany",
        "Owner_reputation":41,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64099250",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64462918,
        "Question_title":"How to save models in MLFlow with R and get Stages of them in Azure Databricks?",
        "Question_body":"<p>I would like to save a model in MLFlow with Azure Databricks. In Python, I can use the following code to save a model with a name automatically:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.spark.log_model(\n        model,\n        artifact_path = 'model_prueba',\n        registered_model_name = 'model_prueba'\n    )\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/tTaNw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tTaNw.png\" alt=\"Registered models window\" \/><\/a><\/p>\n<p>But I am trying to do the same with <strong>R<\/strong> with the following code:<\/p>\n<pre class=\"lang-r prettyprint-override\"><code>mlflow_log_model(\n          model,\n          artifact_path = 'model_prueba_R',\n          registered_model_name = 'model_prueba_R'\n    )\n<\/code><\/pre>\n<p>But it does not register any model in the Models section. It only saves the model with the artifact path in the run section.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zfAza.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zfAza.png\" alt=\"Artifact location\" \/><\/a><\/p>\n<p>Anyone could tell me the way to save the model for staging automatically with code in R?<\/p>\n<p>Thank you very much!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1603281092693,
        "Question_score":1,
        "Question_tags":"python|r|model|azure-databricks|mlflow",
        "Question_view_count":201,
        "Owner_creation_time":1568015757070,
        "Owner_last_access_time":1642423173287,
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64462918",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59881297,
        "Question_title":"How to serve custom MLflow model with Docker?",
        "Question_body":"<p>We have a project following essentially this\n<a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">docker example<\/a> with the only difference that we created a custom model similar to <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models\" rel=\"nofollow noreferrer\">this<\/a> whose code lies in a directory called <code>forecast<\/code>. We succeeded in running the model with <code>mlflow run<\/code>. The problem arises when we try to serve the model. After doing <\/p>\n\n<pre><code>mlflow models build-docker -m \"runs:\/my-run-id\/my-model\" -n \"my-image-name\"\n<\/code><\/pre>\n\n<p>we fail running the container with<\/p>\n\n<pre><code>docker run -p 5001:8080 \"my-image-name\"\n<\/code><\/pre>\n\n<p>with the following error:<\/p>\n\n<pre><code>ModuleNotFoundError: No module named 'forecast'\n<\/code><\/pre>\n\n<p>It seems that the docker image is not aware of the source code defining our custom model class.\nWith Conda environnement the problem does not arise thanks to the <code>code_path<\/code> argument in <code>mlflow.pyfunc.log_model<\/code>.<\/p>\n\n<p>Our Dockerfile is very basic, with just <code>FROM continuumio\/miniconda3:4.7.12, RUN pip install {model_dependencies}<\/code>.<\/p>\n\n<p>How to let the docker image know about the source code for deserialising the model and run it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1579791133580,
        "Question_score":3,
        "Question_tags":"docker|mlflow",
        "Question_view_count":2105,
        "Owner_creation_time":1429204620943,
        "Owner_last_access_time":1662844490857,
        "Owner_location":"Paris, France",
        "Owner_reputation":41,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59881297",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73570230,
        "Question_title":"How to access Mlflow running on fargate (ECS) with only VPN in\/outbound rules from sagemaker notebook instance?",
        "Question_body":"<p><strong>Context:<\/strong><\/p>\n<p>I have deployed Mlflow on ECS(Fargate) using terraform using this public <a href=\"https:\/\/github.com\/Glovo\/terraform-aws-mlflow\" rel=\"nofollow noreferrer\">git-repo<\/a>. After deploying Mlflow which was publicly accessible using the link, I made some changes in the security group and changed in\/outbound rule to the only company VPN ips, now that link is only accessible under the VPN.<\/p>\n<p><strong>Question:<\/strong><\/p>\n<p>Now I have Sagemake notebook instance and want to access that link inside the notebook and the notebook is running on AWS internet(outside Company-VPN) and I'm not able to access that link. What could be the possible solution?<\/p>\n<p>I don't want to open access of Mlflow-link publicaly to accessible form anywhere on the internet.<\/p>\n<p><strong>Running this code on notebook:<\/strong><\/p>\n<pre><code>!pip install mlflow\nimport mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/mlflow-mlp-xyz-xyz.eu-west-1.elb.amazonaws.com\/&quot;)\nmlflow.get_experiment_by_name('mlpmlflowlogger')\ncurrent_experiment=dict(mlflow.get_experiment_by_name('mlpmlflowlogger'))\nprint(current_experiment)\nexperiment_id=current_experiment['experiment_id']\nprint(experiment_id)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1662039083460,
        "Question_score":0,
        "Question_tags":"amazon-web-services|amazon-ecs|amazon-vpc|aws-security-group|mlflow",
        "Question_view_count":31,
        "Owner_creation_time":1511960637980,
        "Owner_last_access_time":1663681247487,
        "Owner_location":"Deggendorf, Germany",
        "Owner_reputation":813,
        "Owner_up_votes":87,
        "Owner_down_votes":1,
        "Owner_views":115,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73570230",
        "Question_exclusive_tag":"MLFlow"
    }
]