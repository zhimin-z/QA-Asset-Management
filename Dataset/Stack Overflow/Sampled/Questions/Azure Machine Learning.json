[
    {
        "Question_id":65828200,
        "Question_title":"How to use Azure DevOps artifacts repository as source for DatabricksStep of AzureML?",
        "Question_body":"<p>If we have PyPi Packages added as Artifacts to an Azure DevOps Project Feed, how can we use these packages as a source for installing packages in <code>DatabricksStep<\/code> of Azure Machine Learning Service?<\/p>\n<p>While using <code>pip<\/code> in any environment, we use our Azure DevOps Project Artifacts feed in the following way:<\/p>\n<pre><code>pip install example-package --index-url=https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/\n<\/code><\/pre>\n<p>The DatabricksStep class of the Azure Machine Learning Service accepts the following parameters:<\/p>\n<pre><code>python_script_name = &quot;&lt;Some-Script&gt;.py&quot;\nsource_directory = &quot;&lt;Path-To-Script&gt;&quot;\n\n&lt;Some-Placeholder-Name-for-the-step&gt; = DatabricksStep(\n    name=&lt;Some-Placeholder-Name-for-the-step&gt;,\n    num_workers=1,\n    python_script_name=python_script_name,\n    source_directory=source_directory,\n    run_name= &lt;Name-of-the-run&gt;,\n    compute_target=databricks_compute,\n    pypi_libraries = [\n                      PyPiLibrary(package = 'scikit-learn'), \n                      PyPiLibrary(package = 'scipy'), \n                      PyPiLibrary(package = 'azureml-sdk'), \n                      PyPiLibrary(package = 'joblib'), \n                      PyPiLibrary(package = 'azureml-dataprep[pandas]'),\n                      PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')\n                    ], \n\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>However, <code>PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')<\/code> will give an error. How exactly should we consume the Artifacts Feed as an input to the <code>PyPiLibrary<\/code> property of the <code>DatabricksStep<\/code> Class in Azure Machine Learning Service?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1611234834813,
        "Question_score":5,
        "Question_tags":"azure|azure-devops|azure-databricks|azure-machine-learning-service|azure-artifacts",
        "Question_view_count":341,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65828200",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62696966,
        "Question_title":"Why does Azure ML Studio (classic) take additional time to execute Python Scripts?",
        "Question_body":"<p>I have been working with ML Studio (classic) and facing a problem with &quot;Execute Python&quot; scripts. I have noticed that it takes additional time to perform some internal tasks after which it starts executing the actual Python code in ML Studio. This delay has caused an increased time of 40-60 seconds per module which is aggregating and causing a delay of 400-500 seconds per execution when consumed through Batch Execution System or on running the experiments manually. (I've multiple Modules of &quot;Execute Python&quot; scripts)<\/p>\n<p>For instance - If I run a code in my local system, suppose it takes 2-3 seconds. The same would consume 50-60 seconds in Azure ML Studio.<\/p>\n<p>Can you please help understand the reason behind this or any optimization that can be done?<\/p>\n<p>Regards,\nAnant<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1593694819477,
        "Question_score":2,
        "Question_tags":"python-3.x|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":166,
        "Owner_creation_time":1582179684313,
        "Owner_last_access_time":1656918545750,
        "Owner_location":"Hyderabad, Telangana, India",
        "Owner_reputation":601,
        "Owner_up_votes":86,
        "Owner_down_votes":6,
        "Owner_views":94,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The known limitations of Machine Learning Studio (classic) are:<\/p>\n<p>The Python runtime is sandboxed and does not allow access to the network or to the local file system in a persistent manner.<\/p>\n<p>All files saved locally are isolated and deleted once the module finishes. The Python code cannot access most directories on the machine it runs on, the exception being the current directory and its subdirectories.<\/p>\n<p>When you provide a zipped file as a resource, the files are copied from your workspace to the experiment execution space, unpacked, and then used. Copying and unpacking resources can consume memory.<\/p>\n<p>The module can output a single data frame. It's not possible to return arbitrary Python objects such as trained models directly back to the Studio (classic) runtime. However, you can write objects to storage or to the workspace. Another option is to use pickle to serialize multiple objects into a byte array and then return the array inside a data frame.<\/p>\n<p>Hope this helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1593695267950,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62696966",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71412319,
        "Question_title":"Register Trained Model in Azure Machine Learning",
        "Question_body":"<p>I'm training a Azure Machine learning model using script via python SDK. I'm able to see the environment creation and the model getting trained in std_log in output&amp;logs folder. After the Model training I try to dump the model, but I don't see the model in any folder.<\/p>\n<p>If possible I want to register the model directly into the Model section in Azure ML rather than dumping it in the pickle file.<\/p>\n<p>I'm using the following link for reference <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train<\/a><\/p>\n<p>Below is the output log snapshot for the model training run<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/OdkyF.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OdkyF.jpg\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1646841733913,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azureportal|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":156,
        "Owner_creation_time":1629016154667,
        "Owner_last_access_time":1663902242127,
        "Owner_location":"Chennai, Tamil Nadu, India",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1646843402513,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71412319",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73386272,
        "Question_title":"How to log metrics to Azure ML Metrics Tab",
        "Question_body":"<p>I have the following train.py file<\/p>\n<pre><code>import argparse\nimport os\nimport numpy as np\nimport glob\n# import joblib\nimport mlflow\nimport logging\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport pandas as pd \n\nfrom matplotlib import pyplot as plt\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.dataset import Dataset\nfrom azureml.train.automl import AutoMLConfig\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nimport lightgbm as lgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\n\n\n# let user feed in 2 parameters, the dataset to mount or download,\n# and the regularization rate of the logistic regression model\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    &quot;--tablename&quot;, type=str, dest=&quot;tablename&quot;, help=&quot;Table name&quot;\n)\nargs = parser.parse_args()\n\ntablename = args.tablename\n\n\nsubscription_id = ''\nresource_group = 'mlplayground'\nworkspace_name = 'mlplayground'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\ndataset = Dataset.get_by_name(workspace, name=tablename)\ndata = dataset.to_pandas_dataframe()\n\n# use mlflow autologging\nmlflow.autolog()\n\ndata.drop(['postal_code','Column1','province','region','lattitude','longitude'], axis=1, inplace=True)\none_hot_state_of_the_building=pd.get_dummies(data.state_of_the_building) \none_hot_city = pd.get_dummies(data.city_name, prefix='city')\n\n#removing categorical features \ndata.drop(['city_name','state_of_the_building'],axis=1,inplace=True)  \n\n#Merging one hot encoded features with our dataset 'data' \ndata=pd.concat([data,one_hot_city,one_hot_state_of_the_building,],axis=1) \n\ndata['pricepersqm'] = data.price \/ data.house_area\n\nx=data.drop('price',axis=1) \ny=data.price \n\nX_df = DataFrame(x, columns= data.columns)\nX_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.20)\n\n#Converting the data into proper LGB Dataset Format\nd_train=lgb.Dataset(X_train, label=y_train)\n\n\n#Declaring the parameters\nparams = {\n    'task': 'train', \n    'boosting': 'gbdt',\n    'objective': 'regression',\n    'num_leaves': 10,\n    'learning_rate': 0.01,\n    'metric': {'l2','l1'},\n    'verbose': -1\n}\n\nprint(&quot;Train a LightGBM Regression model&quot;)\nclf=lgb.train(params,d_train,1000)\n\n#model prediction on X_test\nprint(&quot;Predict the test set&quot;)\ny_pred=clf.predict(X_test)\n\n#using RMSE error metric\nmse =mean_squared_error(y_pred,y_test)\nprint(&quot;RMSE: &quot;, mse**0.5)\nmlflow.log_metric(&quot;RMSE&quot;, mse**0.5)\n<\/code><\/pre>\n<p>And then from a notebook file I use the following:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core import Experiment\n\n# connect to your workspace\nws = Workspace.from_config()\n\nexperiment_name = &quot;get-started-with-jobsubmission-tutorial-andlightgbm&quot;\nexp = Experiment(workspace=ws, name=experiment_name)\n\n\n\nfrom azureml.core.environment import Environment\n\n# use a curated environment that has already been built for you\n\nenv = Environment.get(workspace=ws, \n                      name=&quot;AzureML-sklearn-1.0-ubuntu20.04-py38-cpu&quot;, \n                      version=1)\n\nfrom azureml.core import ScriptRunConfig\n\nargs = [&quot;--tablename&quot;, &quot;BelgiumRealEstate&quot;]\n\nsrc = ScriptRunConfig(\n    source_directory=&quot;&quot;,\n    script=&quot;train.py&quot;,\n    arguments=args,\n    compute_target=&quot;local&quot;,\n    environment=env,\n)\n\nrun = exp.submit(config=src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>As you can see in the train.py file I am logging the RMSE, however the metric does not appear on the metrics tab.<\/p>\n<p>What should I do?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660729490553,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|mlflow",
        "Question_view_count":40,
        "Owner_creation_time":1302030303093,
        "Owner_last_access_time":1663332147473,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73386272",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42606010,
        "Question_title":"\"Batch execution failed with HTTP status code: BadGateway. The response from the Machine Learning service at endpoint",
        "Question_body":"<p>I want to schedule my AzureML experiment by Azure Data Factory (ADF).  After passing my job from azureML pipeline, I face with this issue \"Batch execution failed with HTTP status code: BadGateway. The response from the Machine Learning service at endpoint <a href=\"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/26c276f8420a4c30aae39b0c27845134\/services\/7b122129b2c041f9b4399d7e4b16e927\/jobs\/job_id\/start\" rel=\"nofollow noreferrer\">https:\/\/ussouthcentral.services.azureml.net\/workspaces\/26c276f8420a4c30aae39b0c27845134\/services\/7b122129b2c041f9b4399d7e4b16e927\/jobs\/job_id\/start<\/a> was 'Internal error occurred.\"<\/p>\n\n<p>Do you have any idea for solving this issue.\nThanks,<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1488701373533,
        "Question_score":0,
        "Question_tags":"azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":379,
        "Owner_creation_time":1486079485687,
        "Owner_last_access_time":1554858720667,
        "Owner_location":"Seattle, WA, United States",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1488702037913,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42606010",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36666418,
        "Question_title":"Azure machine learning specify input size",
        "Question_body":"<p>I just started using Azure ML and I'm trying to figure out how to specify an input size for the models. Specifically, I have a big training set of data, but I want to input only 250 records at a time into the PCA algorithm. It seems like all I can do is hook the entire data set into the PCA module.<\/p>\n\n<p>I know how to partition the data for X-validation, but I want a partition (say 10000 records) to only feed 250 records at a time to the model.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1460822385593,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":81,
        "Owner_creation_time":1329540965833,
        "Owner_last_access_time":1584910587307,
        "Owner_location":null,
        "Owner_reputation":477,
        "Owner_up_votes":38,
        "Owner_down_votes":0,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36666418",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73238138,
        "Question_title":"Azureml pipeline directly pass input dataset to command step",
        "Question_body":"<p>I have an azureml pipeline that uses a command step to run an external software cli, I want to pass a set of arguments to this software and some input and output datasets. From this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-with-commandstep.ipynb\" rel=\"nofollow noreferrer\">notebook<\/a> it's stated<\/p>\n<blockquote>\n<p>If you have an input dataset you want to use in this step, you can specify that as part of the command. For example, if you have a FileDataset object called dataset and a --data-dir script argument, you can do the following: command=['python train.py --epochs 30 --data-dir', dataset.as_mount()].<\/p>\n<\/blockquote>\n<p>The problem is that I don't want to pass my datasets as arguments of the program as the program will crash if it sees unknown arguments like --data-dir, to bypass the issue I've done a very ugly thing, it appears that if I use another command step that just do an echo and receives as input my dataset as --input-data I can then use the dataset anywhere so I can bypass the initial issue. (Part of) The code that I'm using is the following<\/p>\n<pre><code>    environment = Environment.get(\n        workspace=self.workspace,\n        name=self.config.steps.first.environment_name,\n    )\n\n    output_dataset = None\n\n    if self.config.output_dataset is not None:\n        datastore = Datastore.get(workspace=self.workspace, datastore_name=self.config.output_dataset.datastore)\n\n        output_dataset = OutputFileDatasetConfig(\n            name=&quot;output_data&quot;,\n            destination=(datastore, f&quot;{self.config.output_dataset.name}\/{{run-id}}&quot;),\n        ).register_on_complete(self.config.output_dataset.name)\n\n    input_dataset = Dataset.get_by_name(\n        self.workspace, name=self.config.input_dataset.name, version=self.config.input_dataset.version\n    )\n\n    input_dataset_param = PipelineParameter(name=&quot;input_data&quot;, default_value=input_dataset)\n    input_consumption = DatasetConsumptionConfig(\n        &quot;input_data&quot;,\n        input_dataset_param,\n    )\n\n    model_consumption = None\n\n    software_parameters = PipelineParameter(\n        name=&quot;software_parameters&quot;,\n        default_value=self.config.software_parameters if self.config.software_parameters is not None else &quot; &quot;,\n    )\n\n    command = [&quot;magicsoftware&quot;, software_parameters]\n\n    train_src = ScriptRunConfig(\n        source_directory=self.config.source_dir,\n        environment=environment,\n        compute_target=self.__compute_cluster,\n    )\n\n    input_datasets = [input_consumption]\n\n    magic_command = [&quot;echo&quot;, &quot;--input_data&quot;, input_consumption]\n\n    magic_step = CommandStep(\n        name=&quot;magic_step&quot;,\n        command=magic_command,\n        runconfig=train_src,\n        inputs=input_datasets,\n        allow_reuse=False,\n    )\n\n    experiment_step = CommandStep(\n        name=self.config.steps.first.name,\n        command=command,\n        runconfig=train_src,\n        inputs=input_datasets,\n        outputs=[output_dataset] if output_dataset is not None else None,\n        allow_reuse=False,\n    )\n    logging.info(&quot;Build the list of steps&quot;)\n    step_sequence = StepSequence(steps=[magic_step, experiment_step])\n\n    logging.info(&quot;Ending building&quot;)\n    return Pipeline(\n        workspace=self.workspace,\n        steps=step_sequence,\n        description=&quot;&quot;,\n    )\n<\/code><\/pre>\n<p>While this works it's still an ugly workaround and it requires to have a compute cluster running first the echo step, then the real step and it slows down the process.<\/p>\n<p>Am I missing something or it's just a bad design of the command step? I've tried many solutions to make it work but unless I pass the arguments as --something I didn't manage to make it work.<\/p>\n<p>I'm working with azureml-core version 1.40.0<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1659625179437,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":81,
        "Owner_creation_time":1556634159780,
        "Owner_last_access_time":1663257023900,
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73238138",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62701556,
        "Question_title":"Strange algorithm selection when using Azure AutoML with XBoostClassifier on categorial data",
        "Question_body":"<p>I have a data model consisting only of categorial features and a categorial label.<\/p>\n<p>So when I build that model manually in XGBoost, I would basically transform the features to binary columns (using LabelEncoder and OneHotEncoder), and the label into classes using LabelEncoder. I would then run a <strong>Multilabel Classification<\/strong> (multi:softmax).\nI tried that with my dataset and ended up with an accuracy around 0.4 (unfortunately can't share the dataset due to confidentiality)<\/p>\n<p>Now, if I run the same dataset in Azure AutoML, I end up with an accuracy around 0.85 in the best experiment. But what is really interesting is that the AutoML uses SparseNormalizer, XGBoostClassifier, with <strong>reg:logistic<\/strong> as objective.\nSo if I interpret this right, AzureML just normalizes the data (somehow from categorial data?) and then executes a logistic regression? Is this even possible \/ does this make sense with categorial data?<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1593709508303,
        "Question_score":3,
        "Question_tags":"xgboost|azure-machine-learning-service",
        "Question_view_count":281,
        "Owner_creation_time":1534756062257,
        "Owner_last_access_time":1662737261800,
        "Owner_location":null,
        "Owner_reputation":87,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1593766738543,
        "Answer_body":"<p><code>TL;DR<\/code> You're right that normalization doesn't make sense for training gradient-boosted decision trees (<code>GBDT<\/code>s) on categorical data, but it won't have an adverse impact. AutoML is an automated framework for modeling. In exchange for calibration control, you get ease-of-use. It is still worth verifying first that AutoML is receiving data with the columns properly encoded as categorical.<\/p>\n<p>Think of an AutoML model as effectively a <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html\" rel=\"nofollow noreferrer\">sklearn Pipeline<\/a>, which is a bundled set of pre-processing steps along with a predictive Estimator. AutoML will attempt to sample from a large swath of pre-configured Pipelines such that the most accurate Pipeline will be discovered. As <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-automated-ml#automatic-featurization-standard\" rel=\"nofollow noreferrer\">the docs<\/a> say:<\/p>\n<blockquote>\n<p>In every automated machine learning experiment, your data is automatically scaled or normalized to help algorithms perform well. During model training, one of the following scaling or normalization techniques will be applied to each model.<\/p>\n<\/blockquote>\n<p>Too see this, you can called <code>.named_steps<\/code> on your fitted model. Also check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#automated-feature-engineering\" rel=\"nofollow noreferrer\"><code>fitted_model.get_featurization_summary()<\/code><\/a><\/p>\n<p>I especially empathize with your concern especially w.r.t. how <code>LightGBM<\/code> (MSFT's GBDT implementation) is levered by AutoML. <code>LightGBM<\/code> accepts categorical columns and instead of one-hot encoding, will bin them into two subsets whenever split. Despite this, AutoML will pre-process away the categorical columns by one-hot encoding, scaling, and\/or normalization; so this unique categorical approach is never utilized in AutoML.<\/p>\n<p>If you're interested in &quot;manual&quot; ML in Azure ML, I highly suggest looking into <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-train-machine-learning-model#estimators\" rel=\"nofollow noreferrer\"><code>Estimators<\/code><\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-train-machine-learning-model#machine-learning-pipeline\" rel=\"nofollow noreferrer\"><code>Azure ML Pipelines<\/code><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1593795420677,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1594068501473,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62701556",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64535892,
        "Question_title":"How to format body to pass input dataset as parameter in Azure ML?",
        "Question_body":"<p>I'm trying to consume my Azure ML Pipeline (Batch) from LogicApps. For that, I've deployed the Batch pipeline with the dataset as parameter :<a href=\"https:\/\/i.stack.imgur.com\/PYhU5.png\" rel=\"nofollow noreferrer\">1<\/a><\/p>\n<p>But I can't figure it out, how to format my body to invoke the pipeline and I don't find documentation on that.<\/p>\n<p>For now, this is how my logicapp looks like:\n<a href=\"https:\/\/i.stack.imgur.com\/lkKCB.png\" rel=\"nofollow noreferrer\">2<\/a>\nand I get a 415 Http Error code when trying to invoke the pipeline.<\/p>\n<p>Thanks for your help.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1603710297587,
        "Question_score":1,
        "Question_tags":"azure-logic-apps|azure-machine-learning-studio",
        "Question_view_count":67,
        "Owner_creation_time":1431423994833,
        "Owner_last_access_time":1657729027097,
        "Owner_location":null,
        "Owner_reputation":53,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64535892",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62836278,
        "Question_title":"AZURE ML, python code gets: 'tls_process_server_certificate', 'certificate verify failed'",
        "Question_body":"<p>The following code works fine on a jupyter notebook in a compute instance.\nHowever I need to test this locally on Visual Studio Code<\/p>\n<pre><code>import pandas as pd\nimport datetime\nimport csv\nimport numpy as np\nfrom azureml.core import Workspace\nfrom azureml.core import Dataset, Datastore\nfrom azureml.data.datapath import DataPath\nfrom azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\nfrom azureml.core.authentication import AzureCliAuthentication\n\n# #azure-cosmosdb-table\n# from azure.cosmosdb.table.tableservice import TableService\n# from azure.cosmosdb.table.models import Entity\n\n#Azure blob storage\n\ncli_auth = AzureCliAuthentication()\n\nws = Workspace(subscription_id=&quot;xx&quot;,\n               resource_group=&quot;xx&quot;,\n               workspace_name=&quot;xx&quot;,\n               auth=cli_auth)\n\nprint(&quot;Found workspace {} at location {}&quot;.format(ws.name, ws.location))\n\n\nimport os\nfrom azureml.core.authentication import ServicePrincipalAuthentication\n\nsvc_pr_password = &quot;xx&quot; #os.environ.get(&quot;AZUREML_PASSWORD&quot;)\n\nsvc_pr = ServicePrincipalAuthentication(\n    tenant_id=&quot;xx&quot;,\n    service_principal_id=&quot;xx&quot;,\n    service_principal_password=svc_pr_password)\n\n\nws = Workspace(\n    subscription_id=&quot;xx&quot;,\n    resource_group=&quot;xx&quot;,\n    workspace_name=&quot;xx&quot;,\n    auth=svc_pr\n    )\n\nprint(&quot;Found workspace {} at location {}&quot;.format(ws.name, ws.location))\n<\/code><\/pre>\n<p>However this line:<\/p>\n<pre><code>  datastore = Datastore.get(ws, 'yy')\n<\/code><\/pre>\n<p>gets me this error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nError                                     Traceback (most recent call last)\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\n    487             try:\n--&gt; 488                 cnx.do_handshake()\n    489             except OpenSSL.SSL.WantReadError:\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\OpenSSL\\SSL.py in do_handshake(self)\n   1933         result = _lib.SSL_do_handshake(self._ssl)\n-&gt; 1934         self._raise_ssl_error(self._ssl, result)\n   1935 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\OpenSSL\\SSL.py in _raise_ssl_error(self, ssl, result)\n   1670         else:\n-&gt; 1671             _raise_current_error()\n   1672 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\OpenSSL\\_util.py in exception_from_error_queue(exception_type)\n     53 \n---&gt; 54     raise exception_type(errors)\n     55 \n\nError: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]\n\nDuring handling of the above exception, another exception occurred:\n\nSSLError                                  Traceback (most recent call last)\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n    669             # Make the request on the httplib connection object.\n--&gt; 670             httplib_response = self._make_request(\n    671                 conn,\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n    380         try:\n--&gt; 381             self._validate_conn(conn)\n    382         except (SocketTimeout, BaseSSLError) as e:\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py in _validate_conn(self, conn)\n    975         if not getattr(conn, &quot;sock&quot;, None):  # AppEngine might not have  `.sock`\n--&gt; 976             conn.connect()\n    977 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py in connect(self)\n    360 \n--&gt; 361         self.sock = ssl_wrap_socket(\n    362             sock=conn,\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py in ssl_wrap_socket(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\n    376         if HAS_SNI and server_hostname is not None:\n--&gt; 377             return context.wrap_socket(sock, server_hostname=server_hostname)\n    378 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\n    493             except OpenSSL.SSL.Error as e:\n--&gt; 494                 raise ssl.SSLError(&quot;bad handshake: %r&quot; % e)\n    495             break\n\nSSLError: (&quot;bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])&quot;,)\n\nDuring handling of the above exception, another exception occurred:\n\nMaxRetryError                             Traceback (most recent call last)\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n    438             if not chunked:\n--&gt; 439                 resp = conn.urlopen(\n    440                     method=request.method,\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n    723 \n--&gt; 724             retries = retries.increment(\n    725                 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py in increment(self, method, url, response, error, _pool, _stacktrace)\n    438         if new_retry.is_exhausted():\n--&gt; 439             raise MaxRetryError(_pool, url, error or ResponseError(cause))\n    440 \n\nMaxRetryError: HTTPSConnectionPool(host='westeurope.experiments.azureml.net', port=443): Max retries exceeded with url: \/discovery (Caused by SSLError(SSLError(&quot;bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])&quot;)))\n\nDuring handling of the above exception, another exception occurred:\n\nSSLError                                  Traceback (most recent call last)\n in \n----&gt; 1 datastore = Datastore.get(ws, 'utilisationdb')\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\core\\datastore.py in get(workspace, datastore_name)\n    139                 or azureml.data.dbfs_datastore.DBFSDatastore\n    140         &quot;&quot;&quot;\n--&gt; 141         return Datastore._client().get(workspace, datastore_name)\n    142 \n    143     @staticmethod\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\data\\datastore_client.py in get(workspace, datastore_name)\n     63         :rtype: AzureFileDatastore or AzureBlobDatastore\n     64         &quot;&quot;&quot;\n---&gt; 65         return _DatastoreClient._get(workspace, datastore_name)\n     66 \n     67     @staticmethod\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\data\\datastore_client.py in _get(ws, name, auth, host)\n    541         module_logger.debug(&quot;Getting datastore: {}&quot;.format(name))\n    542 \n--&gt; 543         client = _DatastoreClient._get_client(ws, auth, host)\n    544         datastore = client.data_stores.get(subscription_id=ws._subscription_id, resource_group_name=ws._resource_group,\n    545                                            workspace_name=ws._workspace_name, name=name,\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\data\\datastore_client.py in _get_client(ws, auth, host)\n    726         host_env = os.environ.get('AZUREML_SERVICE_ENDPOINT')\n    727         auth = auth or ws._auth\n--&gt; 728         host = host or host_env or get_service_url(\n    729             auth, _DatastoreClient._get_workspace_uri_path(ws._subscription_id, ws._resource_group,\n    730                                                            ws._workspace_name), ws._workspace_id, ws.discovery_url)\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in get_service_url(auth, workspace_scope, workspace_id, workspace_discovery_url, service_name)\n    118 \n    119     cached_service_object = CachedServiceDiscovery(auth)\n--&gt; 120     return cached_service_object.get_cached_service_url(workspace_scope, service_name,\n    121                                                         unique_id=workspace_id, discovery_url=workspace_discovery_url)\n    122 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in get_cached_service_url(self, arm_scope, service_name, unique_id, discovery_url)\n    280         :rtype: str\n    281         &quot;&quot;&quot;\n--&gt; 282         return self.get_cached_services_uris(arm_scope, service_name, unique_id=unique_id,\n    283                                              discovery_url=discovery_url)[service_name]\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in wrapper(self, *args, **kwargs)\n    180             try:\n    181                 lock_to_use.acquire()\n--&gt; 182                 return test_function(self, *args, **kwargs)\n    183             finally:\n    184                 lock_to_use.release()\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in get_cached_services_uris(self, arm_scope, service_name, unique_id, discovery_url)\n    255 \n    256         # Actual service discovery only understands arm_scope\n--&gt; 257         cache[cache_key][DEFAULT_FLIGHT] = super(CachedServiceDiscovery, self).discover_services_uris_from_arm_scope(arm_scope, discovery_url)\n    258         try:\n    259             with open(self.file_path, &quot;w+&quot;) as file:\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in discover_services_uris_from_arm_scope(self, arm_scope, discovery_url)\n    136     def discover_services_uris_from_arm_scope(self, arm_scope, discovery_url=None):\n    137         discovery_url = self.get_discovery_url(arm_scope, discovery_url)\n--&gt; 138         return self.discover_services_uris(discovery_url)\n    139 \n    140     def discover_services_uris(self, discovery_url=None):\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_base_sdk_common\\service_discovery.py in discover_services_uris(self, discovery_url)\n    139 \n    140     def discover_services_uris(self, discovery_url=None):\n--&gt; 141         status = ClientBase._execute_func(requests.get, discovery_url)\n    142         status.raise_for_status()\n    143         return status.json()\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_restclient\\clientbase.py in _execute_func(cls, func, *args, **kwargs)\n    340     @classmethod\n    341     def _execute_func(cls, func, *args, **kwargs):\n--&gt; 342         return cls._execute_func_internal(\n    343             DEFAULT_BACKOFF, DEFAULT_RETRIES, module_logger, func, _noop_reset, *args, **kwargs)\n    344 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_restclient\\clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n    334                 return func(*args, **kwargs)\n    335             except Exception as error:\n--&gt; 336                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n    337 \n    338             reset_func(*args, **kwargs)  # reset_func is expected to undo any side effects from a failed func call.\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_restclient\\clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n    364         &quot;&quot;&quot;\n    365         if left_retry == 0:\n--&gt; 366             raise error\n    367         elif isinstance(error, HttpOperationError):\n    368             if error.response.status_code == 403:\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\azureml\\_restclient\\clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n    332         while left_retry &gt;= 0:\n    333             try:\n--&gt; 334                 return func(*args, **kwargs)\n    335             except Exception as error:\n    336                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\api.py in get(url, params, **kwargs)\n     74 \n     75     kwargs.setdefault('allow_redirects', True)\n---&gt; 76     return request('get', url, params=params, **kwargs)\n     77 \n     78 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\api.py in request(method, url, **kwargs)\n     59     # cases, and look like a memory leak in others.\n     60     with sessions.Session() as session:\n---&gt; 61         return session.request(method=method, url=url, **kwargs)\n     62 \n     63 \n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n    528         }\n    529         send_kwargs.update(settings)\n--&gt; 530         resp = self.send(prep, **send_kwargs)\n    531 \n    532         return resp\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py in send(self, request, **kwargs)\n    641 \n    642         # Send the request\n--&gt; 643         r = adapter.send(request, **kwargs)\n    644 \n    645         # Total elapsed time of the request (approximately)\n\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n    512             if isinstance(e.reason, _SSLError):\n    513                 # This branch is for urllib3 v1.22 and later.\n--&gt; 514                 raise SSLError(e, request=request)\n    515 \n    516             raise ConnectionError(e, request=request)\n\nSSLError: HTTPSConnectionPool(host='westeurope.experiments.azureml.net', port=443): Max retries exceeded with url: \/discovery (Caused by SSLError(SSLError(&quot;bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])&quot;)))\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1594390638313,
        "Question_score":1,
        "Question_tags":"python|python-3.x|azure|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":219,
        "Owner_creation_time":1302030303093,
        "Owner_last_access_time":1663332147473,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62836278",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57209247,
        "Question_title":"Is there any module in Azure ML Studio to identify features correlated with a Target Variable and correlated input features?",
        "Question_body":"<p>Is there any module which outputs high\/low correlated input features with respect to a given target variable, and which can identify highly correlated input features in a data set in Azure Machine Learning Studio?<\/p>\n\n<p>Such a module would help creating better training data sets and that would allow to create better ML models.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1564084180007,
        "Question_score":0,
        "Question_tags":"machine-learning|feature-selection|azure-machine-learning-studio",
        "Question_view_count":57,
        "Owner_creation_time":1418970237687,
        "Owner_last_access_time":1663728521847,
        "Owner_location":"New Jersey, USA",
        "Owner_reputation":747,
        "Owner_up_votes":48,
        "Owner_down_votes":2,
        "Owner_views":96,
        "Question_last_edit_time":1564336396770,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57209247",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41485715,
        "Question_title":"Training Model for Each Individual in AzureML",
        "Question_body":"<p>I want to train an ANN model for each individual, in azure ml. For example, there is an application which wants to learn the behavior of each individual separately. How is this possible in azure-ml? Any suggestion?<\/p>\n\n<p>As I know, I can create a model and train it with some data, but I don't know how can I train it specifically for each user. I should mention that I am seeking for a scalable idea which is applicable for a real situation (might be for 100 thousands users).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1483620989100,
        "Question_score":2,
        "Question_tags":"multi-tenant|azure-machine-learning-studio",
        "Question_view_count":205,
        "Owner_creation_time":1403553737940,
        "Owner_last_access_time":1664024595667,
        "Owner_location":"Belgium",
        "Owner_reputation":17835,
        "Owner_up_votes":636,
        "Owner_down_votes":1612,
        "Owner_views":2203,
        "Question_last_edit_time":1485439340663,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41485715",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38389352,
        "Question_title":"Different Size of Machine Learning Models?",
        "Question_body":"<p>Once the training is done and Model is generated,Model Size can vary according to the dataset and algorithm used.\nI want to know what is the range (in MBs) the (\"generally\") Model Size can vary.<\/p>\n\n<p><a href=\"http:\/\/docs.aws.amazon.com\/machine-learning\/latest\/dg\/system-limits.html\" rel=\"nofollow\">Amazon ML<\/a> sets the limit of Model Size to be between 1 MB to 1GB.<\/p>\n\n<p>The question is mainly revolved about collecting the information about what is the average size of models generated by organizations? Most Models generated by organization are of how much size ?<\/p>\n\n<p>Any pointers in the related field will be helpful.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1468564568543,
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio|amazon-machine-learning",
        "Question_view_count":5731,
        "Owner_creation_time":1372192553610,
        "Owner_last_access_time":1575921971200,
        "Owner_location":"Atlanta, GA, USA",
        "Owner_reputation":338,
        "Owner_up_votes":16,
        "Owner_down_votes":2,
        "Owner_views":63,
        "Question_last_edit_time":1468577121383,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38389352",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34335483,
        "Question_title":"Uniquely identify instances of VMs (Azure ML - web services)",
        "Question_body":"<p>I'm posting this more as a 'probe' question and plan to expand the discussion in case some interest shows up. The reason behind this is that in my experience, the SO community on <code>azure-ml<\/code> (and related) is still developing and there is not much feedback - but I would be happy to help it grow stronger. <\/p>\n\n<p>My situation is as follows: I have an experiment in Azure ML which does all its work inside an <code>R<\/code> module. I published this as a web service and set the 'max concurrent calls' slider to 10 - which I believe guarantees me that there will be at most 10 instances of my web service up and running at any time, to serve requests (please correct me if i am wrong). <\/p>\n\n<p>Now, I am trying to do some performance testing by firing 10 parallel calls to my webservice, but get unexpected results...<\/p>\n\n<p>I am trying to run the load tests and log where each of them actually goes to (which instance). My idea is to get a glimpse into how these calls are actually distributed to the instances by the load balancer, under certain max number of concurrent calls = X. I am doing this by firing a call to \"bot.whatismyipaddress.com\" from inside the <code>R<\/code> script. Here is the important snip of the code:<\/p>\n\n<pre><code>library(rjson)\nmachine.ip &lt;- readLines(\"http:\/\/bot.whatismyipaddress.com\/\", warn=F)\nresult$MachineIP &lt;- machine.ip\n<\/code><\/pre>\n\n<p>Additionally, I am using the sample <code>R<\/code> code from the web service RRS help page to fire up to 70 (sequential) calls to my web service. This sample code returns some info back to the console : the results of my web service as well as some info on to which hostname the call goes through. Here is a sample :<\/p>\n\n<pre><code>* Hostname was NOT found in DNS cache\n*   Trying 40.114.242.9...\n* Connected to europewest.services.azureml.net (40.114.242.9) port 443 (#0)\n<\/code><\/pre>\n\n<p>The difficulty that I am facing is that I cannot <strong>uniquely identify<\/strong> the different instances of my web service. The info out to console from the call (the second snippet) often shows a different IP address than the one from inside-<code>R<\/code>-code logs (<code>result$MachineIP<\/code>)...<\/p>\n\n<p>Can someone point out what am i doing wrong, and how could i uniquely identify the different instances that are serving the calls? Any help would be really appreciated. Thanks!<\/p>\n\n<p>P.S. I've tried <a href=\"https:\/\/stackoverflow.com\/questions\/14357219\/function-for-retrieving-own-ip-address-from-within-r\">this<\/a> as well, but the first apporach does not work when calling it from inside the <code>R<\/code> script and I'm using a modified version of the second apporach (the one suggested there does not work). <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/93f07abf-f0ec-4baa-8225-1ca1a072ca2d\/system-call-from-inside-r-script-does-not-work?forum=MachineLearning\" rel=\"nofollow noreferrer\">Here<\/a> are also my <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/ee6ff5a6-2995-4f3f-b4db-0229b1d9d1d3\/lifetime-of-azure-ml-web-service-container?forum=MachineLearning\" rel=\"nofollow noreferrer\">questions<\/a> on the Azure forum, in case someone is interested.<\/p>\n\n<p>If anyone could help or point me to some source of info I would be really grateful! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1450358009790,
        "Question_score":1,
        "Question_tags":"r|web-services|azure|azure-machine-learning-studio",
        "Question_view_count":61,
        "Owner_creation_time":1432829415467,
        "Owner_last_access_time":1542573864587,
        "Owner_location":null,
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Question_last_edit_time":1495540319593,
        "Answer_body":"<p>This question was resolved thanks to some people on the Azure ML forum so \nI'm going to post an answer for anyone landing here in search for some answers...<\/p>\n\n<p>The short answer is no, this is not possible. The more detailed version is:<br>\n\"From within the R script you cannot identify the internal AzureML IP addresses or the unique web service instances. When you make an external network call from the R script to an outside URL, that URL will see one of the AzureML public virtual IP's as the source IP. These are IP's of the load balancers, and not of the machines that are physically running the web service. AzureML dynamically allocates the instances of R engine in the backend, handles failures, and uses multiple nodes for running the web service for high availability. The exact layout of these for a given web service is not programmatically discoverable.\"<br>\nHere is also the <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/dd1f0658-7b0b-46d8-8e32-3fe4e96ec4be\/uniquely-identify-instances-of-vms-web-services?forum=MachineLearning#cde28631-828d-4d83-9c93-1a1cf0dfb6fb\" rel=\"nofollow\">link<\/a> to the original discussion. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1452244028967,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34335483",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36917948,
        "Question_title":"Feature weightage from Azure Machine Learning Deployed Web Service",
        "Question_body":"<p>I am trying to predict from my past data which has around 20 attribute columns and a label. Out of those 20, only 4 are significant for prediction. But i also want to know that if a row falls into one of the classified categories, what other important correlated columns apart from those 4 and what are their weight. I want to get that result from my deployed web service on Azure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1461854370743,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":303,
        "Owner_creation_time":1461853741067,
        "Owner_last_access_time":1520500022443,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can use permutation feature importance module but that will give importance of the features across the sample set. Retrieving the weights on per call basis is not available in Azure ML.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1461985174657,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36917948",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36344278,
        "Question_title":"Azure machine learning. How can I see all columns",
        "Question_body":"<p>When I upload dataset with more then 100 columns I can see only part of them in the visualisation block. Can I see stats for all columns from dataset? Thanks<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1459460172740,
        "Question_score":0,
        "Question_tags":"cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":736,
        "Owner_creation_time":1459459387887,
        "Owner_last_access_time":1576493624753,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1459517035743,
        "Answer_body":"<p>If you are an owner in the workspace, you can open your dataset in Python inside of a Jupyter Notebook. By the visualize should be an open in notebook button. Then just execute the code that is provided for you, and it should print your dataset. You can then also select specific columns to visualize as well.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1459517016507,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36344278",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64257530,
        "Question_title":"Import data and python scripts in azure ml entry script when deploying models",
        "Question_body":"<p>I have an existing machine learning model saved on my local system. I want to deploy this model as a web service so I can consume this model as a request-response i.e. send an HTTP request to the model and get back a predicted response.<\/p>\n<p>When attempting to deploy this model on AzureML I run into a few problems<\/p>\n<p>The model needs to be initialized in an entry script int the init() function, but for initializing my model I have a custom class and require few txt files to be loaded.<\/p>\n<p>below is the code to initialize the model object<\/p>\n<pre><code>from model_file import MyModelClass  # this is the file which contains the model class\n\ndef init():\n  global robert_model\n\n  my_model = MyModelClass(vocab_path='&lt;path-to-text-files&gt;',\n                          model_paths=['&lt;path-to-model-file&gt;'],\n                          iterations=5,\n                          min_error_probability=0.0,\n                          min_probability=0.0,\n                          weigths=None)\ndef run(json_data):\n  try:\n    data = json.loads(json_data)\n    preds, cnt = my_model.handle_batch([sentence.split()])\n    return {'output': pred, 'count': cnt}\n  except Exception as e:\n    error = str(e)\n    return error\n<\/code><\/pre>\n<p>I don't know how to import those class files and text files in the entry script<\/p>\n<p>I don't know much about azure, and I am having a hard time figuring this out. Please help.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1602141348237,
        "Question_score":3,
        "Question_tags":"python|azure|machine-learning|web-deployment|azure-machine-learning-service",
        "Question_view_count":2616,
        "Owner_creation_time":1595686289650,
        "Owner_last_access_time":1657957414863,
        "Owner_location":"India",
        "Owner_reputation":91,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1602177450750,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64257530",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69473829,
        "Question_title":"Include additional files during model deployment (part 2)",
        "Question_body":"<p>Since we're not supposed to ask questions to answered questions, I'm posting this additional question here.  It references the question\/answers found here however:  <a href=\"https:\/\/stackoverflow.com\/questions\/61803031\/azure-ml-include-additional-files-during-model-deployment\">Azure ML: Include additional files during model deployment<\/a><\/p>\n<p>Problem:  in my scoring script I need to reference data in a file for additional data munging before calling the model.<\/p>\n<p>Option #2 referenced in that link (use InferenceConfig to specify a folder as source directory) appears to be what I need.  But when I attempt to access the included file in my scoring script, I'm getting an error message that the file doesn't exist.  I believe I've done something wrong but I'm not sure what.<\/p>\n<p>My work is taking place strictly in Azure ML Studio.<br \/>\nI have a directory where both my scoring script and the pickle file I want to include are found.\nIt's also where the Jupyter Notebook script is found that's driving the creation of these things.\nThe pathing would look something like this:  Users-&gt;myname-&gt;myfolder<\/p>\n<p>The scoring script is named score.py.  The pickle file is mypickle.pkl.<\/p>\n<p>Code in score.py to read the file.  This code is found in the run() method.<\/p>\n<pre><code>filename=&quot;.\/mypickle.pkl&quot;\ndf = pd.read_pickle(filename)\n<\/code><\/pre>\n<p>The InferenceConfig call:<\/p>\n<pre><code>inference_config = InferenceConfig(\nenvironment=environment,\nsource_directory=&quot;.\/&quot;,\nentry_script=&quot;.\/score.py&quot;\n)\n<\/code><\/pre>\n<p>The model deploys fine but when testing the deployed model (aka endpoint), I receive the error\n&quot;[Errno 2] No such file or directory: 'mypickle.pkl'&quot;<\/p>\n<p>Thoughts?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1633563793660,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":109,
        "Owner_creation_time":1567959306590,
        "Owner_last_access_time":1636567838733,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1633567085057,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69473829",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37807158,
        "Question_title":"Train multiple models with various measures and accumulate predictions",
        "Question_body":"<p>So I have been playing around with Azure ML lately, and I got one dataset where I have multiple values I want to predict. All of them uses different algorithms and when I try to train multiple models within one experiment; it says the \u201ctrain model can only predict one value\u201d, and there are not enough input ports on the train-model to take in multiple values even if I was to use the same algorithm for each measure. I tried launching the column selector and making rules, but I get the same error as mentioned. How do I predict multiple values and later put the predicted columns together for the web service output so I don\u2019t have to have multiple API\u2019s?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1465894075710,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1763,
        "Owner_creation_time":1463041289043,
        "Owner_last_access_time":1465915063043,
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>What you would want to do is to train each model and save them as already trained models.\nSo create a new experiment, train your models and save them by right clicking on each model and they will show up in the left nav bar in the Studio. Now you are able to drag your models into the canvas and have them score predictions where you eventually make them end up in the same output as I have done in my example through the \u201cAdd columns\u201d module. I made this example for Ronaldo (Real Madrid CF player) on how he will perform in match after training day. You can see my demo on <a href=\"http:\/\/ronaldoinform.azurewebsites.net\" rel=\"nofollow noreferrer\">http:\/\/ronaldoinform.azurewebsites.net<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" alt=\"Ronaldo InForm\"><\/a><\/p>\n\n<p>For more detailed explanation on how to save the models and train multiple values; you can check out Raymond Langaeian (MSFT) answer in the comment section on this link:\n<a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1465904564903,
        "Answer_score":2.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37807158",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69135872,
        "Question_title":"How to install R packages into Azure Machine Learning",
        "Question_body":"<p>I have trained a model locally using the R package locfit. I am now trying to run this in Azure Machine Learning.<\/p>\n<p>Most guides\/previous questions appear to be in relation to Azure Machine Learning (classic). Although I believe the process outlined in similar posts will be similar (e.g. <a href=\"https:\/\/stackoverflow.com\/questions\/43176442\/install-r-packages-in-azure-ml\">here<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/27568624\/installing-additional-r-package-on-azure-ml\">here<\/a>, I am still unable to get it to work.<\/p>\n<p>I have outlined the steps I have followed below:<\/p>\n<ol>\n<li><p>Download locfit R package for windows Zip file from <a href=\"https:\/\/cran.r-project.org\/web\/packages\/locfit\/index.html\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<\/li>\n<li><p>Put this downloaded Zip file into a new Zip file entitled &quot;locfit_package&quot;<\/p>\n<\/li>\n<li><p>I upload this &quot;locfit_package&quot; zip folder to AML as a dataset (Create Dataset &gt; From Local Files &gt; <strong>name<\/strong>: locfit_package <strong>dataset<\/strong> <strong>type<\/strong>: file &gt; Upload the zip (&quot;locfit_package&quot;) &gt; Confirm upload is correct<\/p>\n<\/li>\n<li><p>In the R terminal I then execute the following code:<\/p>\n<p>install.packages(&quot;src\/locfit_package.zip&quot;, lib = &quot;.&quot;, repos = NULL, verbose = TRUE)<\/p>\n<p>library(locfit_package, lib.loc=&quot;.&quot;, verbose=TRUE)<\/p>\n<p>library(locfit)<\/p>\n<\/li>\n<li><p>The following error message is then returned:<\/p>\n<p>system (cmd0): \/usr\/lib\/R\/bin\/R CMD INSTALL<\/p>\n<p>Warning: invalid package \u2018src\/locfit_package.zip\u2019\nError: ERROR: no packages specified\nWarning message:<\/p>\n<p>In install.packages(&quot;src\/locfit_package.zip&quot;, lib = &quot;.&quot;, repos = NULL,  : installation of package \u2018src\/locfit_package.zip\u2019 had non-zero exit status\nError in library(locfit_package, lib.loc = &quot;.&quot;, verbose = TRUE) : there is no package called \u2018locfit_package\u2019\nExecution halted<\/p>\n<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1631294643347,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":411,
        "Owner_creation_time":1624530562660,
        "Owner_last_access_time":1639583055450,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69135872",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71023918,
        "Question_title":"ModuleNotFound Error - Azure ML with prebuilt docker image",
        "Question_body":"<p>I have developed a module which works perfectly when executed locally.<\/p>\n<p>I have created an environment on azure using a prebuilt docker image found here:\n<strong>&quot;azureml\/minimal-ubuntu18.04-py37-cpu-inference&quot;<\/strong> <a href=\"https:\/\/mcr.microsoft.com\/v2\/_catalog\" rel=\"nofollow noreferrer\">https:\/\/mcr.microsoft.com\/v2\/_catalog<\/a>\n. Also, Using pythonScriptStep, to run a pipeline. Here is how the step looks<\/p>\n<pre><code>StepPreprocessing = PythonScriptStep(\n    name=&quot;Preprocessing&quot;,\n    script_name=e.preprocess_script_path,\n    arguments=[\n        &quot;--config_path&quot;, e.preprocess_config_path,\n        &quot;--task&quot;, e.preprocess_task,\n    ],\n    inputs=None,\n    compute_target=aml_compute,\n    runconfig=run_config,\n    source_directory=e.sources_directory,\n    allow_reuse=False\n)\nprint(&quot;Step Preprocessing created&quot;)\n<\/code><\/pre>\n<p>This results in error:<\/p>\n<pre><code>Traceback (most recent call last):\n[stderr]  File &quot;Pipeline\/custom_pipeline.py&quot;, line 4, in &lt;module&gt;\n[stderr]    from Preprocess.logger import logger\n[stderr]ModuleNotFoundError: No module named 'Preprocess'\n<\/code><\/pre>\n<p>in the 1st line of entry script (<strong>custom_pipeline.py<\/strong>):<\/p>\n<pre><code>import sys\nsys.path.append(&quot;.&quot;) \nfrom Preprocess.logger import logger\n<\/code><\/pre>\n<p>The folder structure is as:<\/p>\n<pre><code>-Preprocess\n  -__init__.py\n  - Module1\n    -__init__.py\n    -somefile.py\n  - Module2\n    -__init__.py\n    -someOtherfile.py\n  - Pipeline\n    -__init__.py\n    -custom_pipeline.py\n  - logger\n    -__init__.py\n    -logger.py\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1644260100200,
        "Question_score":0,
        "Question_tags":"python|azure|docker|azure-machine-learning-service",
        "Question_view_count":109,
        "Owner_creation_time":1443017464707,
        "Owner_last_access_time":1663923275743,
        "Owner_location":"Sweden",
        "Owner_reputation":644,
        "Owner_up_votes":33,
        "Owner_down_votes":1,
        "Owner_views":126,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I found out that the python script step copies everything inside the source_dir and therefore in my case it was copying the modules and not the root folder. So I had to put the dir Preprocess inside another dir and mention the new dir as source_dir.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1644604906183,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71023918",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52603929,
        "Question_title":"AML Studio: Register mutliple gateways on the same server",
        "Question_body":"<p>I am struggling to find a way to register multiple gateways. I have a local instance of my SQL server and have created a gateway to access to it from the AML Studio workspace. It works fine but now I would like to access to the same SQL server instance from another workspace. So the question is: how to register a new gateway without removing the previous one?\nI followed this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a>.\nDoes the following explanation mean that there is no way to do that?<\/p>\n\n<blockquote>\n  <p>You can create and set up multiple gateways in Studio for each workspace. For example, you may have a gateway that you want to connect to your test data sources during development, and a different gateway for your production data sources. Azure Machine Learning gives you the flexibility to set up multiple gateways depending upon your corporate environment. Currently you can\u2019t share a gateway between workspaces and only one gateway can be installed on a single computer.<\/p>\n<\/blockquote>\n\n<p>It is quite limiting as connecting to the same server from multiple workspaces may be sometimes crucial.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1538466090420,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":40,
        "Owner_creation_time":1528790837107,
        "Owner_last_access_time":1660146049397,
        "Owner_location":"Paris, France",
        "Owner_reputation":610,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":203,
        "Question_last_edit_time":1538485474347,
        "Answer_body":"<p>Well, finally I have found a way to bypass this limitation. From this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a> I have found that: <\/p>\n\n<blockquote>\n  <p>The IR does not need to be on the same machine as the data source. But staying closer to the data source reduces the time for the gateway to connect to the data source. We recommend that you install the IR on a machine that's different from the one that hosts the on-premises data source so that the gateway and data source don't compete for resources.<\/p>\n<\/blockquote>\n\n<p>So the  logic is pretty simple. You provide access to your local server to another machine on vpn and install your gateway there. Important: I have set up the firewall rules on the server before, to be able to establish the connection remotely.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1538648158570,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52603929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65083883,
        "Question_title":"Example for Azure AutoML Forecasting for time series with multiple covariate features",
        "Question_body":"<p>I would like to use Azure AutoML for <code>forecasting<\/code> where I have multiple features for one timeseries. Is there any example which I can replicate?<\/p>\n<p>I have been looking into: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-beer-remote\/auto-ml-forecasting-beer-remote.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-beer-remote\/auto-ml-forecasting-beer-remote.ipynb<\/a>\nand\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb<\/a>\nbut no luck using multiple features instead of only one timeseries.<\/p>\n<p>Any help is greatly appreciated<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1606789538570,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1231,
        "Owner_creation_time":1581649402283,
        "Owner_last_access_time":1623273118283,
        "Owner_location":"C\u00f3rdoba, Cordoba, Argentina",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65083883",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67057782,
        "Question_title":"Azure ML studio really slow",
        "Question_body":"<p>I had been using Azure ML studio for a while now and it was really fast but now when I try to unzip folders containing images around 3000 images using<\/p>\n<pre><code>!unzip &quot;file.zip&quot; -d &quot;to unzip directory&quot;\n<\/code><\/pre>\n<p>it took more than 30 minutes and other activities(longer concatenation methods) also seem to take a long time even using numpy arrays. Wondering if it is something with configuration or other problems. I have tried switching locations, creating new resource groups, workspaces, changing computes(Both CPU and GPU).<\/p>\n<p>Compute and other set of current configurations can be seen on the image<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/GNZao.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GNZao.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1618227931020,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":185,
        "Owner_creation_time":1583404260763,
        "Owner_last_access_time":1663916998617,
        "Owner_location":"Ethiopia",
        "Owner_reputation":412,
        "Owner_up_votes":127,
        "Owner_down_votes":1,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67057782",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62636399,
        "Question_title":"h2o models on Azure ML Containers",
        "Question_body":"<p>I have a requirement to deploy h2o models on Azure . I have successfully handled sklearn models but for sklearn the dependencies in my view are easier . For h2o the java runtime dependency is my bottle-neck.<\/p>\n<p>Will the container that i create will have java runtime ?&gt; Else what are the suggested strategies ?<\/p>\n<p>Should I go for a VM instead ?<\/p>\n<p>Thanks,<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1593427430617,
        "Question_score":1,
        "Question_tags":"containers|h2o|azure-machine-learning-service",
        "Question_view_count":84,
        "Owner_creation_time":1396958226127,
        "Owner_last_access_time":1664040884423,
        "Owner_location":"Mumbai, India",
        "Owner_reputation":169,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62636399",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58478542,
        "Question_title":"Import azure.core not found issue in running Notebook through MachineLearningStudio",
        "Question_body":"<p>I was trying to run a sample tutorial notebook through the ml studio. <\/p>\n\n<p><a href=\"https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/tutorials\/img-classification-part1-training.ipynb\" rel=\"nofollow noreferrer\">https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/tutorials\/img-classification-part1-training.ipynb<\/a><\/p>\n\n<p>But when i uploaded i used kernel python3. But when i ran it failed with the error azureml.core not found.<\/p>\n\n<p>I am new to Azure Stack and ML. Should i install python 3.6 on my own through conda and have my own kernel, i noticed the current installation of python on studio is 3.4.<\/p>\n\n<p>Please let me know how to proceed further ? I am blocked on it. I need help on deploying the 3.6 version of python on the notebook server. I am not using the notebook vm. I am just using whatever came with the azure notebook option in the ml studio.<\/p>\n\n<p>How to alter the sys path to point to my libraries to after installation of the new version of python ?<\/p>\n\n<p>Need help.<\/p>\n\n<p>It works fine in my local environment as i have python3.6 installed. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1571618889040,
        "Question_score":0,
        "Question_tags":"python-3.x|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":143,
        "Owner_creation_time":1484215677137,
        "Owner_last_access_time":1643607883400,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58478542",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67900417,
        "Question_title":"Azure Machine Learning - authorization error despite having maximum permissions",
        "Question_body":"<p>I am trying to build a machine learning model on Azure for my company. The IT team at the company I work at has given me maximum permissions for our Azure Machine Learning account since I am doing all the setup part (we started using it only last month). However, I checked the portal and realized that I am not authorized to access any of the modules within Azure ML, namely Experiment, Models, Endpoints, Datasets, etc. Is there something I am missing that is giving me this error? The error message has this <a href=\"https:\/\/go.microsoft.com\/fwlink\/?linkid=2161335\" rel=\"nofollow noreferrer\">link<\/a> but I am not sure it serves the purpose.<\/p>\n<p><strong>Note:<\/strong> I am new to Azure so please forgive me if this is a very basic doubt.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oPvpP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oPvpP.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1623227559873,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":251,
        "Owner_creation_time":1513143629087,
        "Owner_last_access_time":1664079380110,
        "Owner_location":"Seattle, Washington",
        "Owner_reputation":53,
        "Owner_up_votes":108,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67900417",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58237929,
        "Question_title":"Slow data transfer from Azure Blob Storage to compute target",
        "Question_body":"<p>It's taking 1 hour to download a 48gb dataset with 90000 files.\nI am training an image segmentation model on Azure ML pipeline using compute target p100-nc6s-v2.\nIn my script I'm accessing Azure Blob Storage using DataReference's as_download() functionality. The blob storage is in the same location as workspace (using get_default_datastore).<\/p>\n\n<p><strong>Note:<\/strong> I'm able to download complete dataset to local workstation within a few minutes using <code>az copy<\/code>.<\/p>\n\n<p>When I tried to use as_mount() the first epoch was extremely slow (4700 seconds vs 772 seconds for subsequent epochs).<\/p>\n\n<p>Is this expected behavior? If not, what can be done to improve dataset loading speed?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1570197733587,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":936,
        "Owner_creation_time":1404997159583,
        "Owner_last_access_time":1617571280343,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1570203301407,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58237929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73187536,
        "Question_title":"Error while detaching AKS cluster through Azure ML SDK extension",
        "Question_body":"<p>I created an AKS cluster using Azure Machine Learning SDK extension and I attached to the workspace created. When the cluster is created and attached, I doesn't show any error. When I am trying to detach it from workspace, it is not accepting the operations.<\/p>\n<p>I would like to detach the existing AKS cluster from workspace either by program manner, using CLI or even using Azure portal.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659308799773,
        "Question_score":0,
        "Question_tags":"azure|azure-aks|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_time":1651093614703,
        "Owner_last_access_time":1659335138797,
        "Owner_location":"Netherland",
        "Owner_reputation":19,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":"<p>If we are using any <strong>extensions of SDK or Azure CLI<\/strong> for machine learning to detach AKS cluster, it <strong>will not work<\/strong> and it will not get deleted or detached. Instead, we need to use <strong>Azure CLI with AKS<\/strong>. There are two types of implementations we can perform.<\/p>\n<p><strong>Python:<\/strong><\/p>\n<pre><code>Aks_target.detach()\n<\/code><\/pre>\n<p><strong>Azure CLI:<\/strong><\/p>\n<p>Before performing this step, we need to get the details of the working AKS cluster name attached to our workspace. Resource Group details and workspace name<\/p>\n<pre><code>az ml computertarget detach -n youraksname -g yourresourcegroup -w yourworkspacename\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1659333006090,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73187536",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54433767,
        "Question_title":"how to add new R packages in azure machine learning for time series anomaly detection",
        "Question_body":"<p>I am trying to find out time series anomaly detection in which i need to install new R packages. In this i m following <a href=\"https:\/\/github.com\/business-science\/anomalize\" rel=\"nofollow noreferrer\">https:\/\/github.com\/business-science\/anomalize<\/a> site. In this i needed to install 2 packages: <code>tidyverse<\/code> and <code>anomalize<\/code>.<\/p>\n\n<ol>\n<li><p>can anyone help me on installing package mentioned above as I am getting <\/p>\n\n<blockquote>\n  <p>error \"package or namespace load failed for tidyverse\"<\/p>\n<\/blockquote><\/li>\n<li><p>Also while adding zip of <code>tidyverse<\/code> and <code>anomalize<\/code> do I need to add any other packages and dependencies in that as I am adding only those 2 packages thinking there r no other dependencies I needed for those 2?<\/p><\/li>\n<\/ol>\n\n<p>you can see in code that I created <code>R_Package.zip<\/code> and put <code>tidyverse.zip<\/code> and <code>anomalize.zip<\/code> in that that <\/p>\n\n<pre><code>dataset1 &lt;- maml.mapInputPort(1)\ndata.set &lt;- data.frame(installed.packages())\n#install.packages(\u201csrc\/R_Package\/tidyverse_1.2.1.zip\u201d, lib = \u201c.\u201d, \n                  repos = NULL, verbose = TRUE);\n#library(tidyverse, lib.loc=\u201d.\u201d, verbose=TRUE);\n\ninstall.packages(\"src\/tidyverse.zip\",lib=\".\",repos=NULL,verbose=TRUE)\nlibrary(R_package, lib.loc = \".\", verbose=TRUE);\n\ninstall.packages(\"src\/anomalize.zip\",lib=\".\",repos=NULL,verbose=TRUE)\nlibrary(R_package, lib.loc = \".\", verbose=TRUE);\n\n#success &lt;- library(\"tidyverse\", lib.loc = \".\", \n                    logical.return = TRUE, verbose = TRUE)\n#library(tidyverse)\n\n\nmaml.mapOutputPort(\"dataset1\");\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1548825762143,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":168,
        "Owner_creation_time":1492081349833,
        "Owner_last_access_time":1556108056507,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":42,
        "Question_last_edit_time":1548834576213,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54433767",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64597526,
        "Question_title":"Provision AKS with internal load balancer from AMLS on Azure",
        "Question_body":"<p>I would like to provision an AKS cluster that is connected to a vnet and has an internal load balancer on Azure. I am using code from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=python\" rel=\"nofollow noreferrer\">here<\/a> that looks like this:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Verify that cluster does not exist already\ntry:\n    aks_target = AksCompute(workspace=ws, name=aks_cluster_name)\n    print(&quot;Found existing aks cluster&quot;)\n\nexcept:\n    print(&quot;Creating new aks cluster&quot;)\n\n    # Subnet to use for AKS\n    subnet_name = &quot;default&quot;\n    # Create AKS configuration\n    prov_config=AksCompute.provisioning_configuration(load_balancer_type=&quot;InternalLoadBalancer&quot;)\n    # Set info for existing virtual network to create the cluster in\n    prov_config.vnet_resourcegroup_name = &quot;myvnetresourcegroup&quot;\n    prov_config.vnet_name = &quot;myvnetname&quot;\n    prov_config.service_cidr = &quot;10.0.0.0\/16&quot;\n    prov_config.dns_service_ip = &quot;10.0.0.10&quot;\n    prov_config.subnet_name = subnet_name\n    prov_config.docker_bridge_cidr = &quot;172.17.0.1\/16&quot;\n\n    # Create compute target\n    aks_target = ComputeTarget.create(workspace = ws, name = &quot;myaks&quot;, provisioning_configuration = prov_config)\n    # Wait for the operation to complete\n    aks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>However, I get the following error<\/p>\n<pre><code>K8s failed to assign an IP for Load Balancer after waiting for an hour.\n<\/code><\/pre>\n<p>Is this because the AKS cluster does not yet have a 'network contributor' role for the vnet resource group? Is the only way to get this to work to first create AKS outside of AMLS, grant the network contributor role to the vnet resource group, then attach the AKS cluster to AMLS and configure the internal load balancer afterwards?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1603997735143,
        "Question_score":1,
        "Question_tags":"azure-aks|azure-machine-learning-service|vnet|internal-load-balancer",
        "Question_view_count":352,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1604002322987,
        "Answer_body":"<p>I was able to get this to work by first creating an AKS resource without an internal load balancer, then separately updating the load balancer following this code:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute.aks import AksUpdateConfiguration\nfrom azureml.core.compute import AksCompute\n\n# ws = workspace object. Creation not shown in this snippet\naks_target = AksCompute(ws,&quot;myaks&quot;)\n\n# Change to the name of the subnet that contains AKS\nsubnet_name = &quot;default&quot;\n# Update AKS configuration to use an internal load balancer\nupdate_config = AksUpdateConfiguration(None, &quot;InternalLoadBalancer&quot;, subnet_name)\naks_target.update(update_config)\n# Wait for the operation to complete\naks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>No network contributor role was required.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1604359053333,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64597526",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65781409,
        "Question_title":"AzureMLCompute job failed: container registry failed unexpectedly: container setup task failed",
        "Question_body":"<p>Could you please help me with running python script in azureml environment? I created the workspace and azure container registry and pushed docker image to the container. This is the example of dockerfile:<\/p>\n<pre><code>FROM python:3.7\n\nRUN pip install --upgrade pip\n\nRUN pip install virtualenv\n\nENV VIRTUAL_ENV=\/venv\n\nRUN virtualenv venv -p python3\n\nENV PATH=&quot;VIRTUAL_ENV\/bin:$PATH&quot;\n\nWORKDIR \/app\n\nADD . \/app\n\nENV PYTHON_PACKAGES=&quot;\\\nnumpy \\\npandas \\\nseaborn \\\nmatplotlib \\\nsklearn \\\nscipy \\\nimbalanced-learn \\\nxgboost \\\njoblib \\\n&quot; \n\nRUN pip install --no-cache-dir $PYTHON_PACKAGES\n\nENTRYPOINT [&quot;python3&quot;,&quot;train.py&quot;]\n<\/code><\/pre>\n<p>I created environment like this:\n<code>myenv = Environment.from_pip_requirements(name = ws.get_details()['name'],file_path = &quot;requirements.txt&quot;)<\/code><\/p>\n<p>When I run the experiment I get this error:<\/p>\n<p><code>&quot;Message&quot;: &quot;AzureMLCompute job failed.\\nJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\tJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\terr: container setup task failed: exit status 1\\n\\tReason: container setup task failed: exit status 1\\n\\tInfo: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.&quot;<\/code><\/p>\n<p>I do not understand what this error mean.<\/p>\n<p>I configure and submit training job with following:<\/p>\n<pre><code>    src = ScriptRunConfig(source_directory='.',\n                        script='train.py',\n                        compute_target=cpu_cluster,\n                        environment=myenv)\n    \n    #Submit training job\n    run = Experiment(ws,'test-classification').submit(src)\n    run.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>Thank you!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1611000359923,
        "Question_score":0,
        "Question_tags":"azure|docker|azure-devops|dockerfile|azure-machine-learning-service",
        "Question_view_count":221,
        "Owner_creation_time":1395179633740,
        "Owner_last_access_time":1623677760737,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Question_last_edit_time":1611002029853,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65781409",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42458982,
        "Question_title":"Understanding classification results",
        "Question_body":"<p>I've run a simple two-class neural network where I got this result in the end (eval):<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/vw2jQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vw2jQ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I think I am going to be happy with the <code>True Positive<\/code> and <code>False Negative<\/code> results. But what does <code>False Positive<\/code> mean? <code>False Positive<\/code> means it did not correctly classify 2002 elements and missed them?<\/p>\n\n<p>The <code>Accuracy<\/code> is 66%, that's really bad right? Whats the difference between that and <code>AUC<\/code>?<\/p>\n\n<p><code>Precision<\/code> suffers because Accuracy also is bad (I hoping for a 80%+)?<\/p>\n\n<p>And how do I flip <code>Positive Label<\/code> and <code>Negative Label<\/code>? I really want to predict the classification where the target is to find <code>CANDIDATE<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1488042320197,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":81,
        "Owner_creation_time":1267709938320,
        "Owner_last_access_time":1508513881653,
        "Owner_location":"Norway",
        "Owner_reputation":13032,
        "Owner_up_votes":516,
        "Owner_down_votes":8,
        "Owner_views":1004,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Basically, for the false\/true positives and false\/true negatives :\nYou have detected almost all the CANDIDATE samples in your dataset, 3420 of them were correctly predicted as TRUE and 31 of them were predicted as FALSE. This information is captured in the Recall ratio : 3420\/(3420+31) = 99.1%. It is very high, so very good. <\/p>\n\n<p>However, you have predicted <strong>too many<\/strong> CANDIDATE. Indeed, in all the TRUE values predicted by the model, 3420 were actually TRUE and 2002 were actually FALSE. This makes the Precision ratio bad : 3420\/(3420+2002)=63.1%. Which is not that good. <\/p>\n\n<p>F1 is a combinaison between Precision and Recall, it summarizes them into one value, some kind of weighted average. The formula is 2*(P*R)\/(P+R). So if one of Precision or Recall is bad : the F1score will capture it. <\/p>\n\n<p>You can see that you have a total of 5999 examples in your data set. Out of those, 3451 are really TRUE and 2548 are really FALSE. So you have 57% of your data that is TRUE. If you make a really stupid classifier that classifies everything as TRUE whatever the features are, then you will get 57% accuracy. Given that, 66.1% accuracy is not really good. \nIf you look at the second column of that table, you only predict 577 FALSE out of the 5999 samples. Your classifier is heavily biased towards TRUE predictions. <\/p>\n\n<p>For the AUC, it stands for Area Under the Curve. You can read <a href=\"http:\/\/fastml.com\/what-you-wanted-to-know-about-auc\/\" rel=\"nofollow noreferrer\">more detailed info about it here<\/a>. To summarize : when you predic a value, you don't really get True or False directly. You get a real number between 0 (False) and 1 (True). The way to classify a predicted value, say 0.2, is to use a Threshold. The threshold is by default set to 0.5. So if you predict 0.2, your model will predict to classify it as a False because 0.2&lt;0.5. But you could make that treshold move between 0 and 1. If the classifier is really good, if it discriminates really well the Falses and Trues predictions, then the AUC will be close to 1. If it's really bad, it will be close to 0.5. Refer to the link if you need more information. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1488062187217,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1488063664327,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42458982",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36260727,
        "Question_title":"Equivalent of Subset in Azure machine learning studio",
        "Question_body":"<p>I have a dataset in azure machine learning (.csv), on the same dataset I have multiple models build, I want to subset data for each of the model based on a different column<\/p>\n\n<p>Input:<\/p>\n\n<pre><code>ID col1 col2 col3\n1  0    13   0\n2  5    45   0\n3  10   0    34\n4  12   1    3\n<\/code><\/pre>\n\n<p>For the 1st model I want to retain all records where col1 not equal to None<\/p>\n\n<pre><code>ID col1 col2 col3\n2  5    45   0\n3  10   0    34\n4  12   1    3\n<\/code><\/pre>\n\n<p>Similarly for model 2<\/p>\n\n<pre><code>ID col1 col2 col3\n1  0    13   0\n2  5    45   0\n4  12   1    3\n<\/code><\/pre>\n\n<p>Hope it was clear<\/p>\n\n<p>The equivalent in R would be <\/p>\n\n<pre><code>df[!df$col1 == \"None\",] \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1459161991533,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":243,
        "Owner_creation_time":1406266059940,
        "Owner_last_access_time":1663232189147,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Question_last_edit_time":1459256566467,
        "Answer_body":"<p>You can use the \"Execute R Script\" module and just plug in your R code there.<\/p>\n\n<pre><code>df &lt;- maml.mapInputPort(1)\ndf &lt;- df[!df$col1 == \"None\",] \nmaml.mapOutputPort(\"df\");\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1461479422230,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36260727",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47286717,
        "Question_title":"Fuzzy matching of user generated dataset to stored datasets",
        "Question_body":"<p>I have stored workflows. They're trees with decision points.  Basically every point in the data is a command issued. Adding it all up is a workflow to build something from the commands.<\/p>\n\n<p>I'm trying to use azure ml to take a partially completed workflow from a user and match it against these stored workflows.  <\/p>\n\n<p>Adding to the difficulty is that I'm never sure when the user has started or stopped a workflow so it's always a Time preference match that is never perfect.<\/p>\n\n<p>Despite days of searching I can't find any information on canned algorithms that do this type of pattern matching.<\/p>\n\n<p>Can someone suggest where I might find some information on taking a data series (not numeric) and match that to a tree graph of similar values in real time?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1510664982930,
        "Question_score":1,
        "Question_tags":"azure-hdinsight|azure-data-lake|azure-machine-learning-studio",
        "Question_view_count":65,
        "Owner_creation_time":1341934714620,
        "Owner_last_access_time":1663955765103,
        "Owner_location":null,
        "Owner_reputation":3228,
        "Owner_up_votes":94,
        "Owner_down_votes":2,
        "Owner_views":355,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47286717",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69718265,
        "Question_title":"Azure ML problem with installation fastai with conda",
        "Question_body":"<p>I am struggling to install the fastbook package for fastai in Azure ML. Below is the error I am getting.<\/p>\n<p>I have created a new environment, and all other fast ai packages are installed.<\/p>\n<pre><code>Found conflicts! Looking for incompatible packages.\nThis can take several minutes.  Press CTRL-C to abort.\nfailed      \n                                                                                                                                              \nUnsatisfiableError: The following specifications were found to be incompatible with each other:\nOutput in format: Requested package -&gt; Available versions\nThe following specifications were found to be incompatible with your system:\n  - feature:\/linux-64::__glibc==2.27=0\n  - python=3.9 -&gt; libgcc-ng[version='&gt;=7.5.0'] -&gt; __glibc[version='&gt;=2.17']\nYour installed version is: 2.27\n<\/code><\/pre>\n<p>The command line code is below:<\/p>\n<pre><code> conda install -y pip\n conda install -y ipykernel\n conda install -y -c fastai -c pytorch fastai\n conda install -y -c fastai fastbook\n conda install -y -c fastai nbdev\n<\/code><\/pre>\n<p>I only get the error for the fastbook package<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1635229213020,
        "Question_score":0,
        "Question_tags":"python|conda|fast-ai|azure-machine-learning-service",
        "Question_view_count":124,
        "Owner_creation_time":1620735146277,
        "Owner_last_access_time":1663768429990,
        "Owner_location":"South Africa",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1635234928607,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69718265",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65363117,
        "Question_title":"Connecting to AMLS workspace with private endpoint using Python SDK and proxy",
        "Question_body":"<p>I have created an AMLS workspace with a private endpoint in a vnet that is peered into a company's network. I would like to access the AMLS workspace using a company VM (Windows) to add compute, add datastores, deploy models, etc. using the Azure ML Python SDK.<\/p>\n<p>The company VM has a proxy in place which initially was blocking my ability to even log in to the AMLS workspace. After adding an HTTPS_PROXY environment variable and configuring the powershell profile for the proxy server, I can now log in to Azure from powershell (<code>az login<\/code>) and I can access the AMLS workspace using Python (<code>ws = Workspace.get()<\/code>, <code>ws.get_details()<\/code>, etc.). However, as soon as I try to access any of the resources (e.g.<code> ws.get_default_datastore()<\/code>, <code>cluster = ComputeTarget(workspace=ws, name=cluster_name)<\/code>) I get SSL certificate verification errors:<\/p>\n<pre><code>requests.exceptions.SSLError: HTTPSConnectionPool(host='&lt;WORKSPACE_ID&gt;.workspace.canadacentral.api.azureml.ms', port=443): Max retries\n exceeded with url: \/discovery\/workspaces\/&lt;WORKSPACE_ID&gt; (Caused by SSLError(SSLCertVerificationError(1,\n '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1091)')))\n<\/code><\/pre>\n<p>There is a similar problem mentioned here: <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/1089\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/1089<\/a>, but I'm still unsure how to solve this. What is the best approach here? Should I turn off certificate validation in the Azure ML Python SDK? If so, how?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1608320952537,
        "Question_score":0,
        "Question_tags":"python|ssl|proxy|azure-machine-learning-service",
        "Question_view_count":1139,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65363117",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64599174,
        "Question_title":"Can't use wildcard with Azure Data Lake Gen2 files",
        "Question_body":"<p>I was able to properly connect my Data Lake Gen2 Storage Account with my Azure ML Workspace. When trying to read a specific set of Parquet files from the Datastore, it will take forever and will not load it.<\/p>\n<p>The code looks like:<\/p>\n<pre><code>from azureml.core import Workspace, Datastore, Dataset\nfrom azureml.data.datapath import DataPath\n\nws = Workspace(subscription_id, resource_group, workspace_name)\n\ndatastore = Datastore.get(ws, 'my-datastore')\n\nfiles_path = 'Brazil\/CommandCenter\/Invoices\/dt_folder=2020-05-11\/*.parquet'\n\ndataset = Dataset.Tabular.from_parquet_files(path=[DataPath(datastore, files_path)], validate=False)\ndf = dataset.take(1000)\n\ndf.to_pandas_dataframe()\n<\/code><\/pre>\n<p>Each of these Parquet files have approx. 300kB. There are 200 of them on the folder - generic and straight out of Databricks. Strange is that when I try and read one single parquet file from the exact same folder, it runs smoothly.<\/p>\n<p>Second is that other folders that contain less than say 20 files, will also run smoothly, so I eliminated the possibility that this was due to some connectivity issue. And even stranger is that I tried the wildcard like the following:<\/p>\n<pre><code># files_path = 'Brazil\/CommandCenter\/Invoices\/dt_folder=2020-05-11\/part-00000-*.parquet'\n<\/code><\/pre>\n<p>And theoretically this will only direct me to the <code>00000<\/code> file, but it will also not load. Super weird.<\/p>\n<p>To try to overcome this, I have tried to connect to the Data Lake through ADLFS with Dask, and it just works. I know this can be a workaround for processing &quot;large&quot; datasets\/files, but it would be super nice to do it straight from the Dataset class methods.<\/p>\n<p>Any thoughts?<\/p>\n<p>EDIT: typo<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1604005397523,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-service",
        "Question_view_count":403,
        "Owner_creation_time":1508924024027,
        "Owner_last_access_time":1663957908303,
        "Owner_location":null,
        "Owner_reputation":118,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64599174",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40018320,
        "Question_title":"Is it secure to pass the DB query to AzureML as a global parameter?",
        "Question_body":"<p>When using AzureMLBatchExecution activity in Azure Data Factory, is it secure to pass the DB query as a global parameter to the AzureML web service? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1476354083450,
        "Question_score":2,
        "Question_tags":"azure|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":68,
        "Owner_creation_time":1452608563363,
        "Owner_last_access_time":1562103924250,
        "Owner_location":null,
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When you talk about \"secure\", are you worried about secure transmission between AML and ADF, or secure storage of your DB query information? For the former, all communication between these two services will be done with HTTPS. For the latter, our production storage has its strict access control. Besides, we only log the count of the global parameters and never the values. I believe it's secure to pass your DB query as a global parameter to the AzureML web service.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1476431199480,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40018320",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71203995,
        "Question_title":"RuntimeError: Java gateway process exited before sending its port number when Deploying Pyspark model to Azure Container Instance",
        "Question_body":"<p>I am trying to deploy a PySpark model trained in Azure Databricks with MLflow to an ACI in Azure Machine Learning.<\/p>\n<p>I am following the steps in this link:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks<\/a><\/p>\n<p>but I get this error:<\/p>\n<pre><code>SPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2022-02-21 09:29:30,269 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-02-21 09:29:30,270 | root | INFO | Starting up request id generator\n2022-02-21 09:29:30,270 | root | INFO | Starting up app insight hooks\n2022-02-21 09:29:30,270 | root | INFO | Invoking user's init function\nJAVA_HOME is not set\n2022-02-21 09:29:31,267 | root | ERROR | User's init function failed\n2022-02-21 09:29:31,268 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 191, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/execution_script.py&quot;, line 15, in init\n    model = load_model(model_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 667, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/spark.py&quot;, line 703, in _load_pyfunc\n    pyspark.sql.SparkSession.builder.config(&quot;spark.python.worker.reuse&quot;, True)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/sql\/session.py&quot;, line 228, in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 392, in getOrCreate\n    SparkContext(conf=conf or SparkConf())\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 144, in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 339, in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/java_gateway.py&quot;, line 108, in launch_gateway\n    raise RuntimeError(&quot;Java gateway process exited before sending its port number&quot;)\nRuntimeError: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>My code looks like this:<\/p>\n<pre><code>from mlflow.deployments import get_deploy_client\n\n# set the tracking uri as the deployment client\nclient = get_deploy_client(mlflow.get_tracking_uri())\n\n# set the model path \nmodel_path = &quot;k_means_model&quot;\n\n    # define the model path and the name is the service name\n    # the model gets registered automatically and a name is autogenerated using the &quot;name&quot; parameter below \n    client.create_deployment(model_uri='runs:\/{}\/{}'.format(run_id, model_path), name = 'k-means-model-ml-flow')\n<\/code><\/pre>\n<p>While my model settings are:<\/p>\n<pre><code>artifact_path: k_means_model\ndatabricks_runtime: 10.3.x-cpu-ml-scala2.12\nflavors:\n  python_function:\n    data: sparkml\n    env: conda.yaml\n    loader_module: mlflow.spark\n    python_version: 3.8.10\n  spark:\n    model_data: sparkml\n    pyspark_version: 3.2.1\nmodel_uuid: 76ba9dfb01e1428ab8145a161ec3cf32\nrun_id: c0090fa9-b382-45b8-be08-d05e16f3cd62\nutc_time_created: '2022-02-21 08:47:34.967167'\n<\/code><\/pre>\n<p>Can someone help please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1645436044400,
        "Question_score":1,
        "Question_tags":"pyspark|azure-databricks|azure-machine-learning-service|mlflow",
        "Question_view_count":289,
        "Owner_creation_time":1635865186583,
        "Owner_last_access_time":1657599189513,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1645439952347,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71203995",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29647782,
        "Question_title":"Azureml Web Service - How to create a Rest Service from an Experiment to be consumed by a mobile app?",
        "Question_body":"<p>I've looked all over the google and stackoverflow for the answer but I cant seem to find it. I'm trying to get the output from an azure experiment to an app. I've made the app using <code>ibuildapp<\/code> and google forms. How can I use the inputs from the google form, pass it to azure and get an output to display on the app?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1429093608083,
        "Question_score":1,
        "Question_tags":"json|web-services|azure|webforms|azure-machine-learning-studio",
        "Question_view_count":603,
        "Owner_creation_time":1405675523040,
        "Owner_last_access_time":1494238760807,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":1429213713290,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29647782",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38937247,
        "Question_title":"Separating a tree Regression Model based on unique values of one column",
        "Question_body":"<p>I have a data set of 20,000,000 rows. Each row has 30 columns.<\/p>\n\n<p>One of the columns contains 7000 unique Product Numbers. <\/p>\n\n<p>Each row contains a Unit Cost value that I would like to predict using all the columns other than the Unit Cost.<\/p>\n\n<p>I would like to build a unique decision tree or a unique branch of a decision tree to model the data for each Product Number.  <\/p>\n\n<p>Basically partitioning the rows for each Product Number and modelling each Product Number in isolation.<\/p>\n\n<p>I would like to train a single model in Azure to do this if possible.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1471124448550,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":74,
        "Owner_creation_time":1471124166630,
        "Owner_last_access_time":1471127961390,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1499698390287,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38937247",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63920599,
        "Question_title":"PowerBI and MLflow integration (through AzureML)",
        "Question_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1600261190477,
        "Question_score":0,
        "Question_tags":"azure|powerbi|mlflow|azure-machine-learning-service",
        "Question_view_count":405,
        "Owner_creation_time":1600260166047,
        "Owner_last_access_time":1615561616230,
        "Owner_location":null,
        "Owner_reputation":15,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1600855880503,
        "Answer_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1600604920243,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1600855957377,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68208679,
        "Question_title":"Run script locally with remote dataset on AzureML",
        "Question_body":"<p>I have a script that for development purposes I would like to run and debug locally. However, I do not want to store the data needed for my experiment on my local machine.<\/p>\n<p>I am using the <code>azureml<\/code> library with the Azure Machine Learning Studio. See my code below<\/p>\n<pre><code># General\nimport os\nimport argparse\n\n# Data analysis and wrangling\nimport pandas as pd\n\n# Machine learning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom azureml.core import Run\n\n# Get the environment of this run\nrun = Run.get_context()\n\nif __name__ == &quot;__main__&quot;:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--data_path',\n        type=str,\n        help='Path to the training data',\n        # The default path is on my local machine, however I would like to reference a remote datastore on Azure as a parameter to this script\n        default=os.path.join(os.getcwd(), 'data')\n    )\n    args = parser.parse_args()\n\n    # Obtain the data from the datastore\n    train_df = pd.read_csv(os.path.join(args.data_path, os.listdir(args.data_path)[0]))\n\n    # Drop unnecessary columns\n    train_df = train_df.drop(['Name', 'PassengerId', 'Ticket', 'Cabin'], axis=1)\n\n    # Encode non-numeric features as dummies\n    train_df = pd.get_dummies(train_df)\n\n    # Drop NA's\n    train_df.dropna(inplace=True)\n\n    # Use gridsearch CV to find the best parameters for the model\n    parameters = {'kernel': ('linear', 'rbf'),\n                  'C': [1, 10]}\n\n    # Initialize the grid search\n    search = GridSearchCV(SVC(), param_grid=parameters, cv=8)\n\n    # Train the model\n    search.fit(train_df.drop(&quot;Survived&quot;, axis=1), train_df[&quot;Survived&quot;])\n\n<\/code><\/pre>\n<p>Now, the script uses a local folder 'data'. However, I would like to give an argument to this script that indicates I would like to use a remote datastore in the Azure Machine Learning Studio. How could I achieve that?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1625135942170,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":245,
        "Owner_creation_time":1586168427240,
        "Owner_last_access_time":1663943079773,
        "Owner_location":null,
        "Owner_reputation":299,
        "Owner_up_votes":44,
        "Owner_down_votes":2,
        "Owner_views":21,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68208679",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69332418,
        "Question_title":"AzureML: Engine process terminated. This is most likely due to system running out of memory. Please retry with increased memory",
        "Question_body":"<p>I am trying to run an experiment on AzureML through the notebook. I get the above error on trying to read a dataset created in previous step.<\/p>\n<p>I checked the memory usage through command - <code>df -h<\/code> and it looks ok. I checked git links with same error, but that doesn't appear to have been resolved.<\/p>\n<p>Github issues <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1143\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<p>What is going wrong here?<\/p>\n<p>Below line of code gives the error. This line had run successfully just a day ago on same workspace, using same compute.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vynQe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vynQe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Below is the screen of memory:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Mv3M4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Mv3M4.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_creation_time":1632638161787,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":513,
        "Owner_creation_time":1425952092993,
        "Owner_last_access_time":1657798143527,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":427,
        "Owner_up_votes":28,
        "Owner_down_votes":1,
        "Owner_views":77,
        "Question_last_edit_time":1632638526013,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69332418",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67065023,
        "Question_title":"Max R version of Machine Learning Server",
        "Question_body":"<p>Having used <a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/sql-server-machine-learning-services?view=sql-server-ver15\" rel=\"nofollow noreferrer\">SQL Server Machine Learning Services<\/a> and realised that it only supports R up to version 3.5.2, I am exploring options to be able to deploy models for later versions of R. The experts (or more like sales people) at Microsoft told me about <a href=\"https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/what-is-machine-learning-server\" rel=\"nofollow noreferrer\">Machine Learning Server<\/a>. However, I am suspicious that it has similar issues as:<\/p>\n<blockquote>\n<p>R support is built on a legacy of Microsoft R Server 9.x and Revolution R Enterprise products.<\/p>\n<\/blockquote>\n<p>I am pretty sure that this implies the same as above reg. the max R version (i.e. 3.5.2). Can someone confirm this please? I did many searches but could not find a definite answer.<\/p>\n<p>I know this is looking for an opinion and people will vote for closure, but I reckon containerisation is the only way forward to avoid issues like the above?<\/p>\n<p>Thanks!<\/p>\n<p>PS:<\/p>\n<p>I just installed Machine Learning Server version 9.4.7 as detailed here:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/install\/machine-learning-server-windows-install#howtoinstall\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/install\/machine-learning-server-windows-install#howtoinstall<\/a><\/p>\n<p>If I run:<\/p>\n<pre><code>R.Version()\n<\/code><\/pre>\n<p>I get:<\/p>\n<p>$version.string\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/sql-server-machine-learning-services?view=sql-server-ver15\" rel=\"nofollow noreferrer\">1<\/a> &quot;R version 3.5.2 (2018-12-20)&quot;<\/p>\n<p>I was told by Microsoft that it should be version 4.x. Maybe I am just thick. Can I upgrade to version 4.x.x and if so how please? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1618258028743,
        "Question_score":1,
        "Question_tags":"r|sql-server|azure|azure-machine-learning-service",
        "Question_view_count":58,
        "Owner_creation_time":1267440784443,
        "Owner_last_access_time":1664045779313,
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Question_last_edit_time":1618497243430,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67065023",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67609973,
        "Question_title":"Azure Machine learning python can't open file",
        "Question_body":"<p>I chose to use Python 3.8.1 Azure ML in Azure Machine learning studio, but when i run the command\n<code>!python train.py<\/code>, it uses python Anconda 3.6.9, when i downloaded python 3.8 and run the command <code>!python38 train.py<\/code> in the same dir  as before, the response was <code>python3.8: can't open file<\/code> .\nAny idea?\nAlso Python 3 in azure, is always busy, without anything running from my side.\nThank you.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1621453888223,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":171,
        "Owner_creation_time":1609359946650,
        "Owner_last_access_time":1624561357960,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67609973",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58914326,
        "Question_title":"azure custom vision model precision",
        "Question_body":"<p>Im having problems in identifying  the best way to optimize the custom vision model.<\/p>\n\n<ol>\n<li><p>In using Image classification, will labeling the same image with different label at different time effect the precision of machine learning? \n\/\/for example labeling and training image A today with the label 't-shirt', labeling and training image A tomorrow with the label 'blue'.\n\/\/We are basically trying to input one classification at a time with the same image (total of five classification, such as style and color) and wanted to know whether this way will effect the prediction precision.<\/p><\/li>\n<li><p>Will labeling larger amount of data at once when inputing the image for machine learning increase the precision of the model? (for example, will there be any difference between 50 label and 100 label for an image to learn at a time?)<\/p><\/li>\n<li><p>Is there any way to teach machine learning to identify object recognition using the result gained from the image classification, else can i teach image classification and object recognition separately with the same type of image?<\/p><\/li>\n<li><p>Will running the learning process of the machine learning longer (for example, the difference between 1hour and 10hours) always give better results?<\/p><\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1574079251813,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|microsoft-cognitive|azure-machine-learning-service",
        "Question_view_count":73,
        "Owner_creation_time":1539084602260,
        "Owner_last_access_time":1590394612383,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1574149299680,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58914326",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57679839,
        "Question_title":"Consume AZURE ML with nodejs error 400 status code",
        "Question_body":"<p>I have a problem when I try to consuming the web service, the error is: <\/p>\n\n<pre><code>The request failed with status code: 400 \n{\"error\":\n{\"code\":\"BadArgument\",\"message\":\"Invalid argument provided.\",\n\"details\":[{\"code\":\"BatchJobInputsNotSpecified\",\"message\":\"The following required input(s) were not specified with the request: input1. Please ensure all input data is specified and try again.\"}]}}\n<\/code><\/pre>\n\n<p>I don't know how to solve that, because in the code I send <code>input1<\/code>.<\/p>\n\n<p>Please help me, thanks.<\/p>\n\n<pre><code>let req = require(\"request\");\n\n    const uri = \"bla\";\n    const apiKey = \"key\";\n\n    let data = {\n        \"Inputs\": {\n            \"input1\":\n            [\n                {\n                    'IdEmpleado': \"20000\",\n                    'NivelSatisfaccion': \"0.38\",\n                    'SatisfaccionLaboral_Disc': \"Insatisfecho\",\n                    'UltimaEvaluacion': \"0.53\",\n                    'UltimaEvaluacion_Disc': \"Media\",\n                    'ProyectosRealizados': \"2\",\n                    'ProyectosRealizados_Disc': \"[2-3]\",\n                    'HorasMensuales': \"157\",\n                    'HorasMensuales_Disc': \"[150-199]\",\n                    'Antiguedad': \"3\",\n                    'Antiguedad_Disc': \"[2-4]\",\n                    'AccidentesTrabajo': \"0\",\n                    'AccidentesTrabajo_Disc': \"NO\",\n                    'Ascendido': \"0\",\n                    'Ascendido_Disc': \"NO\",\n                    'AreaTrabajo': \"Ventas\",\n                    'NivelSalarial': \"Bajo\",\n                    'Renuncia': \"1\",\n                    'Renuncia_Disc': \"SI\"\n                }\n            ],\n        },\n        \"GlobalParameters\": {}\n    }\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1566927986790,
        "Question_score":0,
        "Question_tags":"javascript|node.js|azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":119,
        "Owner_creation_time":1512611070780,
        "Owner_last_access_time":1572456249360,
        "Owner_location":"Bogot\u00e1, Colombia",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1567057335737,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57679839",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34923196,
        "Question_title":"Missing data in test data for Azure MachineforMachine Learning",
        "Question_body":"<p>I am new to Azure Machine Learning. I have created a training experiment where training data has some missing values. The logic for handling missing data and few other transformations is in Python code which works on this data.<\/p>\n\n<p>Now I want the same for test data. I have deployed the experiment as web service. So, the schema is produced for input and output data (all are Numeric fields).<\/p>\n\n<p>Two questions:\n1. It asks me to define the label for test data as well, otherwise it gives inconsistent number of columns error since label column is missing in the test data<br>\n2. I have some missing data in test data, which ideally Python script in the experiment should take care. But it gives me the following error because of schema.<\/p>\n\n<pre><code>The request failed with status code: 400\nContent-Length: 323\nContent-Type: application\/json; charset=utf-8\nServer: Microsoft-HTTPAPI\/2.0\nDate: Thu, 21 Jan 2016 11:44:49 GMT\nConnection: close\n\n{u'error': {u'message': u'Invalid argument provided.', u'code': 'BadArgument', u'details': [{u'message': u'Parsing of input vector failed.  Verify the input vector has the correct number of columns and data types.  Additional details: Value was either too large or too small for an Int32..', u'code': u'InputParseError', u'target': u'input1'}]}}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1453377464100,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":796,
        "Owner_creation_time":1372245298297,
        "Owner_last_access_time":1652905906597,
        "Owner_location":"Bellevue, WA, United States",
        "Owner_reputation":757,
        "Owner_up_votes":5,
        "Owner_down_votes":7,
        "Owner_views":125,
        "Question_last_edit_time":1454300414053,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34923196",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37462268,
        "Question_title":"Python in AzureML fail to pass dataframe without changes",
        "Question_body":"<p>when trying to pass data without doing anything in python, getting this error:<\/p>\n\n<pre><code>Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\n  File \"C:\\server\\invokepy.py\", line 175, in batch\n    rutils.RUtils.DataFrameToRFile(outlist[i], outfiles[i])\n  File \"C:\\server\\RReader\\rutils.py\", line 28, in DataFrameToRFile\n    rwriter.write_attribute_list(attributes)\n  File \"C:\\server\\RReader\\rwriter.py\", line 59, in write_attribute_list\n    self.write_object(value);\n  File \"C:\\server\\RReader\\rwriter.py\", line 121, in write_object\n    write_function(flags, value.values())\n  File \"C:\\server\\RReader\\rwriter.py\", line 104, in write_objects\n    self.write_object(value)\n  File \"C:\\server\\RReader\\rwriter.py\", line 121, in write_object\n    write_function(flags, value.values())\n  File \"C:\\server\\RReader\\rwriter.py\", line 71, in write_integers\n    self.write_integer(value)\n  File \"C:\\server\\RReader\\rwriter.py\", line 147, in write_integer\n    self.writer.WriteInt32(value)\n  File \"C:\\server\\RReader\\BinaryIO\\binarywriter.py\", line 26, in WriteInt32\n    self.WriteData(self.Int32Format, data)\n  File \"C:\\server\\RReader\\BinaryIO\\binarywriter.py\", line 14, in WriteData\n    self.stream.write(pack(format, data))\nerror: cannot convert argument to integer\n\n---------- End of error message from Python  interpreter  ----------\nStart time: UTC 05\/26\/2016 13:16:01\nEnd time: UTC 05\/26\/2016 13:16:13\n<\/code><\/pre>\n\n<p>here is the data i'm trying to pass:\n<a href=\"https:\/\/i.stack.imgur.com\/ysG36.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ysG36.png\" alt=\"the data\"><\/a><\/p>\n\n<p>here is the experiment:\n<a href=\"https:\/\/i.stack.imgur.com\/vgdSn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vgdSn.png\" alt=\"the experiment\"><\/a><\/p>\n\n<p>and the python code:\n<a href=\"https:\/\/i.stack.imgur.com\/LRSAE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LRSAE.png\" alt=\"python code\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1464269301867,
        "Question_score":3,
        "Question_tags":"python|python-2.7|pandas|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":739,
        "Owner_creation_time":1320061998253,
        "Owner_last_access_time":1656424560827,
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Question_last_edit_time":null,
        "Answer_body":"<p>after talking to Microsoft support, the problem was that the \"Execute Python Script\" module cannot return empty values.\nthis can be solved by adding a \"Clean Missing Data\" module before reading it from python:\n<a href=\"https:\/\/i.stack.imgur.com\/BzCUZ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BzCUZ.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1468139774183,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37462268",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73283498,
        "Question_title":"Surprising results of Ms Azure vs Google Colab BERT training performance, not sure how to explain",
        "Question_body":"<p>I'm not sure if it's BERT related or not, had no chance to test other models, but did it for BERT.<\/p>\n<p>So what I noticed recently that training algorithms and data that I used to work with in google colab for free, are seemed to work significantly slower in Azure ML workspace which we pay for.<\/p>\n<p>I made the comparison - same data file (classification problem, sentiment analysis of 10K reviews), totally same notebook code (copy+paste), same latest ver of ktrain lib installed on both, both must be on Python 3.8, but GPU is a bit more performant on a colab side.<\/p>\n<p>Results surprised me to say the least: google lab made its job <strong>10 times faster: 17 min vs 170 min<\/strong>, and it's reproducible. Tesla T4 (colab) is faster than K80 (azure) indeed, but not that much as per known benchmarks. So I wonder what else could matter. Is it virt. environment created in Azure ML performing so slow? If you have any idea what it could be, or what else I can check on both sides to reveal it, please share<\/p>\n<p>BTW google gives you T4 in colab for your experimentations for free, while you have to pay for slower K80 at Azure.<\/p>\n<p><strong>Google colab<\/strong>\nexecution time = 17 min\n<a href=\"https:\/\/i.stack.imgur.com\/Y6iVN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Y6iVN.png\" alt=\"enter image description here\" \/><\/a>\n<strong>Google colab hardware<\/strong>: cpu model: Intel(R) Xeon(R) CPU @ 2.20GHz, memory 13Gb, GPU:<br \/>\n<a href=\"https:\/\/i.stack.imgur.com\/3YrWq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3YrWq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Azure<\/strong>\nexecution time = 2h50m = 170min (10x of colab)\n<a href=\"https:\/\/i.stack.imgur.com\/9SPlB.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9SPlB.png\" alt=\"enter image description here\" \/><\/a>\n<strong>Azure hardware information<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/wA0Se.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wA0Se.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>K80 and T4 comparison: <a href=\"https:\/\/technical.city\/en\/video\/Tesla-K80-vs-Tesla-T4\" rel=\"nofollow noreferrer\">https:\/\/technical.city\/en\/video\/Tesla-K80-vs-Tesla-T4<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659989536940,
        "Question_score":2,
        "Question_tags":"azure|google-colaboratory|azure-machine-learning-service",
        "Question_view_count":69,
        "Owner_creation_time":1304556762350,
        "Owner_last_access_time":1664081190543,
        "Owner_location":null,
        "Owner_reputation":4550,
        "Owner_up_votes":321,
        "Owner_down_votes":19,
        "Owner_views":287,
        "Question_last_edit_time":1659989857227,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73283498",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36126897,
        "Question_title":"How to restart VM in Azure ML Notebook?",
        "Question_body":"<p>I am writing code in Jupyter Notebook in Azure ML Studio.<\/p>\n\n<p>At current moment every command causes kernel death. Even in new clear notebook I could not execute even <code>print 'hello'<\/code> - kernel died immediately.<\/p>\n\n<p>Also I could not use bash commands like <code>!ls<\/code> - It crashes kernel too.<\/p>\n\n<p>How could I restart my VM or restart session in Azure ML Studio with killing all running VM?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1458551625417,
        "Question_score":0,
        "Question_tags":"cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":488,
        "Owner_creation_time":1452426675697,
        "Owner_last_access_time":1615978476293,
        "Owner_location":null,
        "Owner_reputation":77,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":1458567186853,
        "Answer_body":"<p>I have found that if I go from notebook menu to File->Open, then I see all my notebooks, their statuses and I could shutdown them.<\/p>\n\n<p>Also I have found that some of my closed notebooks were still alive and have shut them down.<\/p>\n\n<p>After this my working notebook came back to life.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1458573398360,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36126897",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67258917,
        "Question_title":"AzureML ParallelRunStep progress information",
        "Question_body":"<p>is there a way to know the progress percentage a ParallelRunStep has already computed on a pipeline?<\/p>\n<p>As the total number of inputs is known in advance, I think it should not be hard to get this information.<\/p>\n<p>This would be a great feedback for pipelines that takes long time to finish.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1619390617157,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":23,
        "Owner_creation_time":1343828614450,
        "Owner_last_access_time":1664042984127,
        "Owner_location":"Seville, Spain",
        "Owner_reputation":359,
        "Owner_up_votes":265,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Answer from python azure sdk: <em>In Studio, if you go to the step's Metrics tab, you will be able to see a chart\/table of execution progress, including remaining items, remaining mini batches, failed items, etc.<\/em><\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18357\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18357<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1619693209260,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1619694014310,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67258917",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73209864,
        "Question_title":"Azure Synapse: Possible to create\/deploy ONNX model to dedicated sql pool from Synapse Notebook?",
        "Question_body":"<p>The examples I see of installing trained ONNX models to Synapse dedicated sql pool (for use with the PREDICT functionality) all originate from Azure Machine Learning Studio. E.g. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard<\/a><\/p>\n<p>Can this be done from a Synapse Notebook directly, never leaving the Synapse environment?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659453001323,
        "Question_score":0,
        "Question_tags":"azure|azure-synapse|azure-machine-learning-studio",
        "Question_view_count":79,
        "Owner_creation_time":1499405667427,
        "Owner_last_access_time":1663433476640,
        "Owner_location":null,
        "Owner_reputation":393,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":36,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73209864",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50355494,
        "Question_title":"How to continually migrate data from on-premises SQL Db to Azure SQL Db",
        "Question_body":"<p>As a part of <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/\" rel=\"nofollow noreferrer\">Azure Machine Learning<\/a> process, I need to <code>continually<\/code> migrate data from on-premises SQL Db to Azure SQL Db using <code>Data Management Gateway<\/code>.<\/p>\n\n<p>This Azure official article describes how to: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/team-data-science-process\/move-sql-azure-adf\" rel=\"nofollow noreferrer\">Move data from an on-premises SQL server to SQL Azure with Azure Data Factory<\/a>. But the details are a bit confusing to me. If someone to briefly describe the process, how would you do that. What are 2-3 <code>main<\/code> steps one needs to perform on <code>on-premises<\/code> and 2-3 steps on <code>Azure Cloud<\/code>? No details are needed. <strong>Note<\/strong>: The solution has to involve using <code>Data Management Gateway<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1526403046690,
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-storage|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":103,
        "Owner_creation_time":1330144099340,
        "Owner_last_access_time":1664039192277,
        "Owner_location":null,
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Question_last_edit_time":1526409433763,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50355494",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67287063,
        "Question_title":"Azure-ML-R SDK in R Studio ScriptRunConfig not recognized function error after a deprecated estimator replacement",
        "Question_body":"<p>I am trying to use Azure-ML-SDK in R Studio and used Estimator but got error stating estimator deprecated and advised to use ScriptRunConfig and when used it, it not being recognized as a function and fails to run. See the errors below. Please advise.<\/p>\n<p>Already loaded library(azuremlsdk) which should include azureml.core to recognize the ScriptRunConfig function. Is it version compatibility issue? if so, which version should i use for ScriptRunConfig and how to load specific R version in Azure ML Compute (R Studio web interface and not R Studio Desktop)<\/p>\n<p>First Error and code<\/p>\n<pre><code>est &lt;- estimator(source_directory = &quot;train-and-deploy-first-model&quot;,\n                 entry_script = &quot;accidents.R&quot;,\n                 script_params = list(&quot;--data_folder&quot; = ds$path(target_path)),\n                 compute_target = compute_target\n                 )\n<\/code><\/pre>\n<p>cran_packages, github_packages, custom_url_packages, custom_docker_image, image_registry_details, use_gpu, environment_variables, and shm_size parameters will be deprecated. Please create an environment object with them using r_environment() and pass the environment object to the estimator().'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.<\/p>\n<p>Second Code snippet trying to fix above and it's error<\/p>\n<pre><code>config &lt;- ScriptRunConfig(source_directory = &quot;.&quot;,\n                 script = &quot;accidents.R&quot;,\n                 compute_target = compute_target\n                 )\n<\/code><\/pre>\n<p>Error in ScriptRunConfig(source_directory = &quot;.&quot;, script = &quot;accidents.R&quot;,  :\ncould not find function &quot;ScriptRunConfig&quot;<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1619541027510,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service",
        "Question_view_count":159,
        "Owner_creation_time":1397564337880,
        "Owner_last_access_time":1620749682530,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67287063",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42010405,
        "Question_title":"The way to pass input for azure machine experiment from app ( for example console app )",
        "Question_body":"<p>I'm trying to do some kind of web job application that can run for period time and make prediction on azure machine learning studio. After that i want get the result of this experiment and do something with that in my console application. What is the best way to do this in azure with machine learning or maybe some similiar stuff to prediction data from data series ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1486062508683,
        "Question_score":0,
        "Question_tags":"azure|prediction|azure-machine-learning-studio",
        "Question_view_count":62,
        "Owner_creation_time":1432141466930,
        "Owner_last_access_time":1591285402750,
        "Owner_location":null,
        "Owner_reputation":327,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":78,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can try using Azure Data Factory to create a Machine Learning pipeline or use Azure ML Studio's Predictive Web Services.<\/p>\n\n<ol>\n<li><p>With Azure Data Factory\nFollow <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/data-factory-azure-ml-batch-execution-activity\" rel=\"nofollow noreferrer\">this link<\/a> for details. Azure Data Factory implementations would seem difficult at first but they do work great with Azure ML experiments. <\/p>\n\n<p>Azure Data Factory can run your ML Experiment on a schedule or one-off at a specified time (I guess you can set only for UTC Timezone right now) and monitor it through a dashboard (which is pretty cool).<\/p>\n\n<p>As an example you can look @ <a href=\"https:\/\/github.com\/Microsoft\/azure-docs\/blob\/master\/articles\/data-factory\/data-factory-azure-ml-batch-execution-activity.md\" rel=\"nofollow noreferrer\">ML Batch Execution<\/a>. I used this in one of our implementations (we do have latency issues, but trying to solve that).<\/p><\/li>\n<li><p>If you directly want to use the experiment in your console (assuming it is a web application), use create a Predictive Web service out of your ML Experiment, details <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-walkthrough-5-publish-web-service\" rel=\"nofollow noreferrer\">here<\/a><\/p><\/li>\n<\/ol>\n\n<p>I couldn't exactly understand your use case so I posted two alternatives that should help you. Hope this might lead you to a better solution\/approach.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1486537080117,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1486537417793,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42010405",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50113374,
        "Question_title":"What is a trait in Azure ML matchbox recommender?",
        "Question_body":"<p>Azure Machine Learning has an item called <code>Train Matchbox Recommender<\/code>. It can be configured with a <code>Number of traits<\/code>. Unfortunately, the documentation does not describe what such a trait is.<\/p>\n\n<p>What are traits? Is this related to <a href=\"https:\/\/en.wikipedia.org\/wiki\/Latent_variable\" rel=\"nofollow noreferrer\">latent variables<\/a>?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1525162879793,
        "Question_score":0,
        "Question_tags":"azure|recommendation-engine|azure-machine-learning-studio",
        "Question_view_count":859,
        "Owner_creation_time":1290750251813,
        "Owner_last_access_time":1663965312343,
        "Owner_location":"Nimes, France",
        "Owner_reputation":55864,
        "Owner_up_votes":1621,
        "Owner_down_votes":31,
        "Owner_views":4960,
        "Question_last_edit_time":1526046231817,
        "Answer_body":"<p><a href=\"http:\/\/apprize.info\/microsoft\/azure_1\/9.html\" rel=\"nofollow noreferrer\">This<\/a> page may have better descriptions on it.<\/p>\n\n<p>Basically, traits are the features the algorithm will learn about each user related to each item. For example, in the <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Recommender-Restaurant-ratings-2\" rel=\"nofollow noreferrer\">restaurant ratings recommender<\/a> traits could include a user's birth year, if they're a student or working professional, martial status, etc.<\/p>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1525171563377,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50113374",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71662401,
        "Question_title":"Synapse Analytics Auto ML Predict No module named 'azureml.automl'",
        "Question_body":"<p>I follow the official tutotial from microsoft: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a><\/p>\n<p>When I execute:<\/p>\n<pre><code>#Bind model within Spark session\n model = pcontext.bind_model(\n     return_types=RETURN_TYPES, \n     runtime=RUNTIME, \n     model_alias=&quot;Sales&quot;, #This alias will be used in PREDICT call to refer  this   model\n     model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI\n     aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed\n ).register()\n<\/code><\/pre>\n<p>I got : No module named 'azureml.automl'<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/g0UCX.png\" rel=\"nofollow noreferrer\">My Notebook<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1648558433353,
        "Question_score":0,
        "Question_tags":"azure-synapse|azure-machine-learning-studio|automl|azure-auto-ml",
        "Question_view_count":271,
        "Owner_creation_time":1645110475503,
        "Owner_last_access_time":1664057688837,
        "Owner_location":null,
        "Owner_reputation":15,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I solved it. In my case it works best like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/JKEmr.png\" rel=\"nofollow noreferrer\">Imports<\/a><\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#Import libraries\nfrom pyspark.sql.functions import col, pandas_udf,udf,lit\nfrom notebookutils.mssparkutils import azureML\nfrom azureml.core import Workspace, Model\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nfrom azureml.core.model import Model\nimport joblib\nimport pandas as pd\n\nws = azureML.getWorkspace(\"AzureMLService\")\nspark.conf.set(\"spark.synapse.ml.predict.enabled\",\"true\")<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ij760.png\" rel=\"nofollow noreferrer\">Predict function<\/a><\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>def forecastModel():\n    model_path = Model.get_model_path(model_name=\"modelName\", _workspace=ws)\n    modeljob = joblib.load(model_path + \"\/model.pkl\")\n\n    validation_data = spark.read.format(\"csv\") \\\n                            .option(\"header\", True) \\\n                            .option(\"inferSchema\",True) \\\n                            .option(\"sep\", \";\") \\\n                            .load(\"abfss:\/\/....csv\")\n\n    validation_data_pd = validation_data.toPandas()\n\n\n    predict = modeljob.forecast(validation_data_pd)\n\n    return predict<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1648911550930,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1648934074417,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71662401",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36485084,
        "Question_title":"Azure ML Studio: How to import images dataset?",
        "Question_body":"<p>In Azure ML studio, how to import images dataset, for image recognition algorithms. As zip file?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1460056088943,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|dataset|image-recognition|azure-machine-learning-studio",
        "Question_view_count":2420,
        "Owner_creation_time":1282073536110,
        "Owner_last_access_time":1664043684557,
        "Owner_location":null,
        "Owner_reputation":4529,
        "Owner_up_votes":458,
        "Owner_down_votes":11,
        "Owner_views":1142,
        "Question_last_edit_time":1460056872020,
        "Answer_body":"<p>You can use \"<strong>import images<\/strong>\" module in Azure ML Studio that can read images from Azure blob storage - <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Face-detection-2\" rel=\"nofollow\">here<\/a> is the sample experiment <\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1460058230133,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36485084",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48906201,
        "Question_title":"TypeError: object of type 'numpy.float64' has no len() when finding mean",
        "Question_body":"<p>I am doing a simple operations in Azure ML Studio using Python script.<\/p>\n\n<pre><code>import numpy as np\n\ndt_mean = np.mean(dt.iloc[:,0].values)\n<\/code><\/pre>\n\n<p>but it throws error<\/p>\n\n<pre><code>[Critical]     Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\n  File \"C:\\server\\invokepy.py\", line 211, in batch\n    xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\n  File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile\n    attributes = XDRBridge.DataFrameToRObject(dataframe)\n  File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject\n    if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\nTypeError: object of type 'numpy.float64' has no len()\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>This one works perfectly fine in Spyder. But it's not working in Azure ML Python script. <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1519216830073,
        "Question_score":0,
        "Question_tags":"python|mean|azure-machine-learning-studio",
        "Question_view_count":1037,
        "Owner_creation_time":1489644560420,
        "Owner_last_access_time":1646025882010,
        "Owner_location":"Planet Earth",
        "Owner_reputation":791,
        "Owner_up_votes":55,
        "Owner_down_votes":4,
        "Owner_views":253,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48906201",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33091830,
        "Question_title":"How best to convert from azure blob csv format to pandas dataframe while running notebook in azure ml",
        "Question_body":"<p>I have a number of large csv (tab delimited) data stored as azure blobs, and I want to create a pandas dataframe from these. I can do this locally as follows:<\/p>\n\n<pre><code>from azure.storage.blob import BlobService\nimport pandas as pd\nimport os.path\n\nSTORAGEACCOUNTNAME= 'account_name'\nSTORAGEACCOUNTKEY= \"key\"\nLOCALFILENAME= 'path\/to.csv'        \nCONTAINERNAME= 'container_name'\nBLOBNAME= 'bloby_data\/000000_0'\n\nblob_service = BlobService(account_name=STORAGEACCOUNTNAME, account_key=STORAGEACCOUNTKEY)\n\n# Only get a local copy if haven't already got it\nif not os.path.isfile(LOCALFILENAME):\n    blob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)\n\ndf_customer = pd.read_csv(LOCALFILENAME, sep='\\t')\n<\/code><\/pre>\n\n<p>However, when running the notebook on azure ML notebooks, I can't 'save a local copy' and then read from csv, and so I'd like to do the conversion directly (something like pd.read_azure_blob(blob_csv) or just pd.read_csv(blob_csv) would be ideal).<\/p>\n\n<p>I can get to the desired end result (pandas dataframe for blob csv data), if I first create an azure ML workspace, and then read the datasets into that, and finally using <a href=\"https:\/\/github.com\/Azure\/Azure-MachineLearning-ClientLibrary-Python\" rel=\"noreferrer\">https:\/\/github.com\/Azure\/Azure-MachineLearning-ClientLibrary-Python<\/a> to access the dataset as a pandas dataframe, but I'd prefer to just read straight from the blob storage location.<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_creation_time":1444692718393,
        "Question_score":12,
        "Question_tags":"python|azure|pandas|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":22789,
        "Owner_creation_time":1346359012420,
        "Owner_last_access_time":1529010657573,
        "Owner_location":null,
        "Owner_reputation":395,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Question_last_edit_time":1444814426277,
        "Answer_body":"<p>I think you want to use <code>get_blob_to_bytes<\/code>, <code>or get_blob_to_text<\/code>; these should output a string which you can use to create a dataframe as<\/p>\n\n<pre><code>from io import StringIO\nblobstring = blob_service.get_blob_to_text(CONTAINERNAME,BLOBNAME)\ndf = pd.read_csv(StringIO(blobstring))\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1444693139743,
        "Answer_score":17.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":1545116358717,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33091830",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61674239,
        "Question_title":"schedule Azure machine learning compute instances",
        "Question_body":"<p>I want to schedule azure machine learning compute instances so that I can stop them during off-hours like weekends, azure automation solution with runbook seems to be working with VMs in general but not with azure ML. The solution could be either a script or ML pipeline.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1588923299370,
        "Question_score":5,
        "Question_tags":"azure-machine-learning-service|azure-vm",
        "Question_view_count":711,
        "Owner_creation_time":1588923100490,
        "Owner_last_access_time":1602222687747,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1589017455823,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61674239",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32451243,
        "Question_title":"How to load images faster from Azure Blob?",
        "Question_body":"<p>I've been trying to upload some images to azure blob and then using <strong>ImageReader<\/strong> in <strong>Azure ML studio<\/strong> to read them from the blob. The problem is that ImageReader takes a lot of time to load images and I need it in real time. <br>\nI also tried making a <strong>csv<\/strong> of <strong>4 images (four rows)<\/strong> containing 800x600 pixels as columns <strong>(500,000 cols. approx)<\/strong> and tried simple <strong>Reader<\/strong>. Reader took <strong>31 mins<\/strong> to read the file from the blob.<br>\nI want to know the alternate methods of loading and reading images in Azure ML studio. If anyone know any other method or can share a helpful and relevant link.<br>\nPlease share if i can speed up ImageReader by any means.\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1441695780200,
        "Question_score":1,
        "Question_tags":"opencv|azure|azure-machine-learning-studio",
        "Question_view_count":803,
        "Owner_creation_time":1387426285030,
        "Owner_last_access_time":1659463166403,
        "Owner_location":"Lahore, Pakistan",
        "Owner_reputation":2128,
        "Owner_up_votes":128,
        "Owner_down_votes":8,
        "Owner_views":211,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Look at the Azure CDN <a href=\"http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/\" rel=\"nofollow\">http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/<\/a> , after which the blobs will get an alternative url. My blob downloads became about 4 times faster after switching.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1441739836497,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32451243",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51925635,
        "Question_title":"Issue with R version in Azure ML Studio",
        "Question_body":"<p>I need to install \"ompr.roi\" package which requires R version >= 3.4.0.<\/p>\n\n<p>But Azure ML Studio supports R version till 3.2.2. Pls refer below screenshot,<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/bAoaW.jpg\" alt=\"Error in Execute R Script\"><\/p>\n\n<p>Is there any way I can use this library in Azure ML Studio.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1534748925187,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":173,
        "Owner_creation_time":1528121402630,
        "Owner_last_access_time":1546410198623,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1534749536030,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51925635",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69534189,
        "Question_title":"Building Azure Machine Learning environment (tensorflow) from dockerfile failing",
        "Question_body":"<p>I'm trying to create a new environment based on the TF 2.4 curated environment with opencv. Support for opencv is the only difference. I modified the dockerfile to include opencv as following:<\/p>\n<pre><code> FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20211005.v1\n\n    ENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.4\n\n    # Create conda environment\n    RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\n        python=3.7 pip=20.2.4\n\n    # Prepend path to AzureML conda environment\n    ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n\n    # Install pip dependencies\n    RUN HOROVOD_WITH_TENSORFLOW=1 \\\n        pip install 'matplotlib&gt;=3.3,&lt;3.4' \\\n                    'psutil&gt;=5.8,&lt;5.9' \\\n                    'tqdm&gt;=4.59,&lt;4.60' \\\n                    'pandas&gt;=1.1,&lt;1.2' \\\n                    'scipy&gt;=1.5,&lt;1.6' \\\n                    'numpy&gt;=1.10,&lt;1.20' \\\n                    'ipykernel~=6.0' \\\n                    'azureml-core==1.34.0' \\\n                    'azureml-defaults==1.34.0' \\\n                    'azureml-mlflow==1.34.0' \\\n                    'azureml-telemetry==1.34.0' \\\n                    'tensorboard==2.4.0' \\\n                    'tensorflow-gpu==2.4.1' \\\n                    'tensorflow-datasets==4.3.0' \\\n                    'onnxruntime-gpu&gt;=1.7,&lt;1.8' \\\n                    'horovod[tensorflow-gpu]==0.21.3' \\\n                    'opencv-python'\n\n    # This is needed for mpi to locate libpython\n    ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH\n<\/code><\/pre>\n<p>However horovod is failing to build tensorflow and is showing the following error message:<\/p>\n<pre><code> ERROR: Command errored out with exit status 1:\n   command: \/azureml-envs\/tensorflow-2.4\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-pjyu9d6m\/horovod\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-pjyu9d6m\/horovod\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' bdist_wheel -d \/tmp\/pip-wheel-0t6zraqk\n       cwd: \/tmp\/pip-install-pjyu9d6m\/horovod\/\n  Complete output (233 lines):\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\/lib.linux-x86_64-3.7\n  creating build\/lib.linux-x86_64-3.7\/horovod\n  copying horovod\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/task_fn.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/launch.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/js_run.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/gloo_run.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/run_task.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  copying horovod\/runner\/mpi_run.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\n  creating build\/lib.linux-x86_64-3.7\/horovod\/_keras\n  copying horovod\/_keras\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/_keras\n  copying horovod\/_keras\/callbacks.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/_keras\n  copying horovod\/_keras\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/_keras\n  creating build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/sync_batch_norm.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/mpi_ops.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/optimizer.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/functions.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  copying horovod\/torch\/compression.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\n  creating build\/lib.linux-x86_64-3.7\/horovod\/keras\n  copying horovod\/keras\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/keras\n  copying horovod\/keras\/callbacks.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/keras\n  copying horovod\/keras\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/keras\n  creating build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/sync_batch_norm.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/mpi_ops.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/util.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/gradient_aggregation_eager.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/gradient_aggregation.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/functions.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  copying horovod\/tensorflow\/compression.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\n  copying horovod\/spark\/runner.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\n  copying horovod\/spark\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\n  copying horovod\/spark\/conf.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\n  copying horovod\/spark\/gloo_run.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\n  copying horovod\/spark\/mpi_run.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\n  creating build\/lib.linux-x86_64-3.7\/horovod\/common\n  copying horovod\/common\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/common\n  copying horovod\/common\/exceptions.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/common\n  copying horovod\/common\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/common\n  copying horovod\/common\/util.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/common\n  copying horovod\/common\/basics.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/common\n  creating build\/lib.linux-x86_64-3.7\/horovod\/mxnet\n  copying horovod\/mxnet\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/mxnet\n  copying horovod\/mxnet\/mpi_ops.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/mxnet\n  copying horovod\/mxnet\/functions.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/mxnet\n  creating build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/runner.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/ray_logger.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/utils.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  copying horovod\/ray\/driver_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/ray\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/lsf.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/streams.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/threads.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/remote.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/network.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  copying horovod\/runner\/util\/cache.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/util\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/http\n  copying horovod\/runner\/http\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/http\n  copying horovod\/runner\/http\/http_client.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/http\n  copying horovod\/runner\/http\/http_server.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/http\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\n  copying horovod\/runner\/common\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/task\n  copying horovod\/runner\/task\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/task\n  copying horovod\/runner\/task\/task_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/task\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/driver\n  copying horovod\/runner\/driver\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/driver\n  copying horovod\/runner\/driver\/driver_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/driver\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/worker.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/driver.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/registration.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/rendezvous.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/constants.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/discovery.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  copying horovod\/runner\/elastic\/settings.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/elastic\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/host_hash.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/config_parser.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/timeout.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/secret.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/tiny_shell_exec.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/env.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/codec.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/network.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/settings.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/safe_shell_exec.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  copying horovod\/runner\/common\/util\/hosts.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/util\n  creating build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/service\n  copying horovod\/runner\/common\/service\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/service\n  copying horovod\/runner\/common\/service\/driver_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/service\n  copying horovod\/runner\/common\/service\/task_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/runner\/common\/service\n  creating build\/lib.linux-x86_64-3.7\/horovod\/torch\/mpi_lib_impl\n  copying horovod\/torch\/mpi_lib_impl\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\/mpi_lib_impl\n  creating build\/lib.linux-x86_64-3.7\/horovod\/torch\/mpi_lib\n  copying horovod\/torch\/mpi_lib\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\/mpi_lib\n  creating build\/lib.linux-x86_64-3.7\/horovod\/torch\/elastic\n  copying horovod\/torch\/elastic\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\/elastic\n  copying horovod\/torch\/elastic\/state.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\/elastic\n  copying horovod\/torch\/elastic\/sampler.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/torch\/elastic\n  creating build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\/keras\n  copying horovod\/tensorflow\/keras\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\/keras\n  copying horovod\/tensorflow\/keras\/callbacks.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\/keras\n  copying horovod\/tensorflow\/keras\/elastic.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/tensorflow\/keras\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\/torch\n  copying horovod\/spark\/torch\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/torch\n  copying horovod\/spark\/torch\/remote.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/torch\n  copying horovod\/spark\/torch\/estimator.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/torch\n  copying horovod\/spark\/torch\/util.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/torch\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/remote.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/optimizer.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/estimator.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/tensorflow.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/util.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  copying horovod\/spark\/keras\/bare.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/keras\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/store.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/_namedtuple_fix.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/serialization.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/params.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/estimator.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/util.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/backend.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/constants.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  copying horovod\/spark\/common\/cache.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/common\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  copying horovod\/spark\/task\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  copying horovod\/spark\/task\/task_info.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  copying horovod\/spark\/task\/mpirun_exec_fn.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  copying horovod\/spark\/task\/gloo_exec_fn.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  copying horovod\/spark\/task\/task_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/task\n  creating build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/job_id.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/__init__.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/driver_service.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/host_discovery.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/rendezvous.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/rsh.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  copying horovod\/spark\/driver\/mpirun_rsh.py -&gt; build\/lib.linux-x86_64-3.7\/horovod\/spark\/driver\n  running build_ext\n  -- Could not find CCache. Consider installing CCache to speed up compilation.\n  -- The CXX compiler identification is GNU 7.5.0\n  -- Check for working CXX compiler: \/usr\/bin\/c++\n  -- Check for working CXX compiler: \/usr\/bin\/c++ -- works\n  -- Detecting CXX compiler ABI info\n  -- Detecting CXX compiler ABI info - done\n  -- Detecting CXX compile features\n  -- Detecting CXX compile features - done\n  -- Build architecture flags: -mf16c -mavx -mfma\n  -- Using command \/azureml-envs\/tensorflow-2.4\/bin\/python\n  -- Found MPI_CXX: \/usr\/local\/lib\/libmpi.so (found version &quot;3.1&quot;)\n  -- Found MPI: TRUE (found version &quot;3.1&quot;)\n  -- Found CUDA: \/usr\/local\/cuda (found version &quot;11.0&quot;)\n  -- Linking against static NCCL library\n  -- Found NCCL: \/usr\/include\n  -- Determining NCCL version from the header file: \/usr\/include\/nccl.h\n  -- NCCL_MAJOR_VERSION: 2\n  -- Found NCCL (include: \/usr\/include, library: \/usr\/lib\/x86_64-linux-gnu\/libnccl_static.a)\n  -- The C compiler identification is GNU 7.5.0\n  -- Check for working C compiler: \/usr\/bin\/cc\n  -- Check for working C compiler: \/usr\/bin\/cc -- works\n  -- Detecting C compiler ABI info\n  -- Detecting C compiler ABI info - done\n  -- Detecting C compile features\n  -- Detecting C compile features - done\n  -- Found MPI_C: \/usr\/local\/lib\/libmpi.so (found version &quot;3.1&quot;)\n  -- Found MPI: TRUE (found version &quot;3.1&quot;)\n  -- MPI include path: \/usr\/local\/include\n  -- MPI libraries: \/usr\/local\/lib\/libmpi.so\n  CMake Error at \/usr\/share\/cmake-3.10\/Modules\/FindPackageHandleStandardArgs.cmake:137 (message):\n    Could NOT find Tensorflow (missing: Tensorflow_LIBRARIES) (Required is at\n    least version &quot;1.15.0&quot;)\n  Call Stack (most recent call first):\n    \/usr\/share\/cmake-3.10\/Modules\/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE)\n    cmake\/Modules\/FindTensorflow.cmake:31 (find_package_handle_standard_args)\n    horovod\/tensorflow\/CMakeLists.txt:12 (find_package)\n  \n  \n  -- Configuring incomplete, errors occurred!\n  See also &quot;\/tmp\/pip-install-pjyu9d6m\/horovod\/build\/temp.linux-x86_64-3.7\/CMakeFiles\/CMakeOutput.log&quot;.\n  Traceback (most recent call last):\n    File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n    File &quot;\/tmp\/pip-install-pjyu9d6m\/horovod\/setup.py&quot;, line 188, in &lt;module&gt;\n      'horovodrun = horovod.runner.launch:run_commandline'\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/site-packages\/setuptools\/__init__.py&quot;, line 153, in setup\n      return distutils.core.setup(**attrs)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/core.py&quot;, line 148, in setup\n      dist.run_commands()\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/dist.py&quot;, line 966, in run_commands\n      self.run_command(cmd)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/dist.py&quot;, line 985, in run_command\n      cmd_obj.run()\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/site-packages\/wheel\/bdist_wheel.py&quot;, line 299, in run\n      self.run_command('build')\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/cmd.py&quot;, line 313, in run_command\n      self.distribution.run_command(command)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/dist.py&quot;, line 985, in run_command\n      cmd_obj.run()\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/command\/build.py&quot;, line 135, in run\n      self.run_command(cmd_name)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/cmd.py&quot;, line 313, in run_command\n      self.distribution.run_command(command)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/dist.py&quot;, line 985, in run_command\n      cmd_obj.run()\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/site-packages\/setuptools\/command\/build_ext.py&quot;, line 79, in run\n      _build_ext.run(self)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/distutils\/command\/build_ext.py&quot;, line 340, in run\n      self.build_extensions()\n    File &quot;\/tmp\/pip-install-pjyu9d6m\/horovod\/setup.py&quot;, line 89, in build_extensions\n      cwd=self.build_temp)\n    File &quot;\/azureml-envs\/tensorflow-2.4\/lib\/python3.7\/subprocess.py&quot;, line 363, in check_call\n      raise CalledProcessError(retcode, cmd)\n  subprocess.CalledProcessError: Command '['cmake', '\/tmp\/pip-install-pjyu9d6m\/horovod', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELWITHDEBINFO=\/tmp\/pip-install-pjyu9d6m\/horovod\/build\/lib.linux-x86_64-3.7', '-DPYTHON_EXECUTABLE:FILEPATH=\/azureml-envs\/tensorflow-2.4\/bin\/python']' returned non-zero exit status 1.\n  ----------------------------------------\n  ERROR: Failed building wheel for horovod\n<\/code><\/pre>\n<p>I'm new to Azure-ml and I'm finding the documentation a little unclear. I have also tried simply adding opencv-python to the existing curated environment by doing conda_dep.add_pip_package(&quot;opencv-python&quot;). The result is the same.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1634003102133,
        "Question_score":1,
        "Question_tags":"azure|tensorflow|opencv|azure-machine-learning-studio|horovod",
        "Question_view_count":435,
        "Owner_creation_time":1367269683453,
        "Owner_last_access_time":1635573315703,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1634028496833,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69534189",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62171724,
        "Question_title":"How can I access the Workspace object from a training script in AzureML?",
        "Question_body":"<p>I want to access the Workspace object in my <code>train.py<\/code> script, when running in an Estimator.  <\/p>\n\n<p>I currently can access the Run object, using the following code:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>run = Run.get_context()\n<\/code><\/pre>\n\n<p>But I cannot seem to get my hands on the Workspace object in my training script.  I would use this mostly to get access to the Datastores and Datasets (as I would hope to keep all data set references inside the training script, instead of passing them as input datasets)<\/p>\n\n<p>Any idea if\/how this is possible ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591183699477,
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":1148,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Sure, try this:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1591197955080,
        "Answer_score":12.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62171724",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71321757,
        "Question_title":"What are valid Azure ML Workspace connection argument options?",
        "Question_body":"<p>I want to build an Azure ML environment with two python packages that I have in Azure Devops.\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK using a personal access token:<\/p>\n<pre><code>ws.set_connection(name=&quot;ConnectionName&quot;, \n                  category= &quot;PythonFeed&quot;, \n                  target = &quot;https:\/\/pkgs.dev.azure.com\/&quot;, \n                  authType = &quot;PAT&quot;, \n                  value = PAT_TOKEN)\n<\/code><\/pre>\n<p>However, for the other I need to get the package from the git repository in Azure Devops. The documentation of the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#azureml-core-workspace-workspace-set-connection\" rel=\"nofollow noreferrer\">Python SDK<\/a> and the underlying <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspace-connections\/create\" rel=\"nofollow noreferrer\">REST API<\/a> don't give the options for the arguments, only that they need to be strings (see links).<\/p>\n<p>My question: what are the options for the following arguments:<\/p>\n<ul>\n<li>authType<\/li>\n<li>category<\/li>\n<li>valueFormat<\/li>\n<\/ul>\n<p>And what do I need to set for target argument, so that I can connect to the Azure DevOps repository with potentially different authentication?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1646219844250,
        "Question_score":0,
        "Question_tags":"python|azure-devops|azure-machine-learning-studio|azureml-python-sdk|azure-python-sdk",
        "Question_view_count":93,
        "Owner_creation_time":1646219230530,
        "Owner_last_access_time":1663852436163,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":"<p>To get the package from a Azure DevOps git repository you can change the target to the repository URL:<\/p>\n<pre><code>ws.set_connection(\n    name=&quot;ConnectionName&quot;, \n    category = &quot;PythonFeed&quot;,\n    target = &quot;https:\/\/dev.azure.com\/&lt;MY-ORG&gt;\/&lt;MY-PROJECT&gt;\/_git\/&lt;MY-REPO&gt;&quot;, \n    authType = &quot;PAT&quot;, \n    value = &lt;PAT-TOKEN&gt;)\n<\/code><\/pre>\n<p>Note here that there is no user specified in the URL (the standard &quot;clone&quot; URL in Azure DevOps also contains &quot;DevOps-Vx@&quot;).<\/p>\n<p>As for any other options for &quot;authType&quot;, &quot;category&quot; and &quot;valueFormat&quot;, I don't know.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1659435013617,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71321757",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48735257,
        "Question_title":"Azure ML studio web service serialization",
        "Question_body":"<p>I\u2019m trying to set up a web service from a Python notebook in azureml and I want it to return a dictionary of {string: float}. The floats serialize just fine, but the strings do not.<\/p>\n\n<p>This is the function I'm using:<\/p>\n\n<pre><code>def demoservice(N, Vy, My):\n    X = scaler.fit_transform([N, Vy, My])\n    res = clf.predict(X)\n    a = [ {'diam': x[0], 'radius': x[1], 'thickness': x[2]} for x in res]\n    return a\n<\/code><\/pre>\n\n<p>the call:<\/p>\n\n<pre><code>demoservice(\"140\", \"100\", \"0\")\n<\/code><\/pre>\n\n<p>correctly returns:<\/p>\n\n<pre><code>[{'diam': 16.0, 'radius': 2.0, 'thickness': 5.0}]\n<\/code><\/pre>\n\n<p>but the web call returns this json response:<\/p>\n\n<pre><code>{\"Results\":{\"output1\":{\"type\":\"table\",\"value\":{\"Values\":[[\"{\\\"type\\\": \\\"list\\\", \\\"value\\\": [{\\\"type\\\": \\\"dict\\\", \\\"value\\\": [[{\\\"type\\\": \\\"bytes\\\", \\\"value\\\": \\\"ZGlhbQ==\\\"}, {\\\"type\\\": \\\"float\\\", \\\"value\\\": \\\"16.0\\\"}], [{\\\"type\\\": \\\"bytes\\\", \\\"value\\\": \\\"cmFkaXVz\\\"}, {\\\"type\\\": \\\"float\\\", \\\"value\\\": \\\"2.0\\\"}], [{\\\"type\\\": \\\"bytes\\\", \\\"value\\\": \\\"dGhpY2tuZXNz\\\"}, {\\\"type\\\": \\\"float\\\", \\\"value\\\": \\\"5.0\\\"}]]}]}\"]]}},\"output2\":{\"type\":\"table\",\"value\":{\"Values\":[[\"data:text\/plain,Execution OK\\r\\n\",null]]}}}}\n<\/code><\/pre>\n\n<p>As you can see, in the response the dictionary's keys are not being serialized correctly. For example:<\/p>\n\n<pre><code>{\\\"type\\\": \\\"bytes\\\", \\\"value\\\": \\\"cmFkaXVz\\\"}\n<\/code><\/pre>\n\n<p>here I have <code>cmFkaXVz<\/code> instead of a readable value.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1518375728430,
        "Question_score":2,
        "Question_tags":"python|web-services|azure-machine-learning-studio",
        "Question_view_count":87,
        "Owner_creation_time":1376906609053,
        "Owner_last_access_time":1663886929643,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1518457477893,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48735257",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47668450,
        "Question_title":"How to upload .r file into azure ml studio and run it?",
        "Question_body":"<p>I have a R file and I want to run the same in azureML studio. \nAfter running the codes in Rstudio I zip the r file and import it into Azure studio's datasets.I pull the dataset and Execute R script module to the experiment and attach script bundle port to the zip file. It asks for a src path which I am not sure of. When I run, it says CONNECTION NOT FOUND. <\/p>\n\n<p>What should be done to find the connection?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1512542937367,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":288,
        "Owner_creation_time":1480265514083,
        "Owner_last_access_time":1660724770093,
        "Owner_location":null,
        "Owner_reputation":913,
        "Owner_up_votes":16,
        "Owner_down_votes":1,
        "Owner_views":318,
        "Question_last_edit_time":1512547937873,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47668450",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50987140,
        "Question_title":"Getting missing values after uploading CSV to Azure ML studio",
        "Question_body":"<p><a href=\"https:\/\/i.stack.imgur.com\/wLzX0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wLzX0.png\" alt=\"enter image description here\"><\/a>I observed that missing values are generated after uploading the CSV to Azure ML studio.<\/p>\n\n<p>I have re checked with R , Python and Excel just to confirm there are no missing values in my data. And there are none.<\/p>\n\n<p>The columns are of strings and integer, both are containing missing values after uploading my CSV into Azure ML studio<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_time":1529667611530,
        "Question_score":0,
        "Question_tags":"azure|csv|azure-machine-learning-studio",
        "Question_view_count":130,
        "Owner_creation_time":1479194627133,
        "Owner_last_access_time":1531388750387,
        "Owner_location":null,
        "Owner_reputation":2713,
        "Owner_up_votes":26,
        "Owner_down_votes":2,
        "Owner_views":358,
        "Question_last_edit_time":1529907200437,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50987140",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73460989,
        "Question_title":"azureml Submitting deployment to compute taking very long",
        "Question_body":"<p>Azureml is stuck on submitting deployment to compute for a very long time. how can I speed this up? is it because of cpu and memory or due to other reasons?<\/p>\n<pre><code>log output \n\nRunning\n2022-08-23 14:51:11+00:00 Creating Container Registry if not exists.\n2022-08-23 14:51:11+00:00 Registering the environment.\n2022-08-23 14:51:13+00:00 Use the existing image.\n2022-08-23 14:51:13+00:00 Generating deployment configuration.\n2022-08-23 14:51:24+00:00 Submitting deployment to compute..\n<\/code><\/pre>\n<p>code<\/p>\n<pre><code>#Define the deployment configuration\naciconfig = AciWebservice.deploy_configuration(\n    cpu_cores = 1,\n    memory_gb = 1,\n    dns_name_label = os.environ['ACI_DNS_NAME_LABEL']\n)\n\nenv = Environment.from_conda_specification(&quot;env&quot;, &quot;..\/Environments\/score_env.yml&quot;)\n\ninf_conf = InferenceConfig(entry_script=&quot;score.py&quot;,environment=env)\n\n#deploy successful  models as a web service \nwebservice_name = os.environ['WEB_SERVICE_NAME']\nretries = 2\nwhile retries &gt; 0:\n    try:\n        service = Model.deploy(ws, webservice_name,models_latest,inf_conf,aciconfig, overwrite=True)\n        service.wait_for_deployment(True)\n        print(&quot;Webservice updated&quot;)\n        break\n\n    except:\n        print(service.get_logs())\n        retries -= 1\n        if retries == 0:\n            raise\n\n\n    \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1661266766740,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk|azure-ml-pipelines",
        "Question_view_count":31,
        "Owner_creation_time":1635334121057,
        "Owner_last_access_time":1663856043980,
        "Owner_location":null,
        "Owner_reputation":128,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Question_last_edit_time":1661424003943,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73460989",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56666924,
        "Question_title":"Is there a Java SDK for azure machine learning service?",
        "Question_body":"<p>Is there a Java SDK for Azure Machine Learning service? If not, is there a way to create Azure ML pipelines, experiments etc from Java codebase?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1560944696657,
        "Question_score":0,
        "Question_tags":"azure|azure-java-sdk|azure-machine-learning-service",
        "Question_view_count":606,
        "Owner_creation_time":1437373119813,
        "Owner_last_access_time":1632321804710,
        "Owner_location":null,
        "Owner_reputation":132,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":29,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56666924",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71919389,
        "Question_title":"Azureml TabularDataset to_pandas_dataframe() returns InvalidEncoding error",
        "Question_body":"<p>When I run:<\/p>\n<pre><code>datasetTabular = Dataset.get_by_name(ws, &quot;&lt;Redacted&gt;&quot;)\ndatasetTabular.to_pandas_dataframe()\n<\/code><\/pre>\n<p>The following error is returned.  What can I do to get past this?<\/p>\n<pre><code>ExecutionError                            Traceback (most recent call last) File C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:101, in _try_execute(action, operation, dataset_info, **kwargs)\n    100     else:\n--&gt; 101         return action()\n    102 except Exception as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\tabular_dataset.py:169, in TabularDataset.to_pandas_dataframe.&lt;locals&gt;.&lt;lambda&gt;()\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'TabularDataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_DATASET_PROP_TIMESTAMP_FINE, None)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_loggerfactory.py:213, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    212 try:\n--&gt; 213     return func(*args, **kwargs)\n    214 except Exception as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\dataflow.py:697, in Dataflow.to_pandas_dataframe(self, extended_types, nulls_as_nan, on_error, out_of_range_datetime)\n    696 with tracer.start_as_current_span('Dataflow.to_pandas_dataframe', trace.get_current_span()) as span:\n--&gt; 697     return get_dataframe_reader().to_pandas_dataframe(self,\n    698                                                       extended_types,\n    699                                                       nulls_as_nan,\n    700                                                       on_error,\n    701                                                       out_of_range_datetime,\n    702                                                       to_dprep_span_context(span.get_context()))\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:386, in _DataFrameReader.to_pandas_dataframe(self, dataflow, extended_types, nulls_as_nan, on_error, out_of_range_datetime, span_context)\n    384     if have_pyarrow() and not extended_types and not inconsistent_schema:\n    385         # if arrow is supported, and we didn't get inconsistent schema, and extended typed were not asked for - fallback to feather\n--&gt; 386         return clex_feather_to_pandas()\n    387 except _InconsistentSchemaError as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:298, in\n_DataFrameReader.to_pandas_dataframe.&lt;locals&gt;.clex_feather_to_pandas()\n    297 activity_data = dataflow_to_execute._dataflow_to_anonymous_activity_data(dataflow_to_execute)\n--&gt; 298 dataflow._engine_api.execute_anonymous_activity(\n    299     ExecuteAnonymousActivityMessageArguments(anonymous_activity=activity_data, span_context=span_context))\n    301 try:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_aml_helper.py:38, in update_aml_env_vars.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(op_code, message, cancellation_token)\n     37     engine_api_func().update_environment_variable(changed)\n---&gt; 38 return send_message_func(op_code, message, cancellation_token)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\api.py:160, in EngineAPI.execute_anonymous_activity(self, message_args, cancellation_token)\n    158 @update_aml_env_vars(get_engine_api)\n    159 def execute_anonymous_activity(self, message_args: typedefinitions.ExecuteAnonymousActivityMessageArguments, cancellation_token: CancellationToken = None) -&gt; None:\n--&gt; 160     response = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)\n    161     return response\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\engine.py:291, in MultiThreadMessageChannel.send_message(self, op_code, message, cancellation_token)\n    290     cancel_on_error()\n--&gt; 291     raise_engine_error(response['error'])\n    292 else:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\errorhandlers.py:10, in raise_engine_error(error_response)\n      9 if 'ScriptExecution' in error_code:\n---&gt; 10     raise ExecutionError(error_response)\n     11 if 'Validation' in error_code:\n\nExecutionError:  Error Code: ScriptExecution.StreamAccess.Validation Validation Error Code: InvalidEncoding Validation Target: TextFile Failed Step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 Error Message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: Unable to translate bytes [8B] at index 1 from specified code page to Unicode.\n      Unable to translate bytes [8B] at index 1 from specified code page to Unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c\n\nDuring handling of the above exception, another exception occurred:\n\nUserErrorException                        Traceback (most recent call last) Input In [34], in &lt;module&gt;\n      1 # preview the first 3 rows of the dataset\n      2 #datasetTabular.take(3)\n----&gt; 3 datasetTabular.take(3).to_pandas_dataframe()\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\_loggerfactory.py:132, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    130 with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    131     try:\n--&gt; 132         return func(*args, **kwargs)\n    133     except Exception as e:\n    134         if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\tabular_dataset.py:169, in TabularDataset.to_pandas_dataframe(self, on_error, out_of_range_datetime)\n    158 &quot;&quot;&quot;Load all records from the dataset into a pandas DataFrame.\n    159 \n    160 :param on_error: How to handle any error values in the dataset, such as those produced by an error while    (...)\n    166 :rtype: pandas.DataFrame\n    167 &quot;&quot;&quot;\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'TabularDataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_DATASET_PROP_TIMESTAMP_FINE, None)\n    175 if fine_grain_timestamp is not None and df.empty is False:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:104, in _try_execute(action, operation, dataset_info, **kwargs)\n    102 except Exception as e:\n    103     message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n--&gt; 104     _dataprep_error_handler(e, message, is_dprep_exception)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:154, in _dataprep_error_handler(e, message, is_dprep_exception)\n    152     for item in user_exception_list:\n    153         if _contains(item, getattr(e, 'error_code', 'Unexpected')):\n--&gt; 154             raise UserErrorException(message, inner_exception=e)\n    156 raise AzureMLException(message, inner_exception=e)\n\nUserErrorException: UserErrorException:     Message: Execution failed with error message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: [REDACTED]\n      Failed due to inner exception of type: DecoderFallbackException | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c ErrorCode: ScriptExecution.StreamAccess.Validation  InnerException  Error Code: ScriptExecution.StreamAccess.Validation Validation Error Code: InvalidEncoding Validation Target: TextFile Failed Step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 Error Message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: Unable to translate bytes [8B] at index 1 from specified code page to Unicode.\n      Unable to translate bytes [8B] at index 1 from specified code page to Unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c  ErrorResponse  {\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Execution failed with error message: ScriptExecutionException was caused by StreamAccessException.\\r\\n  StreamAccessException was caused by ValidationException.\\r\\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: [REDACTED]\\r\\n      Failed due to inner exception of type: DecoderFallbackException\\r\\n| session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c ErrorCode: ScriptExecution.StreamAccess.Validation&quot;\n    } }\n\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1650339397280,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":335,
        "Owner_creation_time":1650337408350,
        "Owner_last_access_time":1653101508433,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1650489525383,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71919389",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42019977,
        "Question_title":"AzureML - Trained clustering Model cannot be connected with Web Service Output",
        "Question_body":"<p>In AzureML it is not possible to connect trained Clustering Model with web service output. <\/p>\n\n<p>Why does AzureML only allow ILearnerDotNet to be connected with Web Service Output and not IClusterDotNet? <\/p>\n\n<p>This is a serious bug which halts clustering models from deploying them as a web service.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1486111021187,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|cluster-analysis|azure-machine-learning-studio",
        "Question_view_count":192,
        "Owner_creation_time":1452608563363,
        "Owner_last_access_time":1562103924250,
        "Owner_location":null,
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":1486111807267,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42019977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45009184,
        "Question_title":"Powershell AzureML Get-AmlWorkspace",
        "Question_body":"<pre><code>Get-AmlWorkspace : One or more errors occurred.\nAt line:1 char:1\n+ Get-AmlWorkspace\n+ ~~~~~~~~~~~~~~~~\n+ CategoryInfo          : NotSpecified: (:) [Get-AmlWorkspace], \nAggregateException\n+ FullyQualifiedErrorId : \nSystem.AggregateException,AzureML.PowerShell.GetWorkspace\n<\/code><\/pre>\n\n<p>I am trying to use Powershell to connect to Azure ML studio as it looks like an easier way to manage a workspace. I've downloaded the dll file from <a href=\"https:\/\/github.com\/hning86\/azuremlps\" rel=\"nofollow noreferrer\">https:\/\/github.com\/hning86\/azuremlps<\/a> and changed my config.json file, but get the error above if I try to run any AzureML commands. I've unblocked the DLL file and imported the AzureMLPS module, and I can see the module and commands I am trying to use have been imported by doing <code>Get-Module<\/code> and <code>Get-Command<\/code><\/p>\n\n<p>For info I've not used Powershell before.<\/p>\n\n<p>Any suggestions much appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1499681034153,
        "Question_score":1,
        "Question_tags":"powershell|azure-machine-learning-studio",
        "Question_view_count":428,
        "Owner_creation_time":1397507727100,
        "Owner_last_access_time":1663075667463,
        "Owner_location":null,
        "Owner_reputation":340,
        "Owner_up_votes":60,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Have you installed Azure PowerShell Installer on your local machine?\n<strong><a href=\"https:\/\/github.com\/Azure\/azure-powershell\/releases\" rel=\"nofollow noreferrer\">Click here<\/a><\/strong> for more info.<\/p>\n\n<p>Download the latest <strong>Azure PowerShell Installer (4.3.1)<\/strong>, then install on your local machine. Then retry using Azure PowerShell module and commands.<\/p>\n\n<p>I installed mine last May, using Azure PowerShell 4.0.1, and the command Get-AmlWorkspace is working.<\/p>\n\n<pre><code># Set local folder location\nSet-Location -Path \"C:\\Insert here the location of AzureMLPS.dll\"\n\n# Unblock and import Azure Powershell Module (leverages config.json file)\nUnblock-File .\\AzureMLPS.dll\nImport-Module .\\AzureMLPS.dll\n\n# Get Azure ML Workspace info\nGet-AmlWorkspace\n<\/code><\/pre>\n\n<p>The output on my side looks like this:\n<a href=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1503389654690,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45009184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62128489,
        "Question_title":"Azure Machine Learning (preview) to Customer Insights",
        "Question_body":"<p>I am trying to integrate MS Dynamics Customer Insights (CI) with the model I have built within the new Azure Machine Learning (designer). Currently, I see there is only an integration between CI and Azure Machine Learning studio (classic). <\/p>\n\n<p>I have deployed my model behind a web service (REST) within new Azure Machine Learning however it is not getting picked up in CI. However, I am able to score\/generate predictions from the API using a Python script. <\/p>\n\n<p>Please recommend a way to integrate these two MS services or suggest an architecture where CI can pick up the results. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1591000924097,
        "Question_score":2,
        "Question_tags":"azure|microsoft-dynamics|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":107,
        "Owner_creation_time":1369068264257,
        "Owner_last_access_time":1663772456043,
        "Owner_location":"South Africa",
        "Owner_reputation":2907,
        "Owner_up_votes":68,
        "Owner_down_votes":8,
        "Owner_views":402,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62128489",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36063443,
        "Question_title":"Why is this SQLite query not letting me cast the integer and subtract?",
        "Question_body":"<p>I have multiple columns in Azure Machine Learning that each have an hour, year, day, minute, etc for a date. I need to convert this hour from UTC to EDT, and then make it a date string such as<\/p>\n\n<blockquote>\n  <p>YYYY\/MM\/DD HH:SS<\/p>\n<\/blockquote>\n\n<p>This way, I can do an inner join. I've tried using CAST, CONVERT, and other SQLite functions, but none of these combos work. Here is where I am now: <\/p>\n\n<pre><code>select *\nCAST([Col11] as int) -4 as EDTHour\n\n([Col8] || '\/' || [Col9] || '\/' || [Col10] || ' ' || EDTHour|| ':' || [Col12]) as WeatherTime from t1\n\nselect 'Time Stamp' as secondTableTime from t2\n\nSELECT *\nFROM t1\nINNER JOIN t2\nON t1.WeatherTime=t2.secondTableTime\n<\/code><\/pre>\n\n<p>However, It never lets me cast the varchar column Col11 to a integer or decimal. What am I missing? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1458224867397,
        "Question_score":0,
        "Question_tags":"sqlite|azure|timezone|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":64,
        "Owner_creation_time":1389108027810,
        "Owner_last_access_time":1580749761847,
        "Owner_location":"Texas",
        "Owner_reputation":2420,
        "Owner_up_votes":480,
        "Owner_down_votes":3,
        "Owner_views":296,
        "Question_last_edit_time":1458336187940,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36063443",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60654578,
        "Question_title":"ModelErrorResponseException: Unauthorized Azure ML authorization bug",
        "Question_body":"<p>after successfully running a training estimator and experiment in an azure ml notebook I am being given Unauthorized errors when trying to register the model. I also see an unauthorized bar pop up in the top when I look at the estimator or the models tab in the azure portal. <\/p>\n\n<p>This seems like it could be a resource group issue, but I only have one resource group. Has anyone had this issue before?<\/p>\n\n<p>successful experiment:<\/p>\n\n<pre><code>from azureml.core.experiment import Experiment\n\nscript_params = {\n#     '--num_epochs': 3,\n    '--output_dir': '.\/outputs'\n}\n\nestimator = PyTorch(source_directory=os.path.join(os.getcwd(), 'Estimator'), \n                    script_params=script_params,\n                    compute_target=compute_target,\n                    entry_script='train.py',\n                    use_gpu=True,\n                    pip_packages=['pillow==5.4.1', 'torch', 'numpy'])\n\nexperiment_name = 'pytorch-rnn-generator'\nexperiment = Experiment(ws, name=experiment_name)\n\nrun = experiment.submit(estimator)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n\n<p>model registration:<\/p>\n\n<pre><code>model = run.register_model(model_name='rnn-tv-script-gen', model_path='outputs\/')\n<\/code><\/pre>\n\n<p>The stack trace:<\/p>\n\n<pre><code>ModelErrorResponseException               Traceback (most recent call last)\n&lt;ipython-input-6-178d7ee9830a&gt; in &lt;module&gt;\n      1 from azureml.core.model import Model\n      2 \n----&gt; 3 model = run.register_model(model_name='rnn-tv-script-gen', model_path='outputs\/')\n      4 \n      5 servive = Model.deploy(ws, \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in register_model(self, model_name, model_path, tags, properties, model_framework, model_framework_version, description, datasets, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\n   1988             model_name, model_path, tags, properties, model_framework, model_framework_version,\n   1989             description=description, datasets=datasets, unpack=False, sample_input_dataset=sample_input_dataset,\n-&gt; 1990             sample_output_dataset=sample_output_dataset, resource_configuration=resource_configuration, **kwargs)\n   1991 \n   1992     def _update_dataset_lineage(self, datasets):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_run_impl\/run_history_facade.py in register_model(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\n    386                                              artifacts,\n    387                                              metadata_dict=metadata_dict,\n--&gt; 388                                              run_id=self._run_id)\n    389             asset_id = asset.id\n    390         else:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/assets_client.py in create_asset(self, model_name, artifact_values, metadata_dict, project_id, run_id, tags, properties)\n     50                    \"meta\": metadata_dict,\n     51                    \"CreatedTime\": created_time}\n---&gt; 52         return self._execute_with_workspace_arguments(self._client.asset.create, payload)\n     53 \n     54     def get_assets_by_run_id_and_name(self, run_id, name):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, *args, **kwargs)\n     69 \n     70     def _execute_with_workspace_arguments(self, func, *args, **kwargs):\n---&gt; 71         return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), *args, **kwargs)\n     72 \n     73     def _execute_with_arguments(self, func, args_list, *args, **kwargs):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n     85                 return self._call_paginated_api(func, *args_list, **kwargs)\n     86             else:\n---&gt; 87                 return self._call_api(func, *args_list, **kwargs)\n     88         except ErrorResponseException as e:\n     89             raise ServiceException(e)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n    224                 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n    225             else:\n--&gt; 226                 return self._execute_with_base_arguments(func, *args, **kwargs)\n    227 \n    228     def _call_paginated_api(self, func, *args, **kwargs):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n    277         total_retry = 0 if self.retries &lt; 0 else self.retries\n    278         return ClientBase._execute_func_internal(\n--&gt; 279             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n    280 \n    281     @classmethod\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n    292                 return func(*args, **kwargs)\n    293             except Exception as error:\n--&gt; 294                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n    295 \n    296             reset_func(*args, **kwargs)  # reset_func is expected to undo any side effects from a failed func call.\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n    341                 back_off = DEFAULT_503_BACKOFF\n    342             elif error.response.status_code &lt; 500:\n--&gt; 343                 raise error\n    344         elif not isinstance(error, RETRY_EXCEPTIONS):\n    345             raise error\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n    290         while left_retry &gt;= 0:\n    291             try:\n--&gt; 292                 return func(*args, **kwargs)\n    293             except Exception as error:\n    294                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/operations\/asset_operations.py in create(self, subscription_id, resource_group_name, workspace, asset, custom_headers, raw, **operation_config)\n     88 \n     89         if response.status_code not in [200]:\n---&gt; 90             raise models.ModelErrorResponseException(self._deserialize, response)\n     91 \n     92         deserialized = None\n\nModelErrorResponseException: Unauthorized\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1584017649797,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":194,
        "Owner_creation_time":1505519654173,
        "Owner_last_access_time":1663534361873,
        "Owner_location":null,
        "Owner_reputation":153,
        "Owner_up_votes":193,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Question_last_edit_time":1584180834097,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60654578",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64672881,
        "Question_title":"Cannot access registered dataset in AMLS pipeline",
        "Question_body":"<p>I have a service principal for my AMLS workspace that has been granted a storage blob contributor role to ADLS Gen 2. ADLS Gen 2 is behind a vnet, but using the service principal, I was able to register it as a datastore and register a csv file in ADLS Gen 2 as a dataset in my AMLS workspace. I am using azureml.core version 1.16.0<\/p>\n<p>Within my workspace, running<\/p>\n<pre><code>data = ws.datasets.get(&quot;csv data&quot;)\ndata.take(5).to_pandas_dataframe()\n<\/code><\/pre>\n<p>works with no issue. I would like to use this csv data as input into an ML pipeline run with a PythonScriptStep with inputs = [data.as_named_input('data')] after running data = ws.datasets.get(&quot;csv data&quot;). However, when I run the code<\/p>\n<pre><code>run = Run.get_context()\nrun.input_datasets['data'].to_pandas_dataframe()\n<\/code><\/pre>\n<p>in my pipeline script, it fails with an error<\/p>\n<pre><code>StreamAccessException was caused by AuthenticationException.\n'AdlsGen2-ReadHeaders' for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is\nnot authorized to perform this operation.)\n<\/code><\/pre>\n<p>Where am I going wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1604451299120,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|vnet",
        "Question_view_count":185,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1604455484397,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64672881",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50739607,
        "Question_title":"Partition by Rows equivalent in pandas (python",
        "Question_body":"<p>I am using Azure Machine Learning Studio and what to add a running total on my dataset. This includes a date column, and I want to sum all the rows (for a group) on or before the row date.<\/p>\n\n<p>In SQL Server, I would use:<\/p>\n\n<pre><code>    SELECT [t1].*,\nSUM([t1].[Amount (Settlement CCY)) \nOVER (\n  PARTITION BY [t1].[Contract Ref], [t1].[LOBCode], [t1].[Superline], [t1].[Occupation], [t1].[TransType], [t1].[SettCCY]\n  ORDER BY     [t1].[Transaction Date] ASC\n  ROWS BETWEEN UNBOUNDED PRECEDING\n       AND     CURRENT ROW\n)\nFROM [t1]\nGROUP BY [t1].[contract ref], [t1].[Transaction date], [t1].[LOBCode], [t1].[Superline], [t1].[Occupation], [t1].[TransType], [t1].[SettCCY]\n<\/code><\/pre>\n\n<p>but Azure Machine learning uses SQLite where the Over \/ Partition clauses aren't implemented.<\/p>\n\n<p>I've tried an alternative in python\/pandas:<\/p>\n\n<pre><code>dataframe1 = dataframe1.assign(cumAMTscTD=dataframe1.groupby(['ContractRef', 'Basis', 'LOBCode', 'Superline', 'Occupation', 'TransType', 'SettCCY'])['AmtSettCCY'].transform('sum')).sort_values(['ContractRef','TransDate'])\n<\/code><\/pre>\n\n<p>but this sums up everything for the group, not just the those for the dates up toe current row. I assume therefore it doesn't cover the:<\/p>\n\n<pre><code>ROWS BETWEEN UNBOUNDED PRECEDING\n   AND     CURRENT ROW\n<\/code><\/pre>\n\n<p>How would I acheive this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1528369446120,
        "Question_score":0,
        "Question_tags":"python|sql|pandas|sqlite|azure-machine-learning-studio",
        "Question_view_count":744,
        "Owner_creation_time":1392992106703,
        "Owner_last_access_time":1552468853350,
        "Owner_location":null,
        "Owner_reputation":167,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Question_last_edit_time":1528370042660,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50739607",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58203287,
        "Question_title":"Using `inference_schema.schema_decorators` with dynamic `numpy` array shape",
        "Question_body":"<p><strong>Question summary<\/strong><\/p>\n\n<p>I'm deploying a model to an Azure Container Instance, using the Azure Machine Learning Service API. Specifically, the model is a PyTorch (fastai) model classifying images of varying shapes.<\/p>\n\n<p>Microsoft provides some nice decoraters to handle input and output data schemas in the scoring script. However, I am unable to figure out, if it's possible to use the <code>NumpyParameterType<\/code> with dynamic shape for the input.<\/p>\n\n<p><strong>Scoring script<\/strong><\/p>\n\n<p>A sample of the scoring script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pickle\nimport json\nimport numpy as np\nimport time\nimport os\n\nfrom PIL import Image as PilImage\nfrom azureml.core.model import Model\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef preprocess_inference(img):\n    # Preprocessing handled here\n\ndef make_prediction(data_preprocessed):\n    # Model prediction handled here\n\ndef init():\n    global model\n\n    model_path = Model.get_model_path(model_name='my_pytorch_model',\n                                      version=1)\n\n    # Get paths\n    split_path = model_path.split('\/')\n\n    model = fastai.load_learner(path = '\/'.join(split_path[:-1]), file = split_path[-1])\n\n# How to use the schema decoraters with dynamic size?\ninput_sample = np.array(PilImage.open('src\/deployment\/test\/test_image.png'))\noutput_sample = np.array([0, None], dtype=np.object)\n\n@input_schema('raw_data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(raw_data):\n\n    try:\n\n        data_preprocessed = preprocess_inference(raw_data)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>Which only works if the image uploaded has the exact same shape as 'src\/deployment\/test\/test_image.png'. Right now my solution is to avoid the decoraters and do the data interpretation myself.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\ndef run(raw_data):\n\n    try:\n\n        img = np.array(json.loads(raw_data)['raw_data'], dtype=np.uint8)\n        img = np.expand_dims(img, axis=2)\n\n        data_preprocessed = preprocess_inference(img)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>But it would be nice to be able to use the decorators, such that endusers can benefit from the nice warning messages as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570025484313,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":971,
        "Owner_creation_time":1377156004257,
        "Owner_last_access_time":1571123387553,
        "Owner_location":null,
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58203287",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73501103,
        "Question_title":"Getting Bad request while searching run in mlflow",
        "Question_body":"<p>Training a ml model with mlflow in azure environment.<\/p>\n<pre><code>import mlflow\nfrom mlflow import MlflowClient\nfrom azureml.core import Experiment, Workspace\n\nexperiment_name = 'housing-lin-mlflow'\n\nexperiment = Experiment(ws, experiment_name)\n\nruns = mlflow.search_runs(experiment_ids=[ experiment.id ])\n\n<\/code><\/pre>\n<p>While fetching runs from search_runs getting this error :<\/p>\n<pre><code>RestException: BAD_REQUEST: For input string: &quot;5b649b3c-3b8f-497a-bb4f&quot;\n<\/code><\/pre>\n<p>MLflow version : 1.28.0\nIn Azure studio jobs have been created and successfully run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1661517215980,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|mlflow",
        "Question_view_count":56,
        "Owner_creation_time":1582101477803,
        "Owner_last_access_time":1663953873503,
        "Owner_location":"Delhi, India",
        "Owner_reputation":171,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1661625379893,
        "Answer_body":"<p>The bad request in MLFlow after successful running the job is because of not giving proper API permissions for the application.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Search for <strong>MLFLOW<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Scroll down<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/s50AL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/s50AL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Click on View API Permissions<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Under API permissions, assign the permissions according to the application running region and requirements. Checkout the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models-mlflow\" rel=\"nofollow noreferrer\">document<\/a> for further information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1661603882123,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73501103",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71185505,
        "Question_title":"XGBClassifer, when de-serialized, gives 'XGBModel' object has no attribute 'enable_categorical'",
        "Question_body":"<p>I have a serialized XGBClassifier object, trained and generated using xgboost=1.5.2.<\/p>\n<pre><code>XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n              colsample_bynode=1, colsample_bytree=0.30140958911801474,\n              eval_metric='logloss', gamma=0.1203484640861413, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_bin=368, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=42,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              single_precision_histogram=True, subsample=0.976171515775659,\n              tree_method='gpu_hist', use_label_encoder=False,\n              validate_parameters=1, verbosity=None)\n<\/code><\/pre>\n<p>I load the object using:<\/p>\n<pre><code>clf_model = joblib.load(model_path)\n<\/code><\/pre>\n<p>I want to use the object to predict on some data I am using Azure environment which also has xgboost=1.5.2. but it gives error:<\/p>\n<pre><code>File &quot;score.py&quot;, line 78, in score_execution\n[stderr]    clf_preds = clf_model.predict(clf_data_transformed)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 1284, in predict\n[stderr]    class_probs = super().predict(\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 879, in predict\n[stderr]    if self._can_use_inplace_predict():\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 811, in _can_use_inplace_predict\n[stderr]    predictor = self.get_params().get(&quot;predictor&quot;, None)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 505, in get_params\n[stderr]    params.update(cp.__class__.get_params(cp, deep))\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 502, in get_params\n[stderr]    params = super().get_params(deep)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/sklearn\/base.py&quot;, line 210, in get_params\n[stderr]    value = getattr(self, key)\n[stderr]AttributeError: 'XGBModel' object has no attribute 'enable_categorical'\n<\/code><\/pre>\n<p>We have same version in pipelines that produce\/serialize the model and in the pipeline that deserialize the model to predict on new data.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1645277798680,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":358,
        "Owner_creation_time":1443017464707,
        "Owner_last_access_time":1663923275743,
        "Owner_location":"Sweden",
        "Owner_reputation":644,
        "Owner_up_votes":33,
        "Owner_down_votes":1,
        "Owner_views":126,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Here are some possible solutions :<\/p>\n<ul>\n<li>Save the model in some other way, e.g. the JSON specified here <a href=\"https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/saving_model.html\" rel=\"nofollow noreferrer\">https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/saving_model.html<\/a><\/li>\n<li>Limit the allowed range of xgboost versions to those that are known to work with our model. This could lead to issues in the future, for example if the aging version of xgboost we require is no longer supported by newer versions of Python.<\/li>\n<li>Using <code>save_model<\/code> to save in JSON is worth a shot to try.<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1645427212643,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71185505",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59143762,
        "Question_title":"Is it supported to create an integrated notebookVM when the workspace is configured to be in a VNET?",
        "Question_body":"<p>Trying to follow doc at <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-virtual-network#use-a-machine-learning-compute\" rel=\"nofollow noreferrer\">secure your experiments<\/a> but after configuring default workspace storage for VNET access,  attempts to create integrated notebook VM fails with what looks like a storage access error.\n\ueb90\nCreate Failed: \nFailed to clone samples. Error details: Microsoft.WindowsAzure.Storage This request is not authorized to perform this operation.<\/p>\n\n<p>thanks,\njim<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1575307043767,
        "Question_score":1,
        "Question_tags":"jupyter-notebook|azure-machine-learning-service|vnet",
        "Question_view_count":36,
        "Owner_creation_time":1575306079827,
        "Owner_last_access_time":1575378386620,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1575307166703,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59143762",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57436140,
        "Question_title":"How to reuse successfully built docker images in Azure ML?",
        "Question_body":"<p>In our company I use Azure ML and I have the following issue. I specify a <em>conda_requirements.yaml<\/em> file with the PyTorch estimator class, like so (... are placeholders so that I do not have to type everything out):<\/p>\n\n<pre><code>from azureml.train.dnn import PyTorch\nest = PyTorch(source_directory=\u2019.\u2019, script_params=..., compute_target=..., entry_script=..., conda_dependencies_file_path=\u2019conda_requirements.yaml\u2019, environment_variables=..., framework_version=\u20191.1\u2019)\n<\/code><\/pre>\n\n<p>The <em>conda_requirements.yaml<\/em> (shortened version of the pip part) looks like this:<\/p>\n\n<pre><code>dependencies:\n  -  conda=4.5.11\n  -  conda-package-handling=1.3.10\n  -  python=3.6.2\n  -  cython=0.29.10\n  -  scikit-learn==0.21.2\n  -  anaconda::cloudpickle==1.2.1\n  -  anaconda::cffi==1.12.3\n  -  anaconda::mxnet=1.1.0\n  -  anaconda::psutil==5.6.3\n  -  anaconda::pip=19.1.1\n  -  anaconda::six==1.12.0\n  -  anaconda::mkl==2019.4\n  -  conda-forge::openmpi=3.1.2\n  -  conda-forge::pycparser==2.19\n  -  tensorboard==1.13.1\n  -  tensorflow==1.13.1\n  -  pip:\n        - torch==1.1.0\n        - torchvision==0.2.1\n<\/code><\/pre>\n\n<p>This successfully builds on Azure. Now in order to reuse the resulting docker image in that case, I use the <code>custom_docker_image<\/code> parameter to pass to the <\/p>\n\n<pre><code>from azureml.train.estimator import Estimator\nest = Estimator(source_directory=\u2019.\u2019, script_params=..., compute_target=..., entry_script=..., custom_docker_image=\u2019&lt;container registry name&gt;.azurecr.io\/azureml\/azureml_c3a4f...\u2019, environment_variables=...)\n<\/code><\/pre>\n\n<p>But now Azure somehow seems to rebuild the image again and when I run the experiment it cannot install torch. So it seems to only install the conda dependencies and not the pip dependencies, but actually I do not want Azure to rebuild the image. Can I solve this somehow?<\/p>\n\n<p>I attempted to somehow build a docker image from my Docker file and then add to the registry. I can do az login and according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-authentication\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-authentication<\/a> I then should also be able to do an acr login and push. This does not work. \nEven using the credentials from<\/p>\n\n<pre><code>az acr credential show \u2013name &lt;container registry name&gt;\n<\/code><\/pre>\n\n<p>and then doing a <\/p>\n\n<pre><code>docker login &lt;container registry name&gt;.azurecr.io \u2013u &lt;username from credentials above&gt; -p &lt;password from credentials above&gt;\n<\/code><\/pre>\n\n<p>does not work.\nThe error message is <em>authentication required<\/em> even though I used <\/p>\n\n<pre><code>az login\n<\/code><\/pre>\n\n<p>successfully. Would also be happy if someone could explain that to me in addition to how to reuse docker images when using Azure ML.\nThank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1565379277197,
        "Question_score":1,
        "Question_tags":"azure|docker|pip|conda|azure-machine-learning-service",
        "Question_view_count":604,
        "Owner_creation_time":1524670343370,
        "Owner_last_access_time":1663769326433,
        "Owner_location":"Z\u00fcrich, Schweiz",
        "Owner_reputation":460,
        "Owner_up_votes":668,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>AzureML should actually cache your docker image once it was created. The service will hash the base docker info and the contents of the conda.yaml file and will use that as the hash key -- unless you change any of that information, the docker should come from the ACR. <\/p>\n\n<p>As for the custom docker usage, did you set the parameter <code>user_managed=True<\/code>? Otherwise, AzureML will consider your docker to be a base image on top of which it will create the conda environment per your yaml file.<br>\nThere is an example of how to use a custom docker image in this notebook:\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4170a394edd36413edebdbab347afb0d833c94ee\/how-to-use-azureml\/training-with-deep-learning\/how-to-use-estimator\/how-to-use-estimator.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4170a394edd36413edebdbab347afb0d833c94ee\/how-to-use-azureml\/training-with-deep-learning\/how-to-use-estimator\/how-to-use-estimator.ipynb<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1565501907287,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57436140",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66838949,
        "Question_title":"onnx model in ubuntu 18.04 not running",
        "Question_body":"<p>I am trying to implement custom vision solution using C#, Azure custom vision, and ONNX Model. My API code is running perfect on windows OS, but when I am trying to run same code on Ubuntu 18.04, getting below error.<\/p>\n<p>I have download trained ONNX model from Azure ml.<\/p>\n<pre><code>Unhandled exception. System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\n ---&gt; System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\n ---&gt; System.DllNotFoundException: Unable to load shared library 'api-ms-win-core-com-l1-1-0.dll' or one of its dependencies. In order to help diagnose loading problems, consider setting the LD_DEBUG environment variable: libapi-ms-win-core-com-l1-1-0.dll: cannot open shared object file: No such file or directory\n   at WinRT.Platform.CoIncrementMTAUsage(IntPtr* cookie)\n   at WinRT.WinrtModule..ctor()\n   --- End of inner exception stack trace ---\n   at System.RuntimeTypeHandle.CreateInstance(RuntimeType type, Boolean publicOnly, Boolean wrapExceptions, Boolean&amp; canBeCached, RuntimeMethodHandleInternal&amp; ctor, Boolean&amp; hasNoDefaultCtor)\n   at System.RuntimeType.CreateInstanceDefaultCtorSlow(Boolean publicOnly, Boolean wrapExceptions, Boolean fillCache)\n   at System.RuntimeType.CreateInstanceDefaultCtor(Boolean publicOnly, Boolean skipCheckThis, Boolean fillCache, Boolean wrapExceptions)\n   at System.Activator.CreateInstance[T]()\n   at System.LazyHelper.CreateViaDefaultConstructor[T]()\n   at System.Lazy`1.CreateViaDefaultConstructor()\n   at System.Lazy`1.ViaConstructor()\n   at System.Lazy`1.ExecutionAndPublication(LazyHelper executionAndPublication, Boolean useDefaultConstructor)\n   at System.Lazy`1.CreateValue()\n   at System.Lazy`1.get_Value()\n   at WinRT.WinrtModule.get_Instance()\n   at WinRT.WinrtModule.GetActivationFactory(String runtimeClassId)\n   at WinRT.BaseActivationFactory..ctor(String typeNamespace, String typeFullName)\n   at Windows.Storage.StorageFile._IStorageFileStatics..ctor()\n   --- End of inner exception stack trace ---\n   at System.RuntimeTypeHandle.CreateInstance(RuntimeType type, Boolean publicOnly, Boolean wrapExceptions, Boolean&amp; canBeCached, RuntimeMethodHandleInternal&amp; ctor, Boolean&amp; hasNoDefaultCtor)\n   at System.RuntimeType.CreateInstanceDefaultCtorSlow(Boolean publicOnly, Boolean wrapExceptions, Boolean fillCache)\n   at System.RuntimeType.CreateInstanceDefaultCtor(Boolean publicOnly, Boolean skipCheckThis, Boolean fillCache, Boolean wrapExceptions)\n   at System.Activator.CreateInstance[T]()\n   at WinRT.WeakLazy`1.get_Value()\n   at Windows.Storage.StorageFile._IStorageFileStatics.get_Instance()\n   at Windows.Storage.StorageFile.GetFileFromPathAsync(String path)\n   at CustomVisionAPI.Controllers.HomeController.Run() in \/home\/aaa\/bbb\/CutomVision\/WebApplication1\/Controllers\/HomeController.cs:line 44\n   at System.Threading.Tasks.Task.&lt;&gt;c.&lt;ThrowAsync&gt;b__139_1(Object state)\n   at System.Threading.QueueUserWorkItemCallback.&lt;&gt;c.&lt;.cctor&gt;b__6_0(QueueUserWorkItemCallback quwi)\n   at System.Threading.ExecutionContext.RunForThreadPoolUnsafe[TState](ExecutionContext executionContext, Action`1 callback, TState&amp; state)\n   at System.Threading.QueueUserWorkItemCallback.Execute()\n   at System.Threading.ThreadPoolWorkQueue.Dispatch()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1616913128993,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|onnx|microsoft-custom-vision|onnxruntime",
        "Question_view_count":76,
        "Owner_creation_time":1614491421440,
        "Owner_last_access_time":1621836613313,
        "Owner_location":"Anand, Gujarat, India",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1616979529367,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66838949",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41845186,
        "Question_title":"Azure ML R Model Train & Score Web Service",
        "Question_body":"<p>I created the the Azure Machine Learning sample \"<a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/R-Model-Train-Score-2\" rel=\"nofollow noreferrer\">R Model Train &amp; Score<\/a>\" from the gallery and followed the tutorial.  However, when I setup, deploy the web service ( as [New] Preview) and test, I get the error:<\/p>\n\n<blockquote>\n  <p>Score Model (RPackage) : Given path to R installation not found on machine or R executable not at this location<\/p>\n<\/blockquote>\n\n<p>The classic deployment works fine.  Any ideas on how to get the [New] Preview deployment example to run as a web service?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1485327001460,
        "Question_score":1,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":131,
        "Owner_creation_time":1277872389890,
        "Owner_last_access_time":1663977781897,
        "Owner_location":"Phoenix, AZ",
        "Owner_reputation":11844,
        "Owner_up_votes":583,
        "Owner_down_votes":29,
        "Owner_views":656,
        "Question_last_edit_time":1485327448237,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41845186",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53588040,
        "Question_title":"No module named 'automl' when unpickle auto-trained model",
        "Question_body":"<p>I'm trying to reproduce 2 tutorials below using my own dataset instead of MNIST dataset.\n<a href=\"https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-auto-train-models\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-auto-train-models<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml<\/a><\/p>\n\n<p>About\n'\/notebooks\/tutorials\/03.auto-train-models.ipynb'\nthere's no problem. I've got 'model.pkl'.<\/p>\n\n<p>However, \n'\/notebooks\/tutorials\/02.deploy-models.ipynb'\nhas an error below in 'Predict test data' cell.\nI guess it's a matter of 'pickle' and 'import'.<\/p>\n\n<p>Tell me solutions, please.<\/p>\n\n<pre><code>ModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-6-11cf888b622f&gt; in &lt;module&gt;\n      2 from sklearn.externals import joblib\n      3 \n----&gt; 4 clf = joblib.load('.\/model.pkl')\n      5 # clf = joblib.load('.\/sklearn_mnist_model.pkl')\n      6 y_hat = clf.predict(X_test)\n\n~\/anaconda3_501\/lib\/python3.6\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py in load(filename, mmap_mode)\n    576                     return load_compatibility(fobj)\n    577 \n--&gt; 578                 obj = _unpickle(fobj, filename, mmap_mode)\n    579 \n    580     return obj\n\n~\/anaconda3_501\/lib\/python3.6\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py in _unpickle(fobj, filename, mmap_mode)\n    506     obj = None\n    507     try:\n--&gt; 508         obj = unpickler.load()\n    509         if unpickler.compat_mode:\n    510             warnings.warn(\"The file '%s' has been generated with a \"\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in load(self)\n   1048                     raise EOFError\n   1049                 assert isinstance(key, bytes_types)\n-&gt; 1050                 dispatch[key[0]](self)\n   1051         except _Stop as stopinst:\n   1052             return stopinst.value\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in load_global(self)\n   1336         module = self.readline()[:-1].decode(\"utf-8\")\n   1337         name = self.readline()[:-1].decode(\"utf-8\")\n-&gt; 1338         klass = self.find_class(module, name)\n   1339         self.append(klass)\n   1340     dispatch[GLOBAL[0]] = load_global\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in find_class(self, module, name)\n   1386             elif module in _compat_pickle.IMPORT_MAPPING:\n   1387                 module = _compat_pickle.IMPORT_MAPPING[module]\n-&gt; 1388         __import__(module, level=0)\n   1389         if self.proto &gt;= 4:\n   1390             return _getattribute(sys.modules[module], name)[0]\n\nModuleNotFoundError: No module named 'automl'\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1543815453630,
        "Question_score":5,
        "Question_tags":"python|pickle|azure-machine-learning-studio|automl",
        "Question_view_count":4788,
        "Owner_creation_time":1543814686770,
        "Owner_last_access_time":1544423620710,
        "Owner_location":null,
        "Owner_reputation":53,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":null,
        "Answer_body":"<p>you have to include azureml-train-automl package. and you have to do this:<\/p>\n\n<p>import azureml.train.automl<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1543816325650,
        "Answer_score":5.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53588040",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32854507,
        "Question_title":"TfidfVectorizer and sublinear_tf scaling for feature extraction in Azure ML",
        "Question_body":"<p>I am working on a ML document classification problem. Does anyone know how to n-gram Tfidf feature extraction and sublinear_tf scaling in Azure ML.<\/p>\n\n<p>In the past I did this inSci-Kit learn using the TfidfVectorizer (see example below) but the problem is that in AzureML I cannot explicitly define my own methods or classes using a python module and would rather not upload zipped code. <\/p>\n\n<p>I am a python person but am open to using R if there is an equivalent. There is  an R sample in the marketplace but it is dependent on unigrams.<\/p>\n\n<pre><code>TfidfVectorizer(max_df=.67,min_df=.015,lowercase=False ,sublinear_tf=True,norm='l2',tokenizer=AbstractTokenizer())\n<\/code><\/pre>\n\n<p>Best,\n-Ari<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1443564159823,
        "Question_score":1,
        "Question_tags":"python|r|azure|azure-machine-learning-studio",
        "Question_view_count":1487,
        "Owner_creation_time":1374162232293,
        "Owner_last_access_time":1641974793103,
        "Owner_location":null,
        "Owner_reputation":523,
        "Owner_up_votes":23,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32854507",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63771896,
        "Question_title":"Can SAC be used instead PPO in Cartpole example?",
        "Question_body":"<p>I'm studying AzureML RL with example codes.<\/p>\n<p>I could run cartpole example (cartpole_ci.ipynb) which trains\nthe PPO model on compute instance.<\/p>\n<p>I tried SAC instead of PPO by changing training_algorithm = &quot;PPO&quot; to training_algorithm = &quot;SAC&quot;\nbut it failed with the message below.<\/p>\n<blockquote>\n<p>ray.rllib.utils.error.UnsupportedSpaceException: Action space Discrete(2) is not supported for SAC.<\/p>\n<\/blockquote>\n<p>Has someone tried SAC algorithm on AzureML RL and did it work?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1599456813160,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":494,
        "Owner_creation_time":1599456092003,
        "Owner_last_access_time":1663744052310,
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63771896",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57910952,
        "Question_title":"Distributed Training with Tensorflow in AMLS",
        "Question_body":"<p>using a TensorFlow estimator in Azure ML Service with the following config. <\/p>\n\n<pre><code>from azureml.core.runconfig import TensorflowConfiguration\ndistributed_training = TensorflowConfiguration()\ndistributed_training.worker_count = 3\nest = TensorFlow(source_directory=script_folder,\n             script_params=script_params,\n             compute_target=compute_target,\n             node_count=4,\n             distributed_training=distributed_training,\n             use_gpu=True,\n             entry_script=train_script)\nrun = exp.submit(est)\n<\/code><\/pre>\n\n<p>It seems like in the run with this configuration, individual workers come up with their own instances of trained models and try to register the model multiple times. Is Distributed Training something I need to deal with in the Tensorflow training script?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1568305461657,
        "Question_score":1,
        "Question_tags":"distributed-computing|tensorflow-estimator|azure-machine-learning-service",
        "Question_view_count":63,
        "Owner_creation_time":1568232368920,
        "Owner_last_access_time":1603476601123,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57910952",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50334563,
        "Question_title":"Deployment of an Azure ML Experiment as a Web Service through Azure Machine Learning Studio",
        "Question_body":"<p>I used Machine learning tutorial: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-experiment\" rel=\"nofollow noreferrer\">Create your first data science experiment in Azure Machine Learning Studio<\/a> to create an <code>Experiment<\/code> and then converted it to a <code>predictive experiment<\/code>. Now I'm trying to deploy it as a Web Service by following this article that was referenced in the above article: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/publish-a-machine-learning-web-service#deploy-it-as-a-web-service\" rel=\"nofollow noreferrer\">Deploy it as a web service<\/a>. But when I click on <code>Run<\/code> and then on <code>Deploy Web Service<\/code>, I don't see the <code>Price Plan<\/code> dropdown and <code>Plan Name<\/code> input box etc as mentioned in the section <code>Machine Learning Web Service portal Deploy Experiment Page<\/code> of the second article above. After I clicked on Deploy Web Service link in ML studio, I got the page shown below.<strong>Question<\/strong>: What I may be doing wrong?<\/p>\n\n<p>Note: You can click on the picture to get a larger view.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1526313605237,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":330,
        "Owner_creation_time":1330144099340,
        "Owner_last_access_time":1664039192277,
        "Owner_location":null,
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I think it depends on what workspace you're in. If you're in the free one then you get the screen that you already get, but if you create a workspace in the Azure portal and use that one, then you will get a screen like below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/drRpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/drRpa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>To create a new workspace, in the Azure Portal, create a new \"Machine Learning Studio Workspace\" and when you go to Azure ML Studio select the new workspace from the top right.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1526322971967,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50334563",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63336351,
        "Question_title":"cannot import name 'RollingOriginValidator'",
        "Question_body":"<p>I'm writing a scoring step with Azure Machine Learning pipeline.\nThis is the score code:<\/p>\n<pre><code>import os\nimport pickle\nimport pandas as pd\nfrom azureml.core.model import Model\nimport argparse\nfrom azureml.core.run import Run, _OfflineRun\nfrom azureml.automl.core.shared.rolling_origin_validator import RollingOriginValidator\n\n# Called when the deployed service starts\ndef init():\n    global model\n    \n    # Get the path where the deployed model can be found. \n    run = Run.get_context()\n    model_path = Model.get_model_path('best_model_data')\n    print(model_path)\n    with open(model_path,&quot;rb&quot;) as f:\n       model = pickle.load(f)\n       print(&quot;loaded&quot;)\n# Handle requests to the service\ndef run(data):\n    try:\n        # Pick out the text property of the JSON request.\n        # This expects a request in the form of {&quot;text&quot;: &quot;some text to score for sentiment&quot;}\n        prediction = predict(data)\n        #Return prediction        \n        return prediction\n    except Exception as e:\n        error = str(e)\n        return error\n\n# Predict sentiment using the model\ndef predict(data, include_neutral=True):\n    # Tokenize text\n    test_data_features=data.drop('ProposalId', 1).drop('CombinedTactics',1)\n    test_data_combos=data['CombinedTactics']\n    print(&quot;data&quot;)\n    # Predict\n    score = model.predict_proba(test_data_features)\n    print(&quot;predicted&quot;)\n    df=pd.DataFrame({'score':score[:, 1],'CombinedTactics':test_data_combos})\n    return df\n<\/code><\/pre>\n<p>This is the pipeline step definition:<\/p>\n<pre><code>parallel_run_config = ParallelRunConfig(\n    environment=myenv,\n    entry_script=&quot;use_model.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    output_action=&quot;append_row&quot;,\n    mini_batch_size=&quot;20&quot;,\n    error_threshold=1,\n    compute_target=compute_target,\n    process_count_per_node=2,\n    node_count=2\n)\nparallel_step_name = &quot;batchscoring-&quot; + datetime.now().strftime(&quot;%Y%m%d%H%M&quot;)\nbatch_score_step = ParallelRunStep(\n    name=parallel_step_name,\n    inputs=[test_data.as_named_input(&quot;test_data&quot;)],\n    output=output_dir,\n    parallel_run_config=parallel_run_config,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>However, I met below error:<\/p>\n<p>File &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/ucmopp-ws\/azureml\/70828787-7515-4db4-b448-a5a4b6c0c8ff\/mounts\/workspaceblobstore\/azureml\/70828787-7515-4db4-b448-a5a4b6c0c8ff\/driver\/azureml_user\/parallel_run\/score_module.py&quot;, line 139, in call_init\nself.init()\nFile &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/ucmopp-ws\/azureml\/70828787-7515-4db4-b448-a5a4b6c0c8ff\/mounts\/workspaceblobstore\/azureml\/70828787-7515-4db4-b448-a5a4b6c0c8ff\/use_model.py&quot;, line 17, in init\nmodel = pickle.load(f)\nFile &quot;\/azureml-envs\/azureml_7e62c7905267a978aa40f8554487e9b9\/lib\/python3.6\/site-packages\/azureml\/automl\/runtime\/featurization\/<strong>init<\/strong>.py&quot;, line 8, in \nfrom .data_transformer import DataTransformer, TransformerAndMapper\nFile &quot;\/azureml-envs\/azureml_7e62c7905267a978aa40f8554487e9b9\/lib\/python3.6\/site-packages\/azureml\/automl\/runtime\/featurization\/data_transformer.py&quot;, line 54, in \nfrom ..featurizer.transformer import (AutoMLTransformer, CategoricalFeaturizers, DateTimeFeaturesTransformer,\nFile &quot;\/azureml-envs\/azureml_7e62c7905267a978aa40f8554487e9b9\/lib\/python3.6\/site-packages\/azureml\/automl\/runtime\/featurizer\/transformer\/<strong>init<\/strong>.py&quot;, line 28, in \nfrom .timeseries import TimeSeriesTransformer, TimeSeriesPipelineType, NumericalizeTransformer, <br \/>\nFile &quot;\/azureml-envs\/azureml_7e62c7905267a978aa40f8554487e9b9\/lib\/python3.6\/site-packages\/azureml\/automl\/runtime\/featurizer\/transformer\/timeseries\/<strong>init<\/strong>.py&quot;, line 65, in \nfrom azureml.automl.core.shared.rolling_origin_validator import RollingOriginValidator\nImportError: cannot import name 'RollingOriginValidator'<\/p>\n<p>Does anyone have any idea about this error?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1597046743060,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":311,
        "Owner_creation_time":1513841518107,
        "Owner_last_access_time":1663924369323,
        "Owner_location":"China",
        "Owner_reputation":71,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63336351",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40577607,
        "Question_title":"AzureML: How to Keep leading zeros in dataset (.CSV)",
        "Question_body":"<p>My data: <code>0671001795<\/code><\/p>\n\n<p>Dataset in Microsoft AzureML: <a href=\"https:\/\/i.stack.imgur.com\/gfCtu.png\" rel=\"nofollow noreferrer\">https:\/\/i.stack.imgur.com\/gfCtu.png<\/a><\/p>\n\n<p>How to Keep leading zeros? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1479063490300,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":162,
        "Owner_creation_time":1425465175007,
        "Owner_last_access_time":1492875567547,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Keeping leading zeros when the data column is in integer format is not possible. Here's an alternative way of keeping the leading zeros. (The String data type is used instead of int)<\/p>\n\n<ol>\n<li>Add an special character('\/' etc) before the number <\/li>\n<li>Pipe the contentthrough 'Preprocess Text' module.<\/li>\n<li>Make sure only to tick \"Remove Special Characters\" option.<\/li>\n<li>Output would be in a string with your desired format.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/H0IBg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/H0IBg.png\" alt=\"Remove Special Characters option\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ML1YM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ML1YM.png\" alt=\"Output as a string\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1479205502147,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40577607",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65212177,
        "Question_title":"MS Azure Automated ML - Output JSON being sent as text",
        "Question_body":"<p>I have started using Azure ML Studio and have come across an issue with the Automated ML model. I create an AutoML run and get a decent precision. I deploy the model and get an endpoint using the out-of-the-box deploy button. I use postman to test the endpoint and get a response. But the response is in text format.<\/p>\n<p>What i'm getting:<\/p>\n<pre><code>&quot;{\\&quot;result\\&quot;: [\\&quot;Prediction Label X\\&quot;]}&quot;\nWhat i'm expecting:\n{&quot;result&quot;:[&quot;Prediction Label X&quot;]}\n<\/code><\/pre>\n<p>Postman has Accept and Content-Type both set to application\/json.<\/p>\n<p>Of course i could clean this text response up and parse it as JSON, but i'd rather get it directly from Azure in the correct format.<\/p>\n<p>There doesnt appear to be anywhere in the ML Studio to modify the code or response format and i'm new to the Azure Studio.<\/p>\n<p>Any thoughts?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1607498019207,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":70,
        "Owner_creation_time":1475293226350,
        "Owner_last_access_time":1638192617070,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1607522785970,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65212177",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45351020,
        "Question_title":"how to add the column names to the input dataset using R script in Machine Learning model",
        "Question_body":"<p>I am trying to add the column names to the input dataset using below R script.<\/p>\n\n<pre><code>dataset1 &lt;- maml.mapInputPort(1)#class: data.frame\n# Sample operation\ncols &lt;- c(\"age\",\n    \"workclass\",\n    \"fnlwgt\",\n    \"education\",\n    \"education-num\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"capital-gain\",\n    \"capital-loss\",\n    \"hours-per-week\",\n    \"native-country\",\n    \"income\")\n colnames(data.frame) &lt;- cols\n data.set = dataset1;\n maml.mapOutputPort(\"data.set\");\n<\/code><\/pre>\n\n<p>But I am getting the error like below figure.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Can you please tell me how to add the column names to the input dataset using R script in Machine Learning model?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1501158990353,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_time":1445426012267,
        "Owner_last_access_time":1662528284260,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":4594,
        "Owner_up_votes":240,
        "Owner_down_votes":22,
        "Owner_views":1089,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45351020",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73760407,
        "Question_title":"Unable to connect Azure DevOps and Azure ML",
        "Question_body":"<p>I have created an automated Service Principal from the service requests on Azure Devops with sufficient permissions. Now, when I am trying to create an artifact which is an ML model (registered) it is not auto populating the registered models and resulting in an error.<\/p>\n<p>I am using a free trial Azure account and attempting to implement CI CD for ML. I turned my firewall off and attempted as well but still the issue persists.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/imvGo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/imvGo.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663480318187,
        "Question_score":0,
        "Question_tags":"azure|azure-devops|azure-machine-learning-service",
        "Question_view_count":40,
        "Owner_creation_time":1501747110080,
        "Owner_last_access_time":1664026893237,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73760407",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64653569,
        "Question_title":"Concurrent AzureML REST requests fail with Too many requests for service (overloaded)",
        "Question_body":"<p>I have deployed my model to a production Azure Kubernetes Service with 6 nodes.<\/p>\n<p>Sequential inference requests get the expected response from score.py.<\/p>\n<p>When I more than one concurrent async inference requests all the requests except for the first return 503 <code>Too many requests for service {my service name} (overloaded)<\/code>.<\/p>\n<p>I built my service and deployed my model based on the example @ <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/production-deploy-to-aks\/production-deploy-to-aks.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/production-deploy-to-aks\/production-deploy-to-aks.ipynb<\/a>.<\/p>\n<p>I am sending requests as large as 4mb.  It seems to work when I send trivially small requests.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1604352348667,
        "Question_score":2,
        "Question_tags":"azure-aks|azure-machine-learning-service",
        "Question_view_count":457,
        "Owner_creation_time":1293587540030,
        "Owner_last_access_time":1663968009273,
        "Owner_location":"Boston, MA",
        "Owner_reputation":722,
        "Owner_up_votes":84,
        "Owner_down_votes":2,
        "Owner_views":41,
        "Question_last_edit_time":1604499310543,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64653569",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66932214,
        "Question_title":"why can't I see Train Model results in Azure ML Designer?",
        "Question_body":"<p>I created data from 1000 sessions of a board game simulator I ran. I'm trying to figure out what the winning strategies are and tracked several features in the data.<\/p>\n<p>I loaded the result in a Azure Machine Learning diagram and connected the data set to a model that uses linear regression.<\/p>\n<p>I click the &quot;Train Model&quot; and go to &quot;View Output&quot;. After clicking through the ensuing links, I seem to be able to locate 9 files. I don't see anything that looks like, &quot;column 9 is best predictor of column 1&quot; or something like that.<\/p>\n<p>Instead I see an iLearner file with a lot of binary I can't read. I see a schema file. There's also a lot of meta files about what version of conda ran it and data types and stuff.<\/p>\n<p>How do I see which features best indicated the label I indicated?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wO0eW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wO0eW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>EDIT:<\/strong><\/p>\n<p>As suggested, I added score model and evaluate model.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/emFsG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/emFsG.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I did see some error metrics in the evaluate results -&gt; visualize.<\/p>\n<p>Train model had a view output and a view log, but no visualize for me. When I went to &quot;view output&quot; there were a lot of files like convert_to_dataset.yaml and boosted_decision_tree_regression.yaml. Also there was a directory there called trained model which had files with names like data_type.json and score.py. It seemed like it was all meta data and nothing like, &quot;Column 1 best predicted X ...&quot;.<\/p>\n<p>I am still not seeing anything that indicates what best predicts the outcome.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/knkUR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/knkUR.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Z8E6y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Z8E6y.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1617459748413,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|machine-learning-model",
        "Question_view_count":354,
        "Owner_creation_time":1304399536083,
        "Owner_last_access_time":1663946253027,
        "Owner_location":"Raleigh, NC",
        "Owner_reputation":2032,
        "Owner_up_votes":996,
        "Owner_down_votes":3,
        "Owner_views":515,
        "Question_last_edit_time":1618582754150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66932214",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62180798,
        "Question_title":"How to increase number of tested images in MS Azure Custom Vision?",
        "Question_body":"<p>I've created a project in Azure Custom Vision (Object Detection, General Compact, Tier S0). I uploaded about 70 images, 35 images per tag then started training my model.<\/p>\n\n<p>Checked tags in the Iterations screen after training (Quick Training) was done. For my surprise, only 7 images were tested per tag.<\/p>\n\n<p>Tried to run Advanced Training for 1 hour. Nothing has changed. Only 7 images per tag were tested.<\/p>\n\n<p>Am I doing something wrong?<\/p>\n\n<p>Is there a way to use all images for object detection training so it can give me a better accuracy?<\/p>\n\n<p>Thanks,\n+ftex<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591211290130,
        "Question_score":0,
        "Question_tags":"azure|microsoft-custom-vision|azure-machine-learning-service|azure-ai",
        "Question_view_count":159,
        "Owner_creation_time":1588263508697,
        "Owner_last_access_time":1663873679483,
        "Owner_location":null,
        "Owner_reputation":15,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>What you are seeing in the test interface after the training is only a part of the total images because these metrics are calculated using k-fold cross validation.<\/p>\n<p>You are not doing something wrong. It would not be logic to test all the images because it would mean testing with your training images.<\/p>\n<p>To have a better accuracy, there's no magic: add more images, relevant to your use-case<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/getting-started-build-a-classifier#evaluate-the-classifier?WT.mc_id=AI-MVP-5003365\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/getting-started-build-a-classifier#evaluate-the-classifier<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1591541807697,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1600465129973,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62180798",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46902487,
        "Question_title":"Installation of Azure Machine Learning Workbench fails on Windows 10",
        "Question_body":"<p>I tried to install the azure machine learning workbench from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/quickstart-installation\" rel=\"nofollow noreferrer\">here<\/a>. Once I double click on the downloaded MSI file, it shows the first screen about licensing terms. Once I click on Continue, it shows dependencies. When I click Install, it starts installation. It downloads Miniconda with Python 3.5.2. While trying to install asn1crypto 0.23.0, it suddenly stops and displays 'Installation fails'. I tried running the MSI file with log option but no error is reported in the log.<\/p>\n\n<p>Here are my machine details:\nWindows 10\nVersion 1709 (OS Build 17017.1000)<\/p>\n\n<p>How can I troubleshoot this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1508820867387,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":497,
        "Owner_creation_time":1313042504323,
        "Owner_last_access_time":1663957327947,
        "Owner_location":null,
        "Owner_reputation":2727,
        "Owner_up_votes":45,
        "Owner_down_votes":1,
        "Owner_views":227,
        "Question_last_edit_time":1511310720170,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46902487",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40253448,
        "Question_title":"How Can I use gensim package in Azure ML?",
        "Question_body":"<p>I am using text analysis with Azure ML. So in my python script I want to create a bag of word model and then calculate TFIDF of each words. For that I am using gensim model, It's not working on Azure ML. So is there any options for me? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1477453917853,
        "Question_score":1,
        "Question_tags":"machine-learning|text-analysis|azure-machine-learning-studio",
        "Question_view_count":1024,
        "Owner_creation_time":1455217250737,
        "Owner_last_access_time":1663917835703,
        "Owner_location":"Auckland, New Zealand",
        "Owner_reputation":3811,
        "Owner_up_votes":118,
        "Owner_down_votes":13,
        "Owner_views":703,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40253448",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32612311,
        "Question_title":"Publish azure machine learning service with feature hashing",
        "Question_body":"<p>I have created an experiment in azure machine learning studio, this experiment is multi-class classification problem using multi-class neural network algorithm, I have also add 'feature hashing' module to transform a stream of English text into a set of features represented as integers. I have successfully run the experiment but when i publish it as web service endpoint i got message \"Reduce the total number of input and output columns to less than 1000 and try publishing again.\"\nI understood after some research that feature hashing convert text into thousands of feature but the problem is how i publish it as web service? and i don't want to remove 'feature hashing' module.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1442415823127,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":405,
        "Owner_creation_time":1422680560157,
        "Owner_last_access_time":1544934963473,
        "Owner_location":"Ahmedabad, Gujarat, India",
        "Owner_reputation":410,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It sounds like you are trying to output all those thousands of columns as an output. What you really only need is the scored probability or the scored label. To solve this, just drop all the feature hashed columns from the score model module. To do this add in a project columns module, and tell it to start with \"no columns\" then \"include\" by \"column names\", and just add predicted column (scored probability\/scored label). <\/p>\n\n<p>Then hook up the output of that project columns module to your web service output module. Your web service should now be returning only 1-3 columns rather than thousands.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1442447100743,
        "Answer_score":2.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32612311",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65362041,
        "Question_title":"Pick up Results From ML Studio Pipeline in Data Factory Pipeline",
        "Question_body":"<p>We currently have a Data Factory pipeline that is able to call one of our ML Studio Pipelines successfully.  After the ML Studio Pipeline completed, we wanted Azure Data Factory to pick up the results of the ML Studio Pipeline and store the results in SQL Server.<\/p>\n<p>We found the PipelineData class stores the results in a folder in blob based on the child run id, which makes it hard for Data factory to pick up the results.  We then discovered OutputFileDatasetConfig which allows ML Studio to save the results to a static location for Data Factory.  This worked great for Data Factory except OutputFileDatasetConfig doesn't always work :( since it's experimental class.  It took us a while to figure this out and we even created a stackoverflow question for this, which we resolved, and can be found here:  <a href=\"https:\/\/stackoverflow.com\/questions\/65240603\/azure-ml-studio-ml-pipeline-exception-no-temp-file-found\/65350106#65350106\">Azure ML Studio ML Pipeline - Exception: No temp file found<\/a><\/p>\n<p>We returned to using PipelineData class which stores the results in a folder in blob based on the child run id, but we can't figure out how to get Data factory to find the blob based on the child run id of the ML Studio Pipeline it just ran.<\/p>\n<p><strong>So my question is, how do you get Data Factory to pick up the results of a ML Studio Pipeline which was triggered from a Data Factory Pipeline???<\/strong><\/p>\n<p>Here is a simple visual of the Data Factory pipeline we're trying to build.<\/p>\n<pre><code>Step 1: Store Data in azure file store --&gt;\nStep 2: Run ML Studio scoring Pipeline --&gt;\nStep 3: Copy Results to SQL Server\n<\/code><\/pre>\n<p>Step 3 is the step we can't figure out.  Any help would be greatly appreciated.  Thanks and happy coding!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1608315418553,
        "Question_score":1,
        "Question_tags":"azure-data-factory|azure-data-factory-2|azure-machine-learning-service|ml-studio|azureml-python-sdk",
        "Question_view_count":281,
        "Owner_creation_time":1528603052363,
        "Owner_last_access_time":1663971435213,
        "Owner_location":null,
        "Owner_reputation":247,
        "Owner_up_votes":637,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65362041",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70923438,
        "Question_title":"Azure ML Studio: Create DATASET via REST API",
        "Question_body":"<p>Please tell me how to create a Dataset via REST API.<\/p>\n<p>There is a way to <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/datastores\" rel=\"nofollow noreferrer\">create a Datastore<\/a>, but I can't find a Dataset.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1643619959523,
        "Question_score":1,
        "Question_tags":"azure|rest|dataset|azure-machine-learning-service",
        "Question_view_count":126,
        "Owner_creation_time":1365773542310,
        "Owner_last_access_time":1663778656053,
        "Owner_location":null,
        "Owner_reputation":131,
        "Owner_up_votes":123,
        "Owner_down_votes":1,
        "Owner_views":32,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70923438",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48879595,
        "Question_title":"ImportError: No module named cassandra in Azure Machine Learning Studio",
        "Question_body":"<p>I am trying to install python package cassandra driver in Azure Machine Learning studio. I am following this answer from <a href=\"https:\/\/stackoverflow.com\/questions\/44371692\/install-python-packages-in-azure-ml\">here<\/a>. Unfortunately i don't see any wheel file for cassandra-driver <a href=\"https:\/\/pypi.python.org\/pypi\/cassandra-driver\/\" rel=\"nofollow noreferrer\">https:\/\/pypi.python.org\/pypi\/cassandra-driver\/<\/a> so i downloaded the .tar file and converted to zip.<\/p>\n<p>I included this .zip file as dataset and connected to python script<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/omsO9.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/omsO9.jpg\" alt=\"jpg1\" \/><\/a><\/p>\n<p>But when i run it, it says No module named cassandra\n<a href=\"https:\/\/i.stack.imgur.com\/4DKTB.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4DKTB.jpg\" alt=\"jpg2\" \/><\/a><\/p>\n<p>Does this work only with wheel file? Any solution is much appreciated.<\/p>\n<p>I am using Python Version :  Anoconda 4.0\/Python 3.5<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1519110374087,
        "Question_score":1,
        "Question_tags":"python|python-3.x|azure|cassandra|azure-machine-learning-studio",
        "Question_view_count":500,
        "Owner_creation_time":1489644560420,
        "Owner_last_access_time":1646025882010,
        "Owner_location":"Planet Earth",
        "Owner_reputation":791,
        "Owner_up_votes":55,
        "Owner_down_votes":4,
        "Owner_views":253,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>I got it working. Changed the folder inside .zip file to <code>\"cassandra\"<\/code> (just like cassandra package). <\/p>\n\n<p>And in the Python script, i added <\/p>\n\n<pre><code>from cassandra import *\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1519124227917,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48879595",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67258465,
        "Question_title":"AzureML ParallelRunStep runs only on one node",
        "Question_body":"<p>I have an inference pipeline with some PythonScriptStep with a ParallelRunStep in the middle. Everything works fine except for the fact that all mini batches are run on one node during the ParallelRunStep, no matter how many nodes I put in the <code>node_count<\/code> config argument.<\/p>\n<p>All the nodes seem to be up and running in the cluster, and according to the logs the <code>init()<\/code> function has been run on them multiple times. Diving into the logs I can see in <strong>sys\/error\/10.0.0.*<\/strong> that all the workers except the one that is working are saying:<\/p>\n<p><code>FileNotFoundError: [Errno 2] No such file or directory: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/virtualstage\/azureml\/c36eb050-adc9-4c34-8a33-5f6d42dcb19c\/wd\/tmp8_txakpm\/bg.png'<\/code><\/p>\n<p><strong>bg.png<\/strong> happens to be a side argument created in a previous PythonScriptStep that I'm passing to the ParallelRunStep:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bg_file = PipelineData('bg',  datastore=data_store)\nbg_file_ds = bg_file.as_dataset()\nbg_file_named = bg_file_ds.as_named_input(&quot;bg&quot;)\nbg_file_dw = bg_file_named.as_download()\n\n...\n\nparallelrun_step = ParallelRunStep(\n    name='batch-inference',\n    parallel_run_config=parallel_run_config,\n    inputs=[frames_data_named.as_download()],\n    arguments=[&quot;--bg_folder&quot;, bg_file_dw],\n    side_inputs=[bg_file_dw],\n    output=inference_frames_ds,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>What's happening here? Why the side argument seems to be available only in one worker while it fails in the others?<\/p>\n<p>BTW I found <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/957\" rel=\"nofollow noreferrer\">this<\/a> similar but unresolved question.<\/p>\n<p>Any help is much appreciated, thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1619386109403,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":244,
        "Owner_creation_time":1343828614450,
        "Owner_last_access_time":1664042984127,
        "Owner_location":"Seville, Spain",
        "Owner_reputation":359,
        "Owner_up_votes":265,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Apparently you need to specify a local mount path to use side_inputs in more than one node:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bg_file_named = bg_file_ds.as_named_input(f&quot;bg&quot;)\nbg_file_mnt = bg_file_named.as_mount(f&quot;\/tmp\/{str(uuid.uuid4())}&quot;)\n\n...\n\nparallelrun_step = ParallelRunStep(\n    name='batch-inference',\n    parallel_run_config=parallel_run_config,\n    inputs=[frames_data_named.as_download()],\n    arguments=[&quot;--bg_folder&quot;, bg_file_mnt],\n    side_inputs=[bg_file_mnt],\n    output=inference_frames_ds,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>Sources:<\/p>\n<ul>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18355\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18355<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1619694485790,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67258465",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57397150,
        "Question_title":"Deploy Notebook VM via ARM Template?",
        "Question_body":"<p>Is it possible to deploy an AML Notebook VM via an ARM template? If so, is there an example or documentation somewhere?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1565189508713,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":71,
        "Owner_creation_time":1529439461717,
        "Owner_last_access_time":1663763488057,
        "Owner_location":null,
        "Owner_reputation":392,
        "Owner_up_votes":8,
        "Owner_down_votes":4,
        "Owner_views":39,
        "Question_last_edit_time":1565217649487,
        "Answer_body":"<p>Unfortunately this is not supported today, but ARM support is in our roadmap<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1565216213847,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57397150",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65997961,
        "Question_title":"How to trigger an AzureML Pipeline from Azure DevOps?",
        "Question_body":"<p>If we have an AzureML Pipeline published, how can we trigger it from Azure DevOps <strong>without using Python Script Step or Azure CLI Step<\/strong>?<\/p>\n<p>The AzureML Steps supported natively in Azure DevOps include Model_Deployment and Model_Profiling.<\/p>\n<p>Is there any step in Azure DevOps which can be used to directly trigger a published Azure Machine Learning Pipeline while maintaining capabilities like using Service Connections and passing environmental variables, Gated Release (Deployment)?<\/p>\n<p>Edit:\nThis process can then be used to run as an agentless job.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1612203126923,
        "Question_score":2,
        "Question_tags":"azure|azure-devops|azure-machine-learning-service",
        "Question_view_count":1923,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":1612249107730,
        "Answer_body":"<p>Assumptions:<\/p>\n<ol>\n<li>An AzureML Pipeline is published and the REST endpoint is ready- To be referred to in this answer as &lt;AML_PIPELINE_REST_URI&gt;. And Published Pipeline ID is also ready- To be referred to in this answer as &lt;AML_PIPELINE_ID&gt;<\/li>\n<li>You have the Azure Machine Learning Extension installed: <a href=\"https:\/\/marketplace.visualstudio.com\/items?itemName=ms-air-aiagility.vss-services-azureml&amp;ssr=false#review-details\" rel=\"nofollow noreferrer\">Azure Machine Learning Extension<\/a><\/li>\n<\/ol>\n<p>To Invoke the Azure Machine Learning Pipeline we use the <code>Invoke ML Pipeline<\/code> step available in Azure DevOps. It is available when running an Agentless Job.<\/p>\n<p>To trigger it the workflow is as follows:<\/p>\n<ol>\n<li>Create a New Pipeline. Using the Classic Editor, delete the default Agent Job 1 stage.\n<a href=\"https:\/\/i.stack.imgur.com\/phzL3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/phzL3.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/QkiPY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QkiPY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li><p>Add an agentless job:\n<a href=\"https:\/\/i.stack.imgur.com\/0PXwg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0PXwg.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Add a task to this Agentless Job:\n<a href=\"https:\/\/i.stack.imgur.com\/trW7j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/trW7j.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Use AzureML Published Pipeline Task:\n<a href=\"https:\/\/i.stack.imgur.com\/3rl4z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3rl4z.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Use the Service Connection Mapped to the AML Workspace. You can find more on this at the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/library\/service-endpoints?view=azure-devops&amp;tabs=yaml\" rel=\"nofollow noreferrer\">official documentation<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/mnV36.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mnV36.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Choose the Pipeline to trigger using the &lt;AML_PIPELINE_ID&gt;:\n<a href=\"https:\/\/i.stack.imgur.com\/fbpQW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fbpQW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Give The experiment name and Pipeline Parameters if any:\n<a href=\"https:\/\/i.stack.imgur.com\/og1kx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/og1kx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>That's it, you can Save and Queue:\n<a href=\"https:\/\/i.stack.imgur.com\/iCwdl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iCwdl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<\/ol>\n<p>Alternatively, you can simply use the following jobs:<\/p>\n<pre><code>- job: Job_2\n  displayName: Agentless job\n  pool: server\n  steps:\n  - task: MLPublishedPipelineRestAPITask@0\n    displayName: Invoke ML pipeline\n    inputs:\n      connectedServiceName: &lt;REDACTED-AML-WS-Level-Service_Connection-ID&gt;\n      PipelineId: &lt;AML_PIPELINE_ID&gt;\n      ExperimentName: experimentname\n      PipelineParameters: ''\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1612256282837,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1612281801243,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65997961",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62935985,
        "Question_title":"Connect to an existing Azure Container Instance ACI from Azure ML",
        "Question_body":"<p>I have an active Azure container Instance which is running, How can I add it to my Workspace using the Azure ML SDK.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_time":1594906481080,
        "Question_score":1,
        "Question_tags":"azure-container-instances|azure-machine-learning-service",
        "Question_view_count":169,
        "Owner_creation_time":1537299924587,
        "Owner_last_access_time":1663176052613,
        "Owner_location":"Laurel, MD, USA",
        "Owner_reputation":359,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62935985",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71872506,
        "Question_title":"Unable To Run AzureML Experiment with SDK - Failed to Build Wheel for pynacl \/ Exit status:1",
        "Question_body":"<p>I am trying to run a AzureML Experiment using sdk (following a Udemy course). When I try to use the Experiment.submit function the experiment prepares and then fails with the following error messages:<\/p>\n<pre><code>ERROR: Command errored out with exit status 1 \n\nERROR: Failed building wheel for pynacl\nERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly\n<\/code><\/pre>\n<p>The Azure env as created within my anaconda navigator for a short period of time and then gets removed.<\/p>\n<p>Does anyone know how I can get around this? Any help would be really appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1649943158360,
        "Question_score":0,
        "Question_tags":"python|azure|anaconda|azure-machine-learning-service|pynacl",
        "Question_view_count":73,
        "Owner_creation_time":1603536549850,
        "Owner_last_access_time":1663761640910,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1650357451940,
        "Answer_body":"<p>To resolve <code>ERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly<\/code> this error, try either of the following ways:<\/p>\n<ol>\n<li><p>Install missing dependencies:<\/p>\n<pre><code>sudo apt install libpython3-dev build-essential\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip:<\/p>\n<pre><code>pip3 install --upgrade pip\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip with setuptools wheel:<\/p>\n<pre><code>pip3 install --upgrade pip setuptools wheel\n<\/code><\/pre>\n<\/li>\n<li><p>Reinstall PEP517:<\/p>\n<pre><code>pip3 install p5py\npip3 install PEP517\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>You can refer to  <a href=\"https:\/\/stackoverflow.com\/questions\/61365790\/error-could-not-build-wheels-for-scipy-which-use-pep-517-and-cannot-be-installe\">ERROR: Could not build wheels for scipy which use PEP 517 and cannot be installed directly<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/64038673\/could-not-build-wheels-for-which-use-pep-517-and-cannot-be-installed-directly\">Could not build wheels for _ which use PEP 517 and cannot be installed directly - Easy Solution<\/a> and <a href=\"https:\/\/github.com\/martomi\/chiadog\/issues\/44\" rel=\"nofollow noreferrer\">failed building wheel for pynacl<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1650257274673,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71872506",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32422626,
        "Question_title":"Part of speech tagging and entity recognition - python",
        "Question_body":"<p>I want to perform part of speech tagging and entity recognition in python similar to Maxent_POS_Tag_Annotator and Maxent_Entity_Annotator functions of openNLP in R.  I would prefer a code in python which takes input as textual sentence and gives output as different features- like number of \"CC\", number of \"CD\", number of \"DT\" etc.. CC, CD, DT are POS tags as used in Penn Treebank. So there should be 36 columns\/features for POS tagging corresponding to 36 POS tags as in <a href=\"http:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html\" rel=\"nofollow\">Penn Treebank POS<\/a>. I want to implement this on Azure ML \"Execute Python Script\" module and Azure ML supports python 2.7.7. I heard nltk in python may does the job, but I am a beginner on python. Any help would be appreciated. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1441535794287,
        "Question_score":0,
        "Question_tags":"python|azure|named-entity-recognition|part-of-speech|azure-machine-learning-studio",
        "Question_view_count":1014,
        "Owner_creation_time":1431324152360,
        "Owner_last_access_time":1444093237570,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":1441776651843,
        "Answer_body":"<p>Take a look at <a href=\"http:\/\/www.nltk.org\/book\/ch05.html\" rel=\"nofollow\">NTLK book<\/a>, Categorizing and Tagging Words section.<\/p>\n\n<p>Simple example, it uses the Penn Treebank tagset:<\/p>\n\n<pre><code>from nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\npos_tag(word_tokenize(\"John's big idea isn't all that bad.\")) \n\n[('John', 'NNP'),\n(\"'s\", 'POS'),\n ('big', 'JJ'),\n ('idea', 'NN'),\n ('is', 'VBZ'),\n (\"n't\", 'RB'),\n ('all', 'DT'),\n ('that', 'DT'),\n ('bad', 'JJ'),\n ('.', '.')]\n<\/code><\/pre>\n\n<p>Then you can use<\/p>\n\n<pre><code>from collections import defaultdict\ncounts = defaultdict(int)\nfor (word, tag) in pos_tag(word_tokenize(\"John's big idea isn't all that bad.\")):\n    counts[tag] += 1\n<\/code><\/pre>\n\n<p>to get frequencies:<\/p>\n\n<pre><code>defaultdict(&lt;type 'int'&gt;, {'JJ': 2, 'NN': 1, 'POS': 1, '.': 1, 'RB': 1, 'VBZ': 1, 'DT': 2, 'NNP': 1})\n<\/code><\/pre>",
        "Answer_comment_count":7.0,
        "Answer_creation_time":1441539548050,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32422626",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72872781,
        "Question_title":"azure ML on AKS memory and CPU parameters",
        "Question_body":"<p>When specifying the memory and core for the AksWebService (deploying Azure ML as a service in AKS), do the values for cpu_cores and memory_gb apply to each replica OR all replicas combined?<\/p>\n<pre><code>AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=True, autoscale_enabled=True, autoscale_min_replicas=4, autoscale_max_replicas=10)\n<\/code><\/pre>\n<p>I am assuming its per replica but just wanted to confirm.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1657038675127,
        "Question_score":0,
        "Question_tags":"azure-aks|azure-machine-learning-service",
        "Question_view_count":32,
        "Owner_creation_time":1376577570773,
        "Owner_last_access_time":1663954112673,
        "Owner_location":null,
        "Owner_reputation":301,
        "Owner_up_votes":27,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72872781",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53922402,
        "Question_title":"Customize Python Script On Azure ML",
        "Question_body":"<p>I want to use Fuzzywuzzy logic on python script. I am implement in this way but i didn't get anything. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/sUaD4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sUaD4.png\" alt=\"Azure ML Studio\"><\/a><\/p>\n\n<p>This is my python script code: <\/p>\n\n<pre><code>import pandas as pd\nfrom fuzzywuzzy import process\ndef azureml_main(dataframe1 = None):    \nreturn dataframe1,\n\ndef get_matches(query, choice, limit = 6):\nresult = process.extract(query, choice, limit = limit)\nreturn result,\n\nget_matches(\"admissibility\", dataframe1)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1545740929480,
        "Question_score":1,
        "Question_tags":"azure|fuzzy-search|azure-machine-learning-studio|fuzzywuzzy|ml-studio",
        "Question_view_count":88,
        "Owner_creation_time":1545735161627,
        "Owner_last_access_time":1564382390783,
        "Owner_location":"Ahmedabad, Gujarat, India",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1545901784670,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53922402",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73447386,
        "Question_title":"OpenSSL critical Vulnerability in AzureML Model Deployment to Kubernetes",
        "Question_body":"<p>I have an issue with OpenSSL, I am using the following command to install the latest version of OpenSSL in my Base Docker Image of Azure ML Deployment as the older version has some critical security vulnerability. However, the final image still has the older versions of OPENSSL, it could either be that or AzureML is installing the packages by itself, can anyone tell me how to get past this issue? or delete older versions of OpenSSL?<\/p>\n<pre><code>FROM ubuntu:18.04\n\n# Install dependencies:\nRUN apt-get update  &amp;&amp; apt-get -y install openssl\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1661181225127,
        "Question_score":0,
        "Question_tags":"docker|kubernetes|openssl|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":46,
        "Owner_creation_time":1453798475090,
        "Owner_last_access_time":1663791011297,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":1661326374980,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73447386",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59510445,
        "Question_title":"Overfitting\/Underfitting Machine Learning Models with Azure Machine Learning vs Python",
        "Question_body":"<p>I'm learning how to perform Machine Learning with Azure ML Studio. At the moment, I've only played around with Machine Learning using Python.<\/p>\n\n<p>I have run identical Machine Learning projects using both Azure ML and Python to see how close the results of each product with the Root Mean Squared Errors (RMSE). So far the RMSE has been widely different for Azure ML and Python.<\/p>\n\n<p>I can't figure out why the RMSE is so far apart. The only reason I can think of is because of the way Python 'fits' the model on the training data. Python uses the following code to fit the training data <\/p>\n\n<pre><code>lr = LinearRegression(labelCol='xxxx')\nlrModel = lr.fit(train_data)\n<\/code><\/pre>\n\n<p>However, I don't know how Azure ML fits the training data.<\/p>\n\n<p>Can someone let me know how Azure ML accomplishes fitting the training data?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1577532437513,
        "Question_score":0,
        "Question_tags":"python-3.x|machine-learning|azure-machine-learning-studio",
        "Question_view_count":138,
        "Owner_creation_time":1466892439907,
        "Owner_last_access_time":1637453769640,
        "Owner_location":null,
        "Owner_reputation":866,
        "Owner_up_votes":49,
        "Owner_down_votes":1,
        "Owner_views":233,
        "Question_last_edit_time":1577532627940,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59510445",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40632047,
        "Question_title":"Azure ML Studio cannot load a installed package in R",
        "Question_body":"<p><a href=\"https:\/\/i.stack.imgur.com\/wSYTs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wSYTs.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am trying to install a package in azure ML studio using the command below.<\/p>\n\n<pre><code>install.packages(\"src\/DMwR.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nlibrary(DMwR, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>DMwR.zip was upload as a dataset in azure. The error I get is below.<\/p>\n\n<pre><code>Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\nzip file 'src\/DMwR.zip' not found\n<\/code><\/pre>\n\n<p>How can I resolve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1479298809787,
        "Question_score":2,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":630,
        "Owner_creation_time":1376770973683,
        "Owner_last_access_time":1616761069497,
        "Owner_location":null,
        "Owner_reputation":1646,
        "Owner_up_votes":117,
        "Owner_down_votes":3,
        "Owner_views":448,
        "Question_last_edit_time":1479309068183,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40632047",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58200953,
        "Question_title":"POST request fails with large data send to model deployed on Azure Container",
        "Question_body":"<p><strong>Summary<\/strong><\/p>\n\n<p>I have a PyTorch model deployed on an Azure Container instance via the Azure Machine Learning Service SDK. The model takes (large) images for classification in standard numpy formatting.<\/p>\n\n<p>It seems, I'm hitting a HTTP request size limit on the server side. Requests to the model succeeds with PNG images of a size in the 8-9mb range and fails with images of the 15mb+ size. Specifically, it fails with 413 Request Entity Too Large.<\/p>\n\n<p>I assume, the limit is set in Nginx in the Docker image being build, as part of the deployment process. My question: <em>Given that the issue is due to the HTTP request size limit, is there any way to increase this limit in the azureml API?<\/em><\/p>\n\n<p><strong>Deployment process<\/strong><\/p>\n\n<p>The deployment process succeeds as expected.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\nfrom azureml.core.model import InferenceConfig, Model\nfrom azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.exceptions import WebserviceException\nfrom pathlib import Path\n\nPATH = Path('\/data\/home\/azureuser\/my_project')\n\nws = Workspace.from_config()\nmodel = ws.models['my_pytorch_model']\n\ninference_config = InferenceConfig(source_directory=PATH\/'src',\n                                   runtime='python',\n                                   entry_script='deployment\/scoring\/scoring.py',\n                                   conda_file='deployment\/environment\/env.yml')\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores=2, memory_gb=4)\naci_service_name = 'azure-model'\n\ntry:\n    service = Webservice(ws, name=aci_service_name)\n    if service:\n        service.delete()\nexcept WebserviceException as e:\n    print()\n\nservice = Model.deploy(ws, aci_service_name, [model], inference_config, deployment_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)\n<\/code><\/pre>\n\n<p><strong>Testing via <code>requests<\/code><\/strong><\/p>\n\n<p>A simple test using requests:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nimport numpy as np\nimport requests\nfrom PIL import Image as PilImage\n\ntest_data = np.array(PilImage.open(PATH\/'src\/deployment\/test\/test_image.png')).tolist()\ntest_sample = json.dumps({'raw_data': \n    test_data\n})\ntest_sample_encoded = bytes(test_sample, encoding='utf8')\n\nheaders = {\n    'Content-Type': 'application\/json'\n}\n\nresponse = requests.post(\n    service.scoring_uri,\n    data=test_sample_encoded,\n    headers=headers,\n    verify=True,\n    timeout=10\n)\n<\/code><\/pre>\n\n<p>Produces the following error in <code>requests<\/code> for larger files:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>ConnectionError: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n<\/code><\/pre>\n\n<p>Which I guess is a known error in requests, when a connection is closed from the server before data upload is completed.<\/p>\n\n<p><strong>Testing via <code>pycurl<\/code><\/strong><\/p>\n\n<p>Using the curl wrapper, I get a more interpretable response.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pycurl\nfrom io import BytesIO\n\nc = pycurl.Curl()\nb = BytesIO()\n\nc.setopt(c.URL, service.scoring_uri)\nc.setopt(c.POST, True)\nc.setopt(c.HTTPHEADER,['Content-Type: application\/json'])\nc.setopt(pycurl.WRITEFUNCTION, b.write)\nc.setopt(c.POSTFIELDS, test_sample)\nc.setopt(c.VERBOSE, True)\nc.perform()\n\nout = b.getvalue()\n\nb.close()\nc.close()\n\nprint(out)\n\n<\/code><\/pre>\n\n<p>For large files, this yields the following error:<\/p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;\n            413 Request Entity Too Large\n        &lt;\/title&gt;\n    &lt;\/head&gt;\n    &lt;body bgcolor=\"white\"&gt;\n        &lt;center&gt;\n            &lt;h1&gt;\n                413 Request Entity Too Large\n            &lt;\/h1&gt;\n        &lt;\/center&gt;\n        &lt;hr&gt;\n        &lt;center&gt;\n                nginx\/1.10.3 (Ubuntu)\n        &lt;\/center&gt;\n    &lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n\n<p>Leading me to believe this is an issue in the Nginx configuration. Specifically, I guess that client_max_body_size is set to 10mb.<\/p>\n\n<p><strong>Question summarised<\/strong><\/p>\n\n<p>Given that I am indeed hitting an issue with the Nginx configuration, can I change it somehow? If not using the Azure Machine Learning Service SDK, then maybe by overwriting the <code>\/etc\/nginx\/nginx.conf<\/code> file?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1570017134097,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":574,
        "Owner_creation_time":1377156004257,
        "Owner_last_access_time":1571123387553,
        "Owner_location":null,
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58200953",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68090119,
        "Question_title":"error creating new kernel in AMLs notebook",
        "Question_body":"<p>i am attempting to create a new kernel in an AMLs notebook.  It turns out that it doesn\u2019t matter which kernel I am trying to create, because it doesn't get that far.  \u2639<\/p>\n<p>i am following the steps here:  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels<\/a><\/p>\n<p>my full terminal session text is below.<\/p>\n<p>the error i get is:<\/p>\n<pre><code>InvalidArchiveError('Error with archive \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu.tar.bz2.  You probably need to delete and re-download or re-create this file.  Message from libarchive was:\\n\\nCould not unlink')\n<\/code><\/pre>\n<p>thanks for any suggestions or pointers.<\/p>\n<pre><code>Welcome to Azure Machine Learning Terminal\n\nType &quot;git clone [url]&quot; to clone a repo                      \nType &quot;git --help&quot; to learn about Git CLI                \nType &quot;az ml --help&quot; to learn about Azure ML CLI           \n\n\nazureuser@qnotebook:\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/qnotebook\/code$ cd ~\/cloudfiles\/code\/Users\/delbertm\/amls-qc \nazureuser@qnotebook:~\/cloudfiles\/code\/Users\/delbertm\/amls-qc$ \nazureuser@qnotebook:~\/cloudfiles\/code\/Users\/delbertm\/amls-qc$ conda create --name qsharp-env\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 4.9.2\n  latest version: 4.10.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\n## Package Plan ##\n\n  environment location: \/anaconda\/envs\/qsharp-env\n\n\n\nProceed ([y]\/n)? y\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate qsharp-env\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nazureuser@qnotebook:~\/cloudfiles\/code\/Users\/delbertm\/amls-qc$ conda activate qsharp-env\n(qsharp-env) azureuser@qnotebook:~\/cloudfiles\/code\/Users\/delbertm\/amls-qc$ conda install pip\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n\n==&gt; WARNING: A newer version of conda exists. &lt;==\n  current version: 4.9.2\n  latest version: 4.10.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\n## Package Plan ##\n\n  environment location: \/anaconda\/envs\/qsharp-env\n\n  added \/ updated specs:\n    - pip\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    _openmp_mutex-4.5          |            1_gnu          22 KB\n    ca-certificates-2021.5.25  |       h06a4308_1         112 KB\n    certifi-2021.5.30          |   py39h06a4308_0         139 KB\n    ld_impl_linux-64-2.35.1    |       h7274673_9         586 KB\n    libffi-3.3                 |       he6710b0_2          50 KB\n    libgcc-ng-9.3.0            |      h5101ec6_17         4.8 MB\n    libgomp-9.3.0              |      h5101ec6_17         311 KB\n    libstdcxx-ng-9.3.0         |      hd4cf53a_17         3.1 MB\n    ncurses-6.2                |       he6710b0_1         817 KB\n    pip-21.1.2                 |   py39h06a4308_0         1.8 MB\n    python-3.9.5               |       h12debd9_4        22.6 MB\n    readline-8.1               |       h27cfd23_0         362 KB\n    setuptools-52.0.0          |   py39h06a4308_0         724 KB\n    sqlite-3.35.4              |       hdfb4753_0         981 KB\n    tk-8.6.10                  |       hbc83047_0         3.0 MB\n    tzdata-2020f               |       h52ac0ba_0         113 KB\n    wheel-0.36.2               |     pyhd3eb1b0_0          33 KB\n    xz-5.2.5                   |       h7b6447c_0         341 KB\n    zlib-1.2.11                |       h7b6447c_3         103 KB\n    ------------------------------------------------------------\n                                           Total:        39.9 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs\/main\/linux-64::_libgcc_mutex-0.1-main\n  _openmp_mutex      pkgs\/main\/linux-64::_openmp_mutex-4.5-1_gnu\n  ca-certificates    pkgs\/main\/linux-64::ca-certificates-2021.5.25-h06a4308_1\n  certifi            pkgs\/main\/linux-64::certifi-2021.5.30-py39h06a4308_0\n  ld_impl_linux-64   pkgs\/main\/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n  libffi             pkgs\/main\/linux-64::libffi-3.3-he6710b0_2\n  libgcc-ng          pkgs\/main\/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n  libgomp            pkgs\/main\/linux-64::libgomp-9.3.0-h5101ec6_17\n  libstdcxx-ng       pkgs\/main\/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n  ncurses            pkgs\/main\/linux-64::ncurses-6.2-he6710b0_1\n  openssl            pkgs\/main\/linux-64::openssl-1.1.1k-h27cfd23_0\n  pip                pkgs\/main\/linux-64::pip-21.1.2-py39h06a4308_0\n  python             pkgs\/main\/linux-64::python-3.9.5-h12debd9_4\n  readline           pkgs\/main\/linux-64::readline-8.1-h27cfd23_0\n  setuptools         pkgs\/main\/linux-64::setuptools-52.0.0-py39h06a4308_0\n  sqlite             pkgs\/main\/linux-64::sqlite-3.35.4-hdfb4753_0\n  tk                 pkgs\/main\/linux-64::tk-8.6.10-hbc83047_0\n  tzdata             pkgs\/main\/noarch::tzdata-2020f-h52ac0ba_0\n  wheel              pkgs\/main\/noarch::wheel-0.36.2-pyhd3eb1b0_0\n  xz                 pkgs\/main\/linux-64::xz-5.2.5-h7b6447c_0\n  zlib               pkgs\/main\/linux-64::zlib-1.2.11-h7b6447c_3\n\n\nProceed ([y]\/n)? y\n\n\nDownloading and Extracting Packages\n_openmp_mutex-4.5    | 22 KB     | ########################################################################################################################################################################################################################################8                                                                                   |  74% WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/lib\/libgomp.so.1.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/licenses\/LICENSE.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/fortomp\/CMakeLists.txt.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/fortomp\/test_fort.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/aligned_alloc.c.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/aligned_alloc.cpp.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/yum_requirements.txt.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/config.old.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc-devel.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/make_tool_links.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/LICENSE.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gdb.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc-no-gomp.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-g++.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/uclibc.config.minimal.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/hello-world.cpp.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-openmp_impl.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgfortran.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/build.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gcc.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/uclibc.config.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-binutils.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/c11threads.c.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/conda_build_config.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-duma.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libstdc++.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgomp.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libstdc++-devel.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/meta.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/write_ctng_config.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gfortran.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/install-openmp_impl.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/conda_build_config.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/meta.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/test\/run_test.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/hash_input.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/run_exports.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/repodata_record.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/about.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/index.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/paths.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/files.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/git.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/lib\/libgomp.so.1.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/licenses\/LICENSE.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/fortomp\/CMakeLists.txt.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/fortomp\/test_fort.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/aligned_alloc.c.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/tests\/aligned_alloc.cpp.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/yum_requirements.txt.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/config.old.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc-devel.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/make_tool_links.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/LICENSE.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gdb.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgcc-no-gomp.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-g++.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/uclibc.config.minimal.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/hello-world.cpp.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-openmp_impl.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgfortran.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/build.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gcc.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/uclibc.config.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-binutils.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/c11threads.c.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/conda_build_config.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-duma.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libstdc++.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libgomp.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-libstdc++-devel.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/meta.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/write_ctng_config.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/parent\/install-gfortran.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/install-openmp_impl.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/conda_build_config.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/recipe\/meta.yaml.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/test\/run_test.sh.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/hash_input.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/run_exports.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/repodata_record.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/about.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/index.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/paths.json.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/files.  Please remove this file manually (you may need to reboot to free file handles)\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(139): Could not remove or rename \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu\/info\/git.  Please remove this file manually (you may need to reboot to free file handles)\n_openmp_mutex-4.5    | 22 KB     | ### | 100% \nreadline-8.1         | 362 KB    | ### | 100% \ntzdata-2020f         | 113 KB    | ### | 100% \nncurses-6.2          | 817 KB    | ### | 100% \nxz-5.2.5             | 341 KB    | ### | 100% \npip-21.1.2           | 1.8 MB    | ### | 100% \nzlib-1.2.11          | 103 KB    | ### | 100% \nsetuptools-52.0.0    | 724 KB    | ### | 100% \nca-certificates-2021 | 112 KB    | ### | 100% \nlibgcc-ng-9.3.0      | 4.8 MB    | ### | 100% \nlibgomp-9.3.0        | 311 KB    | ### | 100% \nlibstdcxx-ng-9.3.0   | 3.1 MB    | ### | 100% \nld_impl_linux-64-2.3 | 586 KB    | ### | 100% \npython-3.9.5         | 22.6 MB   | ### | 100% \ncertifi-2021.5.30    | 139 KB    | ### | 100% \nlibffi-3.3           | 50 KB     | ### | 100% \nsqlite-3.35.4        | 981 KB    | ### | 100% \nwheel-0.36.2         | 33 KB     | ### | 100% \ntk-8.6.10            | 3.0 MB    | ### | 100% \n\nInvalidArchiveError('Error with archive \/anaconda\/pkgs\/_openmp_mutex-4.5-1_gnu.tar.bz2.  You probably need to delete and re-download or re-create this file.  Message from libarchive was:\\n\\nCould not unlink')\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1624392231487,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":363,
        "Owner_creation_time":1565457789270,
        "Owner_last_access_time":1663869520163,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1624460808310,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68090119",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63204081,
        "Question_title":"PySpark ALSModel load fails in deployment over Azure ML service with error java.util.NoSuchElementException: Param blockSize does not exist",
        "Question_body":"<p>I am trying to deploy an ALS model trained using PySpark on Azure ML service. I am providing a score.py file that loads the trained model using ALSModel.load() function. Following is the code of my score.py file.<\/p>\n<pre><code>import os\nfrom azureml.core.model import Model\nfrom pyspark.ml.recommendation import ALS, ALSModel\nfrom pyspark.sql.types import StructType, StructField\nfrom pyspark.sql.types import DoubleType, StringType\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkContext\n\nsc = SparkContext.getOrCreate()\nsqlContext = SQLContext(sc)\nspark = sqlContext.sparkSession\n\ninput_schema = StructType([StructField(&quot;UserId&quot;, StringType())])\nreader = spark.read\nreader.schema(input_schema)\n\n\ndef init():\n    global model\n    # note here &quot;iris.model&quot; is the name of the model registered under the workspace\n    # this call should return the path to the model.pkl file on the local disk.\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), &quot;recommendation-model&quot;)\n    # Load the model file back into a LogisticRegression model\n    model = ALSModel.load(model_path)\n    \n\ndef run(data):\n    try:\n        input_df = reader.json(sc.parallelize([data]))\n        input_df = indexer.transform(input_df)\n        \n        res = model.recommendForUserSubset(input_df[['UserId_index']], 10)\n\n        # you can return any datatype as long as it is JSON-serializable\n        return result.collect()[0]['recommendations']\n    except Exception as e:\n        traceback.print_exc()\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>Following is the error I get when I deploy it as LocalWebService using Model.deploy function in Azure ML service<\/p>\n<pre><code>Generating Docker build context.\nPackage creation Succeeded\nLogging into Docker registry viennaglobal.azurecr.io\nLogging into Docker registry viennaglobal.azurecr.io\nBuilding Docker image from Dockerfile...\nStep 1\/5 : FROM viennaglobal.azurecr.io\/azureml\/azureml_43542b56c5ec3e8d0f68e1556558411f\n ---&gt; 5b3bb174ca5f\nStep 2\/5 : COPY azureml-app \/var\/azureml-app\n ---&gt; 8e540c0746f7\nStep 3\/5 : RUN mkdir -p '\/var\/azureml-app' &amp;&amp; echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjNkN2M1ZjM4LTI1ODEtNGUxNi05NTdhLWEzOTU1OGI1ZjBiMyIsInJlc291cmNlR3JvdXBOYW1lIjoiZGV2LW9tbmljeC10ZnMtYWkiLCJhY2NvdW50TmFtZSI6ImRldi10ZnMtYWktd29ya3NwYWNlIiwid29ya3NwYWNlSWQiOiI1NjkzNGMzNC1iZmYzLTQ3OWUtODRkMy01OGI4YTc3ZTI4ZjEifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode &gt; \/var\/azureml-app\/model_config_map.json\n ---&gt; Running in 502ad8edf91e\n ---&gt; a1bc5e0283d0\nStep 4\/5 : RUN mv '\/var\/azureml-app\/tmpvxhomyin.py' \/var\/azureml-app\/main.py\n ---&gt; Running in eb4ec1a0b702\n ---&gt; 6a3296fe6420\nStep 5\/5 : CMD [&quot;runsvdir&quot;,&quot;\/var\/runit&quot;]\n ---&gt; Running in 834fd746afef\n ---&gt; 5b9f8be538c0\nSuccessfully built 5b9f8be538c0\nSuccessfully tagged recommend-service:latest\nContainer (name:musing_borg, id:0f3163692f5119685eee5ed59c8e00aa96cd472f765e7db67653f1a6ce852e83) cannot be killed.\nContainer has been successfully cleaned up.\nImage sha256:0f146f4752878bbbc0e876f4477cc2877ff12a366fca18c986f9a9c2949d028b successfully removed.\nStarting Docker container...\nDocker container running.\nChecking container health...\nERROR - Error: Container has crashed. Did your init method fail?\n\n\nContainer Logs:\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n2020-07-30T11:57:00,312735664+00:00 - rsyslog\/run \n2020-07-30T11:57:00,312768364+00:00 - gunicorn\/run \n2020-07-30T11:57:00,313017966+00:00 - iot-server\/run \nbash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by bash)\n2020-07-30T11:57:00,313969073+00:00 - nginx\/run \n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n\/usr\/sbin\/nginx: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n2020-07-30T11:57:00,597835804+00:00 - iot-server\/finish 1 0\n2020-07-30T11:57:00,598826211+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http:\/\/127.0.0.1:31311 (10)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 41\nbash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by bash)\nbash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by bash)\nIvy Default Cache set to: \/root\/.ivy2\/cache\nThe jars for the packages stored in: \/root\/.ivy2\/jars\n:: loading settings :: url = jar:file:\/home\/mmlspark\/lib\/spark\/jars\/ivy-2.4.0.jar!\/org\/apache\/ivy\/core\/settings\/ivysettings.xml\ncom.microsoft.ml.spark#mmlspark_2.11 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-e07358bb-d354-4f41-aa4c-f0aa73bb0156;1.0\n    confs: [default]\n    found com.microsoft.ml.spark#mmlspark_2.11;0.15 in spark-list\n    found io.spray#spray-json_2.11;1.3.2 in central\n    found com.microsoft.cntk#cntk;2.4 in central\n    found org.openpnp#opencv;3.2.0-1 in central\n    found com.jcraft#jsch;0.1.54 in central\n    found org.apache.httpcomponents#httpclient;4.5.6 in central\n    found org.apache.httpcomponents#httpcore;4.4.10 in central\n    found commons-logging#commons-logging;1.2 in central\n    found commons-codec#commons-codec;1.10 in central\n    found com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 in central\n:: resolution report :: resolve 318ms :: artifacts dl 11ms\n    :: modules in use:\n    com.jcraft#jsch;0.1.54 from central in [default]\n    com.microsoft.cntk#cntk;2.4 from central in [default]\n    com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 from central in [default]\n    com.microsoft.ml.spark#mmlspark_2.11;0.15 from spark-list in [default]\n    commons-codec#commons-codec;1.10 from central in [default]\n    commons-logging#commons-logging;1.2 from central in [default]\n    io.spray#spray-json_2.11;1.3.2 from central in [default]\n    org.apache.httpcomponents#httpclient;4.5.6 from central in [default]\n    org.apache.httpcomponents#httpcore;4.4.10 from central in [default]\n    org.openpnp#opencv;3.2.0-1 from central in [default]\n    ---------------------------------------------------------------------\n    |                  |            modules            ||   artifacts   |\n    |       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n    ---------------------------------------------------------------------\n    |      default     |   10  |   0   |   0   |   0   ||   10  |   0   |\n    ---------------------------------------------------------------------\n\n:: problems summary ::\n:::: ERRORS\n    unknown resolver repo-1\n\n    unknown resolver repo-1\n\n\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n:: retrieving :: org.apache.spark#spark-submit-parent-e07358bb-d354-4f41-aa4c-f0aa73bb0156\n    confs: [default]\n    0 artifacts copied, 10 already retrieved (0kB\/7ms)\n2020-07-30 11:57:02 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to &quot;WARN&quot;.\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\nInitialized PySpark session.\nInitializing logger\n2020-07-30 11:57:09,464 | root | INFO | Starting up app insights client\nStarting up app insights client\n2020-07-30 11:57:09,464 | root | INFO | Starting up request id generator\nStarting up request id generator\n2020-07-30 11:57:09,464 | root | INFO | Starting up app insight hooks\nStarting up app insight hooks\n2020-07-30 11:57:09,464 | root | INFO | Invoking user's init function\nInvoking user's init function\n2020-07-30 11:57:19,652 | root | ERROR | User's init function failed\nUser's init function failed\n2020-07-30 11:57:19,656 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 163, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/main.py&quot;, line 44, in init\n    model = ALSModel.load(model_path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/ml\/util.py&quot;, line 362, in load\n    return cls.read().load(path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/ml\/util.py&quot;, line 300, in load\n    java_obj = self._jread.load(path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/java_gateway.py&quot;, line 1257, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/sql\/utils.py&quot;, line 63, in deco\n    return f(*a, **kw)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py&quot;, line 328, in get_return_value\n    format(target_id, &quot;.&quot;, name), value)\npy4j.protocol.Py4JJavaError: An error occurred while calling o64.load.\n: java.util.NoSuchElementException: Param blockSize does not exist.\n    at org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:729)\n    at org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:729)\n    at scala.Option.getOrElse(Option.scala:121)\n    at org.apache.spark.ml.param.Params$class.getParam(params.scala:728)\n    at org.apache.spark.ml.PipelineStage.getParam(Pipeline.scala:42)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata$$anonfun$setParams$1.apply(ReadWrite.scala:591)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata$$anonfun$setParams$1.apply(ReadWrite.scala:589)\n    at scala.collection.immutable.List.foreach(List.scala:392)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata.setParams(ReadWrite.scala:589)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata.getAndSetParams(ReadWrite.scala:572)\n    at org.apache.spark.ml.recommendation.ALSModel$ALSModelReader.load(ALS.scala:533)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:282)\n    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    at py4j.commands.CallCommand.execute(CallCommand.java:79)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nEncountered Exception Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 163, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/main.py&quot;, line 44, in init\n    model = ALSModel.load(model_path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/ml\/util.py&quot;, line 362, in load\n    return cls.read().load(path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/ml\/util.py&quot;, line 300, in load\n    java_obj = self._jread.load(path)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/java_gateway.py&quot;, line 1257, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/pyspark\/sql\/utils.py&quot;, line 63, in deco\n    return f(*a, **kw)\n  File &quot;\/home\/mmlspark\/lib\/spark\/python\/lib\/py4j-0.10.7-src.zip\/py4j\/protocol.py&quot;, line 328, in get_return_value\n    format(target_id, &quot;.&quot;, name), value)\npy4j.protocol.Py4JJavaError: An error occurred while calling o64.load.\n: java.util.NoSuchElementException: Param blockSize does not exist.\n    at org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:729)\n    at org.apache.spark.ml.param.Params$$anonfun$getParam$2.apply(params.scala:729)\n    at scala.Option.getOrElse(Option.scala:121)\n    at org.apache.spark.ml.param.Params$class.getParam(params.scala:728)\n    at org.apache.spark.ml.PipelineStage.getParam(Pipeline.scala:42)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata$$anonfun$setParams$1.apply(ReadWrite.scala:591)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata$$anonfun$setParams$1.apply(ReadWrite.scala:589)\n    at scala.collection.immutable.List.foreach(List.scala:392)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata.setParams(ReadWrite.scala:589)\n    at org.apache.spark.ml.util.DefaultParamsReader$Metadata.getAndSetParams(ReadWrite.scala:572)\n    at org.apache.spark.ml.recommendation.ALSModel$ALSModelReader.load(ALS.scala:533)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:282)\n    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    at py4j.commands.CallCommand.execute(CallCommand.java:79)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nWorker exiting (pid: 41)\nShutting down: Master\nReason: Worker failed to boot.\n\/bin\/bash: \/azureml-envs\/azureml_7fbe163ce1d4208cd897650a64b7a54d\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n2020-07-30T11:57:19,833136837+00:00 - gunicorn\/finish 3 0\n2020-07-30T11:57:19,834216245+00:00 - Exit code 3 is not normal. Killing image.\n\n---------------------------------------------------------------------------\nWebserviceException                       Traceback (most recent call last)\n&lt;ipython-input-43-d0992ae9d1c9&gt; in &lt;module&gt;\n      6 local_service = Model.deploy(workspace, &quot;recommend-service&quot;, [register_model], inference_config, deployment_config)\n      7 \n----&gt; 8 local_service.wait_for_deployment()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/local.py in decorated(self, *args, **kwargs)\n     69                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n     70                                           logger=module_logger)\n---&gt; 71             return func(self, *args, **kwargs)\n     72         return decorated\n     73     return decorator\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/local.py in wait_for_deployment(self, show_output)\n    601                                    self._container,\n    602                                    health_url=self._internal_base_url,\n--&gt; 603                                    cleanup_if_failed=False)\n    604 \n    605             self.state = LocalWebservice.STATE_RUNNING\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_model_management\/_util.py in container_health_check(docker_port, container, health_url, cleanup_if_failed)\n    745             # The container has started and crashed.\n    746             _raise_for_container_failure(container, cleanup_if_failed,\n--&gt; 747                                          'Error: Container has crashed. Did your init method fail?')\n    748 \n    749         # The container hasn't crashed, so try to ping the health endpoint.\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_model_management\/_util.py in _raise_for_container_failure(container, cleanup, message)\n   1258         cleanup_container(container)\n   1259 \n-&gt; 1260     raise WebserviceException(message, logger=module_logger)\n   1261 \n   1262 \n\nWebserviceException: WebserviceException:\n    Message: Error: Container has crashed. Did your init method fail?\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Error: Container has crashed. Did your init method fail?&quot;\n    }\n}\n<\/code><\/pre>\n<p>However, the ALSModel.load() works fine when executed in a Jupyter notebook.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1596276786133,
        "Question_score":1,
        "Question_tags":"python|apache-spark|machine-learning|pyspark|azure-machine-learning-service",
        "Question_view_count":598,
        "Owner_creation_time":1596274712793,
        "Owner_last_access_time":1609241506490,
        "Owner_location":"Chandigarh, India",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":"<p>A couple of things to check:<\/p>\n<ol>\n<li>Is your model registered in the workspace? AZUREML_MODEL_DIR only works for registered models. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-\" rel=\"nofollow noreferrer\">this link<\/a> for information about registering a model<\/li>\n<li>Are you specifying the same version of pyspark.ml.recommendation in your InferenceConfig as you use locally? This kind of error might be due to a difference in versions<\/li>\n<li>Have you looked at the output of <code>print(service.get_logs())<\/code>? Check out our <a href=\"https:\/\/review.docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?branch=pr-en-us-124666\" rel=\"nofollow noreferrer\">troubleshoot and debugging documentation here<\/a> for other things you can try<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1596478571823,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63204081",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70179691,
        "Question_title":"Resources for displaying Azure ML Studio application insights on Grafana",
        "Question_body":"<p>I'm looking to display specific metrics from Azure ML Studio application insights on a Grafana Dashboard and haven't found any great documentations so far. Can you please point me to a good resource for this need? Thank you.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1638338044333,
        "Question_score":0,
        "Question_tags":"azure|grafana|azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_time":1638211993203,
        "Owner_last_access_time":1651071910080,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70179691",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72566607,
        "Question_title":"How to trigger a process based on an Azure ML model predictions?",
        "Question_body":"<p>It is possible to trigger, let's say, a process to send emails or SMS based on an Azure ML prediction?<\/p>\n<p>I have a customer segmentation model, and my goal is to contact a customer based on their segment. For example:<\/p>\n<ul>\n<li>All customers group A -&gt; phone call.<\/li>\n<li>All customers group B -&gt; SMS.<\/li>\n<\/ul>\n<p>And so on...<\/p>\n<p>How can I achieve this? How would be the recommended approach?\nI was reading this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-event-grid\" rel=\"nofollow noreferrer\">Microsoft docs<\/a> but these event driven actions are not what I need.<\/p>\n<p>Another thing that I was considering is what about saving the model response on a storage account and create a event action with Logic Apps or Azure Functions when adding data in this storage. This could work? Perhaps, it is important to mention that the model predictions are considered to be done once a month by a scheduled python script.<\/p>\n<p>Can someone give me an advice to what path can I follow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1654808578860,
        "Question_score":0,
        "Question_tags":"azure|azure-functions|azure-logic-apps|azure-machine-learning-studio|azure-eventgrid",
        "Question_view_count":91,
        "Owner_creation_time":1555058508927,
        "Owner_last_access_time":1661373429997,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":1654809277600,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72566607",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72516242,
        "Question_title":"Is there any limitations for runs per users in Azure ML experiments?",
        "Question_body":"<p>I and my team members are working on a machine learning project through the <strong>Azure ML<\/strong> portal.\nWe have created a specific <em>experiment<\/em> in our <em>workspace<\/em> in Azure ML and are submitting our Python script <em>runs<\/em> from our local or remote machines in this experiment.<\/p>\n<p>Although I'm collaborating with my colleagues, most of the runs in this specific experiment are submitted by me.<\/p>\n<p>Recently, I have faced a problem with experiment submissions.\nThe problem is that after some number of experiments created by me, I cannot add any other runs to this experiment, but my colleagues can!!!<\/p>\n<p>Unfortunately, the Azure ML portal does not show any clear error message for this problem. It continues submitting the run till a <em>timeout<\/em> exception occurs!<\/p>\n<p>As a temporary solution, I've just changed the name of the experiment and I could conquer this problem.<\/p>\n<p>This solution helped me to submit my run on <strong>Azure ML<\/strong> but it didn\u2019t satisfy me because we want to collect all related runs under a specific experiment. On the other hand creating multiple number of experiments for each run is overwhelming!<\/p>\n<p>What I know is that there are some service limits for the number of runs in a workspace on this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity\" rel=\"nofollow noreferrer\">page<\/a>. I am sure that the number of runs in our workspace has not reached to the 10 millions, because I can created new runs under new experiments dashboard. But I don\u2019t know anything about the limitations on the number of runs in a specific experiment or even any limitations for the number of runs per users in a specific experiment.\nI couldn't find any clear document explaining this fact.<\/p>\n<p>Is there anyone who can help me for this issue?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1654510800217,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk|azure-python-sdk|azuremlsdk",
        "Question_view_count":82,
        "Owner_creation_time":1558366212313,
        "Owner_last_access_time":1663775379147,
        "Owner_location":"Zanjan, Zanjan Province, Iran",
        "Owner_reputation":425,
        "Owner_up_votes":216,
        "Owner_down_votes":6,
        "Owner_views":32,
        "Question_last_edit_time":1655619106363,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72516242",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62407200,
        "Question_title":"How to set learner type for Python Model in Azure Machine Learning Designer?",
        "Question_body":"<p>I am testing Azure Machine Learning Designer by having a custom Python Model (a simple kNN classification). I would like to tune the value of 'k' and get the best performing model but \"Tune Model Hyperparameters\" module gives following error when giving output from my \"Create Python Model\" as input.<\/p>\n\n<pre><code>ModuleExceptionMessage:LearnerTypesNotCompatible: Got incompatible learner type: \"None\". Expected learner types are: \"(&lt;TaskType.BinaryClassification: 1&gt;, &lt;TaskType.MultiClassification: 2&gt;, &lt;TaskType.Regression: 3&gt;)\".\n<\/code><\/pre>\n\n<p>How I can set the learner type of my own Python model? Is it even possible? Should I just code the parameter tuning myself with \"Execute Python Script\"-module?<\/p>\n\n<p>My \"Create Python model\"-module script:<\/p>\n\n<pre><code>import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclass AzureMLModel:\n    def __init__(self, k = 3):\n        self.model = KNeighborsClassifier(n_neighbors = k)\n        self.feature_column_names = list()\n\n    def train(self, df_train, df_label):\n        self.feature_column_names = df_train.columns.tolist()\n        self.model.fit(df_train, df_label)\n\n    def predict(self, df):\n        return pd.DataFrame({'Scored Labels': self.model.predict(df[self.feature_column_names])})\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1592306247567,
        "Question_score":1,
        "Question_tags":"python|azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":108,
        "Owner_creation_time":1592304949617,
        "Owner_last_access_time":1593094592020,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1592306531683,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62407200",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61415793,
        "Question_title":"Log metrics in PythonScriptStep",
        "Question_body":"<p>In my Azure ML pipeline I've got a PythonScriptStep that is crunching some data. I need to access the Azure ML Logger to track metrics in the step, so I'm trying to import get_azureml_logger but that's bombing out. I'm not sure what dependency I need to install via pip. <\/p>\n\n<p><code>from azureml.logging import get_azureml_logger<\/code><\/p>\n\n<p><code>ModuleNotFoundError: No module named 'azureml.logging'<\/code><\/p>\n\n<p>I came across a similar <a href=\"https:\/\/stackoverflow.com\/questions\/49438358\/azureml-logging-module-not-found\">post<\/a> but it deals with Azure Notebooks. Anyway, I tried adding that blob to my pip dependency, but it's failing with an Auth error.   <\/p>\n\n<pre><code>Collecting azureml.logging==1.0.79 [91m  ERROR: HTTP error 403 while getting\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n[0m91m  ERROR: Could not install requirement azureml.logging==1.0.79 from\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n(from -r \/azureml-environment-setup\/condaenv.g4q7suee.requirements.txt\n(line 3)) because of error 403 Client Error:\nServer failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. for url:\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n<\/code><\/pre>\n\n<p>I'm not sure how to move on this, all I need to do is to log metrics in the step.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1587755548897,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":361,
        "Owner_creation_time":1330016065410,
        "Owner_last_access_time":1662160983830,
        "Owner_location":null,
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Question_last_edit_time":1587809992913,
        "Answer_body":"<p>Check out the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-experiments#option-2-use-scriptrunconfig\" rel=\"nofollow noreferrer\">ScriptRunConfig Section of the Monitor Azure ML experiment runs and metrics<\/a>. <code>ScriptRunConfig<\/code> works effectively the same as a <code>PythonScriptStep<\/code>.<\/p>\n\n<p>The idiom is generally to have the following in your the script of your <code>PythonScriptStep<\/code>:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\nrun.log('foo_score', \"bar\")\n<\/code><\/pre>\n\n<p>Side note: You don't need to change your environment dependencies to use this because <code>PythonScriptStep<\/code>s have <code>azureml-defaults<\/code> installed automatically as a dependency.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1587756432003,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61415793",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71135228,
        "Question_title":"Connection timeout in AzureML studio",
        "Question_body":"<p>I'm trying to connect a VM I have in AzureML studio.  I keep getting the following:  Connection attempt timed out for ''. Verify that server is accessible and SSH service is accepting connections.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1644973069297,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":208,
        "Owner_creation_time":1555914279857,
        "Owner_last_access_time":1644991232357,
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Go to your VM config and test your connection through the 'connect' tab.  Is your test successful?  If not, check if port 22 is blocked.  Watch for automated blocking rules applied to your VM.<\/p>\n<p>we have DSVM attach in preview - might be interesting for you: <a href=\"https:\/\/github.com\/Azure\/azureml-previews\/tree\/main\/previews\/dsvm-attach\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azureml-previews\/tree\/main\/previews\/dsvm-attach<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1644985009903,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1644985509217,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71135228",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68237581,
        "Question_title":"In Azure Machine Learning, where are log files stored?",
        "Question_body":"<p>Every time I submit and execute a Run in Azure Machine Learning, I end up getting logs. I can see the logs by going to the Run page and clicking on 'Outputs+logs' tab (see the image).\nHere I am curious about where the logs actually are. I have an Azure Blob storage but can't find the logs there. Where are they?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MYHwt.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1625325902243,
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":537,
        "Owner_creation_time":1610542341460,
        "Owner_last_access_time":1663140958047,
        "Owner_location":"Seoul, South Korea",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68237581",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60709452,
        "Question_title":"Getting the run_id programmatically from an AzureML run",
        "Question_body":"<pre class=\"lang-python prettyprint-override\"><code>run = Run.get_context()\nrun_id = run.run_id\n<\/code><\/pre>\n\n<p>pruduces the error<\/p>\n\n<blockquote>\n  <p>AttributeError: '_SubmittedRun' object has no attribute 'run_id'  <\/p>\n<\/blockquote>\n\n<p>But <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py\" rel=\"nofollow noreferrer\">the documentation<\/a> seems to suggest that as the correct way to glean the run_id from experiment code.<\/p>\n\n<p>How should I glean the run_id from AzureML SDK code? (N.B. I am using a library that hides the call to <code>submit<\/code> from me.)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1584375132240,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1326,
        "Owner_creation_time":1295000383010,
        "Owner_last_access_time":1663824813343,
        "Owner_location":"Cambridge, United Kingdom",
        "Owner_reputation":15147,
        "Owner_up_votes":2159,
        "Owner_down_votes":27,
        "Owner_views":1915,
        "Question_last_edit_time":1599468848123,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60709452",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58320938,
        "Question_title":"azureml history logging to output dir",
        "Question_body":"<p>When running my Pytorch Estimator in the cloud, I get this output regarding the recommended way to save my training scripts output to a folder called '.\/outputs'. This folder is created by my script, and is in the correct root-folder provided. It has output.<\/p>\n\n<p>However the estimator returns this, while preparing the container:\nStarting the daemon thread to refresh tokens in background for process with pid = 124\nWarning: Unable to import azureml.history. Output collection disabled.<\/p>\n\n<p>all I provide my estimator is my training script, conda env.yml and a compute target.<\/p>\n\n<p>It completes the training script successfully, not errors.<\/p>\n\n<p>Any ideas why I get this ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_time":1570703699080,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":213,
        "Owner_creation_time":1417378487127,
        "Owner_last_access_time":1651826944133,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1570736060340,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58320938",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61168984,
        "Question_title":"Azure ML free trial: how to submit pipeline?",
        "Question_body":"<p>I'm using a free trial account on MS Azure and I'm following this tutorial.<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a><\/p>\n\n<p>I'm stuck when I try to \"submit the pipeline\".<\/p>\n\n<p>The reason seems to be that I can't create a compute instance or a training cluster on a free plan.\nI still have 200USDs of free credits. I guess there must be a solution?<\/p>\n\n<hr>\n\n<p>Error messages:<\/p>\n\n<pre><code>Invalid graph: The pipeline compute target is invalid.\n\n400: Compute Test3 in state Failed, which is not able to use\n\nCompute instance: creation failed\nThe specified subscription has a total vCPU quota of 0 and is less than the requested compute training cluster and\/or compute instance's min nodes of 1 which maps to 4 vCPUs\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1586681686103,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":370,
        "Owner_creation_time":1343682543650,
        "Owner_last_access_time":1655966822477,
        "Owner_location":null,
        "Owner_reputation":135,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Question_last_edit_time":1586690281397,
        "Answer_body":"<p>Please check the announcement from MS Team regarding this:<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/<\/a><\/p>\n\n<p>All the free trials will not work as of now<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1586681759587,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61168984",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72983144,
        "Question_title":"azureml tabular dataset over azure gen2 datalake",
        "Question_body":"<h1>What have I tried<\/h1>\n<ul>\n<li>set up an AzureML DataStore using Identity based authentication<\/li>\n<li>set up an AzureML Dataset for a single file under a specific file system<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>\n    workspace = Workspace.from_config(&quot;config.json&quot;, auth= auth)\n    dataset = Dataset.get_by_name(workspace, 'engage_event_type')\n    frame = dataset.to_pandas_dataframe()\n<\/code><\/pre>\n<p>I am able to explore the dataset from azure portal and it displays the right data correctly.<\/p>\n<p>However running ^ where <code>auth<\/code> is a Service Principal which has the same rights as Azure Workspace Instance I get a bunch of calls like, but no errors \/ exceptions \/ completion.<\/p>\n<p>The data underneath is &lt; 10kb<\/p>\n<pre><code>Resolving access token for scope &quot;https:\/\/datalake.azure.net\/\/.default&quot; using identity of type &quot;SP&quot;.\nResolving access token for scope &quot;https:\/\/datalake.azure.net\/\/.default&quot; using identity of type &quot;SP&quot;.\n<\/code><\/pre>\n<ul>\n<li>I have tried running the script on a local compute<\/li>\n<li>I have tried running the script on a compute instance<\/li>\n<\/ul>\n<p>both gave the same issue<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1657812916327,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":431,
        "Owner_creation_time":1271093246887,
        "Owner_last_access_time":1663988177550,
        "Owner_location":"United States",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72983144",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59873804,
        "Question_title":"Error 0085 while executing python script in Azure Web service but not in ML Experiment",
        "Question_body":"<p>My workflow is running perfect on Experimentation, but after deployed to web service, I receive this error while post.<\/p>\n\n<p>Python Code:<\/p>\n\n<pre><code># -*- coding: utf-8 -*-\n\n#import sys\nimport pickle\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree \n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    print('input dataframe1 ',dataframe1)\n    decision_tree_pkl_predictive_maint = r'.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl'\n\n    #sys.path.insert(0,\".\\Script Bundle\")\n    #model = pickle.load(open(\".\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl\", 'rb'))\n\n    modle_file = open(decision_tree_pkl_predictive_maint,\"rb\")\n    model = pickle.load(modle_file)\n\n    #return the mode of prediciton\n    result = model.predict(dataframe1)\n    print(result)\n    result_df = pd.DataFrame({'prediction_class':result})\n    return result_df,\n<\/code><\/pre>\n\n<p>ERROR:<\/p>\n\n<p>Execute Python Script RRS : Error 0085: The following error occurred during script evaluation, please view the output log for more information: ---------- Start of error message from Python interpreter ---------- Caught exception while executing function: Traceback (most recent call last): File \"\\server\\InvokePy.py\", line 120, in executeScript outframe = mod.azureml_main(*inframes) File \"\\temp-1036260731852293620.py\", line 46, in azureml_main modle_file = open(decision_tree_pkl_predictive_maint,\"rb\") FileNotFoundError: [Errno 2] No such file or directory: '.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl' ---------- End of error message from Python interpreter ----------<\/p>\n\n<p>Please, Advice.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1579766106190,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-web-app-service|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":215,
        "Owner_creation_time":1554724240183,
        "Owner_last_access_time":1664041243347,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":29,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The issue has to do with your file path. Ensure that you have included the correct path.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1580091525613,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59873804",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73692700,
        "Question_title":"AzureML Hyperdrive. Pass data between trials",
        "Question_body":"<p>Is it possible to pass data between individual trials in HyperDrive experiment?<\/p>\n<p>The <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/sdk-preview\/sdk\/jobs\/single-step\/lightgbm\/iris\/src\/main.py\" rel=\"nofollow noreferrer\">example notebook from AzureML<\/a> reads training data inside training script, which will be executed in every separate trial of the HyperDrive experiment. However, it would be much more efficient if we could read data only once and pass it between all trials.<\/p>\n<p>Is it possible to configure it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663001710647,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|hyperdrive",
        "Question_view_count":20,
        "Owner_creation_time":1531993302317,
        "Owner_last_access_time":1663952126937,
        "Owner_location":null,
        "Owner_reputation":367,
        "Owner_up_votes":52,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73692700",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69450547,
        "Question_title":"WebserviceException: Unable to deploy a model with aks and azure machine learning",
        "Question_body":"<p>I tried to deploy a new model in azure databricks notebook.\nThis morning it was working and now I have the following error:<\/p>\n<p>After<\/p>\n<pre><code>service.wait_for_deployment(show_output=True)\nprint(service.state)\nprint(service.get_logs())\n<\/code><\/pre>\n<p>I have:<\/p>\n<pre><code>&quot;message&quot;: &quot;Timed out waiting for AKS deployment to complete. pollTimeout : 00:20:00 serviceName: simdev serviceId: ...&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;DeploymentTimedOut&quot;,\n      &quot;message&quot;: &quot;Your container endpoint is not available. Please follow the steps to debug:\n    1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n    2. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n    3. View the diagnostic events to check status of container, it may help you to debug the issue.\n{&quot;InvolvedObject&quot;:&quot;simdev-757df4f999-rbcws&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Warning&quot;,&quot;Reason&quot;:&quot;FailedScheduling&quot;,&quot;Message&quot;:&quot;0\/2 nodes are available: 2 Insufficient nvidia.com\/gpu.&quot;,&quot;LastTimestamp&quot;:null}\n{&quot;InvolvedObject&quot;:&quot;simdev-757df4f999-rbcws&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Warning&quot;,&quot;Reason&quot;:&quot;FailedScheduling&quot;,&quot;Message&quot;:&quot;0\/2 nodes are available: 2 Insufficient nvidia.com\/gpu.&quot;,&quot;LastTimestamp&quot;:null}\n{&quot;InvolvedObject&quot;:&quot;simdev-757df4f999-rbcws&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Normal&quot;,&quot;Reason&quot;:&quot;Scheduled&quot;,&quot;Message&quot;:&quot;Successfully assigned azureml-train-aml-001-dev\/simdev-757df4f999-rbcws to aks-agentpool-34690879-vmss000000&quot;,&quot;LastTimestamp&quot;:null}\n<\/code><\/pre>\n<p>Yesterday it didn't work. This morning yes, and now no.<\/p>\n<p>Here is aks config:<\/p>\n<pre><code>aks_config = AksWebservice.deploy_configuration(cpu_cores=0.7,\n                                                memory_gb=0.7,\n                                                gpu_cores=1,\n                                                period_seconds=1800,\n                                                failure_threshold=10,\n                                                timeout_seconds=60,\n                                                max_request_wait_time=300000,\n                                                scoring_timeout_ms=300000,)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1633437212317,
        "Question_score":0,
        "Question_tags":"azure-aks|azure-databricks|azure-machine-learning-service",
        "Question_view_count":178,
        "Owner_creation_time":1606642099553,
        "Owner_last_access_time":1654258609767,
        "Owner_location":null,
        "Owner_reputation":371,
        "Owner_up_votes":65,
        "Owner_down_votes":0,
        "Owner_views":55,
        "Question_last_edit_time":1633437593747,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69450547",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40423227,
        "Question_title":"No applicable method for 'predict' applied to an object of class \"MXFeedForwardModel\"",
        "Question_body":"<p>I have created a Neural network model using mxnet package in R studio. I tested the model on local and it works as expected. I have deployed the same model as a webservice in AzureML using <code>publishwebservice()<\/code> function from R.<\/p>\n\n<p>When I try to predict the test data with the webservice using <code>consume()<\/code> function: <\/p>\n\n<pre><code>pred_cnn &lt;- consume(endpoint_cnn, testdf)\n<\/code><\/pre>\n\n<p>it always throws following error:<\/p>\n\n<blockquote>\n  <p>Error: AzureML returns error code: HTTP status code : 400 AzureML\n  error code  : LibraryExecutionError<\/p>\n  \n  <p>Module execution encountered an internal library error.<br>\n  The following\n  error occurred during evaluation of R script: R_tryEval: return error: \n  Error in UseMethod(\"predict\") :<br>\n     no applicable method for 'predict'\n  applied to an object of class \"MXFeedForwardModel\"<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1478264100187,
        "Question_score":2,
        "Question_tags":"r|azure-machine-learning-studio|mxnet",
        "Question_view_count":983,
        "Owner_creation_time":1312015616267,
        "Owner_last_access_time":1664044812267,
        "Owner_location":"Copenhagen, Denmark",
        "Owner_reputation":19521,
        "Owner_up_votes":409,
        "Owner_down_votes":5,
        "Owner_views":2574,
        "Question_last_edit_time":1478546093720,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40423227",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60866431,
        "Question_title":"When deploying an ml model using vscode I get an error docker image build failed",
        "Question_body":"<p>I'm following this tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-train-deploy-image-classification-model-vscode\" rel=\"nofollow noreferrer\">VSCODE tensorflow model deployment on Azure<\/a>.\nHere instead of tensorflow model I'm trying to deploy a simple decision tree model.I create a train.py file like this<\/p>\n<pre><code>import pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport pickle\nimport os\nimport joblib\n\ndata=pd.read_csv('CreditCardWeka.csv')\nmodel=DecisionTreeClassifier()\nY=data['Class']\ndel data['Class']\nX=data\nmodel.fit(X,Y)\nos.makedirs('.\/outputs\/model', exist_ok = True)\njoblib.dump(model, '.\/outputs\/model\/dec_model.sav')\n<\/code><\/pre>\n<p>After this I create a compute,create a run configuration and select this file.After this I create an experiment and run it and download the output.I'm able to download the output and till here it works.\nAfter this I'm able to successfully register my model and when I try to deploy it as an &quot;Azure Container Service&quot; it asks for score.py while which is this<\/p>\n<pre><code>import os\nimport joblib\nimport json\nimport time\nimport sklearn\n# Called when the deployed service starts\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n\n    # Get the path where the deployed model can be found.\n    # load models\n    model_root = Model.get_model_path('decision-tree-model')\n    model = joblib.load(os.path.join(model_root, 'dec-model.sav'))\n\n# Handle requests to the service\ndef run(data):\n    try:\n        # Pick out the text property of the JSON request.\n        # This expects a request in the form of {&quot;text&quot;: &quot;some text to score for sentiment&quot;}\n        data = json.loads(data)\n        prediction = model.predict(data['X'])\n        #Return prediction\n        return prediction\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>It also asks for a yml file which is this<\/p>\n<pre><code>name: decision-tree\nchannels:\n  - defaults\ndependencies:\n  - python\n  - sklearn\n  - joblib\n  - pip\n  - pip:\n    - azureml-defaults\n<\/code><\/pre>\n<p>After this when it starts creating a docker image it failes and the error is &quot;Docker image build failed&quot;.\nHow can I resolve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1585222856953,
        "Question_score":0,
        "Question_tags":"python|azure|docker|visual-studio-code|azure-machine-learning-service",
        "Question_view_count":142,
        "Owner_creation_time":1472571773250,
        "Owner_last_access_time":1588686353090,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":18,
        "Question_last_edit_time":1592644375060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60866431",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52278613,
        "Question_title":"Add custom packages to Azure Machine Learing Studio",
        "Question_body":"<p>I need to use the function tsCV on azure machine learning studio to evaluate models of forecast, but i got the error <\/p>\n\n<pre><code>could not find function \"tsCV\n<\/code><\/pre>\n\n<p>I'm trying to update the forecast package, but no package are loaded.\nI followed this tutorial\n<a href=\"http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html\" rel=\"noreferrer\">http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html<\/a>\nand \n<a href=\"https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/\" rel=\"noreferrer\">https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/<\/a>\nbut i dont get the same result.\nNo packages are load.<\/p>\n\n<p>I need an example of a package with R code that works o Azure ML or an update of forecast package to use tsCV function.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1536677172073,
        "Question_score":3,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":404,
        "Owner_creation_time":1515518171123,
        "Owner_last_access_time":1657119408507,
        "Owner_location":null,
        "Owner_reputation":1108,
        "Owner_up_votes":33,
        "Owner_down_votes":2,
        "Owner_views":183,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have installed the latest version of the forecast package and here are the steps I followed during the installation. <\/p>\n\n<ol>\n<li>Download latest version of CRAN<\/li>\n<li>Be sure that tsCV is working locally<\/li>\n<li>Zip all the dependencies + forecast package<\/li>\n<li>Zip all the generated zips together and upload it to the AMLStudio<\/li>\n<li>Run the following code:<\/li>\n<\/ol>\n\n<blockquote>\n<pre><code>install.packages(\"src\/glue.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/assertthat.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fansi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/utf8.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/labeling.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/munsell.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/R6.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RColorBrewer.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/cli.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/crayon.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/pillar.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/xts.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/TTR.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/curl.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/digest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/gtable.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lazyeval.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/plyr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/reshape2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/rlang.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/scales.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tibble.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/viridisLite.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/withr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quadprog.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quantmod.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/colorspace.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fracdiff.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lmtest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/magrittr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/Rcpp.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/timeDate.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tseries.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/urca.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/uroot.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/zoo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RcppArmadillo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/forecast.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(forecast, lib.loc=\".\", verbose=TRUE)\nfar2 &lt;- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}\ne &lt;- tsCV(lynx, far2, h=1)\n<\/code><\/pre>\n<\/blockquote>\n\n<p><a href=\"https:\/\/drive.google.com\/open?id=10Bj0RGCmRFrRECLQrVc26nbx3T-bNSL6\" rel=\"nofollow noreferrer\">Here is the zip I have generated:<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/bbowH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bbowH.png\" alt=\"My experiment\"><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1537192338793,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52278613",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69245175,
        "Question_title":"Error in azureml \"Non numeric value(s) were encountered in the target column.\"",
        "Question_body":"<p>I am using Automated ML to run a time series forecasting pipeline.<\/p>\n<p>When the AutoMLStep gets triggered, I get this error: <code>Non numeric value(s) were encountered in the target column<\/code>.<\/p>\n<p>The data to this step is passed through an OutputTabularDatasetConfig, after applying the read_delimited_files() on an OutputFileDatasetConfig. I've inspected the prior step, and the data is comprised of a 'Date' column and a numeric column called 'Place' with +80 observations in monthly frequencies.<\/p>\n<p>Nothing seems to be wrong with the column type or the data. I've also applied a number of techniques on the data prep side e.g. pd.to_numeric(), astype(float) to ensure it is numeric.<\/p>\n<p>I've also tried forcing this through the FeaturizationConfig() <code>add_column_purpose('Place','Numeric')<\/code> but in this case, I get another error: <code>Expected column(s) Place in featurization config's column purpose not found in X.<\/code><\/p>\n<p>Any thoughts on how to solve?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1632069680553,
        "Question_score":1,
        "Question_tags":"automl|azure-machine-learning-service",
        "Question_view_count":127,
        "Owner_creation_time":1402462976833,
        "Owner_last_access_time":1664062600860,
        "Owner_location":"Redmond, WA, United States",
        "Owner_reputation":525,
        "Owner_up_votes":70,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>So a few learnings on this interacting with the stellar Azure Machine Learning engineering team.<\/p>\n<ol>\n<li>When calling the <code>read_delimited_files()<\/code> method, ensure that the output folder does not have many inputs or files. For example, if all intermediate outputs are saved to a common folder, it may read all the prior inputs into this folder, and depending upon the shape of the data, borrow the schema from the first file, or confuse all of them together. This can lead to inconsistencies and errors. In my case, I was dumping many files to the same location, hence this was causing confusion for this method. The fix is either to distinctly mark the output folder (e.g. with a UUID) or give different paths.<\/li>\n<li>The dataframe from <code>read_delimiter_files()<\/code> may treat all columns as object type which can lead to a data type check failure (i.e. label_column needs to be numeric). To mitigate, explictly state the type. For example:<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.data import DataType\nprepped_data = prepped_data.read_delimited_files(set_column_types={&quot;Place&quot;:DataType.to_float()})\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1633037776347,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69245175",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54254830,
        "Question_title":"Running Azure Machine Learning Service pipeline locally",
        "Question_body":"<p>I'm using Azure Machine Learning Service with the azureml-sdk python library.<\/p>\n\n<p>I'm using azureml.core version 1.0.8<\/p>\n\n<p>I'm following this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline<\/a> tutorial.<\/p>\n\n<p>I've got it working when I use Azure Compute resources. But I would like to run it locally.<\/p>\n\n<p>I get the following error<\/p>\n\n<pre><code>raise ErrorResponseException(self._deserialize, response)\nazureml.pipeline.core._restclients.aeva.models.error_response.ErrorResponseException: (BadRequest) Response status code does not indicate success: 400 (Bad Request).\nTrace id: [uuid], message: Can't build command text for [train.py], moduleId [uuid] executionId [id]: Assignment for parameter Target is not specified\n<\/code><\/pre>\n\n<p>My code looks like:<\/p>\n\n<pre><code>run_config = RunConfiguration()\ncompute_target = LocalTarget()\nrun_config.target = LocalTarget()    \nrun_config.environment.python.conda_dependencies = CondaDependencies(conda_dependencies_file_path='environment.yml')\nrun_config.environment.python.interpreter_path = 'C:\/Projects\/aml_test\/.conda\/envs\/aml_test_env\/python.exe'\nrun_config.environment.python.user_managed_dependencies = True\nrun_config.environment.docker.enabled = False\n\ntrainStep = PythonScriptStep(\n    script_name=\"train.py\",\n    compute_target=compute_target,\n    source_directory='.',\n    allow_reuse=False,\n    runconfig=run_config\n)\n\nsteps = [trainStep]\n\n# Build the pipeline\npipeline = Pipeline(workspace=ws, steps=[steps])\npipeline.validate()\n\nexperiment = Experiment(ws, 'Test')\n\n# Fails, locally, works on Azure Compute\nrun = experiment.submit(pipeline)\n\n\n# Works both locally and on Azure Compute\nsrc = ScriptRunConfig(source_directory='.', script='train.py', run_config=run_config)\nrun = experiment.submit(src)\n<\/code><\/pre>\n\n<p>The <code>train.py<\/code> is a very simple self contained script only dependent on numpy that approximates pi.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1547817410513,
        "Question_score":5,
        "Question_tags":"azure-machine-learning-workbench|azure-machine-learning-service",
        "Question_view_count":2476,
        "Owner_creation_time":1313998995867,
        "Owner_last_access_time":1663912609667,
        "Owner_location":null,
        "Owner_reputation":3148,
        "Owner_up_votes":29,
        "Owner_down_votes":12,
        "Owner_views":347,
        "Question_last_edit_time":1554703788007,
        "Answer_body":"<p>Local compute cannot be used with ML Pipelines. Please see this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-set-up-training-targets#supported-compute-targets\" rel=\"noreferrer\">article<\/a>.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1548188011640,
        "Answer_score":7.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":1548188395573,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54254830",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56848293,
        "Question_title":"What is Random seed in Azure Machine Learning?",
        "Question_body":"<p>I am learning Azure Machine Learning. I am frequently encountering the <strong>Random Seed<\/strong> in some of the steps like,<\/p>\n\n<ol>\n<li>Split Data<\/li>\n<li>Untrained algorithm models as Two Class Regression, Multi-class regression, Tree, Forest,..<\/li>\n<\/ol>\n\n<p>In the tutorial, they choose Random Seed as '123'; trained model has high accuracy but when I try to choose other random integers like 245, 256, 12, 321,.. it did not do well.<\/p>\n\n<hr>\n\n<p><strong>Questions<\/strong><\/p>\n\n<ul>\n<li>What is a Random Seed Integer?<\/li>\n<li>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/li>\n<li>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/li>\n<\/ul>\n\n<hr>\n\n<p><strong>Pretext<\/strong><\/p>\n\n<ol>\n<li>I have <a href=\"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\" rel=\"nofollow noreferrer\">Iris-Sepal-Petal-Dataset<\/a> with Sepal (<em>Length &amp; Width<\/em>) and Petal (<em>Length &amp; Width<\/em>)<\/li>\n<li>Last column in data-set is 'Binomial ClassName'<\/li>\n<li>I am training the data-set with Multiclass Decision Forest Algorithm and splitting the data with different random seeds 321, 123 and 12345 in order<\/li>\n<li>It affects the final quality of trained model. Random seed#123 being best of Prediction probability score: 1.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/12OyD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/12OyD.png\" alt=\"ML Studio Snap\"><\/a><\/p>\n\n<hr>\n\n<p><strong>Observations<\/strong><\/p>\n\n<p><strong>1. Random seed: 321<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" alt=\"Random-seed-321\"><\/a><\/p>\n\n<p><strong>2. Random seed: 123<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" alt=\"Random-seed-123\"><\/a><\/p>\n\n<p><strong>3. Random seed: 12345<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" alt=\"Random-seed-12345\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":9,
        "Question_creation_time":1562056038867,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio|random-seed|iris-dataset",
        "Question_view_count":2046,
        "Owner_creation_time":1475691108437,
        "Owner_last_access_time":1658651167790,
        "Owner_location":"India",
        "Owner_reputation":1849,
        "Owner_up_votes":366,
        "Owner_down_votes":21,
        "Owner_views":253,
        "Question_last_edit_time":1562066943383,
        "Answer_body":"<blockquote>\n  <p>What is a Random Seed Integer?<\/p>\n<\/blockquote>\n\n<p>Will not go into any details regarding what a random seed is in general; there is plenty of material available by a simple web search (see for example <a href=\"https:\/\/stackoverflow.com\/questions\/22639587\/random-seed-what-does-it-do\">this SO thread<\/a>).<\/p>\n\n<p>Random seed serves just to initialize the (pseudo)random number generator, mainly in order to make ML examples reproducible.<\/p>\n\n<blockquote>\n  <p>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/p>\n<\/blockquote>\n\n<p>Arguably this is already answered implicitly above: you are simply not supposed to choose any particular random seed, and your results should be roughly the same across different random seeds.<\/p>\n\n<blockquote>\n  <p>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/p>\n<\/blockquote>\n\n<p>Now, to the heart of your question. The answer <em>here<\/em> (i.e. with the iris dataset) is the <strong>small-sample effects<\/strong>...<\/p>\n\n<p>To start with, your reported results across different random seeds are not <em>that<\/em> different. Nevertheless, I agree that, at first sight, a difference in macro-average precision of 0.9 and 0.94 might <em>seem<\/em> large; but looking more closely it is revealed that the difference is really not an issue. Why?<\/p>\n\n<p>Using the 20% of your (only) 150-samples dataset leaves you with only 30 samples in your test set (where the evaluation is performed); this is stratified, i.e. about 10 samples from each class. Now, for datasets of <em>that<\/em> small size, it is not difficult to imagine that a difference in the correct classification of <strong>only 1-2<\/strong> samples can have this apparent difference in the performance metrics reported.<\/p>\n\n<p>Let's try to verify this in scikit-learn using a decision tree classifier (the essence of the issue does not depend on the specific framework or the ML algorithm used):<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_iris(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321, stratify=y)\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n<\/code><\/pre>\n\n<p>Result:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  9  1]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.90      0.95        10\n           2       0.91      1.00      0.95        10\n\n   micro avg       0.97      0.97      0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n<\/code><\/pre>\n\n<p>Let's repeat the code above, changing only the <code>random_state<\/code> argument in <code>train_test_split<\/code>; for <code>random_state=123<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  7  3]\n [ 0  2  8]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.78      0.70      0.74        10\n           2       0.73      0.80      0.76        10\n\n   micro avg       0.83      0.83      0.83        30\n   macro avg       0.84      0.83      0.83        30\nweighted avg       0.84      0.83      0.83        30\n<\/code><\/pre>\n\n<p>while for <code>random_state=12345<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  8  2]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.80      0.89        10\n           2       0.83      1.00      0.91        10\n\n   micro avg       0.93      0.93      0.93        30\n   macro avg       0.94      0.93      0.93        30\nweighted avg       0.94      0.93      0.93        30\n<\/code><\/pre>\n\n<p>Looking at the <em>absolute numbers<\/em> of the 3 confusion matrices (in <em>small samples<\/em>, percentages can be <strong>misleading<\/strong>), you should be able to convince yourself that the differences are not that big, and they can be arguably justified by the random element inherent in the whole procedure (here the exact split of the dataset into training and test).<\/p>\n\n<p>Should your test set be significantly bigger, these discrepancies would be practically negligible... <\/p>\n\n<p>A last notice; I have used the exact same seed numbers as you, but this does not actually mean anything, as in general the random number generators <em>across<\/em> platforms &amp; languages are not the same, hence the corresponding seeds are not actually compatible. See own answer in <a href=\"https:\/\/stackoverflow.com\/questions\/52293899\/are-random-seeds-compatible-between-systems\">Are random seeds compatible between systems?<\/a> for a demonstration.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1562069850057,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1562070151170,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56848293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69113428,
        "Question_title":"Model deployment in Azure ML",
        "Question_body":"<p>I am a beginner in the Azure. I am using this tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a> of setting a dummy script for a local web service but many errors are coming up. It is strange because I am using an h5 file (model involving Keras and tensor flow) in place of onxx file. I used the code<\/p>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.model import InferenceConfig\n\nenv = Environment(name=&quot;myenv&quot;)\nconda_dep = CondaDependencies()\nconda_dep.add_conda_package(&quot;tensorflow&quot;)\nconda_dep.add_conda_package(&quot;pip&quot;)\nconda_dep.add_pip_package(&quot;azureml-core&quot;)\nconda_dep.add_pip_package(&quot;azureml-contrib-services&quot;)\nenv.python.conda_dependencies=conda_dep\ninference_config = InferenceConfig(\n    environment=env,\n    source_directory=&quot;.\/source_dir&quot;,\n    entry_script=&quot;.\/echo_score.py&quot;,\n)\n \n<\/code><\/pre>\n<p>There is a Error<\/p>\n<pre><code>ERROR: Could not find a version that satisfies the requirement pickle (from -r \/azureml-environment-setup\/condaenv.4f206b3i.requirements.txt (line 5)) (from versions: none)\n<\/code><\/pre>\n<p>I have tried many times and getting error. Can anyone help.\nMy azureml core is 1.34.0 and python version 3.8.11.I am also not sure if it is a pickle protocol error. Pickle version in my system is 4.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1631169973543,
        "Question_score":0,
        "Question_tags":"python|azure-web-app-service|web-deployment|azure-machine-learning-service",
        "Question_view_count":185,
        "Owner_creation_time":1622179709977,
        "Owner_last_access_time":1632984750927,
        "Owner_location":"Singapore",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1631796790997,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69113428",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40302499,
        "Question_title":"Recommendation API: what is the difference between null results and empty results",
        "Question_body":"<p>In the Azure Recommendation API sample there is a snippet like this:<\/p>\n\n<pre><code>     if (itemSets.RecommendedItemSetInfo != null)\n        {\n            ...\n        }\n        else\n        {\n            Console.WriteLine(\"No recommendations found.\");\n        }\n<\/code><\/pre>\n\n<p>So I assume that nullable recommended set means no recommendations. But what is the case with this set being not nullable but still empty ( as I am having it running the example)?<\/p>\n\n<p>I provided my own usages and catalog files. I have not too many entries there however for i2i recommendations I have results and for u2i there is an empty set.\nAllowColdItemPlacement doesn't change a think here.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1477648288960,
        "Question_score":0,
        "Question_tags":"azure|microsoft-cognitive|azure-machine-learning-studio",
        "Question_view_count":130,
        "Owner_creation_time":1354118434117,
        "Owner_last_access_time":1613750840957,
        "Owner_location":"Wroc\u0142aw, Poland",
        "Owner_reputation":393,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":"<p>We did not mean to convey a difference in meaning between null recommendations and empty recommendations. I will check why we may be sending two different types of results. Either way, don't treat those two cases as different cases. <\/p>\n\n<p>If you are not getting results for user-to-item recommendations, most likely there was no data for that user when the build was created or the items that the user interacted with do not have enough co-occurrences with other items in the usage.<\/p>\n\n<p>What to do when you get empty recommendations is up to you, you may decide to not show any recommendations, or back-fill with popular items you may want to promote.<\/p>\n\n<p>Thanks!<\/p>\n\n<p>Luis Cabrera\nProgram Manager - Recommendations API.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1478186851717,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40302499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39483984,
        "Question_title":"R package ( qdapTools) version not getting detected correctly in Azure ML",
        "Question_body":"<p>I'm trying to install qdap package in Azure ML. Rest of the dependent packages get installed without any issues. When it comes to qdapTools, I get this error , though the version that I try to install is 1.3.1 ( Verified this from the Decription file that comes with the R package)<\/p>\n\n<pre><code>package 'qdapTools' 1.1.0 was found, but &gt;= 1.3.1 is required by 'qdap\n<\/code><\/pre>\n\n<p>The code in \"Execute R Script\" :<\/p>\n\n<pre><code>install.packages(\"src\/qdapTools.zip\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/magrittr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdapDictionaries.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdapRegex.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RColorBrewer.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdap.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(stringr, lib.loc=\".\", verbose=TRUE)\nlibrary(qdap, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>And the log : <\/p>\n\n<pre><code>[ModuleOutput] End R Execution: 9\/22\/2016 6:44:44 AM\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:16.7828106\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\npackage 'qdapTools' 1.1.0 was found, but &gt;= 1.3.1 is required by 'qdap'\n\n\npackage 'qdapTools' 1.1.0 was found, but &gt;= 1.3.1 is required by 'qdap'\n----------- End of error message from R -----------\n[Critical]     {\"InputParameters\":{\"DataTable\":[{\"Rows\":2,\"Columns\":1,\"estimatedSize\":11767808,\"ColumnTypes\":{\"System.String\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[2,0]}}],\"Generic\":{\"bundlePath\":\"..\\\\..\\\\Script Bundle\\\\Script Bundle.zip\",\"rLibVersion\":\"R310\"},\"Unknown\":[\"Key: rStreamReader, ValueType : System.IO.StreamReader\"]},\"OutputParameters\":[],\"ModuleType\":\"LanguageWorker\",\"ModuleVersion\":\" Version=6.0.0.0\",\"AdditionalModuleInfo\":\"LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\",\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0063: The following error occurred during evaluation of R script:\\r\\n---------- Start of error message from R ----------\\r\\npackage 'qdapTools' 1.1.0 was found, but &gt;= 1.3.1 is required by 'qdap'\\r\\n\\r\\n\\r\\npackage 'qdapTools' 1.1.0 was found, but &gt;= 1.3.1 is required by 'qdap'\\r\\n----------- End of error message from R -----------\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.ExecuteR(NewRWorker worker, DataTable dataset1, DataTable dataset2, IEnumerable`1 bundlePath, StreamReader rStreamReader, Nullable`1 seed) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 287\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS._RunImpl(NewRWorker worker, DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptExternalResource source, String url, ExecuteRScriptGitHubRepositoryType githubRepoType, SecureString accountToken) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 207\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.RunRSNR(DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptRVersion rLibVersion) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\REntryPoint.cs:line 105\",\"Warnings\":[],\"Duration\":\"00:00:16.7752607\"}\nModule finished after a runtime of 00:00:17.1411124 with exit code -2\nModule failed due to negative exit code of -2\n\nRecord Ends at UTC 09\/22\/2016 06:44:44.\n<\/code><\/pre>\n\n<p>Editing the code to : <\/p>\n\n<pre><code>install.packages(\"src\/qdapTools.zip\",lib=\".\" , repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdapDictionaries.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdapRegex.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RColorBrewer.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/qdap.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nlibrary(qdapTools, lib.loc=\".\", verbose=TRUE)\nlibrary(qdap, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>throws the following error :- <\/p>\n\n<pre><code>[ModuleOutput] 4: package 'qdapTools' was built under R version 3.3.1 \n[ModuleOutput] \n[ModuleOutput] End R Execution: 9\/22\/2016 7:11:05 AM\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:17.0656414\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\npackage or namespace load failed for 'qdapTools'\n\n\npackage or namespace load failed for 'qdapTools'\n----------- End of error message from R -----------\n<\/code><\/pre>\n\n<p>Not sure how to proceed, can someone help please.<\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_time":1473835293153,
        "Question_score":10,
        "Question_tags":"r|azure-machine-learning-studio|qdap",
        "Question_view_count":443,
        "Owner_creation_time":1370288261667,
        "Owner_last_access_time":1663937917137,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":1353,
        "Owner_up_votes":80,
        "Owner_down_votes":7,
        "Owner_views":524,
        "Question_last_edit_time":1474530017473,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39483984",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69402391,
        "Question_title":"Merge distinct sklearn models into a single one",
        "Question_body":"<p>I have a dataset where, after exploring data, I detect some patron:<\/p>\n<ul>\n<li>The entire dataset have, imagine, 9 numerical variables, 1 dichotomous variable (take 'A' or 'B' value) and 1 numerical output<\/li>\n<li>The output is a cost (in \u20ac)<\/li>\n<li>I find a sklearn regression model that, when 'A', using 4 of 9 variables I can predict output with good performance.<\/li>\n<li>I find another sklearn regression model that, when 'B', using the last 5 variables, I can predict output with good performance.<\/li>\n<li>If I try to find a model which predict output with all the variables as input, encoding the dichotomous one with One-Hot-Encoder, the model has a bad performance.<\/li>\n<\/ul>\n<p>My goal is to implement a unique model in Azure Machine Learning, using a .joblib\/.pkl, but with this approach, I have two separated models with the same output (a cost) but different inputs, depending of dichotomous variable.<\/p>\n<p>Is there any way to merge the two models into a single one? So that with the 10 inputs, estimate a single output (internally discriminate options 'A' and 'B' to select the correct model and its inputs).<\/p>\n<p>Notice that using something like Voting Ensemble it's not valid because there are different inputs on each category (or I think it so)<\/p>\n<p>I accept another approach as a solution. Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1633074956947,
        "Question_score":0,
        "Question_tags":"python|machine-learning|scikit-learn|categorical-data|azure-machine-learning-service",
        "Question_view_count":119,
        "Owner_creation_time":1611139028547,
        "Owner_last_access_time":1663993378950,
        "Owner_location":"Vigo, Espa\u00f1a",
        "Owner_reputation":39,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69402391",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54287231,
        "Question_title":"Modifying loss function faster rcnn detectron",
        "Question_body":"<p>For my thesis I am trying to modify the loss function of faster-rcnn with regards to recognizing table structures.<\/p>\n\n<p>Currently I am using Facebooks Detectron. Seems to be working great but I am now actively trying to modify the loss function. Debugging my code I notice this is where the loss functions are added <a href=\"https:\/\/github.com\/facebookresearch\/Detectron\/blob\/master\/detectron\/modeling\/fast_rcnn_heads.py#L75\" rel=\"nofollow noreferrer\">fast_rcnn_heads.py:75<\/a>:<\/p>\n\n<pre><code>def add_fast_rcnn_losses(model):\n\"\"\"Add losses for RoI classification and bounding box regression.\"\"\"\ncls_prob, loss_cls = model.net.SoftmaxWithLoss(\n    ['cls_score', 'labels_int32'], ['cls_prob', 'loss_cls'],\n    scale=model.GetLossScale()\n)\nloss_bbox = model.net.SmoothL1Loss(\n    [\n        'bbox_pred', 'bbox_targets', 'bbox_inside_weights',\n        'bbox_outside_weights'\n    ],\n    'loss_bbox',\n    scale=model.GetLossScale()\n)\nloss_gradients = blob_utils.get_loss_gradients(model, [loss_cls, loss_bbox])\nmodel.Accuracy(['cls_prob', 'labels_int32'], 'accuracy_cls')\nmodel.AddLosses(['loss_cls', 'loss_bbox'])\nmodel.AddMetrics('accuracy_cls')\nreturn loss_gradients\n<\/code><\/pre>\n\n<p>The debugger cant find any declaration or implementation of mode.net.SmoothL1Loss nor SoftmaxWithLoss. Detectron uses caffe, and when I look in the net_builder (which inits the model.net) I see it makes \"binds\"(dont know the proper word) to caffe2, which on itself is a pylib with a compiled lib behind it. <\/p>\n\n<p>Am I looking in the wrong place to make a minor adjustment to this loss function, or will I really have to open de source from dcaffe, adjust the loss, recompile the lib? <\/p>\n\n<p>Greets, <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1548064081110,
        "Question_score":2,
        "Question_tags":"machine-learning|computer-vision|image-recognition|azure-machine-learning-studio|caffe2",
        "Question_view_count":1281,
        "Owner_creation_time":1548063410383,
        "Owner_last_access_time":1548176015840,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54287231",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35411741,
        "Question_title":"Azure ML: Getting Error 503: NoMoreResources to any web service API even when I only make 1 request",
        "Question_body":"<p>Getting the following response even when I make one request (concurrency set to 200) to a web service. <\/p>\n\n<p>{ status: 503, headers: '{\"content-length\":\"174\",\"content-type\":\"application\/json; charset=utf-8\",\"etag\":\"\\\"8ce068bf420a485c8096065ea3e4f436\\\"\",\"server\":\"Microsoft-HTTPAPI\/2.0\",\"x-ms-request-id\":\"d5c56cdd-644f-48ba-ba2b-6eb444975e4c\",\"date\":\"Mon, 15 Feb 2016 04:54:01 GMT\",\"connection\":\"close\"}',  body: '{\"error\":{\"code\":\"ServiceUnavailable\",\"message\":\"Service is temporarily unavailable.\",\"details\":[{\"code\":\"NoMoreResources\",\"message\":\"No resources available for request.\"}]}}' }<\/p>\n\n<p>The request-response web service is a recommender retraining web service with the training set containing close to 200k records. The training set is already present in my ML studio dataset, only 10-15 extra records are passed in the request. The same experiment was working flawlessly till 13th Feb 2016. I have already tried increasing the concurrency but still the same issue. I even reduced the size of the training set to 20 records, still didn't work.<\/p>\n\n<p>I have two web service both doing something similar and both aren't working since 13th Feb 2016. <\/p>\n\n<p>Finally, I created a really small experiment ( skill.csv --> split row ---> web output )   which doesn't take any input. It just has to return some part of the dataset. Did not work, response code 503.<\/p>\n\n<p>The logs I got are as follows<\/p>\n\n<p>{\n  \"version\": \"2014-10-01\",\n  \"diagnostics\": [{\n    .....\n    {\n      \"type\": \"GetResourceEndEvent\",\n      \"timestamp\": 13.1362,\n      \"resourceId\": \"5e2d653c2b214e4dad2927210af4a436.865467b9e7c5410e9ebe829abd0050cd.v1-default-111\",\n      \"status\": \"Failure\",\n      \"error\": \"The Uri for the target storage location is not specified. Please consider changing the request's location mode.\"\n    },\n    {\n      \"type\": \"InitializationSummary\",\n      \"time\": \"2016-02-15T04:46:18.3651714Z\",\n      \"status\": \"Failure\",\n      \"error\": \"The Uri for the target storage location is not specified. Please consider changing the request's location mode.\"\n    }\n  ]\n}<\/p>\n\n<p>What am I missing? Or am I doing it completely wrong?<\/p>\n\n<p>Thank you in advance.<\/p>\n\n<p>PS: Data is stored in mongoDB and then imported as CSV<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1455545889500,
        "Question_score":1,
        "Question_tags":"azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":283,
        "Owner_creation_time":1425802890213,
        "Owner_last_access_time":1662088405513,
        "Owner_location":"Boston, MA, USA",
        "Owner_reputation":41,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":1456850010663,
        "Answer_body":"<p>This was an Azure problem. I quote the Microsoft guy, <\/p>\n\n<blockquote>\n  <p>We believe we have isolated the issue impacting tour service and we are currently working on a fix. We will be able to deploy this in the next couple of days. The problem is impacting only the ASIA AzureML region at this time, so if this is an option for you, might I suggest using a workspace in either the US or EU region until the fix gets rolled out here.<\/p>\n<\/blockquote>\n\n<p>To view the complete discussion, click <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/985e253e-5e54-45a5-a359-5c501152c445\/getting-error-503-nomoreresources-to-any-web-service-api-even-when-i-only-make-1-request?forum=MachineLearning&amp;prof=required\" rel=\"nofollow\">here<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1455597422633,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35411741",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70279636,
        "Question_title":"Azure Auto ML JobConfigurationMaxSizeExceeded error when using a cluster",
        "Question_body":"<p>I am running into the following error when I try to run Automated ML through the studio on a GPU compute cluster:<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/uLyxr.png\" alt=\"Azure ML error message\" \/><\/p>\n<blockquote>\n<p>Error: AzureMLCompute job failed. JobConfigurationMaxSizeExceeded: The\nspecified job configuration exceeds the max allowed size of 32768\ncharacters. Please reduce the size of the job's command line arguments\nand environment settings<\/p>\n<\/blockquote>\n<p>The attempted run is on a registered tabulated dataset in filestore and is a simple regression case. Strangely, it works just fine with the CPU compute instance I use for my other pipelines. I have been able to run it a few times using that and wanted to upgrade to a cluster only to be hit by this error. I found online that it could be a case of having the following setting: AZUREML_COMPUTE_USE_COMMON_RUNTIME:false; but I am not sure where to put this in when just running from the web studio.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1638986274657,
        "Question_score":5,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":171,
        "Owner_creation_time":1592412555903,
        "Owner_last_access_time":1663862196937,
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1641204588637,
        "Answer_body":"<p>It looks like the bug was fixed. I just ran it on a cluster without changing any of the parameters. Thank you Yutong for the help!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1639585163673,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70279636",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35600907,
        "Question_title":"Azure ML Web Service request not working in C#",
        "Question_body":"<p>I have created an Azure ML Web service which outputs JSON response on request, and the structure of the sample request is as following:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"gender\",\n        \"age\",\n        \"income\"\n      ],\n      \"Values\": [\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ],\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>And the input parameters are supposedly like this:<\/p>\n\n<p>gender  String<br>\nage Numeric<br>\nincome  Numeric     <\/p>\n\n<p>My Post method looks like this:<\/p>\n\n<pre><code>    [HttpPost]\n        public ActionResult GetPredictionFromWebService()\n        {\n            var gender = Request.Form[\"gender\"];\n            var age = Request.Form[\"age\"];\n\n\n            if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n            {\n                var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = Int32.Parse(result[0, 2])\n                    };\n                }\n            }\n\n\n\n\n            return RedirectToAction(\"index\");\n        }\n<\/code><\/pre>\n\n<p>But for whatever reason; the Azure ML Webservice doesn\u2019t seem to respond anything to my request.\nDoes anyone know what the reason might be? I see no error or anything, just an empty response.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1456313293347,
        "Question_score":0,
        "Question_tags":"c#|asp.net|azure|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":480,
        "Owner_creation_time":1456309738853,
        "Owner_last_access_time":1471868452243,
        "Owner_location":null,
        "Owner_reputation":39,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1456839908307,
        "Answer_body":"<p>The answer to your problem is that the \u201cNumeric\u201d datatype which is written in the input parameters in Azure ML is in fact a float and not an integer for your income measure. So when trying to request a response from Azure ML, you are not providing it the \u201cadequate\u201d information needed in the right format for it to respond correctly, resulting in it not giving you any response.<\/p>\n\n<p>I believe your model would look something similar to this based on your input parameters:<\/p>\n\n<pre><code>public class Person\n    {\n        public string Gender { get; set; }\n        public int Age { get; set; }\n        public int Income { get; set; }\n\n\n        public override string ToString()\n        {\n            return Gender + \",\" + Age + \",\" + Income;\n        }\n    }\n<\/code><\/pre>\n\n<p>You would have to change your Income datatype into float like so:<\/p>\n\n<pre><code>public class Person\n{\n    public string Gender { get; set; }\n    public int Age { get; set; }\n    public float Income { get; set; }\n\n    public override string ToString()\n    {\n        return Gender + \",\" + Age + \",\" + Income;\n    }\n}\n<\/code><\/pre>\n\n<p>And then your post-method would look something like this:<\/p>\n\n<pre><code>    [HttpPost]\n    public ActionResult GetPredictionFromWebService()\n    {\n        var gender = Request.Form[\"gender\"];\n        var age = Request.Form[\"age\"];\n\n        if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n        {\n            var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n                };\n            }\n        }\n\n        ViewBag.myData = PersonResult.Income.ToString();\n        return View(\"Index\");\n    }\n<\/code><\/pre>\n\n<p>The key here is simply:<\/p>\n\n<pre><code>Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n<\/code><\/pre>\n\n<p>Rather than your legacy <\/p>\n\n<pre><code>Income = Int32.Parse(result[0, 2])\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1456314151450,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35600907",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53891907,
        "Question_title":"Pandas dataframe and apply - Can't figure out why resulting values are negative",
        "Question_body":"<p>Here's a picture of my data, the column of interest RUL is on the far right the names got cut off (I'm using the Turbo Engine Degradation dataset from NASA) can be found here: <a href=\"https:\/\/data.nasa.gov\/widgets\/vrks-gjie\" rel=\"nofollow noreferrer\">https:\/\/data.nasa.gov\/widgets\/vrks-gjie<\/a><\/p>\n\n<p>I'm doing this in Azure ML Studio but code snippet below, I have 2 helper functions get_engine_last_cycle (which when I unit test it seems to do as expected - compute the last cycle for that engine, for example engine 2 has a max cycle in this dataset of 287 when it fails). The final helper function I call get_engine_remainig_life, takes the engine and cycle as arguments and returns the max cycle - current cycle for that engine (again I've unit tested this and it seems to give me expected results).<\/p>\n\n<p>For some reason this isn't working when I run my notebook. The column which I call \"RUL\" should return a sequence of decreasing, positive integers for example 287, 286, 285 284, etc for engine #2. However, it's giving me negative values. I can't seem to figure out why but know the problem is likely with this one piece of code<\/p>\n\n<pre><code> df['RUL'] = df[['engine', 'cycle']].apply(lambda x: get_engine_remaining_life(*x), axis=1)\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/8IYOx.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8IYOx.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<pre><code>    def get_engine_last_cycle(engine):\n        return int(df.loc[engine, ['cycle']].max())\n\n\n    def get_engine_remaining_life(engine, cycle):\n        return get_engine_last_cycle(engine) - int(cycle)\n\n    df['RUL'] = df[['engine', 'cycle']].apply(lambda x: get_engine_remaining_life(*x), axis=1)\n\n    return df\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1545435517580,
        "Question_score":0,
        "Question_tags":"pandas|azure-machine-learning-studio",
        "Question_view_count":66,
        "Owner_creation_time":1442451471347,
        "Owner_last_access_time":1591385407297,
        "Owner_location":null,
        "Owner_reputation":338,
        "Owner_up_votes":49,
        "Owner_down_votes":1,
        "Owner_views":79,
        "Question_last_edit_time":1545438768860,
        "Answer_body":"<p>Just for the sake of trying, this is how I'd implement this. Maybe it will help you.<\/p>\n\n<pre><code>df['RUL'] = df.loc[:, ['engine', 'cycle']].groupby('engine').transform('max')\ndf['RUL'] = df['RUL'] - df['cycle']\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1545439231323,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53891907",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48087407,
        "Question_title":"How to deal with missing values in Azure Machine Learning Studio",
        "Question_body":"<p>Looks like I have 672 mission values, according to statistics. \nThere are NULL value in QuotedPremium column.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/p9Z3X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/p9Z3X.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I implemented Clean Missing Data module where it should substitute missing values with 0, but for some reason I'm still seeing NULL values as QuotedPremium, but...it says that missing values are = 0<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PDg97.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PDg97.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/BEdHD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BEdHD.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Here you see it tells me that missing values = 0, but there are still NULLs <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WKlGZ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WKlGZ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>So what really happened after I ran Clean Missing Data module? Why it ran succesfully but there are still NULL values, even though it tells that number of missing values are 0. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1515028540763,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|ml-studio",
        "Question_view_count":1556,
        "Owner_creation_time":1457596845393,
        "Owner_last_access_time":1663977598457,
        "Owner_location":"San Diego, CA, United States",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Question_last_edit_time":null,
        "Answer_body":"<p><code>NULL<\/code> is indeed a value; entries containing NULLs are <em>not<\/em> missing, hence they are neither cleaned with the 'Clean Missing Data' operator nor reported as missing.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1515030180700,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48087407",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47052996,
        "Question_title":"how to upload multiple files to azure blob storage using azure machine Learning",
        "Question_body":"<p>I have come across a requirement wherein the first part involves reading a blob file (i.e. .csv) present in Azure blob storage and splitting the file data into multiple files, based on the distinct combination of few columns. The second part of the requirement involves writing\/uploading the multiple files to Azure blob Storage at a separate destination folder. <\/p>\n\n<p>I am able to split the blob file into multiple files, but am not able to write\/upload the partitioned files on to azure blob storage. Is there any possibility to write the files to blob storage. Any help will be highly appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1509532865763,
        "Question_score":0,
        "Question_tags":"file|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":1317,
        "Owner_creation_time":1509532022647,
        "Owner_last_access_time":1510059988850,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1653556441370,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47052996",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73193412,
        "Question_title":"Azure Machine Learning Compute Instance Not Creating using Azure CLI and Azure DevOps Pipeline",
        "Question_body":"<p>I create my Azure Machine Learning Workspace using Azure CLI:<\/p>\n<pre><code>$env=&quot;prd&quot;\n$instance=&quot;001&quot;\n$location=&quot;uksouth&quot;\n$suffix=&quot;predict-$env-$location-$instance&quot;\n\n$rg=&quot;rg-$suffix&quot;\n$ws=&quot;mlw-$suffix&quot;\n$computeinstance=&quot;vm-$suffix&quot;.Replace('-','')\n$computeinstance\naz group create --name $rg --location $location\naz configure --defaults group=$rg\naz ml workspace create --name $ws\naz configure --defaults workspace=$ws\naz ml compute create --name $computeinstance --size Standard_DS11_v2 --type ComputeInstance\n<\/code><\/pre>\n<p>I run the above code manually in Visual Studio Code, and everything works properly.<\/p>\n<p>However, when I integrate the above into an Azure DevOps pipeline via the YAML:<\/p>\n<pre><code>steps:\n - bash: az extension add -n ml\n    displayName: 'Install Azure ml extension'\n - task: AzureCLI@2\n    inputs:\n      azureSubscription: &quot;$(AZURE_RM_SVC_CONNECTION)&quot;\n      scriptType: 'ps'\n      scriptLocation: 'scriptPath'\n      scriptPath: '.\/environment_setup\/aml-cli.ps1'\n<\/code><\/pre>\n<ul>\n<li>The pipeline creates the Azure Machine Learning workspace as expected.<\/li>\n<li>The pipeline creates the compute instance, which has the status <strong>&quot;Running&quot;<\/strong> and green status.<\/li>\n<li>However, the compute instance has all applications <strong>greyed out<\/strong>. This means I cannot connect to the compute instance using a terminal, notebook or otherwise, essentially making it useless. The application links in the following screenshot are not clickable:<\/li>\n<\/ul>\n<p><a href=\"https:\/\/i.stack.imgur.com\/OUzpx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OUzpx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I attempted:<\/p>\n<ul>\n<li>Specifying brand new resource names.<\/li>\n<li>Creating the workspace and compute in separate pipelines in case of a timing issue.<\/li>\n<li>Deleting the resource group first using:<\/li>\n<\/ul>\n<pre><code>az group delete -n rg-predict-prd-uksouth-001 --force-deletion-types Microsoft.Compute\/virtualMachines --yes\n<\/code><\/pre>\n<p>All to no avail.<\/p>\n<p>How do I create a useable Azure Machine Learning compute instance using Azure CLI and Azure DevOps pipelines?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659355627063,
        "Question_score":0,
        "Question_tags":"yaml|continuous-integration|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":105,
        "Owner_creation_time":1220819112600,
        "Owner_last_access_time":1662642319957,
        "Owner_location":"Wales, United Kingdom",
        "Owner_reputation":1462,
        "Owner_up_votes":65,
        "Owner_down_votes":6,
        "Owner_views":285,
        "Question_last_edit_time":1659356245777,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73193412",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48043434,
        "Question_title":"Azure Machine Learning Studio Conditional Training Data",
        "Question_body":"<p>I have built an <strong>Microsoft Azure ML Studio<\/strong> workspace predictive web service, and have a scernario where I need to be able to run the service with different training datasets. <\/p>\n\n<p>I know I can setup multiple web services via Azure ML, each with a different training set attached, but I am trying to find a way to do it all within the same workspace and passing a <code>Web Input Parameter<\/code> as the input value to choose which training set to use.<\/p>\n\n<p>I have found <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2017\/06\/19\/loading-a-trained-model-dynamically-in-an-azure-ml-web-service\/\" rel=\"nofollow noreferrer\">this<\/a> article, which describes <em>almost<\/em> my scenario. However, this article relies on the training dataset that is being pulled from the <code>Load Trained Data<\/code> module, as having a static endpoint (or blob storage location). I don't see any way to dynamically (or conditionally) change this location based on a <code>Web Input Parameter<\/code>. <\/p>\n\n<p><strong>Basically, does Azure ML support a \"conditional training data\" loading?<\/strong><\/p>\n\n<p>Or, might there be a way to combine training datasets, then filter based on the passed <code>Web Input Parameter<\/code>?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1514731984430,
        "Question_score":0,
        "Question_tags":"machine-learning|conditional|azure-machine-learning-studio",
        "Question_view_count":252,
        "Owner_creation_time":1269906749850,
        "Owner_last_access_time":1663614060847,
        "Owner_location":"New York",
        "Owner_reputation":11705,
        "Owner_up_votes":138,
        "Owner_down_votes":5,
        "Owner_views":794,
        "Question_last_edit_time":1514740425440,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48043434",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65586756,
        "Question_title":"How connect Azure Function with my own model? It is possible to use Azure Storage?",
        "Question_body":"<h3>Intro<\/h3>\n<p>I created my own model locally and then register it and deploy it to azure and it works.<\/p>\n<h3>deployed model output:<\/h3>\n<p><a href=\"https:\/\/i.stack.imgur.com\/gaLCH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gaLCH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h3>my approach<\/h3>\n<p>I used <a href=\"https:\/\/medium.com\/microsoftazure\/deploying-azure-machine-learning-containers-41bcb02a4e1b\" rel=\"nofollow noreferrer\">this tutorial<\/a>, and I want use my model in Azure Function and I can do it:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def main(req: func.HttpRequest, msg: func.Out[func.QueueMessage]) -&gt; str:\n    name = req.params.get('name')\n    scoring_uri = 'http:\/\/1f72b1bf-5ca9-42d9-bedd-f41773591a4f.francecentral.azurecontainer.io\/score'\n    headers = {'Content-Type':'application\/json'}\n    test_data = json.dumps({'text': 'Today is a great day!'})\n    response = requests.post(scoring_uri, data=test_data, headers=headers)\n\nif not name:\n    try:\n        req_body = req.get_json()\n    except ValueError:\n        pass\n    else:\n        name = req_body.get('name')\n\nif name:\n    msg.set(name)\n    return func.HttpResponse(f&quot;Hello {name}! Najlepszy wynik: {response.json()}&quot;)\nelse:\n    return func.HttpResponse(\n        &quot;Please pass a name on the query string or in the request body&quot;,\n        status_code=400\n    )\n<\/code><\/pre>\n<h3>questions<\/h3>\n<ol>\n<li>Is my usage correct?<\/li>\n<li>Is it possible to use azure storage for model storage and how to do it?<\/li>\n<li>Is there any other way to use the model in Azure Function?<\/li>\n<\/ol>\n<p>I am wondering because I had specified in the requirements that I should use azure functions and azure storage. I don't understand why.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1609881766290,
        "Question_score":0,
        "Question_tags":"azure|azure-functions|azure-storage|azure-machine-learning-service",
        "Question_view_count":210,
        "Owner_creation_time":1605834001337,
        "Owner_last_access_time":1618085210227,
        "Owner_location":null,
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Question_last_edit_time":1609945294497,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65586756",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71669344,
        "Question_title":"AzureML webservice deployment with custom Environment - \/var\/runit does not exist",
        "Question_body":"<p>I'm struggling to deploy a model with a custom environment through the azureml SDK.<\/p>\n<p>I have built a docker image locally and pushed it to azure container registry to use it for environment instantiating. This is how my dockerfile looks like:<\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04\nFROM python:3.9.12\n        \n# Keeps Python from generating .pyc files in the container\nENV PYTHONDONTWRITEBYTECODE=1\n        \n# Turns off buffering for easier container logging\nENV PYTHONUNBUFFERED=1\n        \n# Install requirement for deploying the service\nRUN apt-get update\nRUN apt-get install -y runit\n        \n# Install pip requirements\nRUN pip install --upgrade pip\nCOPY requirements.txt .\nRUN pip install azureml-defaults\nRUN pip install -r requirements.txt\n<\/code><\/pre>\n<p>I want to deploy the webservice locally for testing, so I am following the steps according to official documentation:<\/p>\n<pre><code>ws = Workspace(\n    subscription_id='mysub_id', \n    resource_group='myresource_group', \n    workspace_name='myworkspace'\n)\n        \nmodel = Model.register(\n    ws, \n    model_name='mymodel', \n    model_path='.\/Azure_Deployment\/mymodel_path'\n)\n        \ncontainer = ContainerRegistry()\ncontainer.address = 'myaddress'\nmyenv = Environment.from_docker_image('myenv_name', 'img\/img_name:v1', container)\n        \ninference_config = InferenceConfig(\n    environment=myenv, \n    source_directory='.\/Azure_Deployment', \n    entry_script='echo_score.py',\n)\n        \ndeployment_config = LocalWebservice.deploy_configuration(port=6789)\n        \nservice = Model.deploy(\n    ws, \n    &quot;myservice&quot;, \n    [model], \n    inference_config, \n    deployment_config, \n    overwrite=True,\n)\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>This is what I get from the logs:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/GLafe.png\" rel=\"nofollow noreferrer\">service container logs<\/a><\/p>\n<p>Checking into the resulting container for the service I can see indeed there is no \/runit folder inside \/var. There is also no other folders created for the service besides the azureml-app containing my model's files.<\/p>\n<p>I would really appreciate any insights to what's going on here as I have no clue at this point.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1648591923567,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":156,
        "Owner_creation_time":1648585295487,
        "Owner_last_access_time":1650433060933,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71669344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40844351,
        "Question_title":"R code on Azure Machine Learning is slow compared to local execution time",
        "Question_body":"<p>Getting straight to it:\nWhy is my R code doing fine on my local CPU (under one minute), but tens of times slower on Azure Machine Learning, using one R script block (over 18 minutes)?<\/p>\n\n<p>I assume that it has to do with the resources allocated to the experiment, but how can I be sure? Can I obtain details about the resource allocated to the R script block from somwehere hidden in the Azure-ML Studio machinery?<\/p>\n\n<p>Thank you, Flo<\/p>\n\n<p>Later Edit:\nAs it often happens, I did finally find some information, which still doesn't solve my issue. According to <a href=\"https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes\" rel=\"nofollow noreferrer\">https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes<\/a> \"User-specified R code is run by a 64-bit R interpreter that runs in Azure using an A8 virtual machine with 56 GB of RAM.\"<\/p>\n\n<p>This is more than my local machine has, the R code is still much slower on the Azure-ML studio.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_time":1480336059453,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":733,
        "Owner_creation_time":1459503032960,
        "Owner_last_access_time":1512467737783,
        "Owner_location":"Vienna, Austria",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1480338194650,
        "Answer_body":"<p>Consider using rbenchmark or other benchmarking tools to get an idea of the runtime and complexity of your code. In general for loops tend to be slow.<\/p>\n\n<p>It's very possible that the server has less resources available (ram, cpu) or that you have to wait in a que before you get served. Without any more code it's hard to comment further on this issue.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1480339657187,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40844351",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71562804,
        "Question_title":"Automl object detection local filesystem",
        "Question_body":"<p>I have tried to create a azure automl model to find an object in the image.<\/p>\n<p>According to the tutorial it is required that you specify the labels in adataframe where on of the columns are mounted to a aml datastore.<\/p>\n<p>Question: Is it possible to link it to a local repository instead eg in a compute?<\/p>\n<p>Link:  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models<\/a><\/p>\n<p>I tried to use os path but it did not work.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1647889254553,
        "Question_score":0,
        "Question_tags":"azure|object-detection|azure-machine-learning-service|azure-auto-ml",
        "Question_view_count":21,
        "Owner_creation_time":1526222844170,
        "Owner_last_access_time":1655035727330,
        "Owner_location":"Pakis, Indonesia",
        "Owner_reputation":101,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71562804",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60160773,
        "Question_title":"Workaround for timeout error in Dataset.download()",
        "Question_body":"<p>azureml-sdk version: <code>1.0.85<\/code><\/p>\n\n<p>Calling below (as given in the Dataset UI), I get this<\/p>\n\n<pre><code>ds_split = Dataset.get_by_name(workspace, name='ret- holdout-split')\nds_split.download(target_path=dir_outputs, overwrite=True)\n<\/code><\/pre>\n\n<pre><code>UnexpectedError:\n{'errorCode': 'Microsoft.DataPrep.ErrorCodes.Unknown', 'message':\n    'The client could not finish the operation within specified timeout.',\n    'errorData': {}}\n<\/code><\/pre>\n\n<p>The <code>FileDataset<\/code> 1GB pickled file stored in blob.\n<a href=\"https:\/\/gist.github.com\/swanderz\/c608ced5f2c6a2802b7553bc9ead0762\" rel=\"nofollow noreferrer\">Here's a gist with the full traceback<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1581384771000,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":217,
        "Owner_creation_time":1405457120427,
        "Owner_last_access_time":1663947733100,
        "Owner_location":"Seattle, WA, USA",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Question_last_edit_time":1581436827487,
        "Answer_body":"<p>Tried again this AM and it worked. let's file this under \"transient error\"<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1581436892353,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60160773",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54757598,
        "Question_title":"Add model description when registering model after hyperdrive successful run",
        "Question_body":"<p>I have successfully trained a model on Azure Machine Learning Service using Hyperdrive that has now yielded a hyperdrive run instance<\/p>\n\n<pre><code>hyperdrive_run = exp.submit(config=hypertune_config)\nhyperdrive_run\nbest_run = hyperdrive_run.get_best_run_by_primary_metric()\n<\/code><\/pre>\n\n<p>As a next step, I would like to register a model while adding a description to the model.:<\/p>\n\n<pre><code>pumps_rf = best_run.register_model(model_name='pumps_rf', model_path='outputs\/rf.pkl')\n<\/code><\/pre>\n\n<p>There is a <code>description<\/code> column in the Models section of my AML Workspace on Azure portal but the <code>register_model<\/code> method does not seem to have a <code>description<\/code> flag. So how do I go about adding a description to the model so I see it in Azure Portal?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1550539380057,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":453,
        "Owner_creation_time":1408574571227,
        "Owner_last_access_time":1644544922143,
        "Owner_location":"Toronto, Canada",
        "Owner_reputation":2754,
        "Owner_up_votes":189,
        "Owner_down_votes":1,
        "Owner_views":124,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Good question :).<\/p>\n\n<p>Looking at the current version of the API, it doesn't look like you can add the description using <code>Run.register_model<\/code>, as confirmed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#register-model-model-name--model-path-none--tags-none--properties-none----kwargs-\" rel=\"nofollow noreferrer\">by the docs<\/a>. <\/p>\n\n<p>You can go around this however by registering the model using the <code>Model.register<\/code> method which, fortunately, includes an argument for <code>description<\/code> as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none-\" rel=\"nofollow noreferrer\">here<\/a>. In your case, you also need to <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#download-file-name--output-file-path-none-\" rel=\"nofollow noreferrer\">download the files<\/a> first.<\/p>\n\n<p>In short, use something like:<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>best_run.download_file('outputs\/rf.pkl', output_file_path='.\/rf.pkl')\n\nModel.register(workspace=ws, model_path='.\/rf.pkl', model_name=\"pumps_rf\", description=\"There are many models like it, but this one is mine.\")\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1550668517447,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1550686459150,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54757598",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61644716,
        "Question_title":"MlflowException: API request to ...URL... failed to return code 200 after 3 tries",
        "Question_body":"<p>I am currently trying to track my machine learning model metrics using the MLFlow API in Azure Databricks.<\/p>\n\n<p>I registered the experiment under my team's machine learning workspace and had tried a few metric log commands that worked but were simply used as a test.<\/p>\n\n<p>My notebook ran a for loop logging metrics per calculation within the loop.\nIt took a while (3-5 seconds) before sending out the error.<\/p>\n\n<p>I tried to look at the experiment metrics and it seems to have logged a bit of the for loop's metrics before crashing.<\/p>\n\n<p>Not sure as to why it does it and now it throws the exception to my earlier test calls to log metrics.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1588796738017,
        "Question_score":1,
        "Question_tags":"azure-databricks|mlflow|azure-machine-learning-service",
        "Question_view_count":696,
        "Owner_creation_time":1571508734813,
        "Owner_last_access_time":1597680718507,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61644716",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56418684,
        "Question_title":"Possible to access the internal representation of a neural network trained in Azure Machine Learning Service or Azure Machine Learning Studio?",
        "Question_body":"<p>I'm working with data scientists who would like to gain insight and understanding of the neural network models that they train using the visual interfaces in Azure Machine Learning Studio\/Service. Is it possible to dump out and inspect the internal representation of a neural network model? Is there a way that I could write code that accesses the nodes and weights of a trained neural network in order to visualize the network as a graph structure? Or if Azure Machine Learning Studio\/Service doesn't support this I'd appreciate advice on a different machine learning framework that might be more appropriate for this kind of analysis.<\/p>\n\n<p>Things I have tried:<\/p>\n\n<ul>\n<li>Train Model outputs an ILearnerDotNet (AML Studio) or Model (AML Service). I looked for items to drag into the workspace where I could write custom code such as Execute Python Script. They seem to accept datasets, but not ILearnerDotNet\/Model as input.<\/li>\n<li>I wasn't able to locate documentation about the ILearnerDotNet\/Model interfaces.<\/li>\n<li>Selecting the Train Model output offers the option to Save as Trained Model. This creates a trained model object and that would help me reference the trained model in other places, but I didn't find a way to use this to get at its internals.<\/li>\n<\/ul>\n\n<p>I'm new to the Azure Machine Learning landscape, and could use some help with how to get started on how to access this data.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1559506858340,
        "Question_score":2,
        "Question_tags":"neural-network|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":167,
        "Owner_creation_time":1427643193810,
        "Owner_last_access_time":1663710082517,
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Quote from Azure ML Exam reference:<\/p>\n\n<blockquote>\n  <p>By default, the architecture of neural networks is limited to a single\n  hidden layer with sigmoid as the activation function and softmax in\n  the last layer. You can change this in the properties of the model,\n  opening the Hidden layer specification dropdown list, and selecting a\n  Custom definition script. A text box will appear in which you will be\n  able to insert a Net# script. This script language allows you to\n  define neural networks architectures.<\/p>\n<\/blockquote>\n\n<p>For instance, if you want to create a two layer network, you may put the following code.<\/p>\n\n<pre><code>input Picture [28, 28];\nhidden H1 [200] from Picture all;\nhidden H2 [200] from H1 all;\noutput Result [10] softmax from H2 all;\n<\/code><\/pre>\n\n<p>Nevertheless, with Net# you will face certain limitations as, it does not accept regularization (neither L2 nor dropout). Also, there is no ReLU activation that are\ncommonly used in deep learning due to their benefits in backpropagation. You cannot modify the batch size of the Stochastic Gradient Descent (SGD). Besides that, you cannot use other optimization algorithms. You can use SGD with momentum, but not others like Adam, or RMSprop. You cannot define recurrent or recursive neural networks.<\/p>\n\n<p>Another great tool is CNTK (Cognitive Toolkit) that allows you defining your computational graph and create a fully customizable model.\nQuote from documentation<\/p>\n\n<blockquote>\n  <p>It is a Microsoft open source deep learning toolkit. Like other deep\n  learning tools, CNTK is based on the construction of computational\n  graphs and their optimization using automatic differentiation. The\n  toolkit is highly optimized and scales efficiently (from CPU, to GPU,\n  to multiple machines). CNTK is also very portable and flexible; you\n  can use it with programming languages like Python, C#, or C++, but you\n  can also use a model description language called BrainScript.<\/p>\n<\/blockquote>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1559896269913,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56418684",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40028165,
        "Question_title":"Azure ML's web service asking for label?",
        "Question_body":"<p>I built a linear regression algorithm in Azure ML. On the &quot;Score Model&quot; module I can actually see the predictions and the rest of the features. However, when I deploy this project as a web service, the service is expecting the actual label of the data (e.g. I'm trying to predict a house's price and it asks me for the price of the house to make the prediction), which doesn't make any sense to me... What am I doing wrong? On the &quot;Train Model&quot; module I set that the label column is the HousePrice, which is what I'm trying to predict...<\/p>\n<p>This is my model:\n<a href=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I tried leaving that field blank but the prediction returns null...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1476382562787,
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1012,
        "Owner_creation_time":1401729936860,
        "Owner_last_access_time":1662997148480,
        "Owner_location":null,
        "Owner_reputation":1102,
        "Owner_up_votes":390,
        "Owner_down_votes":25,
        "Owner_views":120,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>The input schema (names\/types of required input) based on the location in the graph where you attach the \"Web Service Input\" module. To get the schema you want, you will need to find -- or if necessary, create -- a place in the experiment where the data has the column names\/types you desire.<\/p>\n\n<p>Consider this simple example experiment that predicts whether a field called \"income\" will be above or below $50k\/year:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When we click \"Set up web service\", the following graph is automatically generated:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Since the input dataset and \"Web service input\" modules are connected to the same port, the web service schema will perfectly match the schema of the input dataset. This is unfortunate because the input dataset contains a column called \"income\", which is what our web service is supposed to predict -- this is equivalent to the problem that you are having.<\/p>\n\n<p>To get around it, we need to create a place in our experiment graph where we've dropped the unneeded \"income\" field from the input dataset, and attach the \"Web service input\" module there:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>With this arrangement, the web service only requests the features actually needed to score the model. I'm sure you can use a similar method to create a predictive experiment with whatever input schema you need for your own work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1476730527013,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40028165",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59309318,
        "Question_title":"Azure ML Studio Error 0035: Features for The vocabulary is empty",
        "Question_body":"<p>I am attempting to give classifications to various bodies of text using Azure ML Studio and I have my successful output all the way until I deploy and test a web service. Once I deploy my web service and attempt to test it I get the following error:<\/p>\n\n<p>Error 0035: Features for The vocabulary is empty. Please check the Minimum n-gram document frequency. required but not provided., Error code: ModuleExecutionError, Http status code: 400<\/p>\n\n<p>The vocabularies for the extract n-gram modules are not empty. The only aspect that changes from the working model to the Web service error is the web service input.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PBsDS.png\" rel=\"nofollow noreferrer\">Training Model<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/X6Sq1.png\" rel=\"nofollow noreferrer\">Predictive Model<\/a><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1576169464783,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":368,
        "Owner_creation_time":1573072787957,
        "Owner_last_access_time":1626121970557,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59309318",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70833499,
        "Question_title":"AzureML Environment for Inference : can't add pip packages to dependencies",
        "Question_body":"<p>I can't find the proper way to add dependencies to my Azure Container Instance for ML Inference.<\/p>\n<p>I basically started by following this tutorial : <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-train-deploy-notebook\" rel=\"nofollow noreferrer\">Train and deploy an image classification model with an example Jupyter Notebook<\/a><\/p>\n<p>It works fine.<\/p>\n<p>Now I want to deploy my trained TensorFlow model for inference. I tried many ways, but I was never able to add python dependencies to the Environment.<\/p>\n<h1>From the TensorFlow curated environment<\/h1>\n<p>Using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/resource-curated-environments#inference-curated-environments-and-prebuilt-docker-images\" rel=\"nofollow noreferrer\">AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference<\/a> :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\n\n# connect to your workspace\nws = Workspace.from_config()\n\n# names\nexperiment_name = &quot;my-experiment&quot;\nmodel_name = &quot;my-model&quot;\nenv_version=&quot;1&quot;\nenv_name=&quot;my-env-&quot;+env_version\nservice_name = str.lower(model_name + &quot;-service-&quot; + env_version)\n\n\n# create environment for the deploy\nfrom azureml.core.environment import Environment, DEFAULT_CPU_IMAGE\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.webservice import AciWebservice\n\n# get a curated environment\nenv = Environment.get(\n    workspace=ws, \n    name=&quot;AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference&quot;,\n# )\ncustom_env = env.clone(env_name)\ncustom_env.inferencing_stack_version='latest'\n\n# add packages\nconda_dep = CondaDependencies()\npython_packages = ['joblib', 'numpy', 'os', 'json', 'tensorflow']\nfor package in python_packages:\n    conda_dep.add_pip_package(package)\n    conda_dep.add_conda_package(package)\n\n# Adds dependencies to PythonSection of env\ncustom_env.python.user_managed_dependencies=True\ncustom_env.python.conda_dependencies=conda_dep\n\ncustom_env.register(workspace=ws)\n\n# create deployment config i.e. compute resources\naciconfig = AciWebservice.deploy_configuration(\n    cpu_cores=1,\n    memory_gb=1,\n    tags={&quot;experiment&quot;: experiment_name, &quot;model&quot;: model_name},\n)\n\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.model import Model\n\n# get the registered model\nmodel = Model(ws, model_name)\n\n# create an inference config i.e. the scoring script and environment\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=custom_env)\n\n# deploy the service\nservice = Model.deploy(\n    workspace=ws,\n    name=service_name,\n    models=[model],\n    inference_config=inference_config,\n    deployment_config=aciconfig,\n)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>I get the following log :<\/p>\n<pre><code>\nAzureML image information: tensorflow-2.4-ubuntu18.04-py37-cpu-inference:20220110.v1\n\n\nPATH environment variable: \/opt\/miniconda\/envs\/amlenv\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPYTHONPATH environment variable: \n\nPip Dependencies\n---------------\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-01-24T10:21:09,855130300+00:00 - iot-server\/finish 1 0\n2022-01-24T10:21:09,856870100+00:00 - Exit code 1 is normal. Not restarting iot-server.\nabsl-py==0.15.0\napplicationinsights==0.11.10\nastunparse==1.6.3\nazureml-inference-server-http==0.4.2\ncachetools==4.2.4\ncertifi==2021.10.8\ncharset-normalizer==2.0.10\nclick==8.0.3\nFlask==1.0.3\nflatbuffers==1.12\ngast==0.3.3\ngoogle-auth==2.3.3\ngoogle-auth-oauthlib==0.4.6\ngoogle-pasta==0.2.0\ngrpcio==1.32.0\ngunicorn==20.1.0\nh5py==2.10.0\nidna==3.3\nimportlib-metadata==4.10.0\ninference-schema==1.3.0\nitsdangerous==2.0.1\nJinja2==3.0.3\nKeras-Preprocessing==1.1.2\nMarkdown==3.3.6\nMarkupSafe==2.0.1\nnumpy==1.19.5\noauthlib==3.1.1\nopt-einsum==3.3.0\npandas==1.1.5\nprotobuf==3.19.1\npyasn1==0.4.8\npyasn1-modules==0.2.8\npython-dateutil==2.8.2\npytz==2021.3\nrequests==2.27.1\nrequests-oauthlib==1.3.0\nrsa==4.8\nsix==1.15.0\ntensorboard==2.7.0\ntensorboard-data-server==0.6.1\ntensorboard-plugin-wit==1.8.1\ntensorflow==2.4.0\ntensorflow-estimator==2.4.0\ntermcolor==1.1.0\ntyping-extensions==3.7.4.3\nurllib3==1.26.8\nWerkzeug==2.0.2\nwrapt==1.12.1\nzipp==3.7.0\n\n\nEntry script directory: \/var\/azureml-app\/.\n\nDynamic Python package installation is disabled.\nStarting AzureML Inference Server HTTP.\n\nAzure ML Inferencing HTTP server v0.4.2\n\n\nServer Settings\n---------------\nEntry Script Name: score.py\nModel Directory: \/var\/azureml-app\/azureml-models\/my-model\/1\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311\/\nScore:          POST  127.0.0.1:31311\/score\n\nStarting gunicorn 20.1.0\nListening at: http:\/\/0.0.0.0:31311 (69)\nUsing worker: sync\nBooting worker with pid: 100\nException in worker process\nTraceback (most recent call last):\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker\n    worker.init_process()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process\n    self.load_wsgi()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load\n    return self.load_wsgiapp()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/entry.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/create_app.py&quot;, line 4, in &lt;module&gt;\n    from routes_common import main\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/routes_common.py&quot;, line 32, in &lt;module&gt;\n    from aml_blueprint import AMLBlueprint\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 28, in &lt;module&gt;\n    main_module_spec.loader.exec_module(main)\n  File &quot;\/var\/azureml-app\/score.py&quot;, line 4, in &lt;module&gt;\n    import joblib\nModuleNotFoundError: No module named 'joblib'\nWorker exiting (pid: 100)\nShutting down: Master\nReason: Worker failed to boot.\n2022-01-24T10:21:13,851467800+00:00 - gunicorn\/finish 3 0\n2022-01-24T10:21:13,853259700+00:00 - Exit code 3 is not normal. Killing image.\n<\/code><\/pre>\n<h1>From a Conda specification<\/h1>\n<p>Same as before, but with a fresh environment from Conda specification and changing the <code>env_version<\/code> number :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># ...\n\n\nenv_version=&quot;2&quot;\n\n# ...\n\ncustom_env = Environment.from_conda_specification(name=env_name, file_path=&quot;my-env.yml&quot;)\ncustom_env.docker.base_image = DEFAULT_CPU_IMAGE\n\n# ...\n\n<\/code><\/pre>\n<p>with <code>my-env.yml<\/code> :<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: my-env\ndependencies:\n- python\n\n- pip:\n  - azureml-defaults\n  - azureml-sdk\n  - sklearn\n  - numpy\n  - matplotlib\n  - joblib\n  - uuid\n  - requests\n  - tensorflow\n\n<\/code><\/pre>\n<p>I get this log :<\/p>\n<pre><code>2022-01-24T11:06:54,887886931+00:00 - iot-server\/run \n2022-01-24T11:06:54,891839877+00:00 - rsyslog\/run \n2022-01-24T11:06:54,893640998+00:00 - gunicorn\/run \n2022-01-24T11:06:54,912032812+00:00 - nginx\/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-01-24T11:06:55,398420960+00:00 - iot-server\/finish 1 0\n2022-01-24T11:06:55,414425146+00:00 - Exit code 1 is normal. Not restarting iot-server.\n\nPATH environment variable: \/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPYTHONPATH environment variable: \n\nPip Dependencies\n---------------\nbrotlipy==0.7.0\ncertifi==2020.6.20\ncffi @ file:\/\/\/tmp\/build\/80754af9\/cffi_1605538037615\/work\nchardet @ file:\/\/\/tmp\/build\/80754af9\/chardet_1605303159953\/work\nconda==4.9.2\nconda-package-handling @ file:\/\/\/tmp\/build\/80754af9\/conda-package-handling_1603018138503\/work\ncryptography @ file:\/\/\/tmp\/build\/80754af9\/cryptography_1605544449973\/work\nidna @ file:\/\/\/tmp\/build\/80754af9\/idna_1593446292537\/work\npycosat==0.6.3\npycparser @ file:\/\/\/tmp\/build\/80754af9\/pycparser_1594388511720\/work\npyOpenSSL @ file:\/\/\/tmp\/build\/80754af9\/pyopenssl_1605545627475\/work\nPySocks @ file:\/\/\/tmp\/build\/80754af9\/pysocks_1594394576006\/work\nrequests @ file:\/\/\/tmp\/build\/80754af9\/requests_1592841827918\/work\nruamel-yaml==0.15.87\nsix @ file:\/\/\/tmp\/build\/80754af9\/six_1605205313296\/work\ntqdm @ file:\/\/\/tmp\/build\/80754af9\/tqdm_1605303662894\/work\nurllib3 @ file:\/\/\/tmp\/build\/80754af9\/urllib3_1603305693037\/work\n\nStarting HTTP server\n2022-01-24T11:06:59,701365128+00:00 - gunicorn\/finish 127 0\n.\/run: line 127: exec: gunicorn: not found\n2022-01-24T11:06:59,706177784+00:00 - Exit code 127 is not normal. Killing image.\n    \n<\/code><\/pre>\n<p>I really don't know what I'm missing, and I've been searching for too long already (Azure docs, SO, ...).<\/p>\n<p>Thanks for your help !<\/p>\n<p>Edit : Non-exhaustive list of solutions I tried :<\/p>\n<ul>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/65159778\/how-to-create-azureml-environement-and-add-required-packages\">How to create AzureML environement and add required packages<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/65159308\/how-to-use-existing-conda-environment-as-a-azureml-environment\">how to use existing conda environment as a AzureML environment<\/a><\/li>\n<li>...<\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-environments#environment-building-caching-and-reuse\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-environments#environment-building-caching-and-reuse<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#add-packages-to-an-environment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#add-packages-to-an-environment<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-inferencing-gpus\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-inferencing-gpus<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-deployment-configuration\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-deployment-configuration<\/a><\/li>\n<li>...<\/li>\n<\/ul>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1643025448957,
        "Question_score":0,
        "Question_tags":"python|tensorflow|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":902,
        "Owner_creation_time":1337868050813,
        "Owner_last_access_time":1663936553207,
        "Owner_location":"Paris, France",
        "Owner_reputation":483,
        "Owner_up_votes":39,
        "Owner_down_votes":2,
        "Owner_views":105,
        "Question_last_edit_time":1643163454173,
        "Answer_body":"<p>OK, I got it working : I started over from scratch and it worked.<\/p>\n<p>I have no idea what was wrong in all my preceding tries, and that is terrible.<\/p>\n<p>Multiple problems and how I (think I) solved them :<\/p>\n<ul>\n<li><code>joblib<\/code> : I actually didn't need it to load my Keras model. But the problem was not with this specific library, rather that I couldn't add dependencies to the inference environment.<\/li>\n<li><code>Environment<\/code> : finally, I was only able to make things work with a custom env : <code>Environment.from_conda_specification(name=version, file_path=&quot;conda_dependencies.yml&quot;)<\/code> . I haven't been able to add my libraries (or specify a specific package version) to a &quot;currated environment&quot;. I don't know why though...<\/li>\n<li><code>TensorFlow<\/code> : last problem I had was that I trained and registered my model in AzureML Notebook's <code>azureml_py38_PT_TF<\/code> kernel (<code>tensorflow==2.7.0<\/code>), and tried to load it in the inference Docker image (<code>tensorflow==2.4.0<\/code>). So I had to specify the version of TensorFlow I wanted to use in the inference image (which required the previous point to be solved).<\/li>\n<\/ul>\n<p>What finally worked :<\/p>\n<ul>\n<li>notebook.ipynb<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import uuid\nfrom azureml.core import Workspace, Environment, Model\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.model import InferenceConfig\n\n\nversion = &quot;test-&quot;+str(uuid.uuid4())[:8]\n\nenv = Environment.from_conda_specification(name=version, file_path=&quot;conda_dependencies.yml&quot;)\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=env)\n\nws = Workspace.from_config()\nmodel = Model(ws, model_name)\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores=1,\n    memory_gb=1,\n)\n\nservice = Model.deploy(\n    workspace=ws,\n    name=version,\n    models=[model],\n    inference_config=inference_config,\n    deployment_config=aci_config,\n    overwrite=True,\n)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<ul>\n<li>conda_dependencies.yml<\/li>\n<\/ul>\n<pre class=\"lang-yaml prettyprint-override\"><code>channels:\n- conda-forge\ndependencies:\n- python=3.8\n- pip:\n  - azureml-defaults\n  - azureml-sdk\n  - numpy\n  - tensorflow==2.7.0\n\n<\/code><\/pre>\n<ul>\n<li>score.py<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nimport numpy as np\nimport tensorflow as tf\n\n\ndef init():\n    global model\n\n    model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;model\/data\/model&quot;)\n    model = tf.keras.models.load_model(model_path)\n\n\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)[&quot;data&quot;])\n    y_hat = model.predict(data)\n\n    return y_hat.tolist()\n\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1643188448820,
        "Answer_score":1.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70833499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48197524,
        "Question_title":"How to remove the entire rows if value is NULL in Azure ML studio",
        "Question_body":"<p>I am preparing the data for regression model. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LFaYl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LFaYl.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I want to remove the entire row If all columns have value <code>NULL<\/code>. <\/p>\n\n<p>With Clean Missing Data module seems to me like I only able to remove missing values. But <code>NULL<\/code> is not considers mission value. <\/p>\n\n<p>So are there any other modules that simply can remove the entire row if all values are <code>NULL<\/code>'s<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1515625426463,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1477,
        "Owner_creation_time":1457596845393,
        "Owner_last_access_time":1663977598457,
        "Owner_location":"San Diego, CA, United States",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Question_last_edit_time":null,
        "Answer_body":"<p>you could use \"<strong>Execute Python Script<\/strong>\" or \"<strong>Execute R Script<\/strong>\" to archive that. Or just use \"<strong>Apply SQL Transformation<\/strong>\" -> <code>SELECT * FROM tbl1 where column1 IS NULL AND column2 IS NULL<\/code>.... <\/p>\n\n<p>Greetings,\nStefan<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1516614808533,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1526560111353,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48197524",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64819708,
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_body":"<p>I'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.<\/p>\n<p>But as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:<\/p>\n<p>UserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:<\/p>\n<ol>\n<li>You are not authorized to access this resource, or directory listing denied.<\/li>\n<li>you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.<\/li>\n<li>You have multiple objects\/login session opened, please close all session and try again.<\/li>\n<\/ol>\n<p>InnerException None\nErrorResponse\n{\n&quot;error&quot;: {\n&quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n                &quot;\n}\n}<\/p>\n<p>with the following call stack<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70         return self.<br \/>\n71             _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---&gt; 72                                               custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74     @error_with_model_id_handling<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, *args, **kwargs)\n65\n66     def _execute_with_workspace_arguments(self, func, *args, **kwargs):\n---&gt; 67         return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), *args, **kwargs)\n68\n69     def get_or_create_experiment(self, experiment_name, is_async=False):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n536                 return self._call_paginated_api(func, *args_list, **kwargs)\n537             else:\n--&gt; 538                 return self._call_api(func, *args_list, **kwargs)\n539         except ErrorResponseException as e:\n540             raise ServiceException(e)<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n234                 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235             else:\n--&gt; 236                 return self._execute_with_base_arguments(func, *args, **kwargs)\n237\n238     def _call_paginated_api(self, func, *args, **kwargs):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n323         total_retry = 0 if self.retries &lt; 0 else self.retries\n324         return ClientBase._execute_func_internal(\n--&gt; 325             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n326\n327     @classmethod<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n343                 return func(*args, **kwargs)\n344             except Exception as error:\n--&gt; 345                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347             reset_func(*args, **kwargs)  # reset_func is expected to undo any side effects from a failed func call.<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385                 &quot;&quot;&quot;\n--&gt; 386                 raise_from(UserErrorException(error_msg), error)\n387\n388             elif error.response.status_code == 429:<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)<\/p>\n<p>Did anybody experience the same error and knows what is its cause and how to solve it?<\/p>\n<p>Best,\nJonas<\/p>\n<p>UPDATE:<\/p>\n<pre><code> model = sklearn.linear_model.LinearRegression ( )\n model_path = &quot;&lt;path to 'model.pkl' in my blob storage&gt;&quot;\n joblib.dump(model, model_path)\n aml_run = azureml.core.get_context ( )\n aml_run.upload_file (name = &quot;model.pkl&quot;, path_or_stream = model_path)\n # Until this point, everything works fine\n    \n aml_run.register_model (model_name = &quot;model.pkl&quot;)\n # This throws the posted &quot;Forbidden&quot;-Error\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1605265124633,
        "Question_score":2,
        "Question_tags":"azure-databricks|azure-machine-learning-studio",
        "Question_view_count":620,
        "Owner_creation_time":1594877973727,
        "Owner_last_access_time":1643018129407,
        "Owner_location":"Germany",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1605513428203,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64819708",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59144503,
        "Question_title":"Azure Machine Learning Service - dataset API question",
        "Question_body":"<p>I am trying to use autoML feature of AML. I saw that in the sample notebook it is using Dataset.Tabular.from_delimited_files(train_data) which only takes data from a https path. I am wondering how can I use pandas dataframe directly automl config instead of using dataset API. Alternatively, what is the way I can convert pandas dataframe to tabular dataset to pass into automl config?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1575310207200,
        "Question_score":0,
        "Question_tags":"automl|azure-machine-learning-service",
        "Question_view_count":982,
        "Owner_creation_time":1430707152817,
        "Owner_last_access_time":1581450353247,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59144503",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73028352,
        "Question_title":"How do i visualize azure ml predictions in power bi",
        "Question_body":"<p>I am working with azure ML notebook  for timeseries predictions\nI have done everything  and i have my predictions  however i want to have my data and my predictions  visualized  in power bi.\nHow do i save my data back to azure blob so i can utilize  it in power bi?\nOr anyotherway to visualize in power bi<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1658176742183,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azureml-python-sdk",
        "Question_view_count":55,
        "Owner_creation_time":1607617423893,
        "Owner_last_access_time":1663931298390,
        "Owner_location":"Slovakia",
        "Owner_reputation":41,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73028352",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52128396,
        "Question_title":"No Experimentation Account found in your Azure Subscriptions in Azure Machine Learning Workbench",
        "Question_body":"<p>I created one Experiment and hosted as web service in Azure ML Stdio<\/p>\n\n<p><a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a><\/p>\n\n<p>However, I have installed Azure Machine Learning Workbench and logging into same account. It says:<\/p>\n\n<p><strong>No Experimentation Account found in your Azure Subscriptions\nYou can create one in the Microsoft Azure Management Portal.<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1535807224517,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-workbench",
        "Question_view_count":113,
        "Owner_creation_time":1378277999787,
        "Owner_last_access_time":1664033338507,
        "Owner_location":"Hyderabad, India",
        "Owner_reputation":2273,
        "Owner_up_votes":37,
        "Owner_down_votes":7,
        "Owner_views":177,
        "Question_last_edit_time":1535822103233,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52128396",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57488706,
        "Question_title":"Deploying custom model on Azure ML Studio",
        "Question_body":"<p>In Azure ML Studio, we have the option of choosing a number of inbuilt ML models like Classification, Regression, etc. , which we can drag and drop to our workflow.<\/p>\n\n<p>My question is, can I upload a custom ML model that I have built locally on my system in Python, and add it to the workflow?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1565761282107,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1187,
        "Owner_creation_time":1565761178210,
        "Owner_last_access_time":1613393617227,
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":1565767277470,
        "Answer_body":"<ol>\n<li>Take the model.pkl file, zip it, and upload it into Azure Machine Learning Studio. Click the \u201cNew\u201d icon in the bottom left:\n<a href=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" alt=\"\"><\/a><\/li>\n<li>In the pane that comes up, click on dataset, and then \u201cFrom Local File\u201d:\n<a href=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" alt=\"\"><\/a><\/li>\n<li>Select the zip file where you stored your serialized model and click the tick. You expirement should look like this:\n<a href=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" alt=\"\"><\/a><\/li>\n<li>Put the following code to run your classification experiment:<\/li>\n<\/ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport sys\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    sys.path.insert(0,\".\\Script Bundle\")\n    model = pickle.load(open(\".\\Script Bundle\\model.pkl\", 'rb'))\n    pred = model.predict(dataframe1)\n    return pd.DataFrame([pred[0]])\n<\/code><\/pre>\n\n<p><strong>Update<\/strong> \nIf you want to declare this experiment as an API you need to add web input and output to the Python script module.\n<a href=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_time":1566202471557,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1566565696980,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57488706",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73714337,
        "Question_title":"Is it possible to use data cleansing in SQL Server by using Azure ML?",
        "Question_body":"<p>I have a SQL Server which I want to run data cleansing every night. To do this I want to use Azure Machine Learning.<\/p>\n<p>To my question; Is it possible to run data cleansing with Azure Machine Learning directly in my SQL Server?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1663146771947,
        "Question_score":0,
        "Question_tags":"sql-server|data-cleaning|azure-machine-learning-service",
        "Question_view_count":22,
        "Owner_creation_time":1525701893967,
        "Owner_last_access_time":1663919853580,
        "Owner_location":"Uppsala, Sverige",
        "Owner_reputation":31,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73714337",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70852922,
        "Question_title":"ModuleNotFoundError: No module named 'azureml' in Azure ML Studio",
        "Question_body":"<p>I am learning Azure ML from Microsoft tutorials, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\" rel=\"nofollow noreferrer\">here<\/a>. The first two tutorials ran fine, but this one is giving me the following error.<\/p>\n<pre><code>[stderr]Traceback (most recent call last):\n[stderr]  File &quot;train.py&quot;, line 8, in &lt;module&gt;\n[stderr]    from azureml.core import Run\n[stderr]ModuleNotFoundError: No module named 'azureml'\n[stderr]\n<\/code><\/pre>\n<p>Working with Azure ML Studio and submitting the code to the environment, I am unable to find how to resolve this error.<\/p>\n<p>I have checked that the package is installed (running on Azure ML studio so this is basic assumption, but I have tested as well). Following is the code 'run-pytorch.py' which calls the script 'train.py'<\/p>\n<pre><code># run-pytorch.py\nfrom azureml.core import Workspace\nfrom azureml.core import Experiment\nfrom azureml.core import Environment\nfrom azureml.core import ScriptRunConfig\n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='day1-experiment-train')\n    config = ScriptRunConfig(source_directory='.\/src',\n                             script='train.py',\n                             compute_target='cpu-cluster')\n\n    # set up pytorch environment\n    env = Environment.from_conda_specification(\n        name='pytorch-env',\n        file_path='pytorch-env.yml'\n    )\n    config.run_config.environment = env\n\n    run = experiment.submit(config)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n    print('Success...!!!')\n<\/code><\/pre>\n<p>Teh code snippet for train.py is as follows<\/p>\n<pre><code># train.py\nimport os\nimport argparse\nimport torch\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom model import Net\nfrom azureml.core import Run\n...\n...\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1643131009297,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":838,
        "Owner_creation_time":1387867856557,
        "Owner_last_access_time":1663872845690,
        "Owner_location":null,
        "Owner_reputation":453,
        "Owner_up_votes":91,
        "Owner_down_votes":2,
        "Owner_views":63,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70852922",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69933296,
        "Question_title":"Azure ML Pipeline fails while running a grid search CV on a cluster",
        "Question_body":"<p>I implemented a gridsearchcv on Azure ML as a pipeline but I keep getting an error that says &quot;User program failed with TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.<\/p>\n<p>The exit codes of the workers are {SIGKILL(-9)}&quot;<\/p>\n<p>I tried changing the package versions but could not get it to work. The code runs well without error when I run it as a script but fails when I run it as a pipeline.<\/p>\n<p>Any idea on how to fix this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1636655875797,
        "Question_score":0,
        "Question_tags":"python-3.x|azure|scikit-learn|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":175,
        "Owner_creation_time":1636655338437,
        "Owner_last_access_time":1643399394220,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69933296",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67867951,
        "Question_title":"AzureML SDK problems with pip-installed dependencies in environment file",
        "Question_body":"<p>i am try to run a Python Script in AzureML SDK. However in the runs log file, it prints the same error over and over again:<\/p>\n<blockquote>\n<p>Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.<\/p>\n<\/blockquote>\n<p>The defined conda environment looks like this:<\/p>\n<pre><code>    {\n    &quot;databricks&quot;: {\n        &quot;eggLibraries&quot;: [],\n        &quot;jarLibraries&quot;: [],\n        &quot;mavenLibraries&quot;: [],\n        &quot;pypiLibraries&quot;: [],\n        &quot;rcranLibraries&quot;: []\n    },\n    &quot;docker&quot;: {\n        &quot;arguments&quot;: [],\n        &quot;baseDockerfile&quot;: null,\n        &quot;baseImage&quot;: &quot;mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210301.v1&quot;,\n        &quot;baseImageRegistry&quot;: {\n            &quot;address&quot;: null,\n            &quot;password&quot;: null,\n            &quot;registryIdentity&quot;: null,\n            &quot;username&quot;: null\n        },\n        &quot;enabled&quot;: false,\n        &quot;platform&quot;: {\n            &quot;architecture&quot;: &quot;amd64&quot;,\n            &quot;os&quot;: &quot;Linux&quot;\n        },\n        &quot;sharedVolumes&quot;: true,\n        &quot;shmSize&quot;: null\n    },\n    &quot;environmentVariables&quot;: {\n        &quot;EXAMPLE_ENV_VAR&quot;: &quot;EXAMPLE_VALUE&quot;\n    },\n    &quot;inferencingStackVersion&quot;: null,\n    &quot;name&quot;: &quot;MyEnvironment04&quot;,\n    &quot;python&quot;: {\n        &quot;baseCondaEnvironment&quot;: null,\n        &quot;condaDependencies&quot;: {\n            &quot;channels&quot;: [\n                &quot;anaconda&quot;,\n                &quot;conda-forge&quot;\n            ],\n            &quot;dependencies&quot;: [\n                &quot;python=3.6.2&quot;,\n                {\n                    &quot;pip&quot;: [\n                        &quot;pip=20.2.40&quot;\n                    ]\n                },\n                &quot;scikit-learn&quot;\n            ],\n            &quot;name&quot;: &quot;azureml_815589d460c271a1415198e7283fa9e9&quot;\n        },\n        &quot;condaDependenciesFile&quot;: null,\n        &quot;interpreterPath&quot;: &quot;python&quot;,\n        &quot;userManagedDependencies&quot;: false\n    },\n    &quot;r&quot;: null,\n    &quot;spark&quot;: {\n        &quot;packages&quot;: [],\n        &quot;precachePackages&quot;: true,\n        &quot;repositories&quot;: []\n    },\n    &quot;version&quot;: &quot;1&quot;\n}\n<\/code><\/pre>\n<p>I am assuming that the definition for my pip package in my environment is wrong.<\/p>\n<pre><code># Create the dependencies object\nmyenv_dep = CondaDependencies.create(conda_packages=['scikit-learn'], pip_packages=['pip=20.2.40'])\nmyenv.python.conda_dependencies = myenv_dep\n<\/code><\/pre>\n<p>Please let me know if i need to provide further information.<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1623052859247,
        "Question_score":0,
        "Question_tags":"python|pip|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":332,
        "Owner_creation_time":1596110326463,
        "Owner_last_access_time":1644575072690,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67867951",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47735839,
        "Question_title":"how to reduce the Run time in Azure ML for decision tree and decision forest",
        "Question_body":"<p>I am trying to run a regression model for a data set containing over 2000000 rows. I tried using linear regression and boosted decision tree regression without tuning model hyperparameter, I didn't get the expected accuracy. so I tried to use Tune model hyperparameter for the boosted decision tree, the model runs over 20 min. the decision forest also takes to0 long (even without tuning model hyperparameter). Is there any way to reduce the runtime without compromising the result accuracy too much?<\/p>\n\n<p>will sampling affect the output (say I took  0.5 as sampling rate)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1512879883917,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":127,
        "Owner_creation_time":1512877126070,
        "Owner_last_access_time":1516544522587,
        "Owner_location":"Portugal",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The execution time on AzureML Studio depends on the pricing tier. The free version does one node execution at time while the standard pricing tier do the execute multiple execution at one time. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1513656866753,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47735839",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73334181,
        "Question_title":"How to save and access pickle\/hdf5 files in azure machine learning studio",
        "Question_body":"<p>I have a pickle file parameters.pkl containing some parameters and their values of a model. The pickle file has been created through the following process:<\/p>\n<pre><code>dict={'scaler': scaler,\n'features': z_tags,\n'Z_reconstruction_loss': Z_reconstruction_loss} \npickle.dump(dict, open('parameters.pkl', 'wb'))\n\nmodel_V2.hdf5\n<\/code><\/pre>\n<p>I am new to azure machine learning studio.It will be helpful to know, how the pickle file and hdf5 files can be stored in Azure machine Learning Studio and an API endpoint be created, so that the the pickle file can be accessed through API. Objective is to access the pickle file and its contents through API.. I have tried the following:<\/p>\n<pre><code>pip install azureml , azureml-core\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n\nws = Workspace.create(\n               name='myworkspace',            \n               subscription_id='&lt;azure-subscription-id&gt;',           \n               resource_group='myresourcegroup',                 \n               create_resource_group=True,                 \n               location='eastus2'                \n               )\n\nws.write_config()\n\nws = Workspace.from_config()\n\nmodel = Model.register(workspace = ws,\n              model_path =&quot;model\/parameters.pkl&quot;,\n              model_name = &quot;parameters&quot;,\n              tags = {&quot;version&quot;: &quot;1&quot;},\n              description = &quot;parameters&quot;,\n              )\n\n\n# to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0'], conda_packages = ['scikit-learn==0.23.2'])\nenv.python.conda_dependencies = cd\n# Register environment to re-use later\nenv.register(workspace = ws)\nprint(&quot;Registered Environment&quot;)\n\nmyenv = Environment.get(workspace=ws, name=&quot;env&quot;)\n\nmyenv.save_to_directory('.\/environ', overwrite=True)\n\naciconfig = AciWebservice.deploy_configuration(\n            cpu_cores=1,\n            memory_gb=1,\n            tags={&quot;data&quot;:&quot;parameters&quot;},\n            description='parameters MODEL',\n            )\n\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=myenv)\n<\/code><\/pre>\n<p>What to modify in following score script, as I don't want to predict anything but access the parameter values stored in the pickle file.<\/p>\n<pre><code>def init():\n    global modelmodel_path = Model.get_model_path(&quot;parameters&quot;)\n    print(&quot;Model Path is  &quot;, model_path)\n    model = joblib.load(model_path)\n\ndef run(data):\n   try:\n     data = json.loads(data)\n     result = model.predict(data['data'])\n     return {'data' : result.tolist() , 'message' : &quot;Successfully \n            accessed&quot;}\n   except Exception as e:\n      error = str(e)\n      return {'data' : error , 'message' : 'Failed to access'}\n\nDeploy the Model\nservice = Model.deploy(workspace=ws,\n                name='iris-model',\n                models=[model],\n                inference_config=inference_config,\n                deployment_config=aciconfig, \n                overwrite = True)\nservice.wait_for_deployment(show_output=True)\nurl = service.scoring_uri\nprint(url)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660307228527,
        "Question_score":1,
        "Question_tags":"python-3.x|azure|pickle|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":130,
        "Owner_creation_time":1431685926620,
        "Owner_last_access_time":1663756216813,
        "Owner_location":null,
        "Owner_reputation":543,
        "Owner_up_votes":17,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73334181",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33741912,
        "Question_title":"How connect Azure Machine Learning and Spark Streaming or Apache Storm",
        "Question_body":"<p>Is there possibility to get stream from Spark Streaming or Apache Storm into Azure Machine Learning? In <strong><em>reader<\/em><\/strong> option there is an input to read data from Hive database\n<a href=\"https:\/\/i.stack.imgur.com\/8Em26.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8Em26.png\" alt=\"hive\"><\/a><\/p>\n\n<p>but how to achive real time stream of data from Spark or Storm, for example <strong><em>Real-time fraud detection<\/em><\/strong><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1447697540763,
        "Question_score":0,
        "Question_tags":"azure|hadoop|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":549,
        "Owner_creation_time":1327481639093,
        "Owner_last_access_time":1663925285370,
        "Owner_location":"Poznan, Poland",
        "Owner_reputation":2923,
        "Owner_up_votes":875,
        "Owner_down_votes":5,
        "Owner_views":838,
        "Question_last_edit_time":1456849966663,
        "Answer_body":"<p>To do real time Fraud detection typically you will create a Model on Azure ML, then publish that model to oWeb service, then on you Spark or Storm system you will call that Web service, in  sequence ( like payment happened on commercial sites for example), then you will get an immediate answer about the actual parameters you had sent in you web service call.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1448457555593,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33741912",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41451123,
        "Question_title":"An example to create a training model on real data in AzureML",
        "Question_body":"<p>Can you introduce a real sample for azure ML and show how can it be possible to see the result of the training?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1483472453410,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":76,
        "Owner_creation_time":1403553737940,
        "Owner_last_access_time":1664024595667,
        "Owner_location":"Belgium",
        "Owner_reputation":17835,
        "Owner_up_votes":636,
        "Owner_down_votes":1612,
        "Owner_views":2203,
        "Question_last_edit_time":null,
        "Answer_body":"<p><a href=\"http:\/\/blog.learningtree.com\/how-to-build-a-predictive-model-using-azure-machine-learning\/\" rel=\"nofollow noreferrer\">Here<\/a> is a good sample to create your first model.\nI should notice that I can't load data from url, as there is a forbidden error to load from url, and I don't know why! \nAnyhow, you can import data manually by copy the data from <a href=\"http:\/\/blog.learningtree.com\/wp-content\/uploads\/2015\/01\/breast-cancer-wisconsin.data_.arff_.txt\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>Also, you can find the created model which is published here: \n<a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Cancer-Model-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Cancer-Model-1<\/a><\/p>\n\n<p>About see the result of the training model, you can right click on the tick (highlighted by a red circle in the following picture) of Evaluation Model. Then, in the opened menu, go to \"Evaluation Result -> Visualization\".\n<a href=\"https:\/\/i.stack.imgur.com\/vhJWE.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vhJWE.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>After that you can see a window like the following (which shows ROC curve and some related result such as accuracy of the training model):<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/FAuzU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FAuzU.png\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/B39lI.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/B39lI.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Besides, you can see <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-azure-ml-customer-churn-scenario\" rel=\"nofollow noreferrer\">this example<\/a> as an another sample.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1483472453410,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1483537837233,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41451123",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45121271,
        "Question_title":"Does Azure ML Studio not working with Chrome\/Firefox?",
        "Question_body":"<p>See attached, is it because I am on Chrome\/Firefox? I am currently on a Macbook, so I can't really test this out on Edge browser. Why does Microsoft build something that won't work for other browsers?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/v744g.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/v744g.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_creation_time":1500141920653,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":194,
        "Owner_creation_time":1297803164077,
        "Owner_last_access_time":1663909246143,
        "Owner_location":"San Francisco, CA",
        "Owner_reputation":2399,
        "Owner_up_votes":1178,
        "Owner_down_votes":2,
        "Owner_views":256,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45121271",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49604773,
        "Question_title":"Azure Machine Learning Studio vs. Workbench",
        "Question_body":"<p>What is the difference between <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-studio\/\" rel=\"noreferrer\">Azure Machine Learning Studio<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-services\/\" rel=\"noreferrer\">Azure Machine Learning Workbench<\/a>?  What is the <em>intended<\/em> difference? And is it expected that Workbench is heading towards deprecation in favor of Studio?<\/p>\n\n<p>I have gathered an assorted collection of differences:<\/p>\n\n<ul>\n<li>Studio has a hard limit of 10 GB total input of training data per module, whereas Workbench has a variable limit by price.<\/li>\n<li>Studio appears to have a more fully-featured GUI and user-friendly deployment tools, whereas Workbench appears to have more powerful \/ customizable deployment tools.<\/li>\n<li>etc.<\/li>\n<\/ul>\n\n<p>However, I have also found several scattered references claiming that Studio is a renamed updated of Workbench, even though both services appear to still be offered.<\/p>\n\n<p>For a fresh Data Scientist looking to adopt the Microsoft stack (potentially on an enterprise scale within the medium-term and for the long-term), which offering should I prefer?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1522638099293,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":3387,
        "Owner_creation_time":1434736108840,
        "Owner_last_access_time":1663241421093,
        "Owner_location":"Dallas, TX, United States",
        "Owner_reputation":2045,
        "Owner_up_votes":1074,
        "Owner_down_votes":66,
        "Owner_views":166,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Azure Machine Learning Workbench is a preview downloadable application. It provides a UI for many of the Azure Machine Learning CLI commands, particularly around experimentation submission for Python based jobs to DSVM or HDI. The Azure Machine Learning CLI is made up of many key functions, such as job submisison, and creation of real time web services. The workbench installer provided a way to install everything required to participate in the preview. <\/p>\n\n<p>Azure Machine Learning Studio is an older product, and provides a drag and drop interface for creating simply machine learning processes. It has limitations about the size of the data that can be handled (about 10gigs of processing). Learning and customer requests have based on this service have contributed to the design of the new Azure Machine Learning CLI mentioned above.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1524806701633,
        "Answer_score":6.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49604773",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42367141,
        "Question_title":"Annotated images classification",
        "Question_body":"<p>I've got a bunch of images (~3000) which have been manually classified (approved\/rejected) based on some business criteria. I've processed these images with Google Cloud Platform obtaining annotations and SafeSearch results, for example (csv format):<\/p>\n\n<p>file name; approved\/rejected; adult; spoof; medical; violence; annotations\nA.jpg;approved;VERY_UNLIKELY;VERY_UNLIKELY;VERY_UNLIKELY;UNLIKELY;boat|0.9,vehicle|0.8\nB.jpg;rejected;VERY_UNLIKELY;VERY_UNLIKELY;VERY_UNLIKELY;UNLIKELY;text|0.9,font|0.8<\/p>\n\n<p>I want to use machine learning to be able to predict if a new image should be approved or rejected (second column in the csv file).<\/p>\n\n<p>Which algorithm should I use? <\/p>\n\n<p>How should I format the data, especially the annotations column? Should I obtain first all the available annotation types and use them as a feature with the numerical value (0 if it doesn't apply)? Or would it be better to just process the annotation column as text?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1487679435450,
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio|amazon-machine-learning",
        "Question_view_count":97,
        "Owner_creation_time":1364894167927,
        "Owner_last_access_time":1584637381497,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42367141",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58050526,
        "Question_title":"How to have my customized score file deployed on Azure with azure.mlflow sdk?",
        "Question_body":"<p>I have a customized score.py file which was generated within databricks but I didn't find a way to deploy it on a container.<\/p>\n\n<p>I am using the mlflow.azureml, on my image creation I couldn't find how to specify the score.py in particular.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow.azureml\n\nmodel_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                      workspace=workspace,\n                                                      model_name=\"my_model\",\n                                                      image_name=\"image_name\",\n                                                      description=\"Predicts\",\n                                                      synchronous=False)\n<\/code><\/pre>\n\n<p>Is there a way to specify the score.py using the lib?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1569165044150,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|mlflow",
        "Question_view_count":226,
        "Owner_creation_time":1396493951190,
        "Owner_last_access_time":1615670657030,
        "Owner_location":null,
        "Owner_reputation":85,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58050526",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62189492,
        "Question_title":"How to pass PipelineParameter into AutoMLStep in AzureML Python SDK",
        "Question_body":"<p>I am using AzureML SDK pipeline with AutoMLStep. How can I add PipelineParameter into AutoMLStep configuration? I would like to use it for a definition of max_horizon.\nIt should work with <\/p>\n\n<blockquote>\n  <p>passthru_automl_config=False<\/p>\n<\/blockquote>\n\n<p>but I am getting error <\/p>\n\n<blockquote>\n  <p>Message: Unsupported value of max_horizon. max_horizon must be integer or 'auto'<\/p>\n<\/blockquote>\n\n<pre><code>max_horizon = PipelineParameter(name='max_horizon', default_value=30)\n\nautoml_settings = {\n            \"iteration_timeout_minutes\" : 60\n            \"grain_column_names\": [\"COUNTRY_CODE\"],\n            \"time_column_name\": \"DATE\"\n        }        \n\nautoml_config = AutoMLConfig(task='forecasting',\n                             path = \".\/src\",\n                             primary_metric=primary_metric,\n                             iterations=iterations,\n                             max_concurrent_iterations=max_concurrent_iterations,\n                             training_data = train_data,\n                             label_column_name = label,\n                             n_cross_validations=5,\n                             compute_target = compute_target,\n                             max_horizon= max_horizon,\n                             **automl_settings)\n\ntrainWithAutomlStep = AutoMLStep(name=\"experiment_name\",\n                                 automl_config=automl_config,\n                                 passthru_automl_config=False,\n                                 outputs=[metrics_data, model_data],\n                                 allow_reuse=True)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1591257136050,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":316,
        "Owner_creation_time":1436771091480,
        "Owner_last_access_time":1652881662557,
        "Owner_location":"Brno, \u010cesko",
        "Owner_reputation":51,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1592201521010,
        "Answer_body":"<p>Here is a response from Microsoft:<\/p>\n\n<blockquote>\n  <p>PipelineParameter is currently not supported for use with AutoMLConfig parameters inside of AutoMLStep.<\/p>\n  \n  <p>Then, the only workaround in order to use PipelineParameter with\n  AutoMLConfig would be to use AutoML in a PythonScriptStep, which is a\n  similar usage\/approach when you use AutoMLConfig with\n  ParallelRunConfig in pipelines (without using AutoMLStep), like the\n  \u2018Many Models\u2019 solution accelerator does.<\/p>\n<\/blockquote>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1592202183327,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62189492",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72621994,
        "Question_title":"How to build Face\/ Image Classifier in Azure ML like Google Photos",
        "Question_body":"<p>I need to build an image classification model in Azure  ML- which initially takes an input from Phone (A check in app which takes information like ID and also we will capture the image of the person- Here ID is used to tag the image) which will be redirected to data storage. once it's done, we will upload the n number of images of person to the data storage, it should able to classify the image based on facial recognition and should categorize as separate image folder for different person( Just like Google Photos). In short, If there's a 100 unique people come for check in and during the event if we click random images of these 100 unique persons, when we load this data to blob - it should categorize the persons separately.<\/p>\n<p>Can I go with approach-<\/p>\n<p>1.Check in app-- Loads image with tag\n2.Blob- store the image\n3. custom vison- ML classifier\n4.Loding n number of images to blob\n5. comparing the image with check in app loaded image and categorizing as album just like google photos\n6. Loading albums to app to make attendees to see the images<\/p>\n<p>Please guide me with the solution and services need to be considered to make this possible in azure<\/p>\n<p>Thanks in adavance<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655232509777,
        "Question_score":0,
        "Question_tags":"azure-cognitive-services|image-classification|azure-machine-learning-service|microsoft-custom-vision|facial-identification",
        "Question_view_count":34,
        "Owner_creation_time":1651208274493,
        "Owner_last_access_time":1660105136120,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72621994",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69584991,
        "Question_title":"Azure AutoML seems to add extra input?",
        "Question_body":"<p>I'm using azure Automated ML to do some proof of concepts. I'm trying to identify a person based on some parameters.<\/p>\n<p>In my dataset I have 4 columns of floats and 1 column containing the name of the person. My ambition is to be able to detect the person, based on the input of these 4 floats.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AEZg0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AEZg0.png\" alt=\"Dataset schema. Contains 5 columns\" \/><\/a><\/p>\n<p>I have successfully trained some models based on this information. The data transformation chart looks like this, which is as I would expect:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/r4X2r.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/r4X2r.png\" alt=\"Data Transformation Chart\" \/><\/a><\/p>\n<p>So it ignores one column (the &quot;person&quot; column I assume) and uses the remaining 4 as input to a RandomForrest classifier. All is well and good so far.<\/p>\n<p>When I then go and deploy the model, I now need to add a new variable simply called &quot;Column2&quot;. This variable seems to have significant influence on the output data<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ssBhq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ssBhq.png\" alt=\"Input example\" \/><\/a><\/p>\n<p>When I make a request to the endpoint with two inputs where the only difference is the value of the &quot;Column2&quot; I get two different probabilities back:<\/p>\n<pre><code>\n{'PCA_0': -574.0043295463845, 'PCA_1': 3455.9091610620617, 'PCA_2': 2352.2555893520835, 'PCA_3': -6941.596091271862, 'Column2': '0'} = [0.24, 0.4, 0.06, 0.3]\n{'PCA_0': -574.0043295463845, 'PCA_1': 3455.9091610620617, 'PCA_2': 2352.2555893520835, 'PCA_3': -6941.596091271862, 'Column2': '1'} = [0.26, 0.19, 0.54, 0.01]\n<\/code><\/pre>\n<p>Anyone has any idea about what I'm doing wrong here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1634302137757,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":100,
        "Owner_creation_time":1504519461013,
        "Owner_last_access_time":1663923545203,
        "Owner_location":"Copenhagen, Denmark",
        "Owner_reputation":159,
        "Owner_up_votes":23,
        "Owner_down_votes":3,
        "Owner_views":28,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69584991",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":31609319,
        "Question_title":"'Enter Data' as list instead of list of lists in Azure ML Web Service",
        "Question_body":"<p>In Azure ML, I want to enter data to a model through a published Web Service. \nThe way to tell this to the Web Service, as far as I can tell, it to have an 'Enter Data' box coming into the same input as the Web service. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/m1x5x.png\" alt=\"enter image description here\"><\/p>\n\n<p>You can then set you data format in the 'Enter Data' properties:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/VQJ9V.png\" alt=\"enter image description here\"><\/p>\n\n<p>I want that list to be an arbitrary-length array of samples. This works if your input is:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"samples\"\n      ],\n      \"Values\": [\n        [\n          1\n        ],\n        [\n          2\n        ],\n        [\n          3\n        ],\n        [\n          4\n        ],\n        [\n          5\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>This is ok, but ideally it would be easier, and (more importantly) more network-efficient, if I could send them as:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"samples\"\n      ],\n      \"Values\": [\n        [\n          1,2,3,4,5\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>Is there a correct syntax to implement this? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1437737046243,
        "Question_score":0,
        "Question_tags":"python|json|azure|azure-machine-learning-studio",
        "Question_view_count":174,
        "Owner_creation_time":1266595927520,
        "Owner_last_access_time":1633931623067,
        "Owner_location":null,
        "Owner_reputation":7681,
        "Owner_up_votes":284,
        "Owner_down_votes":8,
        "Owner_views":361,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have worked internally to request a confirmation of your concern - <\/p>\n\n<blockquote>\n  <p>'Enter Data' as list instead of list of lists in Azure ML Web Service<\/p>\n<\/blockquote>\n\n<p>but you expected feature is not available today in Azure ML Studio (The reason behind is Azure ML has to be able to read the input data as a tabular format, rows and columns). Such being the case, I would like to suggest you to submit a new feature request via below option:<\/p>\n\n<p>On Azure ML Studio -> the upper right corner, there is a smiley face, please click that and send the feedback.<\/p>\n\n<p>Should you have any further concerns, please feel free to let me know.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1438871325837,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/31609319",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60550897,
        "Question_title":"Pipeline error: \"AttributeError: 'ColumnTransformer' object has no attribute '_feature_names_in'\"",
        "Question_body":"<p>I am trying to use scikitlearn to predict over new data using a pipeline object I had trained back in February. Since Friday, February 28th, the predict function no longer works for my pipeline object, citing the error:<\/p>\n\n<pre><code>&gt;&gt;&gt; df = pd.read_csv('test_df_for_example.csv')\n&gt;&gt;&gt; mdl = joblib.load('split_0_model.pkl')\n&gt;&gt;&gt; mdl.predict(df)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/sklearn\/utils\/metaestimators.py\", line 116, in &lt;lambda&gt;\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/sklearn\/pipeline.py\", line 419, in predict\n    Xt = transform.transform(Xt)\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/sklearn\/compose\/_column_transformer.py\", line 587, in transform\n    self._validate_features(X.shape[1], X_feature_names)\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/sklearn\/compose\/_column_transformer.py\", line 411, in _validate_features\n    if ((self._feature_names_in is None or feature_names is None)\nAttributeError: 'ColumnTransformer' object has no attribute '_feature_names_in'\n<\/code><\/pre>\n\n<p>I am using Microsoft Azure's virtual machines to do this predicting (although the above code I ran on my local computer), so working with the versioning of the modules is difficult, and most of the time I am forced to use the latest versions of packages. I believe this error comes from scikitlearn's new version 0.22.2.post1, which I am using.<\/p>\n\n<p>I have an example CSV with testing data <a href=\"https:\/\/drive.google.com\/open?id=1iS2X1jM8eY246AJ5Eh1nnpwCJmjbilM0\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n\n<p>The model file pickled with joblib <a href=\"https:\/\/drive.google.com\/open?id=13Cz374Uvn-ssGZWGps3MQVzpWjilmNKO\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n\n<p>And code to reproduce the error <a href=\"https:\/\/drive.google.com\/open?id=1iS2X1jM8eY246AJ5Eh1nnpwCJmjbilM0\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n\n<p>And yaml environment file <a href=\"https:\/\/drive.google.com\/open?id=1hJTErtqCT3gNUKdcFeZ7EaUZhHm40Juv\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n\n<p>Is there any way I can upgrade my model so that this error does not occur?<\/p>\n\n<p>Thanks!\nKristine<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1583429013407,
        "Question_score":2,
        "Question_tags":"python|python-3.x|scikit-learn|azure-machine-learning-service",
        "Question_view_count":2071,
        "Owner_creation_time":1572270460550,
        "Owner_last_access_time":1593992185087,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60550897",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49673502,
        "Question_title":"Azure Machine Learning - Predicting a win\/lose\/draw API",
        "Question_body":"<p>I'm experimenting with an existing experiment on the Azure Machine learning gallery.  Its called <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Beat-the-Bookie\" rel=\"nofollow noreferrer\">beat the bookie<\/a>.  I want to take it to the next step and add a web service to it.  This particular experiment has a dataset for years of matches.  It has a small python script to calculate an ELO (like chess or most online games).  I'm struggling to create an input API with 2 inputs: homeTeam and awayTeam.  With an output of 1 value FTR (Full-Time Result) which is either W\/D\/L (Win, Draw or Lose).<\/p>\n\n<p>The issue I have is that when I create the API it has too many required inputs.  Do I have to give them averaged data or how do I reduce the inputs to 2?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1522934588567,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":64,
        "Owner_creation_time":1469533385120,
        "Owner_last_access_time":1656601407173,
        "Owner_location":"Ireland",
        "Owner_reputation":970,
        "Owner_up_votes":93,
        "Owner_down_votes":1,
        "Owner_views":68,
        "Question_last_edit_time":1526058346293,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49673502",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37749862,
        "Question_title":"Azure Machine Learning, 1 web input with multiple outputs?",
        "Question_body":"<p>Im trying to deploy a web app that takes 1 web input, then \"Set Column In Dataset\" a few times for each model , and then sends out a web output for each model.  <\/p>\n\n<p>Right now the way I have it setup is I have a few web inputs, then a model that runs for each, and then a web output for each.  It works for now, but it's a hassle because every time I want to add a new model to be predicted I have to add a bunch of stuff in both azure and my web application.  Just wondering if there is an easier way I'm missing.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1465566251803,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":492,
        "Owner_creation_time":1365606882047,
        "Owner_last_access_time":1521227952720,
        "Owner_location":null,
        "Owner_reputation":810,
        "Owner_up_votes":10,
        "Owner_down_votes":1,
        "Owner_views":49,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I am not quite sure I understand the workflow you described. Can you provide more details on what are you trying to accomplish with your web app and your experiment? For example, what do you mean when you say \"I have to add a bunch of stuff\"?<\/p>\n\n<p>Azure ML does support multiple web service inputs and outputs. Adding a new model to the experiment requires you to re-deploy your web service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1467051292427,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37749862",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42204411,
        "Question_title":"Why require only R >= 3.3.0?",
        "Question_body":"<p>I'm building a R model in Azure machine learning with a zipped xgboost package attached to the 'execute R script'. <\/p>\n\n<p>Azure machine learning uses R 3.2.2.<\/p>\n\n<p>The model returns with an error saying \"This is R 3.2.2, package 'xgboost' needs >= 3.3.0\".<\/p>\n\n<p>Is there any reason it insists on >= 3.3.0. If not, can I get it down to run with R 3.2.2?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1486989987357,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":106,
        "Owner_creation_time":1351534968770,
        "Owner_last_access_time":1663768904350,
        "Owner_location":null,
        "Owner_reputation":823,
        "Owner_up_votes":16,
        "Owner_down_votes":4,
        "Owner_views":114,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42204411",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29906812,
        "Question_title":"forecast package versions different result",
        "Question_body":"<p>I am using R forecast package auto.arima() function, testing it against a predictable sine wave time series. When I run the R code on local machine in R studio, I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1430172286407,
        "Question_score":0,
        "Question_tags":"r|azure-virtual-machine|azure-machine-learning-studio",
        "Question_view_count":212,
        "Owner_creation_time":1430171674327,
        "Owner_last_access_time":1474914701380,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1483523471853,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29906812",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42105549,
        "Question_title":"Azure Machine Learning Studio and OpenCV",
        "Question_body":"<p>Has anyone successfully used the entire opencv library with Azure ML Studio and the Python Module? I know to use a python module that is not included in the ananconda version it must be uploaded in as a zip and from there you can use the entire library. Could someone explain to me exactly what to upload as a zip and then how to access specific functions of the opencv library once uploaded.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_creation_time":1486532576980,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":2112,
        "Owner_creation_time":1444619451790,
        "Owner_last_access_time":1663806305207,
        "Owner_location":"Sydney NSW, Australia",
        "Owner_reputation":823,
        "Owner_up_votes":98,
        "Owner_down_votes":8,
        "Owner_views":48,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42105549",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73119660,
        "Question_title":"SAME PARQUET FILE different float values read when using AzureML Dataset vs Directly Getting From Azure Storage using Bytestream",
        "Question_body":"<p>A little background, we are exploring a dataset given by a 3rd party vendor, which they've exposed to us using their SNOWFLAKE instance. What I did then was I exported this dataset into our Azure Blob Storage(s) as parquet files then created an AzureML dataset that encapsulates the parquet files that are stored in our BLOB CONTAINERS.<\/p>\n<p>As I was exploring the data, I raised to them that I saw erroneous data with their longitude and latitude data which they denied. I then sent screenshots of the erroneous data, and when we queried the same data using SNOWFLAKE that I am raising as erroneous, the values were indeed correct!<\/p>\n<p>I was baffled, and upon investigation, I narrowed it down to AzureML dataset somewhat gives INCORRECT data VERSUS if you directly read the parquet file \/ blob via stream into a pandas dataframe.<\/p>\n<p>Also, all text data were identical, but when it came to FLOAT values, the incorrect values are manifesting.<\/p>\n<p>I checked the datatypes when defining the schema of the AzureML dataset, and they are correct<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Gfr2n.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Gfr2n.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Honestly, Im stomped. Any ideas or anyone encountered this issue and can explain to me what is happening? Thank you<\/p>\n<h2><strong>SCREENSHOTS BELOW<\/strong><\/h2>\n<p>Here is when read using the AzureML dataset<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/kqN0Y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kqN0Y.png\" alt=\"Here is when read using the AzureML dataset\" \/><\/a><\/p>\n<hr \/>\n<p>Here is the same file, same record, read directly from blob storage using bytestream<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Bs5Pp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Bs5Pp.png\" alt=\"Here is the same file, same record, read directly from blob storage using bytestream\" \/><\/a><\/p>\n<p>Downloaded the parquet file to my local machine and viewed it<\/p>\n<hr \/>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2UyOl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2UyOl.png\" alt=\"Downloaded the parquet file to my local machine and viewed it\" \/><\/a><\/p>\n<hr \/>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1658822270190,
        "Question_score":1,
        "Question_tags":"pandas|dataframe|azure|parquet|azure-machine-learning-service",
        "Question_view_count":129,
        "Owner_creation_time":1340063804277,
        "Owner_last_access_time":1664031102627,
        "Owner_location":null,
        "Owner_reputation":298,
        "Owner_up_votes":10,
        "Owner_down_votes":1,
        "Owner_views":38,
        "Question_last_edit_time":1658824845597,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73119660",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68463080,
        "Question_title":"how create azure machine learning scoring image using local package",
        "Question_body":"<p>I have pkl package saved in my azure devops repository<\/p>\n<p>using below code it searches for package in workspace.\nHow to provide package saved in repository<\/p>\n<pre><code> ws = Workspace.get(\n         name=workspace_name,\n         subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=cli_auth)\n\nimage_config = ContainerImage.image_configuration(\n    execution_script=&quot;score.py&quot;,\n    runtime=&quot;python-slim&quot;,\n    conda_file=&quot;conda.yml&quot;,\n    description=&quot;Image with ridge regression model&quot;,\n    tags={&quot;area&quot;: &quot;ml&quot;, &quot;type&quot;: &quot;dev&quot;},\n)\n\nimage = Image.create(\n    name=image_name,  models=[model], image_config=image_config, workspace=ws\n)\n\nimage.wait_for_creation(show_output=True)\n\nif image.creation_state != &quot;Succeeded&quot;:\n    raise Exception(&quot;Image creation status: {image.creation_state}&quot;)\n\nprint(\n    &quot;{}(v.{} [{}]) stored at {} with build log {}&quot;.format(\n        image.name,\n        image.version,\n        image.creation_state,\n        image.image_location,\n        image.image_build_log_uri,\n    )\n)\n\n# Writing the image details to \/aml_config\/image.json\nimage_json = {}\nimage_json[&quot;image_name&quot;] = image.name\nimage_json[&quot;image_version&quot;] = image.version\nimage_json[&quot;image_location&quot;] = image.image_location\nwith open(&quot;aml_config\/image.json&quot;, &quot;w&quot;) as outfile:\n    json.dump(image_json, outfile)\n<\/code><\/pre>\n<p>I tried to provide path to models but its fails saying package not found<\/p>\n<p>models = $(System.DefaultWorkingDirectory)\/package_model.pkl<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1626831896507,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":140,
        "Owner_creation_time":1567209656790,
        "Owner_last_access_time":1663349187993,
        "Owner_location":null,
        "Owner_reputation":417,
        "Owner_up_votes":53,
        "Owner_down_votes":0,
        "Owner_views":233,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Register model:\nRegister a file or folder as a model by calling <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-\" rel=\"nofollow noreferrer\">Model.register()<\/a>.<\/p>\n<p>In addition to the content of the model file itself, your registered model will also store model metadata -- model description, tags, and framework information -- that will be useful when managing and deploying models in your workspace. Using tags, for instance, you can categorize your models and apply filters when listing models in your workspace.<\/p>\n<pre><code>model = Model.register(workspace=ws,\n                       model_name='',                # Name of the registered model in your workspace.\n                       model_path='',  # Local file to upload and register as a model.\n                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n                       sample_input_dataset=input_dataset,\n                       sample_output_dataset=output_dataset,\n                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n                       description='Ridge regression model to predict diabetes progression.',\n                       tags={'area': 'diabetes', 'type': 'regression'})\n\nprint('Name:', model.name)\nprint('Version:', model.version)\n<\/code><\/pre>\n<p>Deploy machine learning models to Azure: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a><\/p>\n<p>To Troubleshooting remote model deployment Please follow the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#function-fails-get_model_path\" rel=\"nofollow noreferrer\">document<\/a>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BL0Nm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BL0Nm.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1627276170737,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1627278873550,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68463080",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36967126,
        "Question_title":"Why do I get good accuracy with IRIS dataset with a single hidden node?",
        "Question_body":"<p>I have a minimal example of a neural network with a back-propagation trainer, testing it on the IRIS data set. I started of with 7 hidden nodes and it worked well.<\/p>\n\n<p>I lowered the number of nodes in the hidden layer to 1 (expecting it to fail), but was surprised to see that the accuracy went up.<\/p>\n\n<p>I set up the experiment in azure ml, just to validate that it wasn't my code. Same thing there, 98.3333% accuracy with a single hidden node.<\/p>\n\n<p>Can anyone explain to me what is happening here?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1462108714660,
        "Question_score":4,
        "Question_tags":"machine-learning|neural-network|backpropagation|azure-machine-learning-studio",
        "Question_view_count":4488,
        "Owner_creation_time":1426502047333,
        "Owner_last_access_time":1663944347530,
        "Owner_location":null,
        "Owner_reputation":825,
        "Owner_up_votes":46,
        "Owner_down_votes":0,
        "Owner_views":82,
        "Question_last_edit_time":null,
        "Answer_body":"<p>First, it has been well established that a variety of classification models yield incredibly good results on Iris (Iris is very predictable); see <a href=\"http:\/\/lab.fs.uni-lj.si\/lasin\/wp\/IMIT_files\/neural\/doc\/seminar8.pdf\" rel=\"noreferrer\">here<\/a>, for example.<\/p>\n\n<p>Secondly, we can observe that there are relatively few features in the Iris dataset. Moreover, if you look at the <a href=\"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.names\" rel=\"noreferrer\">dataset description<\/a> you can see that two of the features are very highly correlated with the class outcomes.<\/p>\n\n<p>These correlation values are linear, single-feature correlations, which indicates that one can most likely apply a linear model and observe good results. Neural nets are highly nonlinear; they become more and more complex and capture greater and greater nonlinear feature combinations as the number of hidden nodes and hidden layers is increased.<\/p>\n\n<p>Taking these facts into account, that (a) there are few features to begin with and (b) that there are high linear correlations with class, would all point to a less complex, linear function as being the appropriate predictive model-- by using a single hidden node, you are very nearly using a linear model.<\/p>\n\n<p>It can also be noted that, in the absence of any hidden layer (i.e., just input and output nodes), and when the logistic transfer function is used, this is equivalent to logistic regression.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1462119764790,
        "Answer_score":6.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1462144469997,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36967126",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66557604,
        "Question_title":"Issues Formatting Azure Cognitive skill set input correctly for ML integration",
        "Question_body":"<p>I am attempting to integrate Azure machine learning with Azure Cognitive Search. I am using a Skill Set and currently the schema for the real-time ML endpoint is this:<\/p>\n<pre><code>&quot;Inputs&quot;: {\n        &quot;WebServiceInput0&quot;:\n        [\n            {\n\n                &quot;CompanyName&quot;: &quot;Apple Inc&quot;,\n            }\n        ]\n    }\n\n<\/code><\/pre>\n<p>When using a debugging session to determine if the skill set setup is correct, I get an error saying that the input data doesn't follow the schema.<\/p>\n<p>This is what the skill set outputs:<\/p>\n<pre><code>&quot;Inputs&quot;: {\n          &quot;WebServiceInput0&quot;: {\n            &quot;CompanyName&quot;: &quot;Apple Inc&quot;,\n          }\n        }\n<\/code><\/pre>\n<p>I have noticed in the schema that the <strong>WebServiceInput0<\/strong> property is an array and therefore this is potentially causing the issue.<\/p>\n<p>I am wondering how I could format the input and add &quot;[&quot; to make <strong>WebServiceInput0<\/strong> an array.<\/p>\n<p>I have tried the Shaper Skill although this wasn't helpful.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1615344173743,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-cognitive-search|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":30,
        "Owner_creation_time":1385945361683,
        "Owner_last_access_time":1628570902717,
        "Owner_location":"Sydney NSW, Australia",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66557604",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65231534,
        "Question_title":"How to use Pipeline parameters on AzureML",
        "Question_body":"<p>I've built a pipeline on AzureML Designer and I'm trying to use pipeline parameters but I'm not able to get the values of those parameters on a python script module.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-your-first-pipeline<\/a>\nThis documentation contains a section called &quot;<em>Use pipeline parameters for arguments that change at inference time&quot;<\/em> but, unfortunately, it is empty.<\/p>\n<p>I'm defining the parameters on the pipeline setting, see the screenshot on the bottom. Does anyone know how to use the parameters when using the Designer to build the pipeline?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nJTlv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nJTlv.png\" alt=\"pipeline parameters definition\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1607591444673,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":2215,
        "Owner_creation_time":1536515516827,
        "Owner_last_access_time":1663940912323,
        "Owner_location":null,
        "Owner_reputation":85,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1607679025793,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65231534",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67533091,
        "Question_title":"where are registered models in azure machine learning",
        "Question_body":"<p>I try to use azuremlsdk to deploy a locally trained model (a perfectly valid use case AFIK). I follow <a href=\"https:\/\/cran.r-project.org\/web\/packages\/azuremlsdk\/vignettes\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">this<\/a> and managed to create a ML workspace and register a &quot;model&quot; like so:<\/p>\n<pre><code>library(azuremlsdk)\n\ninteractive_auth &lt;- interactive_login_authentication(tenant_id=&quot;xxx&quot;)\nws &lt;- get_workspace(\n        name = &quot;xxx&quot;, \n        subscription_id = &quot;xxx&quot;, \n        resource_group =&quot;xxx&quot;, \n        auth = interactive_auth\n)\n\nadd &lt;- function(a, b) {\n    return(a + b)\n}\n\nadd(1,2)\n\nsaveRDS(add, file = &quot;D:\/add.rds&quot;)\n\nmodel &lt;- register_model(\n    ws, \n    model_path = &quot;D:\/add.rds&quot;, \n    model_name = &quot;add_model&quot;,\n    description = &quot;An amazing model&quot;\n)\n<\/code><\/pre>\n<p>This seemed to work fine, as I get some nice log messages telling me that the model was registered. For my sanity, I wonder where can I find this registered (&quot;materialised&quot;) model\/object\/function in the Azure UI please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1620989367110,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":41,
        "Owner_creation_time":1267440784443,
        "Owner_last_access_time":1664045779313,
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Question_last_edit_time":null,
        "Answer_body":"<p>On ml.azure.com, there is a &quot;Models&quot; option on the left-hand blade.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" alt=\"UI Sidebar\" \/><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1621001633740,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67533091",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":28205136,
        "Question_title":"Does Microsoft Azure Machine Learning use Hadoop as its underlying layer?",
        "Question_body":"<p>I'm going to use Microsoft Azure ML for some text analysis purposes such as keyword extraction and as the size of my input is big I want to know whether ML package actually uses the Hadoop (HDP) as its underlying layer or not? If not, how can I use the ML in combination with Hadoop?<\/p>\n\n<p>Does Mahout have some text analysis tools?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1422491951960,
        "Question_score":1,
        "Question_tags":"java|azure|mahout|azure-machine-learning-studio",
        "Question_view_count":660,
        "Owner_creation_time":1355343131933,
        "Owner_last_access_time":1649125560750,
        "Owner_location":null,
        "Owner_reputation":5655,
        "Owner_up_votes":73,
        "Owner_down_votes":3,
        "Owner_views":629,
        "Question_last_edit_time":1642755247410,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28205136",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68912185,
        "Question_title":"Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties' in Azure Machine Learning Designer",
        "Question_body":"<p>From today (Aug 24th, 2021) I'm receiving the following error message when submit any operation in Azure Machine Learning Designer with a dataset:<\/p>\n<p><strong>Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'<\/strong><\/p>\n<p>Complete error message:<\/p>\n<p><em>UserError: Job submission to AzureML Compute encountered an Exception with status code , Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'. Path 'properties.intellectualPropertyPublisher', line 309, position 36.<\/em><\/p>\n<p>I'm seeing there's new items in user interface, maybe could be an updating error?\nSomeone is receiving something that?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1629828602630,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":30,
        "Owner_creation_time":1629828242253,
        "Owner_last_access_time":1653671859740,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1630364458667,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68912185",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73178409,
        "Question_title":"How to get absolute path to \"outputs\" folder in Azure ML",
        "Question_body":"<p>In the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-save-write-experiment-files\" rel=\"nofollow noreferrer\">documentation<\/a> of Azure Machine Learning, under &quot;Where to write files&quot;, it says<\/p>\n<blockquote>\n<p>Otherwise, write files to the <code>.\/outputs<\/code> and\/or <code>.\/logs<\/code> folder.<\/p>\n<\/blockquote>\n<p>These are relative paths, i.e. relative to the folder where my script is run by the Azure ML framework. I was not able to find a function in the Azure ML SDK that would return the absolute path -- have I missed it or is there none? (Meaning that I should read the <code>cwd<\/code> at the beginning of my script and store it myself.)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659208299903,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":111,
        "Owner_creation_time":1248371469417,
        "Owner_last_access_time":1664058388787,
        "Owner_location":null,
        "Owner_reputation":7506,
        "Owner_up_votes":752,
        "Owner_down_votes":11,
        "Owner_views":360,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73178409",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62571695,
        "Question_title":"AzureML Model.profile() timeout without ever running the model",
        "Question_body":"<p>When trying to profile our AzureML model we run into a timeout. According to the log statements, <strong>the model is initialized<\/strong> but the <strong>run function is never called<\/strong>.<\/p>\n<p>The dataset provided contains one column (&quot;profile_requests&quot;) and 100 samples of serialized json that the model usually consumes. Both model and score.py work fine when deploying via Model.deploy (see below).<\/p>\n<p>Why is the run function never called?<\/p>\n<pre><code>profile = Model.profile(ws, \n    profile_name='my-profile-name',\n    models=[latest_model], \n    inference_config=InferenceConfig(\n                                    entry_script='score.py', \n                                    source_directory=&quot;deployment&quot;,\n                                    environment=Environment.get(ws, &quot;my_environment&quot;)), \n    input_dataset=processed_dataset,\n    cpu=2,\n    memory_in_gb=3)\n<\/code><\/pre>\n<pre><code>{...,\n 'error': {'code': 'ModelTestTimeOut',\n  'statusCode': 500,\n  'message': 'The model did not finish the test within the allowed time: 30 min. Error logs URL: https:\/\/link-to-logfile',\n  'details': []},\n 'errorLogsUri': 'https:\/\/link-to-logfile'}\n<\/code><\/pre>\n<p>Profiling log file:<\/p>\n<pre><code>==========Logs from model deployed to container with 2 cpu and 3 GB memory==========\n[...]\nInvoking user's init function\nModel loaded.\nUsers's init has completed successfully\nScoring timeout setting is not found. Use default timeout: 3600000 ms\n<\/code><\/pre>\n<p>One sample from the DataFrame (<code>sample_event=processed_dataset.to_pandas_dataframe().loc[0,&quot;profile_requests&quot;]<\/code>)<\/p>\n<pre><code>'{&quot;allevents&quot;: [{&quot;temperature&quot;: 103.76252626686478, &quot;ambienttemperature&quot;: 20.763083531178108, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:02&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 104.00700291712167, &quot;ambienttemperature&quot;: 20.77088671236806, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:07&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.73538818128196, &quot;ambienttemperature&quot;: 20.927115571418366, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:12&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.26993925975171, &quot;ambienttemperature&quot;: 20.977784248757075, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:17&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.47584351197627, &quot;ambienttemperature&quot;: 20.528207412934027, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:22&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.53497833736942, &quot;ambienttemperature&quot;: 21.176729435416277, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:27&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.33621482217512, &quot;ambienttemperature&quot;: 21.083552645791112, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:32&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.13542993745558, &quot;ambienttemperature&quot;: 20.80351544511668, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:37&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.45331951321728, &quot;ambienttemperature&quot;: 21.404335822865523, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:42&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.52506972734126, &quot;ambienttemperature&quot;: 20.51882900857312, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:47&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.61395300883524, &quot;ambienttemperature&quot;: 21.110307039511532, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:52&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.49871551548077, &quot;ambienttemperature&quot;: 21.133206947070178, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:57&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}]}'\n<\/code><\/pre>\n<p>Running the sample against the deployed webservice that uses the same environment and score.py <code>service.run(sample_event)<\/code> works as expected.<\/p>\n<pre><code>{'result': False,\n 'ConnectionDeviceId': 'milkbottleEdge',\n 'timeCreatedStart': '2020-04-02T12:07:02',\n 'timeCreatedEnd': '2020-04-02T12:07:57',\n 'hasError': False,\n 'errorMessage': None}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1593075784063,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":176,
        "Owner_creation_time":1584715327427,
        "Owner_last_access_time":1629377918267,
        "Owner_location":"Hamburg, Germany",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62571695",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73761872,
        "Question_title":"Azure ML Studio Docker Endpoint Deployment Error 400 Client Error",
        "Question_body":"<p>I would like to deploy an ML endpoint (first locally to see the error messages) from custom environment. But I am getting the following error message. Can anybody clarify what does this stands for?<\/p>\n<p>The environment deployment is fine, I can pull and play with the environment image, the the ML model also works as it expected, but in the endpoint development I fail.<\/p>\n<pre><code>from azureml.core.model import InferenceConfig, Model\nfrom azureml.core.webservice import AciWebservice, LocalWebservice\n\nocr_model = Model(name='OCR_model', workspace=workspace)\nquality_model = Model(name='Quality_model', workspace=workspace)\ninference_config = InferenceConfig(entry_script=&quot;ml_scores.py&quot;, environment=python_env)\ndeployment_config = LocalWebservice.deploy_configuration(port=6789)\n\nservice = Model.deploy(workspace=workspace,\n                       name=&quot;ml-service-v2&quot;,\n                       overwrite=True,\n                       models=[ocr_model, quality_model],\n                       inference_config=inference_config,\n                       deployment_config=deployment_config)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>The error message:<\/p>\n<pre><code>Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\nWarning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\nDocker container start has failed:\n400 Client Error for http+docker:\/\/localhost\/v1.41\/containers\/f4ee0f109af60a21a11683dd3d69db87b6371b2c3b038ea0227a8cc8422c4200\/start: Bad Request (&quot;failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &quot;runsvdir&quot;: executable file not found in $PATH: unknown&quot;)\n\nDownloading model OCR_model:42 to \/tmp\/azureml_25emn1le\/OCR_model\/42\nDownloading model Quality_model:40 to \/tmp\/azureml_25emn1le\/Quality_model\/40\nGenerating Docker build context.\nPackage creation Succeeded\nLogging into Docker registry 088e52be0d7942c4a6e11258fa37a140.azurecr.io\nLogging into Docker registry 088e52be0d7942c4a6e11258fa37a140.azurecr.io\nBuilding Docker image from Dockerfile...\nStep 1\/5 : FROM 088e52be0d7942c4a6e11258fa37a140.azurecr.io\/azureml\/azureml_152ffef9bfdf00715d63c8352ff2cc66\n ---&gt; 31b97aac1e18\nStep 2\/5 : COPY azureml-app \/var\/azureml-app\n ---&gt; a31c2d80deb2\nStep 3\/5 : RUN mkdir -p '\/var\/azureml-app' &amp;&amp; echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjIwMjQ0MjYwLWQyY2ItNDNkMy05NjZlLWQwZjcyMDE3ZWJhMCIsInJlc291cmNlR3JvdXBOYW1lIjoibWxfYmV0YV9yZyIsImFjY291bnROYW1lIjoibWFjaGluZS1sZWFybmluZy1iZXRhLXdzIiwid29ya3NwYWNlSWQiOiIwODhlNTJiZS0wZDc5LTQyYzQtYTZlMS0xMjU4ZmEzN2ExNDAifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode &gt; \/var\/azureml-app\/model_config_map.json\n ---&gt; Running in 783f521ea037\n ---&gt; 8900434882b2\nStep 4\/5 : RUN mv '\/var\/azureml-app\/tmpdswbb3xk.py' \/var\/azureml-app\/main.py\n ---&gt; Running in 8b61d3f35a90\n ---&gt; 05890493cdd1\nStep 5\/5 : CMD [&quot;runsvdir&quot;,&quot;\/var\/runit&quot;]\n ---&gt; Running in 052ae96b5d75\n ---&gt; b15b8dfb9deb\nSuccessfully built b15b8dfb9deb\nSuccessfully tagged ml-service-v2:latest\nContainer (name:xenodochial_goldwasser, id:2757f295fa1836dd83d2dcb162ccbb566c04cba1f3fb0c35943f5d4d101d5479) cannot be killed.\nContainer has been successfully cleaned up.\nImage sha256:ed2b4e50c397597d857883a76e5d53a5c27ce700894d3b2f7167d477f7b82be2 successfully removed.\nStarting Docker container...\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/api\/client.py:268, in APIClient._raise_for_status(self, response)\n    267 try:\n--&gt; 268     response.raise_for_status()\n    269 except requests.exceptions.HTTPError as e:\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/requests\/models.py:1021, in Response.raise_for_status(self)\n   1020 if http_error_msg:\n-&gt; 1021     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: http+docker:\/\/localhost\/v1.41\/containers\/f4ee0f109af60a21a11683dd3d69db87b6371b2c3b038ea0227a8cc8422c4200\/start\n\nDuring handling of the above exception, another exception occurred:\n\nAPIError                                  Traceback (most recent call last)\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/_model_management\/_util.py:495, in start_docker_container(container)\n    493 print(&quot;Starting Docker container...&quot;)\n--&gt; 495 container.start()\n    497 print('Docker container running.')\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/models\/containers.py:404, in Container.start(self, **kwargs)\n    396 &quot;&quot;&quot;\n    397 Start this container. Similar to the ``docker start`` command, but\n    398 doesn't support attach options.\n   (...)\n    402         If the server returns an error.\n    403 &quot;&quot;&quot;\n--&gt; 404 return self.client.api.start(self.id, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/utils\/decorators.py:19, in check_resource.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapped(self, resource_id, *args, **kwargs)\n     16     raise errors.NullResource(\n     17         'Resource ID was not provided'\n     18     )\n---&gt; 19 return f(self, resource_id, *args, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/api\/container.py:1109, in ContainerApiMixin.start(self, container, *args, **kwargs)\n   1108 res = self._post(url)\n-&gt; 1109 self._raise_for_status(res)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/api\/client.py:270, in APIClient._raise_for_status(self, response)\n    269 except requests.exceptions.HTTPError as e:\n--&gt; 270     raise create_api_error_from_http_exception(e)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/docker\/errors.py:31, in create_api_error_from_http_exception(e)\n     30         cls = NotFound\n---&gt; 31 raise cls(e, response=response, explanation=explanation)\n\nAPIError: 400 Client Error for http+docker:\/\/localhost\/v1.41\/containers\/f4ee0f109af60a21a11683dd3d69db87b6371b2c3b038ea0227a8cc8422c4200\/start: Bad Request (&quot;failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &quot;runsvdir&quot;: executable file not found in $PATH: unknown&quot;)\n\nDuring handling of the above exception, another exception occurred:\n\nWebserviceException                       Traceback (most recent call last)\nInput In [20], in &lt;cell line: 12&gt;()\n      9 # deployment_config = AciWebservice.deploy_configuration(cpu_cores=2, memory_gb=4)\n     10 deployment_config = LocalWebservice.deploy_configuration(port=6789)\n---&gt; 12 service = Model.deploy(workspace=workspace,\n     13                        name=&quot;ml-service-v2&quot;,\n     14                        overwrite=True,\n     15                        models=[ocr_model, quality_model],\n     16                        inference_config=inference_config,\n     17                        deployment_config=deployment_config)\n     19 service.wait_for_deployment(show_output=True)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/model.py:1649, in Model.deploy(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\n   1647 # Local webservice.\n   1648 if deployment_config and isinstance(deployment_config, LocalWebserviceDeploymentConfiguration):\n-&gt; 1649     return deployment_config._webservice_type._deploy(workspace, name, models,\n   1650                                                       inference_config=inference_config,\n   1651                                                       deployment_config=deployment_config)\n   1653 # IotWebservice does not support environment-style deployment,\n   1654 # so make sure we don't deploy IotWebservice with environment;\n   1655 # We only support ACI, AKS, AKS endpoint, and MIR for now.\n   1656 from azureml._model_management._constants import IOT_WEBSERVICE_TYPE\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/local.py:739, in LocalWebservice._deploy(workspace, name, models, image_config, deployment_config, wait, inference_config)\n    735     raise WebserviceException('Error, provided inference configuration must be of type InferenceConfig '\n    736                               'in order to deploy a local service.', logger=module_logger)\n    738 service = LocalWebservice(workspace, name, must_exist=False)\n--&gt; 739 service.update(models=models,\n    740                image_config=image_config,\n    741                inference_config=inference_config,\n    742                deployment_config=deployment_config,\n    743                wait=wait)\n    744 return service\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/local.py:72, in _in_state.&lt;locals&gt;.decorator.&lt;locals&gt;.decorated(self, *args, **kwargs)\n     69 if self.state not in states:\n     70     raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n     71                               logger=module_logger)\n---&gt; 72 return func(self, *args, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/local.py:549, in LocalWebservice.update(self, models, image_config, deployment_config, wait, inference_config)\n    547 self._generate_docker_context()\n    548 self._build_image()\n--&gt; 549 self._run_container(wait=wait)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/local.py:1021, in LocalWebservice._run_container(self, wait)\n   1018         LocalWebservice._copy_local_asset(container, self._inference_config.entry_script)\n   1020 # Engage!\n-&gt; 1021 start_docker_container(container)\n   1023 # Record the state of the deployment.\n   1024 self._container = container\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/_model_management\/_util.py:503, in start_docker_container(container)\n    500     raise WebserviceException('Docker container start has failed, the port you are attempting to use '\n    501                               'is already in use:\\n{}'.format(e), logger=module_logger)\n    502 else:\n--&gt; 503     raise WebserviceException('Docker container start has failed:\\n{}'.format(e), logger=module_logger)\n\nWebserviceException: WebserviceException:\n    Message: Docker container start has failed:\n400 Client Error for http+docker:\/\/localhost\/v1.41\/containers\/f4ee0f109af60a21a11683dd3d69db87b6371b2c3b038ea0227a8cc8422c4200\/start: Bad Request (&quot;failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &quot;runsvdir&quot;: executable file not found in $PATH: unknown&quot;)\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Docker container start has failed:\\n400 Client Error for http+docker:\/\/localhost\/v1.41\/containers\/f4ee0f109af60a21a11683dd3d69db87b6371b2c3b038ea0227a8cc8422c4200\/start: Bad Request (\\&quot;failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: \\&quot;runsvdir\\&quot;: executable file not found in $PATH: unknown\\&quot;)&quot;\n    }\n}\n<\/code><\/pre>\n<p>Thanks for any kind of guidance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663496243223,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":53,
        "Owner_creation_time":1663495768960,
        "Owner_last_access_time":1663888717353,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73761872",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33708725,
        "Question_title":"Azure Machine learning: error with multiclass classification algo",
        "Question_body":"<p>I have <a href=\"https:\/\/yadi.sk\/i\/--Vkm7FTkTAxY\" rel=\"nofollow noreferrer\">training set<\/a> and <a href=\"https:\/\/yadi.sk\/i\/wYu0ZsmukTAw3\" rel=\"nofollow noreferrer\">test set<\/a> (csv files with header), in which I have to classify each value. There is 118.000 uniq values in X column, and only about 13000 in y1 column, so there will be 13000 categories.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qc1i8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qc1i8.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>From Training set I need only <code>X<\/code> and <code>y1<\/code> column to train model. I need to classify X value to one of categories (find normal from of initial word). I tried all multi algo but failed trying to evaluate model.<\/p>\n\n<p>Visualizing Score model return this:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/EnDZq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EnDZq.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What can be a problem, it just returns -2 code as error and this <a href=\"https:\/\/yadi.sk\/i\/I6WiEoCGkTCXc\" rel=\"nofollow noreferrer\">log<\/a><\/p>\n\n<p>UPD1: By Metadata Editor module under Project Column Module made column y1  as categorical,  nothing seems to be changed<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1447506491170,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":75,
        "Owner_creation_time":1349985908313,
        "Owner_last_access_time":1654028256077,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":4886,
        "Owner_up_votes":1215,
        "Owner_down_votes":15,
        "Owner_views":1228,
        "Question_last_edit_time":1454300637020,
        "Answer_body":"<p><strong>Moncef<\/strong> provided <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/aabb9080-adf8-4fc0-b332-2a3c8ee29a28\/azure-machine-learning-error-with-multiclass-classification-algo?forum=MachineLearning\" rel=\"nofollow\">here<\/a> the solution to my problem:<\/p>\n\n<p>The point is that Azure has limitations on maximum categories 8192, this is why the number should be decreased by R or python modules or own evaluation module may be created. Or there is another way, evaluation step may be skipped, because model`ve been trained successfully. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1448271863193,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33708725",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67536581,
        "Question_title":"conda dependencies file r model in azure machine learning",
        "Question_body":"<p>I understand what the entry script\/scoring script is and does. See <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/articles\/deploying-models.html\" rel=\"nofollow noreferrer\">here<\/a> as an example. As I struggle to expose my deployed model via code as described <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/articles\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">here<\/a> (see also <a href=\"https:\/\/stackoverflow.com\/questions\/67535014\/deploy-model-to-azure-machine-learning-via-azuremlsdk\">here<\/a>), I am trying to use the UI ml.azure.com instead. I am a bit puzzled by the mandatory dependency: conda dependencies file:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BWtsE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BWtsE.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I have an R model but clearly this is a Python thing. What shall I use in this case?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1621004713270,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":609,
        "Owner_creation_time":1267440784443,
        "Owner_last_access_time":1664045779313,
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Question_last_edit_time":null,
        "Answer_body":"<p>conda is actually not just a Python thing, you might be thinking of pip?<\/p>\n<p>Conda is a package &amp; environment manager for nearly any kind of package, provided that it has been uploaded to anaconda. So you <em>can<\/em> use anaconda (and conda environment files) for R projects.<\/p>\n<p>The trouble is that the <code>azuremlsdk<\/code> CRAN package is not hosted as an anaconda package, but is probably needed for the scoring service. Worth using a file like below to see what it works.<\/p>\n<p>If it doesn't work, then I agree that this UI needs to generalized to better support R model deployment scenarios.<\/p>\n<p>It is also possible to add the <code>azuremlsdk<\/code> CRAN package to anaconda, but that requires <a href=\"https:\/\/stackoverflow.com\/a\/36653411\/3842610\">some extra work<\/a>, but ideally you shouldn't have to require this much manual effort.<\/p>\n<code>environment.yml<\/code>\n<p>Here's an example conda dependencies file for R.<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: scoring_environment\nchannels:\n  - defaults\ndependencies:\n  - r-base=3.6.1\n  - r-essentials=3.6.0\n  # whatever other dependencies you have\n  - r-tidyverse=1.2.1\n  - r-caret=6.0_83\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1621007147567,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67536581",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64139290,
        "Question_title":"How can I mark an Azure Dataset as a time series dataset reading from a parquet folder with date partitions?",
        "Question_body":"<p>I would like to create a Time series dataset from a folder that contains parquet files this way:<\/p>\n<ul>\n<li>timestamp=2018-01-06<\/li>\n<li>timestamp=2018-01-07<\/li>\n<\/ul>\n<p>How can I make Azure Dataset, through the GUI, recognises the timestamp partition as a date and mark my dataset as a time series dataset?<\/p>\n<p>It is supposed to be automatic, but it doesn't work.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1601474658457,
        "Question_score":2,
        "Question_tags":"parquet|azure-machine-learning-studio",
        "Question_view_count":109,
        "Owner_creation_time":1423640080283,
        "Owner_last_access_time":1663943557963,
        "Owner_location":"Lyon, France",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Thanks for reaching out to us.<\/p>\n<p>In Azure Machine Learning Studio, you would need to setup partition format similar to python SDK, as follows, assuming your data path is &quot;timeseries\/timestamp=2020-01-01\/data.parquet&quot;:\n<a href=\"https:\/\/i.stack.imgur.com\/HwYfF.png\" rel=\"nofollow noreferrer\">Set up partition format when creating time series dataset<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1601920685457,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64139290",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70268372,
        "Question_title":"How to adjust feature importance in Azure AutoML",
        "Question_body":"<p>I am hoping to have some <strong>low code model<\/strong> using Azure AutoML, which is really just going to the AutoML tab, running a classification experiment with my dataset, after it's done, I deploy the best selected model.<\/p>\n<p>The model kinda works (meaning, I publish the endpoint and then I do some manual validation, seems accurate), however, I am not confident enough, because when I am looking at the explanation, I can see something like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qM51x.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qM51x.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4 top features are not really closely important. The most &quot;important&quot; one is really not the one I prefer it to use. I am hoping it will use the <code>Title<\/code> feature more.<\/p>\n<p>Is there such a thing I can adjust the importance of individual features, like ranking all features before it starts the experiment?<\/p>\n<p>I would love to do more reading, but I only found this:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/52484233\/increase-feature-importance\">Increase feature importance<\/a><\/p>\n<p>The only answer seems to be about how to measure if a feature is important.<\/p>\n<p>Hence, does it mean, if I want to customize the experiment, such as selecting which features to &quot;focus&quot;, I should learn how to use the &quot;designer&quot; part in Azure ML? Or is it something I can't do, even with the designer. I guess my confusion is, with ML being such a big topic, I am looking for a direction of learning, in this case of what I am having, so I can improve my current model.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1638921326880,
        "Question_score":2,
        "Question_tags":"machine-learning|azure-machine-learning-studio|azure-machine-learning-service|azure-auto-ml",
        "Question_view_count":119,
        "Owner_creation_time":1296571549840,
        "Owner_last_access_time":1663809103810,
        "Owner_location":"Seattle, WA",
        "Owner_reputation":1021,
        "Owner_up_votes":79,
        "Owner_down_votes":7,
        "Owner_views":138,
        "Question_last_edit_time":1638925038330,
        "Answer_body":"<p>Here is <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-automated-ml#customize-featurization\" rel=\"nofollow noreferrer\">link<\/a> to the document for feature customization.<\/p>\n<p>Using the SDK you can specify &quot;feauturization&quot;: 'auto' \/ 'off' \/ 'FeaturizationConfig' in your <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">AutoMLConfig<\/a> object. Learn more about <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features\" rel=\"nofollow noreferrer\">enabling featurization<\/a>.<\/p>\n<p>Automated ML tries out different ML models that have different settings which control for overfitting.  Automated ML will pick which overfitting parameter configuration is best based on the best score (e.g. accuracy) it gets from hold-out data.  The kind of overfitting settings these models has includes:<\/p>\n<ul>\n<li>Explicitly penalizing overly-complex models in the loss function that the ML model is optimizing<\/li>\n<li>Limiting model complexity before training, for example by limiting the size of trees in an ensemble tree learning model (e.g. gradient boosting trees or random forest)<\/li>\n<\/ul>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641210936730,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70268372",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36106614,
        "Question_title":"Push parameters from powerBi to Azure ML",
        "Question_body":"<p>I am planning to build a model in Azure Ml and there are certain parameters that needs to passed to the model ,before the model could be run.These parameters should come from PowerBi,maybe based on some filters . Is it possible ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1458418332563,
        "Question_score":0,
        "Question_tags":"azure|powerbi|azure-machine-learning-studio",
        "Question_view_count":102,
        "Owner_creation_time":1422821109973,
        "Owner_last_access_time":1664007162760,
        "Owner_location":"India",
        "Owner_reputation":1238,
        "Owner_up_votes":45,
        "Owner_down_votes":5,
        "Owner_views":172,
        "Question_last_edit_time":1458425260707,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36106614",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72878787,
        "Question_title":"How to authenticate within Azure ML pipeline and avoid browser interactive authentication?",
        "Question_body":"<p>I have created a very simple azure ml pipeline. Basically, it accesses data through an api and prints it.\nI have tried using a ClientSecretCredential and a ServicePrincipalAuthentication but the pipeline still asks me for a web browser authentication to continue (even though the script runs when I just run the python file in the terminal)<\/p>\n<pre><code>    from azureml.core.compute import ComputeTarget, AmlCompute\n    import azureml.core\n    from azureml.core import Workspace, Datastore\n    from azure.identity import ClientSecretCredential\n    from azureml.core.authentication import ServicePrincipalAuthentication\n    \n    \n    ws = Workspace.from_config()\n    \n    keyvault = ws.get_default_keyvault()\n    \n    client_id = keyvault.get_secret(&quot;ClientID&quot;)\n    tenant_id = keyvault.get_secret(&quot;TENANTID&quot;)\n    secret_id = keyvault.get_secret(&quot;CLIENTSECRET&quot;)\n    \n    sp = ClientSecretCredential(tenant_id = tenant_id, client_id = client_id, client_secret = secret_id)\n\n#  sp = ServicePrincipalAuthentication(tenant_id, client_id, secret_id)\n<\/code><\/pre>\n<p>This is the output from the pipeline:<\/p>\n<p>2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/azureProfile.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.sess. It will be overridden by default settings.\n2022-07-06 06:08:21,498|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,501|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,527|azureml._vendor.azure_cli_core._profile|INFO|No web browser is available. Fall back to device code.\n<strong>2022-07-06 06:08:21,628|azureml._vendor.azure_cli_core.auth.identity|WARNING|To sign in, use a web browser to open the page <a href=\"https:\/\/microsoft.com\/devicelogin\" rel=\"nofollow noreferrer\">https:\/\/microsoft.com\/devicelogin<\/a> and enter the code XXXXXXXXXX to authenticate.<\/strong>\n2022-07-06 06:08:49,950|azureml.core.authentication|DEBUG|Time to expire 1814345.049124 seconds<\/p>\n<p>What can I do for it to pick up the credential in the code and avoid asking for interactive authentication?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1657088789413,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":67,
        "Owner_creation_time":1516041506383,
        "Owner_last_access_time":1663922766340,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72878787",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71407308,
        "Question_title":"Azure ML model to a container instance, call to the model fails when using the code provided in the \"Consume\" section of the endpoint (Python and C#)",
        "Question_body":"<p>After deploying an Azure ML model to a container instance, call to the model fails when using the code provided in the &quot;Consume&quot; section of the endpoint (Python and C#).<\/p>\n<p>I have trained a model in Azure Auto-ML and deployed the model to a container instance.<\/p>\n<p><strong>Now when I am try to use the Python code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: 502\nContent-Length: 55\nContent-Type: text\/html; charset=utf-8\nDate: Mon, 07 Mar 2022 12:32:07 GMT\nServer: nginx\/1.14.0 (Ubuntu)\nX-Ms-Request-Id: 768c2eb5-10f3-4e8a-9412-3fcfc0f6d648\nX-Ms-Run-Function-Failed: True\nConnection: close\n\n---------------------------------------------------------------------------\nJSONDecodeError Traceback (most recent call last)\n&lt;ipython-input-1-6eeff158e915&gt; in &lt;module&gt;\n48 # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n49 print(error.info())\n---&gt; 50 print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/init.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n352 parse_int is None and parse_float is None and\n353 parse_constant is None and object_pairs_hook is None and not kw):\n--&gt; 354 return _default_decoder.decode(s)\n355 if cls is None:\n356 cls = JSONDecoder\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in decode(self, s, _w)\n337\n338 &quot;&quot;&quot;\n--&gt; 339 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n340 end = _w(s, end).end()\n341 if end != len(s):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in raw_decode(self, s, idx)\n355 obj, end = self.scan_once(s, idx)\n356 except StopIteration as err:\n--&gt; 357 raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None\n358 return obj, end\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n<p><strong>If I use C# code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: BadGateway\nConnection: keep-alive\nX-Ms-Request-Id: 5c3543cf-29ac-46a3-a9fb-dcb6a0041b08\nX-Ms-Run-Function-Failed: True\nDate: Mon, 07 Mar 2022 12:38:32 GMT\nServer: nginx\/1.14.0 (Ubuntu)\n\n'&lt;=' not supported between instances of 'str' and 'int'\n<\/code><\/pre>\n<p><strong>The Python code I am using:<\/strong><\/p>\n<pre><code> import urllib.request\n import json\n import os\n import ssl\n    \n def allowSelfSignedHttps(allowed):\n     # bypass the server certificate verification on client side\n     if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n         ssl._create_default_https_context = ssl._create_unverified_context\n    \n allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n    \n data = {\n     &quot;Inputs&quot;: {\n         &quot;data&quot;:\n         [\n             {\n                 &quot;SaleDate&quot;: &quot;2022-02-08T00:00:00.000Z&quot;,\n                 &quot;OfferingGroupId&quot;: &quot;0&quot;,\n                 &quot;week_of_year&quot;: &quot;7&quot;,\n                 &quot;month_of_year&quot;: &quot;2&quot;,\n                 &quot;day_of_week&quot;: &quot;1&quot;\n             },\n         ]\n     },\n     &quot;GlobalParameters&quot;: {\n         &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n     }\n }\n    \n body = str.encode(json.dumps(data))\n    \n url = 'http:\/\/4a0427c2-30d4-477e-85f5-dfdfdfdfdsfdff623f.uksouth.azurecontainer.io\/score'\n api_key = '' # Replace this with the API key for the web service\n headers = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n    \n req = urllib.request.Request(url, body, headers)\n    \n try:\n     response = urllib.request.urlopen(req)\n    \n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(&quot;The request failed with status code: &quot; + str(error.code))\n    \n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n<\/code><\/pre>\n<p><strong>The C# code I have tried<\/strong>:<\/p>\n<pre><code> using System;\n using System.Collections.Generic;\n using System.IO;\n using System.Net.Http;\n using System.Net.Http.Headers;\n using System.Text;\n using System.Threading.Tasks;\n using Newtonsoft.Json;\n    \n namespace MLModelAPICall\n {\n     class Program\n     {\n         static void Main(string[] args)\n         {\n             InvokeRequestResponseService().Wait();\n         }\n    \n         static async Task InvokeRequestResponseService()\n         {\n             var handler = new HttpClientHandler()\n             {\n                 ClientCertificateOptions = ClientCertificateOption.Manual,\n                 ServerCertificateCustomValidationCallback =\n                         (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n             };\n             using (var client = new HttpClient(handler))\n             {\n                 \/\/ Request data goes here\n                 var scoreRequest = new\n                 {\n                     Inputs = new Dictionary&lt;string, List&lt;Dictionary&lt;string, string&gt;&gt;&gt;()\n                     {\n                         {\n                             &quot;data&quot;,\n                             new List&lt;Dictionary&lt;string, string&gt;&gt;()\n                             {\n                                 new Dictionary&lt;string, string&gt;()\n                                 {\n                                     {\n                                         &quot;SaleDate&quot;, &quot;2022-02-08T00:00:00.000Z&quot;\n                                     },\n                                     {\n                                         &quot;OfferingGroupId&quot;, &quot;0&quot;\n                                     },\n                                     {\n                                         &quot;week_of_year&quot;, &quot;7&quot;\n                                     },\n                                     {\n                                         &quot;month_of_year&quot;, &quot;2&quot;\n                                     },\n                                     {\n                                         &quot;day_of_week&quot;, &quot;1&quot;\n                                     }\n                                 }\n                             }\n                         }\n                     },\n                     GlobalParameters = new Dictionary&lt;string, string&gt;()\n                     {\n                         {\n                             &quot;quantiles&quot;, &quot;0.025,0.975&quot;\n                         }\n                     }\n                 };\n    \n    \n                 const string apiKey = &quot;&quot;; \/\/ Replace this with the API key for the web service\n                 client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(&quot;Bearer&quot;, apiKey);\n                 client.BaseAddress = new Uri(&quot;http:\/\/4a0427c2-30d4-477e-85f5-xxxxxxxxxxxxx.uksouth.azurecontainer.io\/score&quot;);\n    \n                 \/\/ WARNING: The 'await' statement below can result in a deadlock\n                 \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                 \/\/ One way to address this would be to call ConfigureAwait(false)\n                 \/\/ so that the execution does not attempt to resume on the original context.\n                 \/\/ For instance, replace code such as:\n                 \/\/      result = await DoSomeTask()\n                 \/\/ with the following:\n                 \/\/      result = await DoSomeTask().ConfigureAwait(false)\n    \n                 var requestString = JsonConvert.SerializeObject(scoreRequest);\n                 var content = new StringContent(requestString);\n    \n                 content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application\/json&quot;);\n    \n                 HttpResponseMessage response = await client.PostAsync(&quot;&quot;, content);\n    \n                 if (response.IsSuccessStatusCode)\n                 {\n                     string result = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(&quot;Result: {0}&quot;, result);\n                 }\n                 else\n                 {\n                     Console.WriteLine(string.Format(&quot;The request failed with status code: {0}&quot;, response.StatusCode));\n    \n                     \/\/ Print the headers - they include the requert ID and the timestamp,\n                     \/\/ which are useful for debugging the failure\n                     Console.WriteLine(response.Headers.ToString());\n    \n                     string responseContent = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(responseContent);\n                     Console.ReadLine();\n                 }\n             }\n         }\n     }\n }\n<\/code><\/pre>\n<p>Could you please help me with this issue? I am not sure what do to if Microsoft's provided code is erroring out, don't know what else to do.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1646819247667,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":89,
        "Owner_creation_time":1360013608220,
        "Owner_last_access_time":1663933881363,
        "Owner_location":"Bolton, United Kingdom",
        "Owner_reputation":65842,
        "Owner_up_votes":1661,
        "Owner_down_votes":333,
        "Owner_views":4569,
        "Question_last_edit_time":null,
        "Answer_body":"<p>After much more digging I found out that the &quot;Consume&quot; scripts provided with the endpoint are wrong (Python and C#) .<\/p>\n<p>When making a call to the endpoint the GlobalParameters expects an integer value, but the provided scripts have wrapped the values in double quotes hence making it a string:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n }\n<\/code><\/pre>\n<p>If you are using Python to consume the model, when making call to the endpoint your GlobalParameters should be define as this:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: [0.025,0.975]\n }\n<\/code><\/pre>\n<p>wrapped in square brackets<\/p>\n<blockquote>\n<p>[0.025,0.975]<\/p>\n<\/blockquote>\n<p>and not in double quotes &quot;<\/p>\n<blockquote>\n<p><em>I have also opened a ticket with microsoft so hopefully they will fix the code provided in the &quot;consume&quot; section of every endpoint<\/em><\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1646835298180,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71407308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58293193,
        "Question_title":"Using the Environment Class with Pipeline Runs",
        "Question_body":"<p>I am using an estimator step for a pipeline using the Environment class, in order to have a custom Docker image as I need some <code>apt-get<\/code> packages to be able to install a specific pip package. It appears from the logs that it's completely ignoring, unlike the non-pipeline version of the estimator, the docker portion of the environment variable. Very simply, this seems broken : <\/p>\n\n<p>I'm running on SDK v1.0.65, and my dockerfile is completely ignored, I'm using <\/p>\n\n<pre><code>FROM mcr.microsoft.com\/azureml\/base:latest\\nRUN apt-get update &amp;&amp; apt-get -y install freetds-dev freetds-bin vim gcc\n<\/code><\/pre>\n\n<p>in the base_dockerfile property of my code. \nHere's a snippet of my code : <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Environment\nfrom azureml.core.environment import CondaDependencies\nconda_dep = CondaDependencies()\nconda_dep.add_pip_package('pymssql==2.1.1')\nmyenv = Environment(name=\"mssqlenv\")\nmyenv.python.conda_dependencies=conda_dep\nmyenv.docker.enabled = True\nmyenv.docker.base_dockerfile = 'FROM mcr.microsoft.com\/azureml\/base:latest\\nRUN apt-get update &amp;&amp; apt-get -y install freetds-dev freetds-bin vim gcc'\nmyenv.docker.base_image = None\n<\/code><\/pre>\n\n<p>This works well when I use an Estimator by itself, but if I insert this estimator in a Pipeline, it fails. Here's my code to launch it from a Pipeline run: <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.pipeline.steps import EstimatorStep\n\nsql_est_step = EstimatorStep(name=\"sql_step\", \n                         estimator=est, \n                         estimator_entry_script_arguments=[],\n                         runconfig_pipeline_params=None, \n                         compute_target=cpu_cluster)\nfrom azureml.pipeline.core import Pipeline\nfrom azureml.core import Experiment\npipeline = Pipeline(workspace=ws, steps=[sql_est_step])\npipeline_run = exp.submit(pipeline)\n<\/code><\/pre>\n\n<p>When launching this, the logs for the container building service reveal:<\/p>\n\n<pre><code>FROM continuumio\/miniconda3:4.4.10... etc.\n<\/code><\/pre>\n\n<p>Which indicates it's ignoring my <code>FROM mcr....<\/code> statement in the Environment class I've associated with this Estimator, and my <code>pip install<\/code> fails.<\/p>\n\n<p>Am I missing something? Is there a workaround?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1570564388707,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":751,
        "Owner_creation_time":1538275960603,
        "Owner_last_access_time":1658458641830,
        "Owner_location":"Montreal, QC, Canada",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58293193",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58933565,
        "Question_title":"How to register model from the Azure ML Pipeline Script step",
        "Question_body":"<p>I am running the <code>pipeline.submit()<\/code> in AzureML, which has a <code>PythonScriptStep<\/code>.\nInside this step, I download a model from tensorflow-hub, retrain it and save it as a <code>.zip<\/code>, and finally, I would like to register it in the Azure ML.\nBut as inside the script I do not have a workspace, <code>Model.register()<\/code> is not the case.\nSo I am trying to use <code>Run.register_model()<\/code> method as below:<\/p>\n\n<pre><code>os.replace(os.path.join('.', archive_name + '.zip'), \n           os.path.join('.', 'outputs', archive_name + '.zip'))\n\nprint(os.listdir('.\/outputs'))\nprint('========================')\n\nrun_context = Run.get_context()\nfinetuning_model = run_context.register_model(model_name='finetuning_similarity_model',\n                                              model_path=os.path.join(archive_name+'.zip'),\n                                              tags={},\n                                              description=\"Finetuning Similarity model\")\n<\/code><\/pre>\n\n<p>But then I have got an error:<\/p>\n\n<blockquote>\n  <p>ErrorResponse \n  {\n      \"error\": {\n          \"message\": \"Could not locate the provided model_path retrained.zip in the set of files uploaded to the run:<\/p>\n<\/blockquote>\n\n<p>despite I have the retrained <code>.zip<\/code> in the <code>.\/outputs<\/code> dir as we can see from the log:<\/p>\n\n<pre><code>['retrained.zip']\n========================\n<\/code><\/pre>\n\n<p>I guess that I am doing something wrong?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1574164584153,
        "Question_score":7,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":3429,
        "Owner_creation_time":1574162655727,
        "Owner_last_access_time":1632472959343,
        "Owner_location":null,
        "Owner_reputation":75,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1578744224353,
        "Answer_body":"<p>I was able to fix the same issue (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.modelpathnotfoundexception?view=azure-ml-py\" rel=\"noreferrer\"><code>ModelPathNotFoundException<\/code><\/a>) by explicitly uploading the model into the run history record before trying to register the model:<\/p>\n\n<pre><code>run.upload_file(\"outputs\/my_model.pickle\", \"outputs\/my_model.pickle\")\n<\/code><\/pre>\n\n<p>Which I found surprising because this wasn't mentioned in many of the official examples and according to the <code>upload_file()<\/code> <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#upload-file-name--path-or-stream-\" rel=\"noreferrer\">documentation<\/a>:<\/p>\n\n<blockquote>\n  <p>Runs automatically capture file in the specified output directory, which defaults to \".\/outputs\" for most run types. Use upload_file only when additional files need to be uploaded or an output directory is not specified.<\/p>\n<\/blockquote>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1578745983587,
        "Answer_score":14.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":1578746319987,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58933565",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72210450,
        "Question_title":"Is there any way to create or delete workspaces in AML studio using powershell?",
        "Question_body":"<p>I am working on a prediction model and am about to use the azure machine learning studio resources. The main operation is to create a workspace on azure ML studio through Powershell. I would like to operate my workspace through the command line. Is there any way to develop and operate the ML Studio workspace through Powershell?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1652332894457,
        "Question_score":0,
        "Question_tags":"azure|powershell|azure-machine-learning-studio",
        "Question_view_count":104,
        "Owner_creation_time":1652331444420,
        "Owner_last_access_time":1652336195337,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":"<p>According to the requirements, there is no procedure developed to create\/delete workspaces through PowerShell in machine learning studio. For reference of creation of workspaces, you can check the below link and the point to be noted is we can create\/delete workspaces using <em><strong>Az<\/strong><\/em><\/p>\n<p>Here is the table link to check PowerShell support table<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/classic\/powershell-module\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/classic\/powershell-module<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/PGfhb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PGfhb.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1652333522490,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72210450",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72589399,
        "Question_title":"What is Threshold in the Evaluate Model Module?",
        "Question_body":"<p>Notice in the image below, if I increase the value of &quot;Threshold,&quot; the accuracy of the model seems to increase (with diminishing returns after about .62).<\/p>\n<p>What does this mean and can I somehow update this value such that my model will retain this setting?<\/p>\n<p>For example, I am using a boosted decision tree, but I don't see any such value for &quot;threshold.&quot;<\/p>\n<p>Ref. <a href=\"https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/studio-module-reference\/evaluate-model?redirectedfrom=MSDN\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/studio-module-reference\/evaluate-model?redirectedfrom=MSDN<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/E0o5I.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E0o5I.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1655006504270,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":70,
        "Owner_creation_time":1340487313997,
        "Owner_last_access_time":1662779989497,
        "Owner_location":null,
        "Owner_reputation":20199,
        "Owner_up_votes":7887,
        "Owner_down_votes":10,
        "Owner_views":2396,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72589399",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62200162,
        "Question_title":"How to import custom functions on my experiment script for Azure ML?",
        "Question_body":"<p>I can successfully submit an experiment to processing on a remote compute target on Azure ML.<\/p>\n\n<p>In my notebook, for submitting the experiment, I have:<\/p>\n\n<pre><code># estimator\nestimator = Estimator(\n    source_directory='scripts',\n    entry_script='exp01.py',\n    compute_target='pc2',\n    conda_packages=['scikit-learn'],\n    inputs=[data.as_named_input('my_dataset')],\n    )\n\n# Submit\nexp = Experiment(workspace=ws, name='my_exp')\n\n# Run the experiment based on the estimator\nrun = exp.submit(config=estimator)\nRunDetails(run).show()\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n\n<p>However, in order to keep things clean, I want to define my general use functions on an auxiliary script, so the first will import it.<\/p>\n\n<p>On my script experiment file exp01.py, I wanted:<\/p>\n\n<pre><code>import custom_functions as custom\n\n# azure experiment start\nrun = Run.get_context()\n\n# the data from azure datasets\/datastorage\ndf = run.input_datasets['my_dataset'].to_pandas_dataframe()\n\n# prepare data\ndf_transformed = custom.prepare_data(df)\n\n# split data\nX_train, X_test, y_train, y_test = custom.split_data(df_transformed)\n\n# run my models.....\nmodel_name = 'RF'\nmodel = custom.model_x(model_name, a_lot_of_args)\n\n# log the results\nrun.log(model_name, results)\n\n# azure finish\nrun.complete()\n<\/code><\/pre>\n\n<p>The thing is: Azure wont let me import the custom_functions.py.<\/p>\n\n<p>How are you doing it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591289910473,
        "Question_score":2,
        "Question_tags":"python-3.x|azure|scikit-learn|azure-machine-learning-service",
        "Question_view_count":428,
        "Owner_creation_time":1469143327747,
        "Owner_last_access_time":1663952044637,
        "Owner_location":"Brazil",
        "Owner_reputation":914,
        "Owner_up_votes":791,
        "Owner_down_votes":5,
        "Owner_views":100,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62200162",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57432959,
        "Question_title":"Azure ML Service dump logs",
        "Question_body":"<p>With the AzureML service, how can I dump the correct Loss curve or Accuracy curve for different epochs for keras deep learning on multiple nodes with Horovod?<\/p>\n\n<p>The Loss vs epochs plt from Keras deep learning using Horovod and AzureML appears to have issues.<\/p>\n\n<p>Training CNN with Keras\/Horovod (2 GPUs) and AMLS SDK generates weird graphs\n<a href=\"https:\/\/i.stack.imgur.com\/iKusU.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iKusU.jpg\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/loJTI.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/loJTI.jpg\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1565363771400,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":168,
        "Owner_creation_time":1565362834960,
        "Owner_last_access_time":1663006027963,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1565375098713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57432959",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58213125,
        "Question_title":"ModuleNotFoundError: No module named 'keras' in Azure ML Pipeline",
        "Question_body":"<p>I am trying to get a a simple Azure ML pipeline with the dogs vs cats data set following the steps  - <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">documented here<\/a><\/p>\n\n<p>My notebook contains the following -<\/p>\n\n<pre><code>import azureml.core\nfrom azureml.core import Workspace, Datastore\nfrom azureml.core import Environment\nfrom azureml.core.environment import CondaDependencies\nfrom azureml.pipeline.steps import PythonScriptStep\n\nws = Workspace.from_config()\n\nmyenv = Environment(name=\"myenv\")\nconda_dep = CondaDependencies()\nconda_dep.add_conda_package(\"keras\")\nconda_dep.add_conda_package(\"PIL\")\nmyenv.python.conda_dependencies=conda_dep\nmyenv.register(workspace=ws)\n<\/code><\/pre>\n\n<p>After setting up the data reference and the compute, here's how I am creating the pipeline -<\/p>\n\n<pre><code>trainStep = PythonScriptStep(\n    script_name=\"dogs_vs_cats.py\",\n    arguments=[\"--input\", blob_input_data, \"--output\", output_data1],\n    inputs=[blob_input_data],\n    outputs=[output_data1],\n    compute_target=compute_target,\n    source_directory=\"..\/dogs-vs-cats\"\n)\n\nSteps = [trainStep]\n\nfrom azureml.pipeline.core import Pipeline\npipeline1 = Pipeline(workspace=ws, steps=[Steps])\n\nfrom azureml.core import Experiment\n\npipeline_run1 = Experiment(ws, 'dogs_vs_cats_exp').submit(pipeline1)\npipeline_run1.wait_for_completion()\n<\/code><\/pre>\n\n<p>Once this steps is executed, the experiment fails and I get the following error after a bunch of information -<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"dogs_vs_cats.py\", line 30, in &lt;module&gt;\n    import keras\nModuleNotFoundError: No module named 'keras'\n<\/code><\/pre>\n\n<p>The terminal shows my conda environment set to azureml_py36 and Keras seems be listed in the output of <code>conda list<\/code>.<\/p>\n\n<p>Am I setting up the environment correctly? What is mising <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570082438523,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":697,
        "Owner_creation_time":1570078371343,
        "Owner_last_access_time":1643112550783,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Question_last_edit_time":1570094136667,
        "Answer_body":"<p>From the way you have specified your environment, it's hard to see if it's a proper RunConfiguration object. If it is, it should be a matter of adding it to you PythonScriptStep.<\/p>\n\n<pre><code>trainStep = PythonScriptStep(\n    script_name=\"dogs_vs_cats.py\",\n    arguments=[\"--input\", blob_input_data, \"--output\", output_data1],\n    inputs=[blob_input_data],\n    outputs=[output_data1],\n    compute_target=compute_target,\n    source_directory=\"..\/dogs-vs-cats\",\n    runconfig=myenv\n)\n<\/code><\/pre>\n\n<p>Right now you're defining the environment, but no using it anywhere it seems. If your trouble persists maybe try defining your RunConfiguration like they do under the \"Specify the environment to run the script\" step in this notebook:<\/p>\n\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/pipeline-batch-scoring\/pipeline-batch-scoring.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/pipeline-batch-scoring\/pipeline-batch-scoring.ipynb<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1570089071900,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58213125",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64772514,
        "Question_title":"How to download folder from AzureML notebook folder to local or blob storage?",
        "Question_body":"<p>I saved file to the same directory using (.\/folder_name) when I use AzureML jupyter. Now how can I download to my local machine or blob storage?<\/p>\n<p>The folder have a lot of files and sub-directory in it, which I scraped online. So it is not realistic to save one by one.<\/p>\n<pre><code>file_path = &quot;.\/&quot;\n\nfor i in target_key_word:\n    tem_str = i.replace(' ', '+')\n    dir_name = file_path + i\n    if not os.path.exists(dir_name):\n        os.mkdir(dir_name)\n    else:    \n        print(&quot;Directory &quot; , dir_name ,  &quot; already exists&quot;)\n<\/code><\/pre>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_time":1605024635707,
        "Question_score":1,
        "Question_tags":"python|azure|azure-storage|azure-blob-storage|azure-machine-learning-service",
        "Question_view_count":3310,
        "Owner_creation_time":1589508579330,
        "Owner_last_access_time":1663966063383,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":1605030541670,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64772514",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59517355,
        "Question_title":"Permission denied: '.\\NTUSER.DAT' when trying to run an Azure ML Pipeline",
        "Question_body":"<p>The short story is, when I try to submit an azure ML pipeline run (an <em>azure ML pipeline<\/em>, not an <em>Azure pipeline<\/em>) from a jupyter notebook, I get PermissionError: [Errno 13] Permission denied: '.\\NTUSER.DAT'.  More details:<\/p>\n\n<p>Relevant code:<\/p>\n\n<pre><code>from azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.runtime import AutoMLStep\nautoml_settings = {\n    \"iteration_timeout_minutes\": 20,\n    \"experiment_timeout_minutes\": 30,\n    \"n_cross_validations\": 3,\n    \"primary_metric\": 'r2_score',\n    \"preprocess\": True,\n    \"max_concurrent_iterations\": 3,\n    \"max_cores_per_iteration\": -1,\n    \"verbosity\": logging.INFO,\n    \"enable_early_stopping\": True,\n    'time_column_name': \"DateTime\"\n}\n\nautoml_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             path = \".\",\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config,                               \n                             training_data = financeforecast_dataset,\n                             label_column_name = 'TotalUSD',\n                             **automl_settings\n                            )\n\nautoml_step = AutoMLStep(\n    name='automl_module',\n    automl_config=automl_config,\n    allow_reuse=False)\n\ntraining_pipeline = Pipeline(\n    description=\"training_pipeline\",\n    workspace=ws,    \n    steps=[automl_step])\n\ntraining_pipeline_run = Experiment(ws, 'test').submit(training_pipeline)\n<\/code><\/pre>\n\n<p>The training_pipeline step runs for apx 20 seconds, and then I get a long trace, ending in:<\/p>\n\n<pre><code>~\\AppData\\Local\\Continuum\\anaconda2\\envs\\forecasting\\lib\\site- \npackages\\azureml\\pipeline\\core\\_module_builder.py in _hash_from_file_paths(hash_src)\n    100             hasher = hashlib.md5()\n    101             for f in hash_src:\n--&gt; 102                 with open(str(f), 'rb') as afile:\n    103                     buf = afile.read()\n    104                     hasher.update(buf)\n\nPermissionError: [Errno 13] Permission denied: '.\\\\NTUSER.DAT'\n<\/code><\/pre>\n\n<p>According to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">Azure's docs on this topic<\/a>, submitting a pipeline uploads a \"snapshot\" of the \"source directory\" you specified.  Initially, I hadn't specified a source directory, so, to test that out, I added: <\/p>\n\n<pre><code>default_source_directory=\"testing\",\n<\/code><\/pre>\n\n<p>as a parameter for the training_pipeline object, but saw the same behavior when I then tried to run it.  Not sure if that is the same source directory the documentation is referring to.  The docs also say that if no source directory is specified, the \"current local directory\" is uploaded.  I used print (os.getcwd()) to get the working directory and gave \"Everyone\" full control permissions on the directory (working in a windows env).<\/p>\n\n<p>All the preceding code works fine, and I can submit an experiment if I use a ScriptRunConfig and run it on attached compute rather than using a pipeline\/training cluster.  <\/p>\n\n<p>Any ideas?  Thanks in advance to anyone who tries to help.  P.S. There is no \"azure-machine-learning-pipelines\" tag, and I can't add one because I don't have enough reputation points.  Someone else could though!  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines\" rel=\"nofollow noreferrer\">General<\/a> info on what they are.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1577601580777,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio|automl",
        "Question_view_count":409,
        "Owner_creation_time":1541802293200,
        "Owner_last_access_time":1663773706450,
        "Owner_location":null,
        "Owner_reputation":163,
        "Owner_up_votes":53,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I resolved this answer by setting the path and the data_script variables in the AutoMLConfig task object, like this (relevant code indicated by -->):<\/p>\n\n<pre><code>automl_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config,\n                             --&gt;path = \"c:\\\\users\\\\me\",\n                             data_script =\"script.py\",&lt;--\n                             **automl_settings\n                            )\n<\/code><\/pre>\n\n<p>Setting the data_script variable to include the full path, as shown below, did not work.<\/p>\n\n<pre><code>automl_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             path = \".\",\n                             --&gt;data_script = \"c:\\\\users\\\\me\\\\script.py\"&lt;--\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config, \n                             **automl_settings\n                            )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1577994637207,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59517355",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45051055,
        "Question_title":"Read multiple CSV files in Azure ML Python Script",
        "Question_body":"<p>I have 4 csv files that are inputs to the python script in azure ML, but the widget has only 2 inputs for dataframes and the third for a zip file. I tried to put the csv files in a zipped folder and connect it to the third input for the script but that also did not work :\n<a href=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" alt=\"Image of workspace\"><\/a><\/p>\n\n<p>I would like to know how to read multiple csv files in the python script.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1499844354733,
        "Question_score":1,
        "Question_tags":"python|csv|azure|azure-machine-learning-studio",
        "Question_view_count":944,
        "Owner_creation_time":1470376815797,
        "Owner_last_access_time":1660941481503,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":72,
        "Owner_down_votes":3,
        "Owner_views":57,
        "Question_last_edit_time":1499850837700,
        "Answer_body":"<p>Here's some more detail on the approach others have outlined above. Try replacing the code currently in the \"Execute Python Script\" module with the following:<\/p>\n\n<pre><code>import pandas as pd\nimport os\ndef azureml_main(dataframe1=None, dataframe2=None):\n    print(os.listdir('.'))\n    return(pd.DataFrame([]))\n<\/code><\/pre>\n\n<p>After running the experiment, click on the module. There should be a \"View output log\" link now in the right-hand bar. I get something like the following:<\/p>\n\n<pre><code>[Information]         Started in [C:\\temp]\n[Information]         Running in [C:\\temp]\n[Information]         Executing 4af67c05ba02417a980f6a16e84e61dc with inputs [] and generating outputs ['.maml.oport1']\n[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         temp.csv                                       2016-05-06 13:16:56           52\n[Information]         [ READING ] 0:00:00\n[Information]         ['4af67c05ba02417a980f6a16e84e61dc.py', 'Script Bundle', 'Script Bundle.zip']\n<\/code><\/pre>\n\n<p>This tells me that the contents of my zip file have been extracted to the <code>C:\\temp\\Script Bundle<\/code> folder. In my case the zip file contained just one CSV file, <code>temp.csv<\/code>: your output would probably have four files. You may also have zipped a folder containing your four files, in which case the filepath would be one layer deeper. You can use the <code>os.listdir()<\/code> to explore your directory structure further if necessary.<\/p>\n\n<p>Once you think you know the full filepaths for your CSV files, edit your Execute Python Script module's code to load them, e.g.:<\/p>\n\n<pre><code>import pandas as pd\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    df = pd.read_csv('C:\/temp\/Script Bundle\/temp.csv')\n    # ...load other files and merge into a single dataframe...\n    return(df)\n<\/code><\/pre>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1500412322170,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45051055",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58772261,
        "Question_title":"Public windows docker image for azure machine learning",
        "Question_body":"<p>Our machine learning workflow requires use of a custom windows .pyc file. Where can I find a windows docker image file.<\/p>\n\n<p>I am puzzled by this statement from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-custom-docker-image#create-a-custom-base-image\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-custom-docker-image#create-a-custom-base-image<\/a>. Is it really true that azure cannot use windows images? <\/p>\n\n<pre><code>Image requirements: Azure Machine Learning only supports Docker images that provide the following software:\n\nUbuntu 16.04 or greater.\nConda 4.5.# or greater.\nPython 3.5.# or 3.6.#.\n\n<\/code><\/pre>\n\n<p>Searching on docker hub also did not turn up anything promising<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1573239057720,
        "Question_score":0,
        "Question_tags":"docker|azure-machine-learning-service",
        "Question_view_count":69,
        "Owner_creation_time":1565794118450,
        "Owner_last_access_time":1664072200673,
        "Owner_location":null,
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58772261",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63158394,
        "Question_title":"Custom Docker file for Azure ML Environment that contains COPY statements errors with COPY failed: \/path no such file or directory",
        "Question_body":"<p>I'm trying to submit an experiment to Azure ML using a Python script.<\/p>\n<p>The Environment being initialised uses a custom Dockerfile.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>env = Environment(name=&quot;test&quot;)\nenv.docker.base_image = None\nenv.docker.base_dockerfile = '.\/Docker\/Dockerfile'\nenv.docker.enabled = True\n<\/code><\/pre>\n<p>However the DockerFile needs a few <code>COPY<\/code> statements but those fail as follow:<\/p>\n<pre><code>Step 9\/23 : COPY requirements-azure.txt \/tmp\/requirements-azure.txt\nCOPY failed: stat \/var\/lib\/docker\/tmp\/docker-builder701026190\/requirements-azure.txt: no such file or directory\n<\/code><\/pre>\n<p>The Azure host environment responsible to build the image does not contain the files the Dockerfile requires, those exist in my local development machine from where I initiate the python script.<\/p>\n<p>I've been searching for the whole day of a way to add to the environment these files but without success.<\/p>\n<p>Below an excerpt from the Dockerfile and the python script that submits the experiment.<\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04 as base\nCOPY .\/Docker\/requirements-azure.txt \/tmp\/requirements-azure.txt # &lt;- breaks here\n\n[...]\n\n<\/code><\/pre>\n<p>Here is how I'm submitting the experiment:<\/p>\n<pre><code>from azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Experiment\nfrom azureml.core.compute import ComputeTarget\n\nfrom azureml.core import Experiment, Workspace\nfrom azureml.train.estimator import Estimator\nimport os\n\nws = Workspace.from_config(path='\/mnt\/azure\/config\/workspace-config.json')\nenv = Environment(name=&quot;test&quot;)\nenv.docker.base_image = None\nenv.docker.base_dockerfile = '.\/Docker\/Dockerfile'\nenv.docker.enabled = True\ncompute_target = ComputeTarget(workspace=ws, name='GRComputeInstance')\nestimator = Estimator(\n    source_directory='\/workspace\/',\n    compute_target=compute_target,\n    entry_script=&quot;.\/src\/ml\/train\/main.py&quot;,\n    environment_definition=env\n)\nexperiment = Experiment(workspace=ws, name=&quot;estimator-test&quot;)\nrun = experiment.submit(estimator)\nrun.wait_for_completion(show_output=True, wait_post_processing=True)\n<\/code><\/pre>\n<p>Any idea?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1596040632287,
        "Question_score":7,
        "Question_tags":"python|azure|docker|dockerfile|azure-machine-learning-service",
        "Question_view_count":927,
        "Owner_creation_time":1248452771430,
        "Owner_last_access_time":1664006575380,
        "Owner_location":"London, United Kingdom",
        "Owner_reputation":3317,
        "Owner_up_votes":466,
        "Owner_down_votes":8,
        "Owner_views":296,
        "Question_last_edit_time":1596701189560,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63158394",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58285038,
        "Question_title":"Trying to query Azure SQL Database with Azure ML \/ Docker Image",
        "Question_body":"<p>I wanted to do a realtime deployment of my model on azure, so I plan to create an image which firsts queries an ID in azure SQL db to get the required features, then predicts using my model and returns the predictions. The error I get from PyODBC library is that drivers are not installed<\/p>\n\n<p>I tried it on the azure ML jupyter notebook to establish the connection and found that no drivers are being installed in the environment itself. After some research i found that i should create a docker image and deploy it there,  but i still met with the same results<\/p>\n\n<pre><code>    driver= '{ODBC Driver 13 for SQL Server}'\n    cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password+';Encrypt=yes'+';TrustServerCertificate=no'+';Connection Timeout=30;')\n<\/code><\/pre>\n\n<blockquote>\n  <p>('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC\n  Driver 13 for SQL Server' : file not found (0) (SQLDriverConnect)\")<\/p>\n<\/blockquote>\n\n<p>i want a result to the query instead i get this message<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_time":1570532396097,
        "Question_score":1,
        "Question_tags":"sql-server|azure|azure-machine-learning-service",
        "Question_view_count":1319,
        "Owner_creation_time":1525963887537,
        "Owner_last_access_time":1575968994133,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":1570535747687,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58285038",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44371692,
        "Question_title":"Install Python Packages in Azure ML?",
        "Question_body":"<p>Similar question as <a href=\"https:\/\/stackoverflow.com\/questions\/43176442\/install-r-packages-in-azure-ml\">here<\/a> but now on Python packages. Currently, the CVXPY is missing in Azure ML. I am also trying to get other solvers such as GLPK, CLP and COINMP working in Azure ML.<\/p>\n<p><strong>How can I install Python packages in Azure ML?<\/strong><\/p>\n<hr \/>\n<p><em>Update about trying to install the Python packages not found in Azure ML.<\/em><\/p>\n<blockquote>\n<p>I did as instructed by Peter Pan but I think the 32bits CVXPY files are wrong for the Anaconda 4 and Python 3.5 in Azure ML, logs and errors are <a href=\"https:\/\/pastebin.com\/zN5QrPtL\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<pre><code>[Information]         Running with Python 3.5.1 |Anaconda 4.0.0 (64-bit)| (default, Feb 16 2016, 09:49:46) [MSC v.1900 64 bit (AMD64)]\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rS0Us.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rS0Us.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6qz3p.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6qz3p.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9glSm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9glSm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/blockquote>\n<p><em>Update 2 with win_amd64 files (paste <a href=\"https:\/\/pastebin.com\/tisWuP5C\" rel=\"nofollow noreferrer\">here<\/a>)<\/em><\/p>\n<blockquote>\n<pre><code>[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         cvxopt-1.1.9-cp35-cp35m-win_amd64.whl          2017-06-07 01:03:34      1972074\n[Information]         __MACOSX\/                                      2017-06-07 01:26:28            0\n[Information]         __MACOSX\/._cvxopt-1.1.9-cp35-cp35m-win_amd64.whl 2017-06-07 01:03:34          452\n[Information]         cvxpy-0.4.10-py3-none-any.whl                  2017-06-07 00:25:36       300880\n[Information]         __MACOSX\/._cvxpy-0.4.10-py3-none-any.whl       2017-06-07 00:25:36          444\n[Information]         ecos-2.0.4-cp35-cp35m-win_amd64.whl            2017-06-07 01:03:40        56522\n[Information]         __MACOSX\/._ecos-2.0.4-cp35-cp35m-win_amd64.whl 2017-06-07 01:03:40          450\n[Information]         numpy-1.13.0rc2+mkl-cp35-cp35m-win_amd64.whl   2017-06-07 01:25:02    127909457\n[Information]         __MACOSX\/._numpy-1.13.0rc2+mkl-cp35-cp35m-win_amd64.whl 2017-06-07 01:25:02          459\n[Information]         scipy-0.19.0-cp35-cp35m-win_amd64.whl          2017-06-07 01:05:12     12178932\n[Information]         __MACOSX\/._scipy-0.19.0-cp35-cp35m-win_amd64.whl 2017-06-07 01:05:12          452\n[Information]         scs-1.2.6-cp35-cp35m-win_amd64.whl             2017-06-07 01:03:34        78653\n[Information]         __MACOSX\/._scs-1.2.6-cp35-cp35m-win_amd64.whl  2017-06-07 01:03:34          449\n[Information]         [ READING ] 0:00:00\n[Information]         Input pandas.DataFrame #1:\n[Information]         Empty DataFrame\n[Information]         Columns: [1]\n[Information]         Index: []\n[Information]         [ EXECUTING ] 0:00:00\n[Information]         [ WRITING ] 0:00:00\n<\/code><\/pre>\n<p>where <code>import cvxpy<\/code>, <code>import cvxpy-0.4.10-py3-none-any.whl<\/code> or <code>cvxpy-0.4.10-py3-none-any<\/code> do not work so<\/p>\n<p><strong>How can I use the following wheel files downloaded from <a href=\"http:\/\/www.lfd.uci.edu\/%7Egohlke\/pythonlibs\/#cvxpy\" rel=\"nofollow noreferrer\">here<\/a> to use the external Python packages not found in Azure ML?<\/strong><\/p>\n<\/blockquote>\n<p><em>Update about permission problem about importing cvxpy (paste <a href=\"https:\/\/pastebin.com\/3kTKgLfc\" rel=\"nofollow noreferrer\">here<\/a>)<\/em><\/p>\n<blockquote>\n<pre><code> [Error]         ImportError: No module named 'canonInterface'\n<\/code><\/pre>\n<p>where the ZIP Bundle is organised a bit differently, the content of each wheel downloaded to a folder and the content having all zipped as a ZIP Bundle.<\/p>\n<\/blockquote>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1496674339213,
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio|cvxpy",
        "Question_view_count":12625,
        "Owner_creation_time":1251372839053,
        "Owner_last_access_time":1653648989307,
        "Owner_location":null,
        "Owner_reputation":48616,
        "Owner_up_votes":1240,
        "Owner_down_votes":41,
        "Owner_views":3348,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>According to the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts#limitations\" rel=\"nofollow noreferrer\"><code>Limitations<\/code><\/a> and <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn955437.aspx#Anchor_3\" rel=\"nofollow noreferrer\"><code>Technical Notes<\/code><\/a> of <code>Execute Python Script<\/code> tutorial, the only way to add custom Python modules is via the zip file mechanism to package the modules and all dependencies.<\/p>\n\n<p>For example to install <code>CVXPY<\/code>, as below.<\/p>\n\n<ol>\n<li>Download the wheel file of <a href=\"http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#cvxpy\" rel=\"nofollow noreferrer\"><code>CVXPY<\/code><\/a> and its dependencies like <a href=\"http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#cvxopt\" rel=\"nofollow noreferrer\"><code>CVXOPT<\/code><\/a>.<\/li>\n<li>Decompress these wheel files, and package these files in the path <code>cvxpy<\/code> and <code>cvxopt<\/code>, etc as a zipped file with your script.<\/li>\n<li>Upload the zip file as a dataset and use it as the script bundle.<\/li>\n<\/ol>\n\n<p>If you were using IPython, you also can try to install the Python Package via the code <code>!pip install cvxpy<\/code>.<\/p>\n\n<p>And there are some similar SO threads which may be helpful for you, as below.<\/p>\n\n<ol>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/44285641\/azure-ml-python-with-script-bundle-cannot-import-module\">Azure ML Python with Script Bundle cannot import module<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/8663046\/how-to-install-a-python-package-from-within-ipython\">How to install a Python package from within IPython?<\/a><\/li>\n<\/ol>\n\n<p>Hope it helps.<\/p>\n\n<hr>\n\n<p>Update:<\/p>\n\n<p>For IPython interface of Azure ML, you move to the <code>NOTEBOOKS<\/code> tab to create a notebook via <code>ADD TO PROJECT<\/code> button at the bottom of the page, as the figure below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/X2Asv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/X2Asv.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Or you can directly login to the website <code>https:\/\/notebooks.azure.com<\/code> to use it.<\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_time":1496732346280,
        "Answer_score":2.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":1496760284030,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44371692",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39073386,
        "Question_title":"Azure Machine Learning Experiment Creation",
        "Question_body":"<p>I am new to create Experiments in Azure ML. I want to done a sample and small POC on Azure ML.<\/p>\n\n<p>I have a data for the students consisting of StudentID, Student Name and Marks for Monthly Tests 1,2 and 3. I just to want to Predict data for the Final Monthly Test (i.e., Monthly Test 4).<\/p>\n\n<p>I don't know how to create and what kind of Transformations to be used in Predicting the Data.<\/p>\n\n<p>Anyone Please...<\/p>\n\n<p>Thanks in Advance\nPradeep<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1471850213390,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":79,
        "Owner_creation_time":1406630302783,
        "Owner_last_access_time":1520847578177,
        "Owner_location":"Chennai, Tamil Nadu, India",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39073386",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67255397,
        "Question_title":"What is real-time inference pipeline?",
        "Question_body":"<p>From Azure Machine Learning designer, to deploy a real-time inference pipeline as a service for others to consume, you must deploy the model to an Azure Kubernetes Service (AKS).\nWhat is real-time inference pipeline ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1619366165967,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":211,
        "Owner_creation_time":1610715294930,
        "Owner_last_access_time":1648997946363,
        "Owner_location":"United States",
        "Owner_reputation":306,
        "Owner_up_votes":200,
        "Owner_down_votes":2,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67255397",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45051184,
        "Question_title":"Can i Pass Dataset as a parameter to AzureML experiment in Streaming Analytics Job?",
        "Question_body":"<p>Can i Pass Dataset as a parameter to AzureML experiment in Streaming Analytics Job? Right now im passing parameters like this ,  <\/p>\n\n<pre><code>   SELECT test (var1,var2,var3,var4,var5) as Result\n   FROM [Input-eventhub]\n<\/code><\/pre>\n\n<p>So instead of that can i pass dataset instead of this like,\n      SELECT test (datset) as Result\n       FROM [Input-eventhub]Azurestre<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1499844731840,
        "Question_score":0,
        "Question_tags":"tsql|azure-stream-analytics|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_time":1498115097193,
        "Owner_last_access_time":1567158670357,
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":1499928470637,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45051184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64576059,
        "Question_title":"Azure ML Service Principal Password",
        "Question_body":"<p>We want to use a service principal in Azure ML to access the Workspace as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-setup-authentication#use-a-service-principal-from-the-sdk\" rel=\"nofollow noreferrer\">here<\/a>, and are wondering how to save the SP password. It says correctly to not store it in the juypter sources, but to use <code>os.environ['AML_PRINCIPAL_PASS']<\/code> instead. But how do I get it into the environment in a way that survives reboot of compute instance etc?<\/p>\n<p>There is a Keyvault in the workspace, but I need to authenticate the SP first before I can access the workspace and thus the keyvault.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1603898857127,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service|azure-service-principal",
        "Question_view_count":142,
        "Owner_creation_time":1383178639610,
        "Owner_last_access_time":1659632827730,
        "Owner_location":"Germany",
        "Owner_reputation":389,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":73,
        "Question_last_edit_time":1603952587467,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64576059",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":28929813,
        "Question_title":"Python support for Azure ML -- speed issue",
        "Question_body":"<p>We are trying to create an Azure ML web-service that will receive a (.csv) data file, do some processing, and return two similar files. The Python support recently added to the azure ML platform was very helpful and we were able to successfully port our code, run it in experiment mode and publish the web-service.<\/p>\n\n<p>Using the \"batch processing\" API, we are now able to direct a file from blob-storage to the service and get the desired output. However, run-time for small files (a few KB) is significantly slower than on a local machine, and more importantly, the process seems to never return for slightly larger input data files (40MB). Processing time on my local machine for the same file is under 1 minute. <\/p>\n\n<p>My question is if you can see anything we are doing wrong, or if there is a way to get this to speed up. Here is the DAG representation of the experiment:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MalhQ.png\" alt=\"The DAG representation of the experiment\"><\/p>\n\n<p>Is this the way the experiment should be set up? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1425837068693,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":491,
        "Owner_creation_time":1419868247680,
        "Owner_last_access_time":1535114076180,
        "Owner_location":null,
        "Owner_reputation":877,
        "Owner_up_votes":46,
        "Owner_down_votes":0,
        "Owner_views":55,
        "Question_last_edit_time":1425890468080,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28929813",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58642295,
        "Question_title":"Trying to connect Azure SQL database from Azure ML Service using MSI authentication (Without username and passowrd connect the Azure database)",
        "Question_body":"<p>I am trying to connect the <strong>Azure SQL Database<\/strong> from <strong>Azure Machine Learning Service<\/strong> with <strong>MSI Authentication (Without a username and password).<\/strong><\/p>\n\n<p>I am trying to Machine learning model on azure Machine learning service that purpose I need data that' why I want to connect Azure SQL Database from Azure Machine Learning Service using MSI Authentication.<\/p>\n\n<p>But I got below error:-<\/p>\n\n<pre><code> \"error\": {\"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with KeyError: 'MSI_ENDPOINT'\\\",\\n\n<\/code><\/pre>\n\n<p>Please check the below code that I have used for the database connection.<\/p>\n\n<pre><code>import logging\nimport struct\nimport pyodbc\nimport os\nimport requests\n\n\nclass AzureDbConnect:\n    def __init__(self):\n        print(\"Inside msi database\")\n        msi_endpoint = os.environ[\"MSI_ENDPOINT\"]\n        msi_secret = os.environ[\"MSI_SECRET\"]\n\n        resource_uri = 'https:\/\/database.windows.net\/'\n\n        logging.info(msi_endpoint)\n        print(msi_endpoint)\n        logging.info(msi_secret)\n        print(msi_secret)\n        print(\"Inside token\")\n\n        token_auth_uri = f\"{msi_endpoint}?resource={resource_uri}&amp;api-version=2017-09-01\"\n        head_msi = {'Secret': msi_secret}\n        resp = requests.get(token_auth_uri, headers=head_msi)\n        access_token = resp.json()['access_token']\n        logging.info(access_token)\n        print(\"Token is :- \")\n        print(access_token)\n\n        accesstoken = bytes(access_token, 'utf-8')\n        exptoken = b\"\"\n        for i in accesstoken:\n            exptoken += bytes({i})\n            exptoken += bytes(1)\n        tokenstruct = struct.pack(\"=i\", len(exptoken)) + exptoken\n\n        conn = pyodbc.connect(\"Driver={ODBC Driver 17 for SQL Server};\"\n                              \"Server=tcp:&lt;Server Name&gt;\"\n                              \"1433;Database=&lt;Database Name&gt;\",\n                              attrs_before={1256: bytearray(tokenstruct)})\n\n        print(conn)\n\n        self.sql_db = conn.cursor()\n<\/code><\/pre>\n\n<p><strong>Is there any way to connect Azure, SQL Database from Azure Machine Learning Service With MSI Authentication?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_time":1572520944167,
        "Question_score":2,
        "Question_tags":"python|python-3.x|azure-sql-database|azure-machine-learning-service|azure-managed-identity",
        "Question_view_count":708,
        "Owner_creation_time":1554466050937,
        "Owner_last_access_time":1578409023530,
        "Owner_location":null,
        "Owner_reputation":219,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Question_last_edit_time":1572588280713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58642295",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52908711,
        "Question_title":"Azure ML Web Service Parmeters Input",
        "Question_body":"<p>Looking to use Azure ML to allow the input value to be inputted through the web service call.  As of now, I have the datasource and and SQL Transformation.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/I5d6u.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/I5d6u.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/8XUDE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8XUDE.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>In the SQL transformation, here is my code that does not accept the parmeter:<\/p>\n\n<pre><code>select pagename, cp \nfrom t1\nwhere %webserviceparm\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1540059334607,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":30,
        "Owner_creation_time":1406068130647,
        "Owner_last_access_time":1663872279057,
        "Owner_location":null,
        "Owner_reputation":2113,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":183,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52908711",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54747199,
        "Question_title":"Authentication problems",
        "Question_body":"<p>I am trying to automate the process to create a model with azure machine learning services and I get some problems with the authentication. When I run my code on my remote machine everything is fine but when I run the code on remote I get this authentication sentence:<\/p>\n\n<pre><code>Make sure your code doesn't require 'az login' to have happened before using azureml-SDK, except the case when you are specifying AzureCliAuthentication in azureml-SDK.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https:\/\/microsoft.com\/devicelogin and enter the code CZMKCYS8B to authenticate\"\n<\/code><\/pre>\n\n<p>Azure ask me for authentication and I have to make it manually.\nI would like to know if there is some way to do it automatically.<\/p>\n\n<p>I was looking for it and I was investigated how to do it using tokens but I couldn't find any solution<\/p>\n\n<p>Someone can give me an advice?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_time":1550492451810,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":653,
        "Owner_creation_time":1501608884543,
        "Owner_last_access_time":1641814166423,
        "Owner_location":null,
        "Owner_reputation":71,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1550494245457,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54747199",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71488101,
        "Question_title":"How to connect labeled data in Azure Machine Learning Studio\/Data Labeling to Power BI?",
        "Question_body":"<p>I am trying to connect already labeled dataset in <strong>Azure ML Studio<\/strong> in <strong>Data Labeling<\/strong> to <strong>PowerBI<\/strong>. I would like to see the progress of labeling or the result of labeled data without exporting it manually and connecting the exported files one by one.\nThank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1647373302570,
        "Question_score":0,
        "Question_tags":"azure|powerbi|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_time":1615200289193,
        "Owner_last_access_time":1663836997667,
        "Owner_location":"Mil\u00e1no, Mil\u00e1n, It\u00e1lie",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71488101",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62770218,
        "Question_title":"Azure - prediction over time",
        "Question_body":"<p>I am currently studying machine learning and predictive analysis so thought a good way to start would be using Azure ML Studio.\nI did the Car Price Tutorial quite successfully however I now want to do something different.\nI thought about using Currency Data; Price and Volume to try and predict the price the next day.\nEverything has gone smoothly as I copied the Car Price tutorial. However when I come to test it the test wants all the variables to predict the new price, but I don't have any of &quot;tomorrows&quot; data. All I want to do is type tomorrows date and it will predict the price using yesterdays and before price and volume data.\nCould you help me please? I am sure it is a small amendment but not sure what!\nThank you\nSam<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1594107238817,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|predictive",
        "Question_view_count":42,
        "Owner_creation_time":1594107133893,
        "Owner_last_access_time":1594280258643,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1594110672470,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62770218",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71454995,
        "Question_title":"Getting the error \"str' object has no attribute 'decode\" when trying to use custom weights for image classification",
        "Question_body":"<p>I am trying to develop a simple image classification model in Azure ML notebooks. ResNet50 model was trained and the custom weights from the model is being used in the following code for image classification. The custom weights are saved in a folder called Model.<\/p>\n<pre><code>import os\nworking_directory = os.getcwd()\nmodel_directory = working_directory + &quot;\/Model\/model.h5&quot; \n<\/code><\/pre>\n<p>The above code is being used for accessing the saved model.<\/p>\n<pre><code>def classifyingImages(image_list):\n    value = 0\n\n    for image in image_list:\n        image_resized = cv2.resize(image, (img_height, img_width))\n        image = np.expand_dims(image_resized, axis=0)\n\n        \n        model = load_model(model_directory)\n        #classifying the image\n        prediction = model.predict(image)\n        output_class = class_names[np.argmax(prediction)]\n\n        #getting the image name\n        image_name = img_name_list[value]\n        print(image_name)\n\n        if(np.argmax(prediction)==0):\n            print(&quot;check negative&quot;)\n            # cv2.imwrite((negative_path+&quot;\/&quot;+image_name), image)\n        else:\n            print(&quot;check positive&quot;)\n            # cv2.imwrite((path_positive+&quot;\/&quot;+image_name), image)\n\n        value = value +1\n\n\n    return value\n\nclassifyingImages(image_list)\n<\/code><\/pre>\n<p>The code added above is the image classification code<\/p>\n<p>The <code>image_list<\/code> contains the test images which saved in the blob storage.<\/p>\n<p>After running the classification function i get the error <code>str' object has no attribute 'decode<\/code> and as a solution i tried to change the h5py lib version using below code. But still it gives me the same error. It would be great if i could a solution for this issue. Thank you in advance.\n<code>!pip install h5py==2.10.0<\/code><\/p>\n<p>The stack trace<\/p>\n<pre><code>AttributeError                            Traceback (most recent call last)\n&lt;ipython-input-96-6e38a2f74291&gt; in &lt;module&gt;\n     42     return value\n     43 \n---&gt; 44 classifyingImages(image_list)\n\n&lt;ipython-input-96-6e38a2f74291&gt; in classifyingImages(image_list)\n     20         print(image.dtype)\n     21 \n---&gt; 22         model = load_model(model_directory)\n     23 \n     24         #classifying the image\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/save.py in load_model(filepath, custom_objects, compile)\n    144   if (h5py is not None and (\n    145       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n--&gt; 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n    147 \n    148   if isinstance(filepath, six.string_types):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\n    164     if model_config is None:\n    165       raise ValueError('No model found in config file.')\n--&gt; 166     model_config = json.loads(model_config.decode('utf-8'))\n    167     model = model_config_lib.model_from_config(model_config,\n    168                                                custom_objects=custom_objects)\n\nAttributeError: 'str' object has no attribute 'decode'\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":9,
        "Question_creation_time":1647159554620,
        "Question_score":0,
        "Question_tags":"python|tensorflow|azure-machine-learning-studio",
        "Question_view_count":68,
        "Owner_creation_time":1556718046720,
        "Owner_last_access_time":1662885742377,
        "Owner_location":"1040\/3 Athurugiriya Road, Malabe, Sri Lanka",
        "Owner_reputation":25,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1647162639363,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71454995",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60832279,
        "Question_title":"Influx DB as a source for MLS as a direct connection",
        "Question_body":"<p>Can we use InfluxDB as a data source for Azure ML Serv, in the form of a direct connection.  If not, what are the proposed alternatives to setup this connection?\n(Put differently, Is it possible for M LServ to connect to an InfluxDB next to some API to fetch data from. Or do we have to put all data in a SQL database?)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1585057386130,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":105,
        "Owner_creation_time":1585057281607,
        "Owner_last_access_time":1614093458423,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60832279",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70376362,
        "Question_title":"Unable to use \"join data\" to combine multiple datasets into one using Azure Machine Learning Studio Designer",
        "Question_body":"<p>How can I combine mutiple datasets into one using Azure Machine Learning Studio?<\/p>\n<p>(The following graph doesn't work)\n<a href=\"https:\/\/i.stack.imgur.com\/ROmcV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ROmcV.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Same question: <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/666021\/unable-to-use-34join-data34-to-combine-multiple-da.html\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/666021\/unable-to-use-34join-data34-to-combine-multiple-da.html<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1639645564350,
        "Question_score":0,
        "Question_tags":"azure|azure-pipelines|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":141,
        "Owner_creation_time":1626943035463,
        "Owner_last_access_time":1663968468203,
        "Owner_location":"Hong Kong",
        "Owner_reputation":43,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":1639709288793,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70376362",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53273551,
        "Question_title":"Visualizing decision jungle in Azure Machine Learning Studio",
        "Question_body":"<p>I have trained a decision jungle model on Azure Machine Learning, and  now I want to visualize the trees, to see if I can identify the root nodes that are the most determinant in the decision.<\/p>\n\n<p>When I right-click and click Visualize on the Train Model, what is shown is the parameter set used for the training. How can I either visualize the jungle, or identify the features with highest information gain from this?<\/p>\n\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1542081348593,
        "Question_score":1,
        "Question_tags":"decision-tree|azure-machine-learning-studio|information-gain",
        "Question_view_count":88,
        "Owner_creation_time":1384225745143,
        "Owner_last_access_time":1654030338327,
        "Owner_location":"Milton, ON, Canada",
        "Owner_reputation":179,
        "Owner_up_votes":174,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53273551",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51587956,
        "Question_title":"Activation function of Regression Neural Net in Azure ML Studio?",
        "Question_body":"<p>I am not able to find activation function for Regression Neural Network in Azure Machine Learning Studio. I am not able to identify what is the activation function taken for my NN. Followed this document also-<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/neural-network-regression\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/neural-network-regression<\/a><\/p>\n\n<p>Can someone suggest where to mention it\/ what is the default activation function used?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1532931331770,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":352,
        "Owner_creation_time":1439280053903,
        "Owner_last_access_time":1660234274593,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":541,
        "Owner_up_votes":457,
        "Owner_down_votes":6,
        "Owner_views":269,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51587956",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52032535,
        "Question_title":"Does the primary key of Web Service API in ML Studio expire?",
        "Question_body":"<p>I deployed a web-service from an experiment in ML studio. I tested the API, and everything was working fine. I tested it in Postman. After 2 hours, I got an authentication error when I sent a request using the same API. So to resolve this, I republished my Web Service and got new authentication code, so the API is working fine for now. I have two questions:<\/p>\n\n<p>1) Does the primary key automatically expire after a while or by signing out from ML studio? \n2) What is the application of the second key in ML Studio APIs? Where do we need the second key? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1535343803617,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":228,
        "Owner_creation_time":1501114346137,
        "Owner_last_access_time":1605792960497,
        "Owner_location":"Australia",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":"<blockquote>\n  <p>1) Does the primary key automatically expire after a while or by signing out from ML studio?<\/p>\n<\/blockquote>\n\n<p>I could not find any limit of the primary key in the office docs. Per my test, my primary key does not expire more than two hours or sign out from ML studio.<\/p>\n\n<blockquote>\n  <p>2) What is the application of the second key in ML Studio APIs? Where do we need the second key?<\/p>\n<\/blockquote>\n\n<p>The second key is the same usage of the primary key, like a backup of the primary key. Also, the primary key equals the API key in the ML studio.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1535450343787,
        "Answer_score":0.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52032535",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35970126,
        "Question_title":"Increase the size of \/dev\/shm in Azure ML Studio",
        "Question_body":"<p>I'm trying to execute the following code in Azure ML Studio notebook:<\/p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cross_validation import KFold, cross_val_score\n\nfor C in np.linspace(0.01, 0.2, 30):\n    cv = KFold(n=X_train.shape[0], n_folds=7, shuffle=True, random_state=12345)\n    clf = LogisticRegression(C=C, random_state=12345)\n    print C, sum(cross_val_score(clf, X_train_scaled, y_train, scoring='roc_auc', cv=cv, n_jobs=2)) \/ 7.0\n<\/code><\/pre>\n\n<p>and I'm getting this error:<\/p>\n\n<pre><code>Failed to save &lt;type 'numpy.ndarray'&gt; to .npy file:\nTraceback (most recent call last):\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py\", line 271, in save\n    obj, filename = self._write_array(obj, filename)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py\", line 231, in _write_array\n    self.np.save(filename, array)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/numpy\/lib\/npyio.py\", line 491, in save\n    pickle_kwargs=pickle_kwargs)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/numpy\/lib\/format.py\", line 585, in write_array\n    array.tofile(fp)\nIOError: 19834920 requested and 8384502 written\n\n---------------------------------------------------------------------------\nIOError                                   Traceback (most recent call last)\n&lt;ipython-input-29-9740e9942629&gt; in &lt;module&gt;()\n      6     cv = KFold(n=X_train.shape[0], n_folds=7, shuffle=True, random_state=12345)\n      7     clf = LogisticRegression(C=C, random_state=12345)\n----&gt; 8     print C, sum(cross_val_score(clf, X_train_scaled, y_train, scoring='roc_auc', cv=cv, n_jobs=2)) \/ 7.0\n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/cross_validation.pyc in cross_val_score(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\n   1431                                               train, test, verbose, None,\n   1432                                               fit_params)\n-&gt; 1433                       for train, test in cv)\n   1434     return np.array(scores)[:, 0]\n   1435 \n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/parallel.pyc in __call__(self, iterable)\n    808                 # consumption.\n    809                 self._iterating = False\n--&gt; 810             self.retrieve()\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/parallel.pyc in retrieve(self)\n    725                 job = self._jobs.pop(0)\n    726             try:\n--&gt; 727                 self._output.extend(job.get())\n    728             except tuple(self.exceptions) as exception:\n    729                 # Stop dispatching any new job in the async callback thread\n\n\/home\/nbcommon\/env\/lib\/python2.7\/multiprocessing\/pool.pyc in get(self, timeout)\n    565             return self._value\n    566         else:\n--&gt; 567             raise self._value\n    568 \n    569     def _set(self, i, obj):\n\nIOError: [Errno 28] No space left on device\n<\/code><\/pre>\n\n<p>With <code>n_jobs=1<\/code> it works fine.<\/p>\n\n<p>I think this is because <code>joblib<\/code> library tries to save my data to <code>\/dev\/shm<\/code>. The problem is that it has only 64M capacity:<\/p>\n\n<pre><code>Filesystem         Size  Used Avail Use% Mounted on\nnone               786G  111G  636G  15% \/\ntmpfs               56G     0   56G   0% \/dev\nshm                 64M     0   64M   0% \/dev\/shm\ntmpfs               56G     0   56G   0% \/sys\/fs\/cgroup\n\/dev\/mapper\/crypt  786G  111G  636G  15% \/etc\/hosts\n<\/code><\/pre>\n\n<p>I can't change this folder by setting <code>JOBLIB_TEMP_FOLDER<\/code> environment variable (<code>export<\/code> doesn't work).<\/p>\n\n<pre><code>In [35]: X_train_scaled.nbytes\n\nOut[35]: 158679360\n<\/code><\/pre>\n\n<p>Thanks for any advice!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1457871506333,
        "Question_score":2,
        "Question_tags":"python|azure|scikit-learn|joblib|azure-machine-learning-studio",
        "Question_view_count":630,
        "Owner_creation_time":1452022246890,
        "Owner_last_access_time":1657271456120,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":708,
        "Owner_up_votes":34,
        "Owner_down_votes":69,
        "Owner_views":167,
        "Question_last_edit_time":1457939841650,
        "Answer_body":"<p>The <code>\/dev\/shm<\/code> is a virtual filesystem for passing data between programs that implementation of traditional shared memory on Linux.<\/p>\n\n<p>So you could not increase it via set up some options on Application Layout.<\/p>\n\n<p>But for example, you can remount <code>\/dev\/shm<\/code> with 8G size in Linux Shell with administrator permission like <code>root<\/code> as follows.<\/p>\n\n<p><code>mount -o remount,size=8G \/dev\/shm<\/code><\/p>\n\n<p>However, it seems that Azure ML studio not support remote access via SSH protocol, so the feasible plan is upgrade the standard tier if using free tier at present.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1457947589353,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35970126",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57998468,
        "Question_title":"Unpickling error when running fairseq on AML using multiple GPUs",
        "Question_body":"<p>I am trying to run fairseq translation task on AML using 4 GPUs (P100)and it fails with the following error:<\/p>\n\n<blockquote>\n  <p>-- Process 2 terminated with the following error: Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 174, in all_gather_list\n      result.append(pickle.loads(bytes(out_buffer[2 : size + 2].tolist())))\n  _pickle.UnpicklingError: invalid load key, '\\xad'.<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\",\n  line 19, in _wrap\n      fn(i, *args)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 272, in distributed_main\n      main(args, init_distributed=True)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 82, in main\n      train(args, trainer, task, epoch_itr)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 123, in train\n      log_output = trainer.train_step(samples)   File \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/trainer.py\",\n  line 305, in train_step\n      [logging_outputs, sample_sizes, ooms, self._prev_grad_norm],   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 178, in all_gather_list\n      'Unable to unpickle data from other workers. all_gather_list requires all ' Exception: Unable to unpickle data from other workers.\n  all_gather_list requires all workers to enter the function together,\n  so this error usually indicates that the workers have fallen out of\n  sync somehow. Workers can fall out of sync if one of them runs out of\n  memory, or if there are other conditions in your training script that\n  can cause one worker to finish an epoch while other workers are still\n  iterating over their portions of the data.<\/p>\n  \n  <p> 2019-09-18\n  17:28:44,727|azureml.WorkerPool|DEBUG|[STOP]<\/p>\n  \n  <p>Error occurred: User program failed with Exception: <\/p>\n  \n  <p>-- Process 2 terminated with the following error: Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 174, in all_gather_list\n      result.append(pickle.loads(bytes(out_buffer[2 : size + 2].tolist())))\n  _pickle.UnpicklingError: invalid load key, '\\xad'.<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\",\n  line 19, in _wrap\n      fn(i, *args)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 272, in distributed_main\n      main(args, init_distributed=True)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 82, in main\n      train(args, trainer, task, epoch_itr)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 123, in train\n      log_output = trainer.train_step(samples)   File \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/trainer.py\",\n  line 305, in train_step\n      [logging_outputs, sample_sizes, ooms, self._prev_grad_norm],   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 178, in all_gather_list\n      'Unable to unpickle data from other workers. all_gather_list requires all ' Exception: Unable to unpickle data from other workers.\n  all_gather_list requires all workers to enter the function together,\n  so this error usually indicates that the workers have fallen out of\n  sync somehow. Workers can fall out of sync if one of them runs out of\n  memory, or if there are other conditions in your training script that\n  can cause one worker to finish an epoch while other workers are still\n  iterating over their portions of the data.<\/p>\n<\/blockquote>\n\n<p>The same code with same param runs fine on a single local GPU. How do I resolve this issue?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1568829707947,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":216,
        "Owner_creation_time":1568829254257,
        "Owner_last_access_time":1573858168580,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57998468",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55443270,
        "Question_title":"Separators in data file for azure ml studio",
        "Question_body":"<p>I have csv file news.csv with such data:<\/p>\n\n<pre><code>ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n<\/code><\/pre>\n\n<p>But Azure ML studio experiments dont see Separators \\t and when I try to select column I cant do it. How to fix it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1554051628587,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":109,
        "Owner_creation_time":1553239567403,
        "Owner_last_access_time":1557156750967,
        "Owner_location":null,
        "Owner_reputation":67,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55443270",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70380861,
        "Question_title":"Azure ML Dataset Versioning: What is Different if it Points to the Same Data?",
        "Question_body":"<p><strong>Context<\/strong><\/p>\n<p>In AzureML, we are facing an error when running a pipeline. It fails on <code>to_pandas_dataframe<\/code> because a particular dataset &quot;could not be read beyond end of stream&quot;. On its own, this seems to be an issue with the parquet file that is being registered, maybe special characters being misinterpreted.<\/p>\n<p>However, when we explicitly load a previous &quot;version&quot; of this Dataset--which points to the exact same location of data--it works as expected. In the documentation (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-version-track-datasets#versioning-best-practice\" rel=\"nofollow noreferrer\">here<\/a>), Azure says that &quot;when you load data from a dataset, the current data content referenced by the dataset is always loaded.&quot; This makes me think that a new version of the dataset with the same schema will be, well, the same.<\/p>\n<p><strong>Questions<\/strong><\/p>\n<ol>\n<li><p>What makes a Dataset version <em>different<\/em> from another version when both point to the same location? Is it only the schema definition?<\/p>\n<\/li>\n<li><p>Based on these differences, is there a way to figure out why one version would be succeeding and another failing?<\/p>\n<\/li>\n<\/ol>\n<p><strong>Attempts<\/strong><\/p>\n<ul>\n<li>The schemas of the two versions are identical. We can profile both in AzureML, and all the fields have the same profile information.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1639665519797,
        "Question_score":1,
        "Question_tags":"azure|version|azure-synapse|azure-machine-learning-service",
        "Question_view_count":245,
        "Owner_creation_time":1591385782727,
        "Owner_last_access_time":1663012868427,
        "Owner_location":"Chicago, IL, USA",
        "Owner_reputation":594,
        "Owner_up_votes":71,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":"<p>As rightly suggested by @Anand Sowmithiran in comment section, This looks more like a bug with the SDK.<\/p>\n<p>You can raise <a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/create-ticket\/\" rel=\"nofollow noreferrer\">Azure support ticket<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1641212437097,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70380861",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70772040,
        "Question_title":"How to fix Azure ml model deployment Error",
        "Question_body":"<p>I'm trying to deploy a RandomForest model using azure ML with ACI , but after i deploy my service i keep getting this error :<\/p>\n<pre><code>Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 2.9.2 (\/opt\/miniconda\/lib\/python3.6\/site-packages), Requirement.parse('cryptography&gt;=3.3.1; extra == &quot;crypto&quot;'), {'PyJWT'}).*\n<\/code><\/pre>\n<p>Here's a snapshot of the code and the error :\n<a href=\"https:\/\/i.stack.imgur.com\/BbhDT.png\" rel=\"nofollow noreferrer\">enter image description here<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/llrGg.png\" rel=\"nofollow noreferrer\">enter image description here<\/a>\nCan you please tell me what should i do to fix this?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1642601193557,
        "Question_score":0,
        "Question_tags":"python|dependencies|random-forest|azure-machine-learning-service",
        "Question_view_count":250,
        "Owner_creation_time":1642600792490,
        "Owner_last_access_time":1660756607240,
        "Owner_location":null,
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1643392590833,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70772040",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73413792,
        "Question_title":"Error: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\"",
        "Question_body":"<p>I'm running this code on Azure machine learning notebook.<\/p>\n<pre><code>import os\nimport torch\nimport gradio as gr\nfrom vilmedic import AutoModel\nfrom vilmedic.blocks.scorers import RadGraph\nimport glob\n\nmodel, processor = AutoModel.from_pretrained(&quot;rrg\/baseline-mimic&quot;)\ndevice = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)\nmodel = model.to(device)\nradgraph = RadGraph(cuda=-1)\n<\/code><\/pre>\n<p>.....<\/p>\n<pre><code>def run(image, beam_size, num_return_sequences, include_words, exclude_words, do_radgraph):\n    if image is None:\n        return {}, '&lt;b&gt;Please select an image&lt;\/b&gt;'  # , &quot;&quot;\n    if num_return_sequences &gt; beam_size:\n        return {}, '&lt;b&gt;&quot;Beam size&quot;&lt;\/b&gt; must be greater or equal than &lt;b&gt;&quot;Number of generated reports&quot;&lt;\/b&gt;'  # , &quot;&quot;\n\n    try:\n        include_words_ids, include_words = get_token_from_strings(include_words)\n        exclude_words_ids, exclude_words = get_token_from_strings(exclude_words)\n\n        if include_words_ids is not None and [3] in include_words_ids:\n            return {}, '&lt;b&gt;&quot;' + include_words[\n                include_words_ids.index([3])] + '&quot;&lt;\/b&gt; is not in the vocabulary&quot;&lt;\/b&gt;'  # , &quot;&quot;\n\n        with torch.no_grad():\n            batch = processor.inference(image=[\n                [image]\n            ])\n            batch_size = 1\n            encoder_output, encoder_attention_mask = model.encode(**batch)\n            expanded_idx = torch.arange(batch_size).view(-1, 1).repeat(1, beam_size).view(-1)\n            input_ids = torch.ones((len(batch[&quot;images&quot;]), 1), dtype=torch.long)\n            if torch.cuda.is_available():\n                expanded_idx = expanded_idx.cuda()\n                print(&quot;89 line&quot;)\n                input_ids = input_ids.cuda()\n\n            # Using huggingface generate method\n            hyps = model.dec.generate(\n                input_ids=input_ids * model.dec.config.bos_token_id,\n                encoder_hidden_states=encoder_output.index_select(0, expanded_idx),\n                encoder_attention_mask=encoder_attention_mask.index_select(0, expanded_idx),\n                num_return_sequences=num_return_sequences,\n                max_length=processor.tokenizer_max_len,\n                num_beams=beam_size,\n                bad_words_ids=exclude_words_ids,\n                force_words_ids=include_words_ids,\n            )\n\n            # Decode\n            hyps = [processor.tokenizer.decode(h, skip_special_tokens=True, clean_up_tokenization_spaces=False) for h in\n                    hyps]\n\n            # RadGraph\n            if do_radgraph:\n                radgraph_annots = [radgraph(hyps=[h], refs=[h])[-1][0][&quot;entities&quot;] for h in hyps]\n                # Find entites : Radgraph\n                new_hyp_strs = []\n                for hyp_str, radgraph_annot in zip(hyps, radgraph_annots):\n                    values = radgraph_annot.values()\n                    new_hyp_str = hyp_str.split()\n                    for v in values:\n                        new_hyp_str[v[&quot;start_ix&quot;]] = highlight_radgraph_entities(v[&quot;tokens&quot;], v[&quot;label&quot;])\n                    new_hyp_strs.append(' '.join(new_hyp_str))\n            else:\n                new_hyp_strs = hyps\n\n            # Find user entites\n            if include_words is not None:\n                for w in include_words:\n                    new_hyp_strs = [h.replace(w, highlight_word(w, &quot;user&quot;)) for h in new_hyp_strs]\n\n            # Formating\n            new_hyp_strs = [&quot;&lt;p&gt;&lt;b&gt;Hypothesis {}:&lt;\/b&gt; &lt;br\/&gt; {} &lt;\/p&gt;&quot; \\\n                            &quot;&quot;.format(i + 1, h) for i, h in enumerate(new_hyp_strs)] + (\n                               [&quot;&lt;br\/&gt;&lt;br\/&gt;&lt;i&gt;Anat: anatomy&lt;br\/&gt;&quot;\n                                &quot;OBS: observation&lt;br\/&gt;&quot;\n                                &quot;DA: definitely absent&lt;br\/&gt;&quot;\n                                &quot;DP: definitely present&lt;\/i&gt;&quot;] if do_radgraph else [&quot;&quot;])\n\n            # Params\n            out_json = {\n                &quot;beam size&quot;: beam_size, &quot;number of generated reports&quot;: num_return_sequences,\n                &quot;included words&quot;: include_words, &quot;excluded words&quot;: exclude_words, &quot;show radgraph&quot;: do_radgraph\n            }\n\n            return out_json, str(''.join(new_hyp_strs))  # , str(refs[os.path.basename(image)])\n\n    except Exception as e:\n        print(e)\n        return {}, &quot;&lt;b&gt;An error occured, try again...&quot;\n\n<\/code><\/pre>\n<p>The full code is here:<\/p>\n<p><a href=\"https:\/\/huggingface.co\/spaces\/StanfordAIMI\/radiology_report_generation\/blob\/main\/app.py\" rel=\"nofollow noreferrer\">https:\/\/huggingface.co\/spaces\/StanfordAIMI\/radiology_report_generation\/blob\/main\/app.py<\/a><\/p>\n<p>It keeps giving me this error when I upload an image and click the submit button:\n<strong>Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!<\/strong>.\nI'm using an azure computation with following specifications:\nVirtual machine size: <em>Standard_NV6 (6 cores, 56 GB RAM, 380 GB disk)<\/em>\nProcessing unit: <em>GPU - 1 x NVIDIA Tesla M60<\/em><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1660897192447,
        "Question_score":0,
        "Question_tags":"pytorch|azure-machine-learning-studio|huggingface",
        "Question_view_count":147,
        "Owner_creation_time":1659682623830,
        "Owner_last_access_time":1663873466410,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1660905850610,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73413792",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50414639,
        "Question_title":"How to Publish an Azure Bot",
        "Question_body":"<p>Just learning how to use <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">Azure Bot Service<\/a> and <code>Azure Bot Framework<\/code>. I created a Bot in Azure portal following <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">this<\/a> Official Azure tutorial. Does this bot need to be published somewhere? I read somewhere that you <code>Build--&gt;Test--&gt;Publish--&gt;Evaluate<\/code>. I've tested it in Azure portal itself as explained <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">here<\/a>. Not sure about the Publish part of it.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1526657122620,
        "Question_score":3,
        "Question_tags":"azure|botframework|azure-machine-learning-studio|azure-bot-service",
        "Question_view_count":844,
        "Owner_creation_time":1330144099340,
        "Owner_last_access_time":1664039192277,
        "Owner_location":null,
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Question_last_edit_time":null,
        "Answer_body":"<p>How do you intend to use your bot? Azure Bots work by connecting them to existing channels like Skype, Facebook Messenger, SMS, etc or making REST calls from a custom application.<\/p>\n\n<p>However you can also reach your bot directly from: <code>https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE<\/code><\/p>\n\n<p>You can embed it on any web page with this HTML tag:<\/p>\n\n<pre><code>&lt;iframe src=\"https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE\"&gt;&lt;\/iframe&gt;\n<\/code><\/pre>\n\n<p>Please note that both of these methods expose your token and would allow other developers to add your bot to their pages as well.<\/p>\n\n<p>Bot ID is the name of your bot and you can get the token from the portal by going to your bot and choosing \"Channel\" blade and then clicking the \"Get bot embed codes\" link.<\/p>\n\n<p>Edit: I went ahead and wrote a blog post on this topic <a href=\"https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1526659876240,
        "Answer_score":5.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1527282754360,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50414639",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71063820,
        "Question_title":"AzureML: Dataset Profile fails when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I trigger &quot;Generate Profile&quot; operation for the dataset, it throws following error while handling empty parquet file and then the profile generation stops.<\/p>\n<pre><code>User program failed with ExecutionError: \nError Code: ScriptExecution.StreamAccess.Validation\nValidation Error Code: NotSupported\nValidation Target: ParquetFile\nFailed Step: 77866d0a-8243-4d3d-8bc6-599d466488dd\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  Failed to read Parquet file at: &lt;my_blob_path&gt;\/20211217.parquet\n    Current parquet file is not supported.\n      Exception of type 'Thrift.Protocol.TProtocolException' was thrown.\n| session_id=6be4db0b-bdc1-4dd6-b8a6-6e9466f7bc54\n\n<\/code><\/pre>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (<code>pd.read_parquet<\/code>), it results in an empty DF (df.empty == True).<\/p>\n<p>Any suggestion to avoid this error will be appreciated.<\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1644490387177,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":255,
        "Owner_creation_time":1280505139753,
        "Owner_last_access_time":1663935737867,
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Question_last_edit_time":1648643496673,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1646432534340,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71063820",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32884296,
        "Question_title":"Web service input into SQL query into R in Azure ML",
        "Question_body":"<p>I have the following simple setup in Azure ML. <a href=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" alt=\"ML setup\"><\/a> \nBasically the Reader is a SQL query to a DB which returns a vector called Pdelta, which is then passed to the R script for further processing  and the results are then returned back to the web service. The DB query is simple (<code>SELECT Pdelta FROM ...<\/code>) and it works fine. I have set the DB query as a web service paramater as well. <\/p>\n\n<p>Everything seems to work fine, but at the end when i publish it as a web service and test it, it somehow asks for an additional input parameter. The additional parameter gets called <code>PDELTA<\/code>.\n<a href=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am wondering why is this happening, what is it that I am overlooking? I would like to make this web service ask for only one parameter - the SQL query (Delta Query) which would then deliver the Pdeltas. <\/p>\n\n<p>Any ideas or suggestions would be grealty appreciated! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1443692439630,
        "Question_score":3,
        "Question_tags":"web-services|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":347,
        "Owner_creation_time":1432829415467,
        "Owner_last_access_time":1542573864587,
        "Owner_location":null,
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Question_last_edit_time":1456850075240,
        "Answer_body":"<p>You can remove the web service input block and publish the web service without it. That way the Pdelta input will be passed in only from the Reader module.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1444147981107,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32884296",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37418265,
        "Question_title":"Azure Machine Learning using Javascript Ajax call",
        "Question_body":"<p>I wanted to know if there is a way to call the Azure Machine Learning webservice using JavaScript Ajax.<\/p>\n\n<p>The Azure ML gives sample code for C#, Python and R.<\/p>\n\n<p>I did try out to call the webservice using JQuery Ajax but it returns a failure.<\/p>\n\n<p>I am able to call the same service using a python script.<\/p>\n\n<p>Here is my Ajax code : <\/p>\n\n<pre><code>  $.ajax({\n        url: webserviceurl,\n        type: \"POST\",           \n        data: sampleData,            \n        dataType:'jsonp',                        \n        headers: {\n        \"Content-Type\":\"application\/json\",            \n        \"Authorization\":\"Bearer \" + apiKey                       \n        },\n        success: function (data) {\n          console.log('Success');\n        },\n        error: function (data) {\n           console.log('Failure ' +  data.statusText + \" \" + data.status);\n        },\n  });\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_time":1464104729493,
        "Question_score":2,
        "Question_tags":"javascript|ajax|azure|azure-machine-learning-studio",
        "Question_view_count":1607,
        "Owner_creation_time":1460664823627,
        "Owner_last_access_time":1504814384707,
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1526047792277,
        "Answer_body":"<p>Well after a lot of RnD, I was able to finally call Azure ML using some workarounds.<\/p>\n\n<p>Wrapping Azure ML webservice on Azure API is one option.<\/p>\n\n<p>But, what I did was that I created a python webservice which calls the Azure webservice.<\/p>\n\n<p>So now my HTML App calls the python webservice which calls Azure ML and returns data to the HTML App.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1464718210400,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37418265",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70802006,
        "Question_title":"Clean Up Azure Machine Learning Blob Storage",
        "Question_body":"<p>I manage a frequently used Azure Machine Learning workspace. With several Experiments and active pipelines. Everything is working good so far. My problem is to get rid of old data from runs, experiments and pipelines. Over the last year the blob storage grew to enourmus size, because every pipeline data is stored.<\/p>\n<p>I have deleted older runs from experimnents by using the gui, but the actual pipeline data on the blob store is not deleted. Is there a smart way to clean up data on the blob store from runs which have been deleted ?<\/p>\n<p>On one of the countless Microsoft support pages, I found the following not very helpfull post:<\/p>\n<p>*Azure does not automatically delete intermediate data written with OutputFileDatasetConfig. To avoid storage charges for large amounts of unneeded data, you should either:<\/p>\n<ol>\n<li>Programmatically delete intermediate data at the end of a pipeline\nrun, when it is no longer needed<\/li>\n<li>Use blob storage with a short-term storage policy for intermediate data (see Optimize costs by automating Azure Blob Storage access tiers)<\/li>\n<li>Regularly review and delete no-longer-needed data*<\/li>\n<\/ol>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines#delete-outputfiledatasetconfig-contents-when-no-longer-needed\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines#delete-outputfiledatasetconfig-contents-when-no-longer-needed<\/a><\/p>\n<p>Any idea is welcome.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1642771426213,
        "Question_score":4,
        "Question_tags":"azure-blob-storage|azure-machine-learning-service",
        "Question_view_count":368,
        "Owner_creation_time":1635428968927,
        "Owner_last_access_time":1659693572257,
        "Owner_location":"Germany",
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70802006",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66247129,
        "Question_title":"How can I use modules in Azure ML studio designer pipeline?",
        "Question_body":"<p>I am currently using a python script in my Azure pipeline<\/p>\n<pre><code>Import data as Dataframe  --&gt;  Run Python Script  --&gt;  Export Dataframe\n<\/code><\/pre>\n<p>My script is developed locally and <strong>I get import errors when trying to import tensorflow<\/strong>... No problem, guess I just have to add it to environment dependencies somewhere -- and it is here the documentation fails me. They seem to rely on the SDK without touching the GUI, but I am using the designer.<\/p>\n<p>I have at this point already build some enviroments with the dependencies, but utilizing these environments on the run or script level is not obvious to me.<\/p>\n<p>It seems trivial, so any help as to use modules is greatly appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1613583198267,
        "Question_score":0,
        "Question_tags":"azure|azure-devops|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":283,
        "Owner_creation_time":1485179654243,
        "Owner_last_access_time":1663760467837,
        "Owner_location":null,
        "Owner_reputation":167,
        "Owner_up_votes":25,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66247129",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56812071,
        "Question_title":"Is it possible to access datastores from a Azure ML Service webservice?",
        "Question_body":"<p>According to the Azure ML Service <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-access-data#access-datastores-during-training\" rel=\"nofollow noreferrer\">documentation<\/a> it is possible to access datastores during training, but I couldn't find anything about using data from datastores inside the Webservice.<\/p>\n<p>Even though is not necessary use external data to make an Webservice work, to use my model as I intend I need to use some datasets with features created based on historical data. For example: imagine that I'm trying to forecast if a client is going to pay a bill in the right date a good strategy is to create a feature based on previous payments of this same client.<\/p>\n<p>The only external file that I could use in a Webservice is the 'model.pkl' which stores the ML model that I created previously.<\/p>\n<p>How can I get an Azure ML webservice access a datastore?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1561748683060,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":935,
        "Owner_creation_time":1561571259943,
        "Owner_last_access_time":1629948549313,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1658937485407,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56812071",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64137409,
        "Question_title":"How can I create an Azure dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_body":"<p>I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.<\/p>\n<p>In my folder, Spark creates files such as &quot;_SUCCESS&quot; or &quot;_committed_8998000&quot;.<\/p>\n<p>Azure ML Studio is not able to read them or ignore them and tells me:<\/p>\n<pre><code>The provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  &quot;message&quot;: &quot; &quot;\n}\n<\/code><\/pre>\n<p>I selected &quot;Ignore unmatched files path&quot; and yet, it still does not work.<\/p>\n<p>If I remove the &quot;_SUCCESS&quot; and other Spark files, it works.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1601468292143,
        "Question_score":2,
        "Question_tags":"azure|apache-spark|parquet|azure-machine-learning-studio",
        "Question_view_count":178,
        "Owner_creation_time":1423640080283,
        "Owner_last_access_time":1663943557963,
        "Owner_location":"Lyon, France",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Thanks for the feedback. You can use globing in path. e.g. path = '**\/*.parquet' to select only the parquet files<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1601483944070,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64137409",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49586005,
        "Question_title":"Azure ML workbench failed installing on Windows 10 Enterprise",
        "Question_body":"<p>Error installing component: azure_cli_ml_cliextension.windows \"The action failed catastrophically with <\/p>\n\n<p>Microsoft.MachineLearning.Installer.Engine.Actions.RegisteredActions.AzureCliException: Unable to get list of currently installed Azure CLI extensions<\/p>\n\n<p>at <\/p>\n\n<p>Microsoft.MachineLearning.Installer.Engine.Actions.RegisteredActions.InstallAzureCliExtensionAction.d__23.MoveNext() in C:\\swarm\\workspace\\Installer-1.2\\Installer.Engine\\Actions\\RegisteredActions\\InstallAzureCliExtensionAction.cs:line 97<\/p>\n\n<p>from there everything is stops....<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1522486296150,
        "Question_score":2,
        "Question_tags":"windows|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":296,
        "Owner_creation_time":1506435894640,
        "Owner_last_access_time":1664081964040,
        "Owner_location":"Southeast Asia",
        "Owner_reputation":1922,
        "Owner_up_votes":1232,
        "Owner_down_votes":72,
        "Owner_views":404,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Workbench is a preview product and issues may occur. Please try and get a newer exe and try again. It also seems like you have azure powershell issues here which I would have expected to be taken care of by the installer, but perhaps you can try and install azure powershell first. <\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1525629892870,
        "Answer_score":2.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49586005",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67161293,
        "Question_title":"Issues accessing a FileDataset created from HTTP URIs in a PythonScriptStep",
        "Question_body":"<p>I\u2019m having some issues trying to access a FileDataset created from two http URIs in an Azure ML Pipeline PythonScriptStep.<\/p>\n<p>In the step, I\u2019m only getting a single file named <code>['https%3A\u2019]<\/code> when doing an <code>os.listdir()<\/code> on my mount point. I would have expected two files, with their actual names instead. This happens both when sending the dataset <code>as_upload<\/code> and <code>as_mount<\/code>. Even happens when I send the dataset reference to the pipeline step and mount it directly from the step.<\/p>\n<p>The dataset is registered in a notebook, the same notebook that creates and invokes the pipeline, as seen below:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>tempFileData = Dataset.File.from_files(\n        ['https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg',\n        'https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg'])\ntempFileData.register(ws, name='FileData', create_new_version=True)\n\n#...\n\nread_datasets_step = PythonScriptStep(\n    name='The Dataset Reader',\n    script_name='read-datasets.py',\n    inputs=[fileData.as_named_input('Files'), fileData.as_named_input('Files_mount').as_mount(), fileData.as_named_input('Files_download').as_download()],\n    compute_target=compute_target,\n    source_directory='.\/dataset-reader',\n    allow_reuse=False,\n)\n\n<\/code><\/pre>\n<p>The <code>FileDataset<\/code> seems to be registered properly, if I examine it within the notebook I get the following result:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [\n    &quot;https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot;,\n    &quot;https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;\n  ],\n  &quot;definition&quot;: [\n    &quot;GetFiles&quot;\n  ],\n  &quot;registration&quot;: {\n    &quot;id&quot;: &quot;...&quot;,\n    &quot;name&quot;: &quot;FileData&quot;,\n    &quot;version&quot;: 4,\n    &quot;workspace&quot;: &quot;Workspace.create(...)&quot;\n  }\n}\n<\/code><\/pre>\n<p>For reference, the machine running the notebook is using AML SDK v1.24, whereas the node running the pipeline steps is running v1.25.<\/p>\n<p>Has anybody encountered anything like this? Is there a way to make it work?<\/p>\n<p>Note that I'm specifically looking at file datasets created from web uris, and not necessarily interested in getting a <code>FileDataset<\/code> to work with blob storage or similar.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1618832324140,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_time":1250158552417,
        "Owner_last_access_time":1663847198323,
        "Owner_location":"Romania",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Question_last_edit_time":1618849094430,
        "Answer_body":"<p>The files should've been mounted at path &quot;https%3A\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot; and &quot;https%3A\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;.<\/p>\n<p>We retain the directory structure following the url structure to avoid potential conflicts.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1618855169223,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67161293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59392060,
        "Question_title":"Azure ML platform wrongly interprets uploaded dataset",
        "Question_body":"<p>I have a data set with about 7999 attributes and 39 labels, with 3339 total observations (resulting in 3339x8038 data set), and I'm trying to upload id to Azure ML platform.\nI've selected the 'type' as 'tabular', encoding as 'utf-8', no row skipping, and use header from first file.\nThe problem is, that the headers are still not included and the data is interpreted as string with 0s, 1s, and commas (see pic <a href=\"https:\/\/imgur.com\/a\/QdQNt1y\" rel=\"nofollow noreferrer\">https:\/\/imgur.com\/a\/QdQNt1y<\/a>)<\/p>\n\n<p>Am I missing something? For smaller data sets it seemed to work. My headers are A1, ... A7999 for the attributes, and L1, ... L39 for the labels.<\/p>\n\n<p>Thanks for help in advance.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1576672108560,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":49,
        "Owner_creation_time":1527091507810,
        "Owner_last_access_time":1663872222817,
        "Owner_location":"Stockholm, Sweden",
        "Owner_reputation":235,
        "Owner_up_votes":9,
        "Owner_down_votes":1,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":"<p>our system does our best guess over file settings when you try to create a dataset, but cannot guarantee perfect guesses in all cases. <\/p>\n\n<p>In such scenarios, you should be able to adjust the settings. We had a bug with the ability to change those settings, but rolled out a fix. Can you try to change those now?  <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1576813812910,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59392060",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38927230,
        "Question_title":"Panda AssertionError columns passed, passed data had 2 columns",
        "Question_body":"<p>I am working on Azure ML implementation on text analytics with NLTK, the following execution is throwing <\/p>\n\n<pre><code>AssertionError: 1 columns passed, passed data had 2 columns\\r\\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>Below is the code <\/p>\n\n<pre><code># The script MUST include the following function,\n# which is the entry point for this module:\n# Param&lt;dataframe1&gt;: a pandas.DataFrame\n# Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # import required packages\n    import pandas as pd\n    import nltk\n    import numpy as np\n    # tokenize the review text and store the word corpus\n    word_dict = {}\n    token_list = []\n    nltk.download(info_or_id='punkt', download_dir='C:\/users\/client\/nltk_data')\n    nltk.download(info_or_id='maxent_treebank_pos_tagger', download_dir='C:\/users\/client\/nltk_data')\n    for text in dataframe1[\"tweet_text\"]:\n        tokens = nltk.word_tokenize(text.decode('utf8'))\n        tagged = nltk.pos_tag(tokens)\n\n\n      # convert feature vector to dataframe object\n    dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n    return [dataframe_output]\n<\/code><\/pre>\n\n<p>Error is throwing here <\/p>\n\n<pre><code> dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n<\/code><\/pre>\n\n<p>I suspect this to be the tagged data type passed to dataframe, can some one let me know the right approach to add this to dataframe.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1471040597197,
        "Question_score":7,
        "Question_tags":"python|pandas|dataframe|nltk|azure-machine-learning-studio",
        "Question_view_count":48200,
        "Owner_creation_time":1370924418390,
        "Owner_last_access_time":1663478900357,
        "Owner_location":"Toronto, ON, Canada",
        "Owner_reputation":1748,
        "Owner_up_votes":136,
        "Owner_down_votes":55,
        "Owner_views":339,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Try this:<\/p>\n\n<pre><code>dataframe_output = pd.DataFrame(tagged, columns=['Output', 'temp'])\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1471040769603,
        "Answer_score":13.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38927230",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57403281,
        "Question_title":"Installing textshape package for Microsoft R Open 3.4.4 on Azure ML Studio",
        "Question_body":"<p>I'm trying to use the R <code>sentimentr<\/code> package on Azure ML Studio. As this package is not supported, I'm trying to install it and its dependencies as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#bkmk_AddingANewPackage\" rel=\"nofollow noreferrer\">in the documentation<\/a>.<\/p>\n\n<p>The steps that I have performed are:<\/p>\n\n<ul>\n<li><p>downloaded Windows binaries from the R Open 3.4.4 snapshot at <a href=\"https:\/\/mran.microsoft.com\/timemachine\" rel=\"nofollow noreferrer\">CRAN time machine<\/a><\/p>\n\n<ul>\n<li><code>sentimentr_2.2.3.zip<\/code><\/li>\n<li><code>syuzhet_1.0.4.zip<\/code><\/li>\n<li><code>textclean_0.6.3.zip<\/code><\/li>\n<li><code>lexicon_0.7.4.zip<\/code><\/li>\n<li><code>textshape_1.5.0.zip<\/code> <\/li>\n<\/ul><\/li>\n<li><p>zipped those zip files into a zipped folder <code>packages.zip<\/code><\/p><\/li>\n<li>uploaded <code>packages.zip<\/code> as a dataset to Microsoft Azure ML Studio<\/li>\n<\/ul>\n\n<p>In my ML experiment I connect the <code>packages.zip<\/code> dataset to the \"Script Bundle (Zip)\" input port on \"Execute R Script\" and include this code:<\/p>\n\n<pre><code># install R package contained in src  \ninstall.packages(\"src\/lexicon_0.7.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textclean_0.6.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textshape_1.5.0.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/syuzhet_1.0.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/sentimentr_2.2.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\n# load libraries\nlibrary(sentimentr, lib.loc = \".\", verbose = TRUE)\n<\/code><\/pre>\n\n<p>The experiment runs successfully, until I include a function from <code>sentimentr<\/code>:<\/p>\n\n<pre><code>mydata &lt;- mydata %&gt;%\n  get_sentences() %&gt;%\n  sentiment()\n<\/code><\/pre>\n\n<p>This gives the error:<\/p>\n\n<blockquote>\n  <p>there is no package called 'textshape'<\/p>\n<\/blockquote>\n\n<p>Which is difficult to understand given that the output log does not indicate an issue with the packages:<\/p>\n\n<pre><code>[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                           Name  Length                Date\n[Information]         1 sentimentr_2.2.3.zip 3366245 2019-08-07 14:57:00\n[Information]         2    syuzhet_1.0.4.zip 2918474 2019-08-07 15:05:00\n[Information]         3  textclean_0.6.3.zip 1154814 2019-08-07 15:13:00\n[Information]         4    lexicon_0.7.4.zip 4551995 2019-08-07 15:17:00\n[Information]         5  textshape_1.5.0.zip  463095 2019-08-07 15:42:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'lexicon' successfully unpacked and MD5 sums checked   \n[Information]         package 'textclean' successfully unpacked and MD5 sums checked\n[Information]         package 'textshape' successfully unpacked and MD5 sums checked\n[Information]         package 'syuzhet' successfully unpacked and MD5 sums checked\n[Information]         package 'sentimentr' successfully unpacked and MD5 sums checked\n<\/code><\/pre>\n\n<p>Has anyone seen this, or similar issues? Is it possible that \"successfully unpacked\" is not the same as successfully installed and usable?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1565219530070,
        "Question_score":2,
        "Question_tags":"r|package|azure-machine-learning-studio",
        "Question_view_count":157,
        "Owner_creation_time":1239374952693,
        "Owner_last_access_time":1663925914630,
        "Owner_location":"Sydney, Australia",
        "Owner_reputation":30129,
        "Owner_up_votes":685,
        "Owner_down_votes":51,
        "Owner_views":2937,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I can now answer my own question thanks to <a href=\"https:\/\/twitter.com\/bryan_hepworth\/status\/1159432174225055749\" rel=\"nofollow noreferrer\">a hint on Twitter<\/a> from @bryan_hepworth.<\/p>\n\n<p>The R packages were installed correctly, but not in the standard library location. So when a function from <code>sentimentr<\/code> runs, R tries to load the dependency package <code>textshape<\/code>:<\/p>\n\n<pre><code>library(textshape)\n<\/code><\/pre>\n\n<p>Which of course does not exist <em>in the standard location<\/em> as Azure ML does not support it.<\/p>\n\n<p>The solution is to load <code>textshape<\/code> explicitly from its installed location:<\/p>\n\n<pre><code>library(textshape, lib.loc = \".\")\n<\/code><\/pre>\n\n<p>So the solution is: explicitly load packages that you installed at the start of your R code, rather than letting R try to load them as dependencies, which will fail.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1565302474167,
        "Answer_score":0.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57403281",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60149987,
        "Question_title":"ERROR: Setup iteration failed: Unidentified error, check logs in portal \/ compute",
        "Question_body":"<p>Getting error when trying to run the autoML through training cluster. But it is running successfully via the local run. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1581335967710,
        "Question_score":1,
        "Question_tags":"python|automl|azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_time":1522597272890,
        "Owner_last_access_time":1662966923173,
        "Owner_location":"Kolkata, West Bengal, India",
        "Owner_reputation":671,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60149987",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62341639,
        "Question_title":"Run failed: Unable to establish SSH connection in Azure ML Service Pipeline",
        "Question_body":"<p>I am getting <code>Run failed: Unable to establish SSH connection<\/code> error when I trigger my Published Azure ML Pipeline using Azure Function App while the VM is closed. Normally The Azure ML Pipeline should be able to automatically turn the virtual machine on when I trigger it and close the VM when the process done. Otherwise, it doesn't make any sense. <\/p>\n\n<p>Sometimes I don't get such an error and the pipeline just works perfectly. <\/p>\n\n<p>Also, the Pipeline works without a problem when I manually start the VM from AzurePortal before trigger the pipeline.<\/p>\n\n<p>The Published Pipeline uses Azure Data Science Virtual Machine - Ubuntu. I am using username and password to access the VM.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1591955060000,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":253,
        "Owner_creation_time":1449521746610,
        "Owner_last_access_time":1658823186867,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1592055179887,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62341639",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58035744,
        "Question_title":"AML run.log() and run.log_list() fail without error",
        "Question_body":"<p>I have a Pipeline with DatabricksSteps each containing:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\n#do stuff\nrun.log(name, val, desc)\nrun.log_list(name, vals, desc)\nrun.log_image(title, fig, desc)\n<\/code><\/pre>\n\n<p>Only <code>log_image()<\/code> seems to work.  The image appears in the \"images\" section of the AML experiment workspace as expected, but the \"tracked metrics\" and \"charts\" areas are blank.  In an interactive job, <code>run.log()<\/code> and <code>run.log_list()<\/code> work as expected.  I tested that there is no problem with the arguments by using <code>print()<\/code> instead of <code>run.log()<\/code>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1569018204223,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":121,
        "Owner_creation_time":1465320834943,
        "Owner_last_access_time":1617290067470,
        "Owner_location":"Redmond, WA, USA",
        "Owner_reputation":677,
        "Owner_up_votes":13,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Add run.flush() at the end of the script.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1569427861030,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58035744",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67552090,
        "Question_title":"Delete and recreate the registry for an azure machine learning workspace",
        "Question_body":"<p>Our azure machine learning workspace container registry has grown extremely large (4Tb) and has many obsolete entries. I would like to delete the registry and simply create a new one. We do not need any entries from the old one.<\/p>\n<p>If I delete the current registry, create a new one, how do I attach it to the workspace?  I dont want to create a new workspace.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1621122191180,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":172,
        "Owner_creation_time":1565794118450,
        "Owner_last_access_time":1664072200673,
        "Owner_location":null,
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67552090",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60964381,
        "Question_title":"Getting error while connecting ADLS to Notebook in AML",
        "Question_body":"<p>I am getting below error while connecting dataset created and registered in AML notebook and which is based on ADLS. When I connect this dataset in designer I am able to visualize the same. Below is the code that I am using. Please let me know the solution if anyone have faced the same error.<\/p>\n<h3>Examle 1 Import dataset to notebbok<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Dataset\n\nsubscription_id = 'abcd'\nresource_group = 'RGB'\nworkspace_name = 'DSG'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='abc')\ndataset.to_pandas_dataframe()\n<\/code><\/pre>\n<h3>Error 1<\/h3>\n<pre><code>ExecutionError: Could not execute the specified transform.\n(Error in getting metadata for path \/local\/top.txt.\nOperation: GETFILESTATUS failed with Unknown Error: The operation has timed out..\nLast encountered exception thrown after 5 tries.\n[The operation has timed out.,The operation has timed out.,The operation has timed out.,The operation has timed out.,The operation has timed out.]\n[ServerRequestId:])|session_id=2d67\n<\/code><\/pre>\n<h3>Example 2 Import data from datastore to notebook<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Datastore, Dataset\n\ndatastore_name = 'abc'\nworkspace = Workspace.from_config()\n\ndatastore = Datastore.get(workspace, datastore_name)\ndatastore_paths = [(datastore, '\/local\/top.txt')]\ndf_ds = Dataset.Tabular.from_delimited_files(\n    path=datastore_paths, validate=True,\n    include_path=False, infer_column_types=True,\n    set_column_types=None, separator='\\t',\n    header=True, partition_format=None\n    )\n\ndf = df_ds.to_pandas_dataframe()\n<\/code><\/pre>\n<h3>Error 2<\/h3>\n<pre><code>Cannot load any data from the specified path. Make sure the path is accessible.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1585719922157,
        "Question_score":1,
        "Question_tags":"azure-data-lake|azure-machine-learning-service",
        "Question_view_count":277,
        "Owner_creation_time":1585719823390,
        "Owner_last_access_time":1637431208373,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1592644375060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60964381",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50024278,
        "Question_title":"How can I use the predictive experiment of Azure ML on my website",
        "Question_body":"<p>I used Azure ML studio and I obtained a predictive experiment with an API key.<\/p>\n\n<p><strong>My question is:<\/strong><br>\nHow can I embed this API key or the text obtained or the predictive experiment on a website or on my portfolio?<br>\nSo that others can use the predictive experiment from the website...<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1524664856743,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":28,
        "Owner_creation_time":1524663632880,
        "Owner_last_access_time":1525247437023,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1550566774003,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50024278",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47281734,
        "Question_title":"Azure ML Web Service + Python for Querying Pandas Data Frame",
        "Question_body":"<p>I want to use Azure ML Web Service for a non machine learning task with Python. The goal is the following:<\/p>\n\n<p>I have a Pandas DF like this:<\/p>\n\n<pre><code>   Id   Value\n0  111  0.1\n1  222  7.3\n2  333  3.1\n3  444  5.0\n<\/code><\/pre>\n\n<p>I can query this DF successfully (what is the value of a certain row by Id?):<\/p>\n\n<pre><code>float(df.loc[pot['Id'] == 222, 'Value'])\n<\/code><\/pre>\n\n<p>Now, I want to deploy a function in Azure ML Web Service with this functionality where a function uses an uploaded data set as fix lookup table. I constructed the function which gets an Id number as argument, looks for the value in the pre-uploade dataset and gives it back as a float:<\/p>\n\n<pre><code>from azureml import services\nimport pandas as pd\n\n@services.publish(workspace_id, workspace_token)\n@services.types(id=int)\n@services.returns(float)\ndef my_func(id):\n    my_df = ws.datasets[\"uploaded_df.csv\"].to_dataframe()\n    return float(my_df.loc[cent['Id'] == id, 'Value'])\n<\/code><\/pre>\n\n<p>I can deploy it on Azure Web Services but when I try to run a test query It gets stuck (no way even to peep into the details). What is the problem here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1510650824677,
        "Question_score":0,
        "Question_tags":"python|azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":428,
        "Owner_creation_time":1466792392047,
        "Owner_last_access_time":1658205048127,
        "Owner_location":null,
        "Owner_reputation":1078,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":90,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47281734",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40907847,
        "Question_title":"Azure machine learning endpoints with different column count",
        "Question_body":"<p>I would like to automatically set up Azure machine learning endpoints that don't necessarily have the same amount of variables. I am able to programmatically add new endpoints that are trained on different data as long as they have the same column and variable names (headers).<\/p>\n\n<p>When I try to create a new endpoint using a different column count it works. But when I try to call it it gives me errors.<\/p>\n\n<p>I set up an experiment where the default endpoint is accepting two parameters 'x' and 'y'. Then I trained it on a dataset using three columns 'x1', 'x2' and 'y'. The 'Train Model' module in the training experiment is picking out column 1.<\/p>\n\n<p>Calling the endpoint that was trained using three variables with three input columns:<\/p>\n\n<pre><code>{\n\"error\": {\n    \"code\": \"LibraryExecutionError\",\n    \"message\": \"Module execution encountered an internal library error.\",\n    \"details\": [\n        {\n            \"code\": \"TableSchemaColumnCountMismatch\",\n            \"target\": \" (AFx Library)\",\n            \"message\": \"data: The table column count (3) must match the schema column count (2).\"\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>Calling the endpoint that was trained using three variables with ony two input columns:<\/p>\n\n<pre><code>{\n\"error\": {\n    \"code\": \"LibraryExecutionError\",\n    \"message\": \"Module execution encountered an internal library error.\",\n    \"details\": [\n        {\n            \"code\": \"ScoredFeaturesMustMatchTrainingFeatures\",\n            \"target\": \"Score Model (AFx Library)\",\n            \"message\": \"table: The data set being scored must contain all features used during training, missing feature(s): 'x2'.\"\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>It seems to be remembering the setup of the default endpoint and expects all other endpoints to conform to it's metadata. Is there any way around this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1480587217760,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":975,
        "Owner_creation_time":1424173539343,
        "Owner_last_access_time":1663924722033,
        "Owner_location":"Malm\u00f6, Sweden",
        "Owner_reputation":794,
        "Owner_up_votes":1478,
        "Owner_down_votes":2,
        "Owner_views":136,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40907847",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73812159,
        "Question_title":"Azure ML Endpoint error 'GradientBoostingRegressor' object has no attribute 'n_features_'",
        "Question_body":"<p>While running the endpoint testing in Azure ML, I am experiencing one error related to the reading of input data.<\/p>\n<p>Steps followed :<\/p>\n<ol>\n<li>Running Gradient boost model\n2.Train and test the data and save it in the model. pkl file<\/li>\n<li>Registering the model on azure ML and deploying the configuration with the code<\/li>\n<li>Reading score.py for the init() and run()<\/li>\n<\/ol>\n<p>Train.py code<\/p>\n<pre><code>%%writefile $script_folder\/train.py\n\nimport argparse\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import SVC\nimport joblib\nimport pickle\nfrom azureml.core import Workspace, Dataset, Experiment\nfrom azureml.core import Run\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import chi2\nimport math\nimport pickle\n#ws = Workspace.from_config()\n#az_dataset = Dataset.get_by_name(ws, 'pricing')\n\n# let user feed in 2 parameters, the location of the data files (from datastore), and the regularization rate of the logistic regression model\n#parser = argparse.ArgumentParser()\n#parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n#parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n#args = parser.parse_args()\n\ntrain_data = pd.read_csv(&quot;C:\\\\Users\\\\abhay\\\\Downloads\\\\Projects_DataScience\\\\Ensemble_Machine_Learning\\\\dataset\\\\train_update.csv&quot;)\n\ncolumn_datatypes = train_data.dtypes\ncategorical_columns = list(column_datatypes[column_datatypes==&quot;object&quot;].index.values)\ncontinuous_columns = list(column_datatypes[column_datatypes==&quot;float64&quot;].index.values)\ncontinuous_columns.remove('loss')\n\n\n\ntotal_rows = train_data.shape[0]\ncolumns_with_blanks_cat = np.random.randint(1,116,2)\ncolumns_with_blanks_cont = np.random.randint(117,130,3)\ncolumns_with_blank = np.append(columns_with_blanks_cat,columns_with_blanks_cont)\n\n#for every column insert 5 blanks at random locations\nfor col in columns_with_blank:\n    rows_with_blanks = np.random.randint(1,total_rows,5)\n    train_data.iloc[rows_with_blanks,col] = np.nan\n    \nclass Data_preprocessing:\n    def __init__(self,train_data):\n        self.train_data = train_data\n    \n    def missing_value_continuous(self,column_names_with_specific_type,imputation_type=&quot;mean&quot;): # null value imputation with mean value\n        if imputation_type==&quot;mean&quot;: # mean imputation \n            mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n            mean_imputer.fit(self.train_data[column_names_with_specific_type])\n            self.train_data[column_names_with_specific_type]=mean_imputer.transform(self.train_data[column_names_with_specific_type])\n        if imputation_type==&quot;median&quot;: # median imputation\n            median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n            median_imputer.fit(self.train_data[column_names_with_specific_type])\n            self.train_data[column_names_with_specific_type]=median_imputer.transform(self.train_data[column_names_with_specific_type])\n        return self.train_data\n    \n    def missing_value_categorical(self,column_names_with_specific_type,imputation_type=&quot;most_frequent&quot;): # check for missing categorical column values\n        most_frequent = SimpleImputer(strategy=&quot;most_frequent&quot;)\n        most_frequent.fit(self.train_data[column_names_with_specific_type])\n        self.train_data[column_names_with_specific_type] = most_frequent.transform(train_data[column_names_with_specific_type])\n        return self.train_data\n    \n    def outlier_treatment(self,Q1,Q3,IQR,columns_with_outlier,action): # outlier treatmenr\n        if action==&quot;median&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                meadian_outlier = np.median(self.train_data[column_name])\n                self.train_data.loc[self.train_data[((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))].index,column_name]=meadian_outlier\n        if action==&quot;mean&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                mean_outlier = np.mean(self.train_data[column_name])\n                self.train_data.loc[self.train_data[((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))].index,column_name]=mean_outlier\n        if action==&quot;remove&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                self.train_data = self.train_data[~((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))]\n        return self.train_data    \n    \n    \ncolumn_names = np.array(train_data.columns)\nData_preprocessing_obj = Data_preprocessing(train_data)\ntrain_data = Data_preprocessing_obj.missing_value_continuous(continuous_columns,&quot;median&quot;)\ntrain_data = Data_preprocessing_obj.missing_value_categorical(categorical_columns)\ncolumns_with_outlier = ['cont7','cont9','cont10']\nQ1 = train_data[continuous_columns].quantile(0.25)\nQ3 = train_data[continuous_columns].quantile(0.75)\nIQR = (Q3-Q1)\ntrain_data = Data_preprocessing_obj.outlier_treatment(Q1,Q3,IQR,columns_with_outlier,&quot;median&quot;)\ndef feature_selection_numerical_variables(train_data,qthreshold,corr_threshold,exclude_numerical_cols_list):\n    num_colums = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    numerical_columns = list(train_data.select_dtypes(include=num_colums).columns)\n    numerical_columns = [column for column in numerical_columns if column not in exclude_numerical_cols_list]\n    \n    #remove variables with constant variance\n    constant_filter = VarianceThreshold(threshold=0)\n    constant_filter.fit(train_data[numerical_columns])\n    constant_columns = [column for column in train_data[numerical_columns].columns \n                    if column not in train_data[numerical_columns].columns[constant_filter.get_support()]]\n    if len(constant_columns)&gt;0:\n        train_data.drop(labels=constant_columns, axis=1, inplace=True)\n\n    #remove deleted columns from dataframe\n    numerical_columns = [column for column in numerical_columns if column not in constant_columns]\n        \n    #remove variables with qconstant variance\n    #Remove quasi-constant variables\n    qconstant_filter = VarianceThreshold(threshold=qthreshold)\n    qconstant_filter.fit(train_data[numerical_columns])\n    qconstant_columns = [column for column in train_data[numerical_columns].columns \n                         if column not in train_data[numerical_columns].columns[constant_filter.get_support()]]\n    if len(qconstant_columns)&gt;0:\n        train_data.drop(labels=qconstant_columns, axis=1, inplace=True)\n    \n    #remove deleted columns from dataframe\n    numerical_columns = [column for column in numerical_columns if column not in qconstant_columns]\n    \n    #remove correlated variables\n    correlated_features = set()\n    correlation_matrix = train_data[numerical_columns].corr()\n    ax = sns.heatmap(\n    correlation_matrix, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True)\n    ax.set_xticklabels(\n        ax.get_xticklabels(),\n        rotation=45,\n        horizontalalignment='right');\n    #print(correlation_matrix)\n    \n    for i in range(len(correlation_matrix.columns)):\n        for j in range(i):\n            if abs(correlation_matrix.iloc[i, j]) &gt; corr_threshold:\n                colname = correlation_matrix.columns[i]\n                colcompared = correlation_matrix.columns[j]\n                #check if the column compared against is not in the columns excluded list\n                if colcompared not in correlated_features:\n                    correlated_features.add(colname)\n    train_data.drop(labels=correlated_features, axis=1, inplace=True)\n    \n    return train_data,constant_columns,qconstant_columns,correlated_features\ntrain_data,constant_columns,qconstant_columns,correlated_features =feature_selection_numerical_variables(train_data,0.01,0.75,['loss','id'],)\n\nfor cf1 in categorical_columns:\n    le = LabelEncoder()\n    le.fit(train_data[cf1].unique())\n    filename = cf1+&quot;.sav&quot;\n    pickle.dump(le, open(filename, 'wb'))\n    train_data[cf1] = le.transform(train_data[cf1])\n\n#snippet to calculate the unique values with a categorical columns\ndf = pd.DataFrame(columns=[&quot;Column_Name&quot;,&quot;Count&quot;])\nfor cat in categorical_columns:\n    unique_value_count = len(train_data[cat].unique())\n    df = df.append({'Column_Name': cat, &quot;Count&quot;:int(unique_value_count)}, ignore_index=True)\ncolumns_unique_value = np.array(df.Count.value_counts().index)\n\n#snippet to identify the dependent\/correlated categorical variables and drop them\ncolumns_to_drop_cat = set()\ncorrelated_columns = dict()\nfor unique_value_count in columns_unique_value:\n    if unique_value_count&gt;1:\n        categorical_columns = df.loc[df.Count==unique_value_count,'Column_Name']\n        categorical_columns = categorical_columns.reset_index(drop=True)\n        columns_length=len(categorical_columns)\n        for col in range(columns_length-1):\n            column_to_compare = categorical_columns[col]\n            columns_compare_against = categorical_columns[(col+1):columns_length]\n            chi_scores = chi2(train_data[columns_compare_against],train_data[column_to_compare])\n            if column_to_compare not in columns_to_drop_cat:\n                columns_to_be_dropped = [i for i in range(len(columns_compare_against)) if chi_scores[1][i]&lt;=0.05]\n                columns_to_drop_array = np.array(columns_compare_against)[columns_to_be_dropped]\n                correlated_columns[column_to_compare]=columns_to_drop_array\n                columns_to_drop_cat.update(columns_to_drop_array)\n                \ntrain_data = train_data.drop(columns_to_drop_cat,axis=1)\ncorrelated_features = list(correlated_features)\ncolumns_to_drop_cat = list(columns_to_drop_cat)\ncolumns_to_drop_cat.extend(correlated_features)\ncolumns_to_drop = columns_to_drop_cat.copy()\n\n#output the columns_to_drop file to a csv\ncolumns_to_drop_df=pd.DataFrame(columns_to_drop,columns=['colnames'])\n#columns_to_drop_df.to_csv(&quot;\/model\/columns_to_drop.csv&quot;,index=False)\n\ntrain_data['loss'] = np.log(train_data['loss'])\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\n#convert the int64 columns categorical\nColumn_datatypes= train_data.dtypes\nInteger_columns = list(Column_datatypes.where(lambda x: x ==&quot;int64&quot;).dropna().index.values)\ntrain_data[Integer_columns] = train_data[Integer_columns].astype('category',copy=False)\nX,y = train_data.drop(['id','loss'],axis=1),train_data['loss']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # perform train test split\n\nref_cols=X_train.columns\n\n\nfrom sklearn.ensemble import GradientBoostingRegressor  #GBM algorithm\ngbm_base = GradientBoostingRegressor(\n    max_depth=2,\n    n_estimators=3,\n    learning_rate=1.0)\n\ntrained_model=gbm_base.fit(X_train,y_train)\n\n\n\n# Predict the outcome using Test data - Score Model \nY_test_predict_tuned = gbm_base.predict(X_test)\n\n# Get the probability score - Scored Probabilities\n#Y_prob = gbm_base.predict_proba(X_test)[:, 1]\n\n# Get Confusion matrix and the accuracy\/score - Evaluate\n\nscore =np.sqrt(mean_squared_error(y_test, Y_test_predict_tuned))\n\n#print('Export the model to model.pkl')\n#f = open('fwrk2.pkl', 'wb')\n#pickle.dump(trained_model, f)\n#f.close()\n\n#print('Import the model from model.pkl')\n#f2 = open('fwrk2.pkl', 'rb')\n#clf2 = pickle.load(f2)\n\n#X_new = [[154, 54, 35]]\n#print('New Sample:', X_new)\n#print('Predicted class:', clf2.predict(X_new))\n\n#os.makedirs('outputs', exist_ok=True)\n# note file saved in the outputs folder is automatically uploaded into experiment record\n#joblib.dump(value=trained_model, filename='outputs\/fwrk2.pkl')\n<\/code><\/pre>\n<p>Reading the score.py<\/p>\n<pre><code>%%writefile score.py\nimport json\nimport numpy as np\nimport os\nimport pickle\nimport pandas as pd\nimport joblib\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    #model = joblib.load('recommender.pkl')\n    model_path = Model.get_model_path('fwrk2')\n    model = joblib.load(model_path)\n\ninput_sample = pd.DataFrame(data=[{&quot;cat1&quot;:0, &quot;cat4&quot;: 0, &quot;cat14&quot;: 0, &quot;cat15&quot;: 0, &quot;cat18&quot;: 0, &quot;cat19&quot;: 0, &quot;cat20&quot;: 0, &quot;cat21&quot;: 0\n                                   , &quot;cat22&quot;: 0, &quot;cat35&quot;: 0, &quot;cat42&quot;:0, &quot;cat47&quot;: 0, &quot;cat48&quot;: 0, &quot;cat55&quot;: 0\n                                   , &quot;cat56&quot;: 0, &quot;cat58&quot;: 0, &quot;cat59&quot;: 0, &quot;cat60&quot;: 0, &quot;cat61&quot;: 0, &quot;cat62&quot;: 0\n                                   , &quot;cat63&quot;: 0, &quot;cat64&quot;: 0, &quot;cat68&quot;: 0, &quot;cat70&quot;: 0, &quot;cat76&quot;: 0, &quot;cat77&quot;:0\n                                   , &quot;cat78&quot;: 0, &quot;cat82&quot;: 0, &quot;cat85&quot;: 0, &quot;cat86&quot;: 0, &quot;cat89&quot;: 0, &quot;cat91&quot;: 0\n                                   , &quot;cat92&quot;: 0, &quot;cat93&quot;: 0, &quot;cat94&quot;:0, &quot;cat96&quot;: 0, &quot;cat97&quot;: 0, &quot;cat99&quot;: 0\n                                   , &quot;cat100&quot;: 0, &quot;cat101&quot;: 0, &quot;cat103&quot;: 0, &quot;cat105&quot;: 0, &quot;cat107&quot;: 0, &quot;cat109&quot;:0\n                                   , &quot;cat110&quot;: 0, &quot;cat111&quot;: 0, &quot;cat112&quot;: 0, &quot;cat113&quot;: 0, &quot;cat116&quot;: 0, &quot;cont1&quot;: 0\n                                   , &quot;cont2&quot;: 0, &quot;cont3&quot;: 0, &quot;cont4&quot;: 0, &quot;cont5&quot;: 0\n                                   , &quot;cont6&quot;: 0, &quot;cont7&quot;: 0, &quot;cont8&quot;: 0, &quot;cont14&quot;: 0}])\n\noutput_sample = np.array([0])              # This is a integer type sample. Use the data type that reflects the expected result\n\n@input_schema('data', PandasParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    try:\n        result = model.predict(data)\n        # you can return any datatype as long as it is JSON-serializable\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>The endpoint publish is succeeded, and I can see the test feature on the azure portal to enter values, post entering the values.<\/p>\n<pre><code>[{&quot;cat1&quot;:0, &quot;cat4&quot;: 0, &quot;cat14&quot;: 0, &quot;cat15&quot;: 0, &quot;cat18&quot;: 0, &quot;cat19&quot;: 0, &quot;cat20&quot;: 0, &quot;cat21&quot;: 0\n                                   , &quot;cat22&quot;: 0, &quot;cat35&quot;: 0, &quot;cat42&quot;:0, &quot;cat47&quot;: 0, &quot;cat48&quot;: 0, &quot;cat55&quot;: 0\n                                   , &quot;cat56&quot;: 0, &quot;cat58&quot;: 0, &quot;cat59&quot;: 0, &quot;cat60&quot;: 0, &quot;cat61&quot;: 0, &quot;cat62&quot;: 0\n                                   , &quot;cat63&quot;: 0, &quot;cat64&quot;: 0, &quot;cat68&quot;: 0, &quot;cat70&quot;: 0, &quot;cat76&quot;: 0, &quot;cat77&quot;:0\n                                   , &quot;cat78&quot;: 0, &quot;cat82&quot;: 0, &quot;cat85&quot;: 0, &quot;cat86&quot;: 0, &quot;cat89&quot;: 0, &quot;cat91&quot;: 0\n                                   , &quot;cat92&quot;: 0, &quot;cat93&quot;: 0, &quot;cat94&quot;:0, &quot;cat96&quot;: 0, &quot;cat97&quot;: 0, &quot;cat99&quot;: 0\n                                   , &quot;cat100&quot;: 0, &quot;cat101&quot;: 0, &quot;cat103&quot;: 0, &quot;cat105&quot;: 0, &quot;cat107&quot;: 0, &quot;cat109&quot;:0\n                                   , &quot;cat110&quot;: 0, &quot;cat111&quot;: 0, &quot;cat112&quot;: 0, &quot;cat113&quot;: 0, &quot;cat116&quot;: 0, &quot;cont1&quot;: 0\n                                   , &quot;cont2&quot;: 0, &quot;cont3&quot;: 0, &quot;cont4&quot;: 0, &quot;cont5&quot;: 0\n                                   , &quot;cont6&quot;: 0, &quot;cont7&quot;: 0, &quot;cont8&quot;: 0, &quot;cont14&quot;: 0}])\n<\/code><\/pre>\n<p>Error: &quot;'GradientBoostingRegressor' object has no attribute 'n_features&quot;<\/p>\n<p>Please can someone guide what could be the problem in executing the above input sample? Is it related to the version of the package, and if yes, then how to update it and solve it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663838335573,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":21,
        "Owner_creation_time":1517472996617,
        "Owner_last_access_time":1663916153343,
        "Owner_location":"Mumbai",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73812159",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51546796,
        "Question_title":"How to Add Column (script) transform that queries another column for content",
        "Question_body":"<p>I\u2019m looking for a simple expression that puts a \u20181\u2019 in column E if \u2018SomeContent\u2019 is contained in column D.  I\u2019m doing this in Azure ML Workbench through their Add Column (script) function.  Here\u2019s some examples they give.<\/p>\n\n<pre><code>row.ColumnA + row.ColumnB is the same as row[\"ColumnA\"] + row[\"ColumnB\"] \n1 if row.ColumnA &lt; 4 else 2 \ndatetime.datetime.now() \nfloat(row.ColumnA) \/ float(row.ColumnB - 1) \n'Bad' if pd.isnull(row.ColumnA) else 'Good'\n<\/code><\/pre>\n\n<p>Any ideas on a 1 line script I could use for this?  Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1532635853827,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-workbench",
        "Question_view_count":32,
        "Owner_creation_time":1464172964160,
        "Owner_last_access_time":1633099588737,
        "Owner_location":"Brevard, NC, USA",
        "Owner_reputation":111,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51546796",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52055933,
        "Question_title":"Azure Machine Learning Studio append rows to dataset",
        "Question_body":"<p>My \"experiment\" is like this,<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/AgnGE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AgnGE.png\" alt=\"Experiment\"><\/a><\/p>\n\n<p>I have 10 rows (excluding header) in \"Dataset.csv\" and 3 rows (excluding header) in the CSV being imported by <em>Import Data<\/em>. The schema of both CSVs is same. I want <em>Add Rows<\/em> to <strong>append<\/strong> the 3 rows to Dataset.csv.<\/p>\n\n<p>The real \"Dataset.csv\" has more than 25,000 rows and is expected to grow. Hence, using <em>Export Data<\/em> to generate a merged dataset (as a new CSV) is not a feasible solution. Any way to implement <strong>append<\/strong> for this scenario?<\/p>\n\n<p>Thanks<\/p>\n\n<p>Update 1:\nDataset.csv is present in ML Studios <em>Dataset<\/em>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LBimY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LBimY.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_time":1535452910717,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|ml-studio",
        "Question_view_count":590,
        "Owner_creation_time":1409841727700,
        "Owner_last_access_time":1663859408297,
        "Owner_location":null,
        "Owner_reputation":805,
        "Owner_up_votes":599,
        "Owner_down_votes":0,
        "Owner_views":137,
        "Question_last_edit_time":1535461331150,
        "Answer_body":"<p>So it turns out the <a href=\"https:\/\/github.com\/Azure\/Azure-MachineLearning-ClientLibrary-Python\" rel=\"nofollow noreferrer\">Python SDK<\/a> has an <code>update_from_dataframe<\/code> method on it that can be used to update a dataset that has been uploaded to Azure ML Studio. If you're unable to use a new CSV and need to update an existing data set, then this should do the trick.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1535538465923,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52055933",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30068341,
        "Question_title":"How to write the results of Azure ML web service to the azure sql database (The output of Azure ML web service is in Json structure)",
        "Question_body":"<p>The results can be written to SQL Azure using the writer module in the experiment but after publishing the web service the output comes in the Json Structure and it doesn't go to the writer module <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1430890566837,
        "Question_score":0,
        "Question_tags":"azure-sql-database|azure-scheduler|azure-machine-learning-studio",
        "Question_view_count":990,
        "Owner_creation_time":1403541426413,
        "Owner_last_access_time":1592469887883,
        "Owner_location":"Bengaluru, India",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Question_last_edit_time":1431065815883,
        "Answer_body":"<p>Don't set output port and use Batch execution service - details are provided here - <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-publish-a-machine-learning-web-service\/\" rel=\"nofollow\">Publish web service<\/a> and <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">consume web service<\/a><\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1430897690130,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30068341",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57471007,
        "Question_title":"Is there way to fix CSV reading in Russian Language in Azure ML Studio?",
        "Question_body":"<p>I have a large csv file containing some text in Russian language. When I upload it to Azure ML Studio as dataset, it appears like \"\ufffd\ufffd\ufffd\ufffd\". What I can do to fix that problem?<\/p>\n\n<p>I tried changing encoding of my text to UTF8, KOI8-R.<\/p>\n\n<p>There is no code, but I can share part of the dataset for you to try.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1565669343940,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":141,
        "Owner_creation_time":1565668918750,
        "Owner_last_access_time":1566796327907,
        "Owner_location":"Nur-Sultan, Kazakhstan",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57471007",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70517166,
        "Question_title":"Azure ML Studio- Container has crashed. Did your init method fail",
        "Question_body":"<p>I am trying to deploy an ML model through the Azure ML Studio using the notebook itself. The commands we are using can be found here <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-an-inference-configuration\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-an-inference-configuration<\/a><\/p>\n<p>We have registered the model as below-<\/p>\n<pre><code>from azureml.core.model import Model\nmodel = Model.register(ws, model_name=&quot;pdmrfull&quot;, model_path=&quot;pdmrfull.model&quot;)\n<\/code><\/pre>\n<p>But while running this command-<\/p>\n<pre><code>service = Model.deploy(\n    ws,\n    &quot;myservice&quot;,\n    [&quot;pdmrfull.model&quot;],\n    dummy_inference_config,\n    deployment_config,\n    overwrite=True,\n)\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>We are getting the error that <code>container has crashed. Did your init method fail?<\/code><\/p>\n<pre><code>  File &quot;\/var\/azureml-app\/pdmscore.py&quot;, line 3, in &lt;module&gt;\n    from pyspark.ml import Pipeline\nModuleNotFoundError: No module named 'pyspark'\n<\/code><\/pre>\n<p>The <code>init<\/code> method is-<\/p>\n<pre><code>def init():\n    pipeline = PipelineModel.load('pdmrfull.model')\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1640768195997,
        "Question_score":1,
        "Question_tags":"python|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":499,
        "Owner_creation_time":1531888247987,
        "Owner_last_access_time":1663731443473,
        "Owner_location":"India",
        "Owner_reputation":981,
        "Owner_up_votes":34,
        "Owner_down_votes":11,
        "Owner_views":268,
        "Question_last_edit_time":1660803227493,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70517166",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60980937,
        "Question_title":"Recent change in create Dataset from Datastore UI?",
        "Question_body":"<p>I'm working on the new feature \"Data Drift in Azure ML\", but I had problems when I was testing this tool, the interface to create Datasets from Datastore is not like the documentation, is it different?.<\/p>\n\n<p>Also, when I try using format partition like the documentation, the configuration shows me some errors, it only works with this format <code>\/{datetime}\/filename.cvs<\/code> instead of <code>\/{timestamp:yyyy\/MM\/dd}\/filename.csv<\/code>, and the schema section doesn't display the schema like in the documentation.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_time":1585777982300,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":80,
        "Owner_creation_time":1583169309800,
        "Owner_last_access_time":1652380247513,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1587600666860,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60980937",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61225608,
        "Question_title":"Azure Machine Learning : unable to create compute instance with 12 month trial license",
        "Question_body":"<p>I am preparing for DP-100 certification.\nAs a part of self-learning, I created one trial account using my outlook email for 12 months.\nDuring the part where I needed to set up a <strong>Compute Instance<\/strong>, I encounter an error as shown below.\nWhat is the reason, Can't I create a <strong>Compute Instance<\/strong> with a trial account.<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MWsnt.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1586943598133,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":19,
        "Owner_creation_time":1586942899727,
        "Owner_last_access_time":1600269683563,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":1586944099443,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61225608",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40036956,
        "Question_title":"Increasing processing power of Azure Machine Learning workspace",
        "Question_body":"<p>Is there a way to increase the processing power of the Azure ML? I've deployed a neural network on a huge dataset (8000+ retina images, and Azure is taking an impossible amount of time to run the programme. Is it possible to deploy the ML workspace from a Virtual Machine, so that I can leverage increased processing speeds? Help!!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1476428657303,
        "Question_score":2,
        "Question_tags":"image-processing|virtual-machine|azure-machine-learning-studio|azure-dsvm",
        "Question_view_count":706,
        "Owner_creation_time":1476428113303,
        "Owner_last_access_time":1479196975893,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1510175957023,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40036956",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69755442,
        "Question_title":"Getting all existing piplines from an Azure Machine Learning Workspace",
        "Question_body":"<p>I use azure machine learning services (aml) to run a ml-model. When I go to the GUI of AML I can see all the exisiting piplines, but I can't see how they are scheduled. I need to get all puplished piplines and the belonging meta data.<\/p>\n<p>How I can get information about an existing pipline with the python sdk?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1635429379477,
        "Question_score":2,
        "Question_tags":"python|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":82,
        "Owner_creation_time":1635428968927,
        "Owner_last_access_time":1659693572257,
        "Owner_location":"Germany",
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1636156255950,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69755442",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70538937,
        "Question_title":"Pipeline of pipelines in AzureML",
        "Question_body":"<p>I'm trying to create a flow which as different experiments doing train test split, train, validate, get the best model(among 8 diff algos) and predict. The issue is I need to create a dependency of experiments and I need help in that.\nI'm aware of azure ml pipelines, but I'm looking for something where we can create a pipeline of pipelines, or something which will help me create a pipeline of multiple experiments(with dependency).<\/p>\n<p>eg for sample pipeline:\n(train-test-split)-&gt;(train[custom,Many-model])-&gt;(validate)-&gt;(getbest alogos)-&gt;(predict)\nthere will be other experiments in between for tasks like registering modls.downloading pickles etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1640924168193,
        "Question_score":2,
        "Question_tags":"python|azure|azure-pipelines|azure-machine-learning-service|ml-studio",
        "Question_view_count":98,
        "Owner_creation_time":1489047127877,
        "Owner_last_access_time":1662790654517,
        "Owner_location":"India",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70538937",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70255045,
        "Question_title":"Another Azure ML bug caused by new Compute Common Runtime",
        "Question_body":"<p>Many of my Azure ML Studio Designer pipelines began failing today.  I was able to make a minimum repro:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2mXzI.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2mXzI.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Simply excluding columns with the <code>Select Columns In Dataset<\/code> node will fail with a <code>JobConfigurationMaxSizeExceeded<\/code> error.<\/p>\n<p>This appears to be a bug introduced by Microsoft's rollout of their new Compute Common Runtime.<\/p>\n<p>If I go into any nodes failing with the <code>JobConfigurationMaxSizeExceeded<\/code> exception and manually set <code>AZUREML_COMPUTE_USE_COMMON_RUNTIME:false<\/code> in their  <code>Environment JSON<\/code> field, then they will subsequently work correctly.  This is not documented anywhere that I could find, I stumbled over this fix through trial-and-error, and I wasted many hours trying to fix our failing pipelines today.<\/p>\n<p>Does anyone know where I can find a list of possible effects of the Compute Common Runtime migration in Azure ML? I could not find any documentation on this and\/or how it might affect existing Azure ML pipelines.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1638852213613,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_time":1340833876130,
        "Owner_last_access_time":1663795160110,
        "Owner_location":null,
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70255045",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70092793,
        "Question_title":"Azure ML Studio Local Environment \u2014 Numpy package import failure using the Azure ML Python SDK",
        "Question_body":"<p>I am trying to create a local environment for the ML Studio using the Python SDK, following\n<a href=\"https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/environment\/\" rel=\"nofollow noreferrer\">this official cheatsheet<\/a>. The result should be a conda-like environment that can be used for local testing. However, I am running into an error when importing the Numpy package with the <code>add_conda_package()<\/code> method of the <code>CondaDependencies()<\/code> class. Where I've tried not specifying, as well as specifying package versions, like:\n<code>add_conda_package('numpy')<\/code> or <code>add_conda_package('numpy=1.21.2')<\/code>, but it does not seem to make a difference.<\/p>\n<p>Numpy's error message is extensive, and I've tried many of the suggestions, without success nonetheless. I'm grateful for any tips on what might resolve my issues!<\/p>\n<hr \/>\n<h2>Full code<\/h2>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n\ndef get_env() -&gt; Environment:\n    conda = CondaDependencies()\n\n    # add channels\n    conda.add_channel('defaults')\n    conda.add_channel('conda-forge')\n    conda.add_channel('pytorch')\n\n    # Python\n    conda.add_conda_package('python=3.8')\n\n    # Other conda packages\n    conda.add_conda_package('cudatoolkit=11.3')\n    conda.add_conda_package('pip')\n    conda.add_conda_package('python-dateutil')\n    conda.add_conda_package('python-dotenv')\n    conda.add_conda_package('pytorch=1.10')\n    conda.add_conda_package('torchaudio')\n    conda.add_conda_package('torchvision')\n    conda.add_conda_package('wheel')\n    conda.add_conda_package('numpy=1.21.2') # &lt;--- Error with this import \n\n    # create environment\n    env = Environment('test_env')\n    env.python.conda_dependencies = conda\n\n    return env\n<\/code><\/pre>\n<hr \/>\n<h2>Detailed error message:<\/h2>\n<p>User program failed with ImportError:<\/p>\n<p>IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!<\/p>\n<p>Importing the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.<\/p>\n<p>We have compiled some common reasons and troubleshooting tips at:<\/p>\n<pre><code>https:\/\/numpy.org\/devdocs\/user\/troubleshooting-importerror.html\n<\/code><\/pre>\n<p>Please note and check the following:<\/p>\n<ul>\n<li>The Python version is: Python3.8 from &quot;&lt;LOCAL_DIR&gt;.azureml\\envs\\azureml_&gt;\\python.exe&quot;<\/li>\n<li>The NumPy version is: &quot;1.19.1&quot;<\/li>\n<\/ul>\n<p>and make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.<\/p>\n<p>Original error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.<\/p>\n<hr \/>\n<h2>System specifications:<\/h2>\n<ul>\n<li>Local OS: Windows 10<\/li>\n<li>ML studio OS: Linux Ubuntu 18<\/li>\n<li>Python version: 3.8<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1637742407110,
        "Question_score":0,
        "Question_tags":"python|azure|numpy|azure-machine-learning-studio|azureml-python-sdk",
        "Question_view_count":135,
        "Owner_creation_time":1615216681047,
        "Owner_last_access_time":1663944623320,
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I was finally able to resolve the issue by using the pip method instead of the conda method:\n<code>add_pip_package('numpy')<\/code> instead of <code>add_conda_package('numpy')<\/code>\nI can imagine this being the reason for other packages as well.<\/p>\n<hr \/>\n<h2>Full solution<\/h2>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n\ndef get_env() -&gt; Environment:\n    conda = CondaDependencies()\n\n    # add channels\n    conda.add_channel('defaults')\n    conda.add_channel('conda-forge')\n    conda.add_channel('pytorch')\n\n    # Python\n    conda.add_conda_package('python=3.8')\n\n    # Other conda packages\n    conda.add_conda_package('cudatoolkit=11.3')\n    conda.add_conda_package('pip')\n    conda.add_conda_package('python-dateutil')\n    conda.add_conda_package('python-dotenv')\n    conda.add_conda_package('pytorch=1.10')\n    conda.add_conda_package('torchaudio')\n    conda.add_conda_package('torchvision')\n    conda.add_conda_package('wheel')\n    #conda.add_conda_package('numpy=1.21.2') # &lt;--- Error with this import \n\n    # Add pip packages\n    conda.add_pip_package('numpy') # &lt;--- Fixes import error\n\n    # create environment\n    env = Environment('test_env')\n    env.python.conda_dependencies = conda\n\n    return env\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1637743033890,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70092793",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60316009,
        "Question_title":"Authenticate With Workspace",
        "Question_body":"<p>I have a Pipeline registered in my AML workspace. Now I would like to trigger a pipeline run from an Azure Notebook in the same Workspace.\nIn order to get a reference object to the workspace in the notebook I need to authenticate, e.g. <\/p>\n\n<p><code>ws = Workspace.from_config()<\/code><\/p>\n\n<p>However, InteractiveLoginAthentication is blocked by my company's domain and MsiAuthentication throws an error as well. ServicePrincipalAuthentication works, but how do I keep the secret safe? What is the prefered way of dealing with secrets in the Azure Machine Learning Service Notebooks?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1582188630347,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azure-notebooks",
        "Question_view_count":116,
        "Owner_creation_time":1582187824717,
        "Owner_last_access_time":1618135237967,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60316009",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68939332,
        "Question_title":"No module named 'azureml' >> !pip install azureml-core >> from azureml.core import Experiment",
        "Question_body":"<p>I am facing issues with <strong>Azure ML<\/strong> when i try to install the SDK with <code>pip install azureml-core<\/code> and then <code>import azureml.core<\/code> in my script. I do not understand how can it be possible to have this error assuming that the package installation is complete and confirmed by the terminal output with:<\/p>\n<blockquote>\n<p>&quot;Requirement already satisfied: azureml-core in\nc:\\python\\python38\\lib\\site-packages&quot;<\/p>\n<\/blockquote>\n<p><em>I have installed <code>azureml-core<\/code> package with the terminal and in the script with <code>!pip install azureml-core<\/code> but still get this error...<\/em><\/p>\n<p><strong>SCRIPT:<\/strong><\/p>\n<pre><code>!pip install azureml-core\nfrom azureml.core import Experiment \nprint(azureml.core.VERSION)\n<\/code><\/pre>\n<p><strong>OUTPUT:<\/strong><\/p>\n<pre><code>      1 #CONNNECTING TO AZURE INSTANCE\n      2 get_ipython().system('pip install azureml-core')\n----&gt; 3 from azureml.core import Experiment\n      4 print(azureml.core.VERSION)\n      5 \n\nModuleNotFoundError: No module named 'azureml'\n<\/code><\/pre>\n<p>I am running the script locally with Python 3.8.10 on a Windows 10 last update and VSCode Insider.<\/p>\n<blockquote>\n<p><strong>My goal is to compute on an Azure instance without going through a remote because I would like to use my local fodlers.<\/strong><\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1R4AD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1R4AD.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1629984091987,
        "Question_score":1,
        "Question_tags":"visual-studio-code|python-3.8|azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":2454,
        "Owner_creation_time":1587724337817,
        "Owner_last_access_time":1663840945433,
        "Owner_location":null,
        "Owner_reputation":513,
        "Owner_up_votes":37,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68939332",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34320449,
        "Question_title":"Use Azure ML methods like an API",
        "Question_body":"<p>Is that possible to use machine learning methods from Microsoft Azure Machine Learning  as an API from my own code (without ML Studio) with possibility to calculate everything on their side?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1450294016510,
        "Question_score":1,
        "Question_tags":"frameworks|rapidminer|azure-machine-learning-studio",
        "Question_view_count":180,
        "Owner_creation_time":1336227824220,
        "Owner_last_access_time":1663836582560,
        "Owner_location":null,
        "Owner_reputation":834,
        "Owner_up_votes":159,
        "Owner_down_votes":2,
        "Owner_views":122,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-publish-a-machine-learning-web-service\/\" rel=\"nofollow\">publish<\/a> an experiment (machine learning functions you hooked together in Azure ML Studio) as an API. When you call that API in your custom code you give it your data and all the computation runs in the cloud in Azure ML. <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1450317613533,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34320449",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63947132,
        "Question_title":"Trouble connecting to AMLS web service on AKS using Python requests",
        "Question_body":"<p>I am having trouble contacting an AMLS web service hosted on AKS in a vnet. I am able to successfully provision AKS and deploy the models, but I am not able to access the web service using the Python requests module:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>headers = {'Content-Type':'application\/json',\n           'Authorization': 'Bearer ' + &lt;AKS_KEY&gt;}\nresp = requests.post(&lt;AKS_URI&gt;, json={&quot;data&quot;:{&quot;x&quot;: &quot;1&quot;}}, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<blockquote>\n<p>Error: HTTPConnectionPool(host='', port=80): Max retries exceeded with url: &lt;AKS_URL&gt; (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f33f6035a10&gt;: Failed to establish a new connection: [Errno 110] Connection timed out'))<\/p>\n<\/blockquote>\n<p>However, I am able to successfully connect to the web service using Postman:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>curl --location --request POST &lt;AKS_URI&gt; \\\n--header 'Authorization: Bearer &lt;AKS_KEY&gt;' \\\n--header 'Content-Type: application\/json' \\\n--data-raw '{&quot;data&quot;: {&quot;x&quot;: &quot;1&quot;}}'\n<\/code><\/pre>\n<p>If I load the AKS service in my AMLS workspace <code>aks_service.run()<\/code> also gives me the same error message. I don't have these problems when I deploy without vnet integration.<\/p>\n<p>What could be causing this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_time":1600383486567,
        "Question_score":0,
        "Question_tags":"curl|python-requests|postman|azure-aks|azure-machine-learning-service",
        "Question_view_count":76,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1600397592800,
        "Answer_body":"<p>I fixed this by adding an inbound security rule enabled for the scoring endpoint in the NSG group that controls the virtual network.<\/p>\n<p>This should be done so that the scoring endpoint can be called from outside the virtual network (see <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet\" rel=\"nofollow noreferrer\">documentation<\/a>), but apparently Postman can figure out how to access the endpoint without this security rule!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1600397953580,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63947132",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72388777,
        "Question_title":"API Key for Azure Machine Learning Endpoint",
        "Question_body":"<p>I am using Azure ML, I made my models and now I want to connect them to Data Factory to run some process.<\/p>\n<p>I implement an endpoint, but I can't find the API key for the endpoints. Right now, I have the REST endpoint, but not in key-based authentication enabled, it's false. Do you know how to generate the API key?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1653552924533,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|endpoint|azure-machine-learning-service|automl",
        "Question_view_count":206,
        "Owner_creation_time":1653552346057,
        "Owner_last_access_time":1663916267507,
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72388777",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66062015,
        "Question_title":"Executing R script from Azure function",
        "Question_body":"<p>I want to execute a R script every time an azure function is triggered. The R script executes perfectly on Azure machine learning Studio. But I am failing to execute through azure function.\nIs there any way to execute it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1612522682103,
        "Question_score":3,
        "Question_tags":"r|azure-functions|azure-machine-learning-studio",
        "Question_view_count":640,
        "Owner_creation_time":1475153705707,
        "Owner_last_access_time":1663258260290,
        "Owner_location":null,
        "Owner_reputation":79,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Question_last_edit_time":null,
        "Answer_body":"<p>AFAIK you'll have to create your own Runtime as <code>R<\/code> isn't supported natively.<\/p>\n<p>Have you already tried <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-functions\/functions-create-function-linux-custom-image?tabs=bash%2Cportal&amp;pivots=programming-language-other\" rel=\"nofollow noreferrer\">&quot;Create a function on Linux using a custom container&quot;<\/a>? Interestingly they have given <code>R<\/code> as the example of custom runtime, so hopefully that answers your question.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1612564671217,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66062015",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68959934,
        "Question_title":"Contextual version conflict error, Microsoft Azure Machine Learning Studio",
        "Question_body":"<p>I'm trying to run this 10 line .ipynb file from Google Colab in Microsoft Azure Machine Learning Studio<\/p>\n<p><a href=\"https:\/\/colab.research.google.com\/drive\/1o_-QIR8yVphfnbNZGYemyEr111CHHxSv?usp=sharing\" rel=\"nofollow noreferrer\">https:\/\/colab.research.google.com\/drive\/1o_-QIR8yVphfnbNZGYemyEr111CHHxSv?usp=sharing<\/a><\/p>\n<p>When I get to this step:<\/p>\n<pre><code>import gradio as gr\nimport tensorflow as tf\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n<\/code><\/pre>\n<p>I get this error:<\/p>\n<pre><code>ContextualVersionConflict: (Flask 1.0.3 (\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages), Requirement.parse('Flask&gt;=1.1.1'), {'gradio'})\n<\/code><\/pre>\n<p>I tried to install the Flask 1.1.1 version but I get more errors. Any idea what I should do to get past this step in Azure ML Studio?<\/p>\n<pre><code>!pip install \u2013force-reinstall Flask==1.1.1\n\/\/ More errors\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1630103458310,
        "Question_score":2,
        "Question_tags":"python|jupyter-notebook|google-colaboratory|azure-machine-learning-studio",
        "Question_view_count":237,
        "Owner_creation_time":1630103231523,
        "Owner_last_access_time":1664075236640,
        "Owner_location":null,
        "Owner_reputation":17,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1630103807137,
        "Answer_body":"<p>The issue is because <code>gradio<\/code> package using existing Flask package (version 1.0.3). But as your application required Flask&gt;=1.1.1, therefore it is showing error. You need to uninstall the existing Flask package and then install the latest required version.<\/p>\n<p>To uninstall the existing package:\n<code>!pip uninstall Flask -y<\/code><\/p>\n<p>To install latest package:\n<code>!pip install Flask&gt;=1.1.1<\/code><\/p>\n<p><strong>Then, make sure to restart your runtime to pick up the new Flask using the Runtime -&gt; Restart runtime menu.<\/strong><\/p>\n<p>Finally, import gradio.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1630303052770,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68959934",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57589238,
        "Question_title":"Tensorboard launched by Azure ML package doesn't work correctly",
        "Question_body":"<p>I want to access tfevent file created during training and stored in logs in Azure ML service. This tfevent file can be accessed and shown correctly on normal tensorboard so the file is not broken but when I use Azure ML's tensorboard library to access it, either nothing shows up on local tensorboard or get connection refused.<\/p>\n\n<p>I first logged it into .\/logs\/tensorboard like Azure ML has .\/logs\/azureml but tensorboard launched by Azure ML's module says there is no file to show like this below on the browser.<\/p>\n\n<pre><code>No dashboards are active for the current data set.\nProbable causes:\n\nYou haven\u2019t written any data to your event files.\nTensorBoard can\u2019t find your event files.\nIf you\u2019re new to using TensorBoard, and want to find out how to add data and set up your event files, check out the README and perhaps the TensorBoard tutorial.\nIf you think TensorBoard is configured properly, please see the section of the README devoted to missing data problems and consider filing an issue on GitHub.\n\nLast reload: Wed Aug 21 2019 *****\nData location: \/tmp\/tmpkfj7gswu\n<\/code><\/pre>\n\n<p>So I thought that saved location would not be recognized by AML and I changed the save location to .\/logs then browser shows that \"This site can\u2019t be reached. ****** refused to connect.\"<\/p>\n\n<p>My Azure ML Python SDK version is 1.0.57<\/p>\n\n<p>1) How can I fix this?<\/p>\n\n<p>2) Where should I save tfevent file for AML to recognize it? I couldn't find any information about it in the documentation here. \n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-tensorboard\/azureml.tensorboard.tensorboard?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-tensorboard\/azureml.tensorboard.tensorboard?view=azure-ml-py<\/a><\/p>\n\n<p>This is how I'm launching tensorboard through Azure ML.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description=f'This script is to lanuch TensorBoard with '\n        f'accessing run history from machine learning '\n        f'experiments that output Tensorboard logs')\n    parser.add_argument('--experiment-name',\n                        dest='experiment_name',\n                        type=str,\n                        help='experiment name in Azure ML')\n    parser.add_argument('--run-id',\n                        dest='run_id',\n                        type=str,\n                        help='The filename of merged json file.')\n\n    args = parser.parse_args()\n\n    logger = get_logger(__name__)\n    logger.info(f'SDK Version: {VERSION}')\n\n    workspace = get_workspace()\n    experiment_name = args.experiment_name\n    run_id = args.run_id\n    experiment = get_experiment(experiment_name, workspace, logger)\n    run = get_run(experiment, run_id)\n\n    # The Tensorboard constructor takes an array of runs, so pass it in as a single-element array here\n    tb = Tensorboard([run])\n\n    # If successful, start() returns a string with the URI of the instance.\n    url = tb.start()\n    print(url)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1566382098297,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":687,
        "Owner_creation_time":1566350007733,
        "Owner_last_access_time":1580220215467,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57589238",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66888622,
        "Question_title":"How to effectively use azureml.exceptions.WebserviceException for efficient REST API Error Management?",
        "Question_body":"<p>In Azure Machine Learning Service, when we deploy a Model as an AKS Webservice Endpoint, how can we raise exceptions to let the end-user get proper feedback if their API call is unsuccessful? Azure mentions using <code>azureml.exceptions.WebserviceException<\/code> in their <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.webserviceexception?view=azure-ml-py\" rel=\"nofollow noreferrer\">documentation<\/a>. However, how do we use this class to raise exceptions in case the API call cannot be processed properly and the end-user is responsible for it?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1617196440647,
        "Question_score":0,
        "Question_tags":"rest|azure-web-app-service|azure-machine-learning-service",
        "Question_view_count":250,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":null,
        "Answer_body":"<p>To raise exceptions to let the end-user get proper feedback if their API call is unsuccessful, we use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-services\/azureml.contrib.services.aml_response.amlresponse?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>azureml.contrib.services.aml_response.AMLResponse<\/code> Class<\/a>.<\/p>\n<p>Example of use in <code>score.py<\/code>:<\/p>\n<pre><code>if [some-condition]:    \n    return AMLResponse(&quot;bad request&quot;, 500)\n<\/code><\/pre>\n<p>Documentation Link can be found <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1617344350897,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66888622",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51622144,
        "Question_title":"scikit-learn regression prediction results are too good. What did I mess up?",
        "Question_body":"<p>We have some ML models running in Azure on top of the Azure ML Studio platform (the initial drag &amp; drop system). All has been good for over a year but we need to move on so we can scale better. So I'm working on rewriting these in Python using scikit-learn and testing them in an Jupyter notebook.<\/p>\n<p>The good news\/bad news is that our data to train on is fairly small (several hundred records in a database). It's very imperfect data making very imperfect regression predictions, so error is to be expected. And that's fine. And for this question, it's good. Because the problem is that, when I test these models, the predictions are way too perfect. I don't understand what I'm doing wrong, but I'm clearly doing <strong>something<\/strong> wrong.<\/p>\n<p>The obvious things to suspect (in my mind) are that either I'm training on the test data or there's an obvious\/perfect causation found via the correlations. My use of <code>train_test_split<\/code> tells me that I'm not training on my test data and I guarantee the second is false because of how messy this space is (we started doing manual linear regression on this data about 15 years ago, and still maintain Excel spreadsheets to be able to manually do it in a pinch, even if it's significantly less accurate than our Azure ML Studio models).<\/p>\n<p>Let's look at the code. Here's the relevant portion of my Jupyter notebook (sorry if there's a better way to format this):<\/p>\n<pre><code>X = myData\ny = myData.ValueToPredict\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    train_size = 0.75,\n    test_size = 0.25)\nprint(&quot;X_train: &quot;, X_train.shape)\nprint(&quot;y_train: &quot;, y_train.shape)\nprint(&quot;X_test:  &quot;, X_test.shape)\nprint(&quot;y_test:  &quot;, y_test.shape)\n<\/code><\/pre>\n<blockquote>\n<p>X_train:  (300, 17)<\/p>\n<p>y_train:  (300,)<\/p>\n<p>X_test:   (101, 17)<\/p>\n<p>y_test:   (101,)<\/p>\n<\/blockquote>\n<pre><code>ESTIMATORS = {\n    &quot;Extra Trees&quot;: ExtraTreesRegressor(criterion = &quot;mse&quot;,\n                                       n_estimators=10,\n                                       max_features=16,\n                                       random_state=42),\n    &quot;Decision Tree&quot;: DecisionTreeRegressor(criterion = &quot;mse&quot;,\n                                  splitter = &quot;best&quot;,\n                                       random_state=42),\n    &quot;Random Forest&quot;: RandomForestRegressor(criterion = &quot;mse&quot;,\n                                       random_state=42),\n    &quot;Linear regression&quot;: LinearRegression(),\n    &quot;Ridge&quot;: RidgeCV(),\n}\n\ny_test_predict = dict()\ny_test_rmse = dict()\nfor name, estimator in ESTIMATORS.items():\n    estimator.fit(X_train, y_train)\n    y_test_predict[name] = estimator.predict(X_test)\n    y_test_rmse[name] = np.sqrt(np.mean((y_test - y_test_predict[name]) ** 2)) # I think this might be wrong but isn't the source of my problem\nfor name, error in y_test_rmse.items():\n    print(name + &quot; RMSE: &quot; + str(error))\n<\/code><\/pre>\n<blockquote>\n<p>Extra Trees RMSE: 0.3843540838630157<\/p>\n<p>Decision Tree RMSE: 0.32838969545222946<\/p>\n<p>Random Forest RMSE: 0.4304701784728594<\/p>\n<p>Linear regression RMSE: 7.971345895791494e-15<\/p>\n<p>Ridge RMSE: 0.0001390197344951183<\/p>\n<\/blockquote>\n<pre><code>y_test_score = dict()\nfor name, estimator in ESTIMATORS.items():\n    estimator.fit(X_train, y_train)\n    y_test_predict[name] = estimator.predict(X_test)\n    y_test_score[name] = estimator.score(X_test, y_test)\nfor name, error in y_test_score.items():\n    print(name + &quot; Score: &quot; + str(error))\n<\/code><\/pre>\n<blockquote>\n<p>Extra Trees Score: 0.9990166492769291<\/p>\n<p>Decision Tree Score: 0.999282165241745<\/p>\n<p>Random Forest Score: 0.998766521504593<\/p>\n<p>Linear regression Score: 1.0<\/p>\n<p>Ridge Score: 0.9999999998713534<\/p>\n<\/blockquote>\n<p>I thought maybe I was doing the error metrics wrong, so I just looked at simple scores (which is why I included both). However, both show that these predictions are too good to be true. Keep in mind that the volume of inputs are small (~400 items in total?). And the data this is running over is essentially making predictions of a commodity consumption based on weather patterns, which is kind of a messy space to begin with, so lots of error should be present.<\/p>\n<p>What am I doing wrong here?<\/p>\n<p>(Also, if I can ask this question in a better way or provide more useful information, I'd greatly appreciate it!)<\/p>\n<hr \/>\n<p>Here is a heatmap of the data. I indicated the value we're predicting.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6wdsw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6wdsw.png\" alt=\"Seaborn heatmap of the data\" \/><\/a><\/p>\n<p>I also plotted a couple of those more important inputs vs the value we're predicting (color-coded by yet another dimension):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/kOsz3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kOsz3.png\" alt=\"A plot of values we're predicting\" \/><\/a><\/p>\n<p>Here's column #2, as asked about in comments\n<a href=\"https:\/\/i.stack.imgur.com\/R00jM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/R00jM.png\" alt=\"Another plot\" \/><\/a><\/p>\n<hr \/>\n<h1>Solution!<\/h1>\n<p>As pointed out by @jwil, I wasn't pulling my <code>ValueToPredict<\/code> column out of my <code>X<\/code> variable. The solution was a one-liner added to remove that column:<\/p>\n<pre><code>X = myData\ny = myData.ValueToPredict\nX = X.drop(&quot;ValueToPredict&quot;, 1) # &lt;--- ONE-LINE FIX!\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    train_size = 0.75,\n    test_size = 0.25)\n<\/code><\/pre>\n<p>With this in place, my error &amp; scores are much more where I expect:<\/p>\n<blockquote>\n<p>Extra Trees RMSE: 1.6170428819849574<\/p>\n<p>Decision Tree RMSE: 1.990459810552763<\/p>\n<p>Random Forest RMSE: 1.699801032532343<\/p>\n<p>Linear regression RMSE: 2.5265108241534397<\/p>\n<p>Ridge RMSE: 2.528721533965162<\/p>\n<p>Extra Trees Score: 0.9825944193611161<\/p>\n<p>Decision Tree Score: 0.9736274412836977<\/p>\n<p>Random Forest Score: 0.9807672396970707<\/p>\n<p>Linear regression Score: 0.9575098985510281<\/p>\n<p>Ridge Score: 0.9574355079097321<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_time":1533071537980,
        "Question_score":2,
        "Question_tags":"python|machine-learning|scikit-learn|azure-machine-learning-studio",
        "Question_view_count":1278,
        "Owner_creation_time":1268752315037,
        "Owner_last_access_time":1661196671610,
        "Owner_location":"Indianapolis, IN",
        "Owner_reputation":12751,
        "Owner_up_votes":980,
        "Owner_down_votes":52,
        "Owner_views":1280,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>You're right; I strongly suspect that you have one or more features in your X data that is nearly perfectly correlated with the Y data. Usually this is bad, because those variables don't explain Y but are either explained by Y or jointly determined with Y. To troubleshoot this, consider performing a linear regression of Y on X and then using simple p values or AIC\/BIC to determine which X variables are the least relevant. Drop these and repeat the process until your R^2 begins to drop seriously (though it will drop a little each time). The remaining variables will be the most relevant in prediction, and hopefully you'll be able to identify from that subset which variables are so tightly correlated with Y.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1533073081377,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51622144",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69495213,
        "Question_title":"Not able to read model.pkl from output folder in Azure ML",
        "Question_body":"<p>I'm try to read the model.pkl file from the artifacts output folder like this<\/p>\n<pre><code>def init():\n    global model\n    # infile = open('model.pkl','rb') \n    # model = pickle.load(infile)\n    #model = joblib.load('model.pkl')\n    model_path = Model.get_model_path(model_name = '&lt;&lt;modelname&gt;&gt;')\n    model_path=&quot;outputs\/model.pkl&quot;\n    # deserialize the model file back into a sklearn model\n    model = joblib.load(model_path)\n<\/code><\/pre>\n<p>But still its not working please guide me how to read model.pkl file from artifacts output folder, because of this it is failing to deploy into Azure container instance<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_time":1633692984917,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":172,
        "Owner_creation_time":1557408362973,
        "Owner_last_access_time":1663966969360,
        "Owner_location":null,
        "Owner_reputation":97,
        "Owner_up_votes":24,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69495213",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29180287,
        "Question_title":"Azure ML & Pandas: How to convert String to DateTime",
        "Question_body":"<p>I've got a dataset at hand with a column of DateTime in String format, eg.<\/p>\n\n<pre><code>a = 'Tue Sep 22 1998 00:00:00 GMT+0000 (Coordinated Universal Time)'\n<\/code><\/pre>\n\n<p>and a is just a value from the column.<\/p>\n\n<p>If I use Metadata Editor in Azure Machine Learning Studio, it won't work and will complain that it can't do the conversion (from String to DateTime). I guess it's something to do with the format. So I'm trying the following:<\/p>\n\n<pre><code>a = str(a)[:10]+','+str(a)[10:15]\n#'Tue Sep 22, 1998'\n<\/code><\/pre>\n\n<p>Now .NET surely can do the conversion, I mean by method like Convert.ToDateTime(). However, when I visualized the output of the Python script, I found the String has been changed into 'Tue Sep 22, 1998 None,', which is quite weird. Anyone knows what's wrong with it? I'm attaching the excerpt of python code down below:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n\n  dataframe1['timestamp'] = dataframe1['timestamp'].apply(lambda a: str(a)[:10]+','+str(a)[10:15])\n\n  return dataframe1,\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1426922780947,
        "Question_score":3,
        "Question_tags":"python|pandas|machine-learning|azure-machine-learning-studio",
        "Question_view_count":2509,
        "Owner_creation_time":1340282566043,
        "Owner_last_access_time":1663814648533,
        "Owner_location":null,
        "Owner_reputation":1618,
        "Owner_up_votes":1035,
        "Owner_down_votes":5,
        "Owner_views":185,
        "Question_last_edit_time":1453514644060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29180287",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46539159,
        "Question_title":"Call Azure ML Batch Job via Azure Data Factory",
        "Question_body":"<p>I have scheduled the Azure ML Batch Job via Azure Data Factory to run daily at 12:00 AM UTC.<\/p>\n\n<p>Don't know what is the issue, but it is failing for every month's 3rd day, otherwise it runs perfectly.<\/p>\n\n<p>Anybody facing same issue?<\/p>\n\n<p><strong>For September<\/strong> <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/z2sBN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/z2sBN.png\" alt=\"Error Log that display in Azure Data Factory for September\"><\/a><\/p>\n\n<p><strong>For October<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/skXoU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/skXoU.png\" alt=\"Error Log that display in Azure Data Factory for October\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/mQ1Oy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mQ1Oy.png\" alt=\"Azure ML Batch Service Job Log\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1507015266990,
        "Question_score":1,
        "Question_tags":"azure|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":150,
        "Owner_creation_time":1347281202153,
        "Owner_last_access_time":1643314917583,
        "Owner_location":"Vadodara, Gujarat, India",
        "Owner_reputation":8112,
        "Owner_up_votes":47,
        "Owner_down_votes":28,
        "Owner_views":597,
        "Question_last_edit_time":1507036866960,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46539159",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57143923,
        "Question_title":"How to combine two algorithms for predictive analysis in MS Azure",
        "Question_body":"<p>I am developing a combined-algorithm model in MS Azure Machine Learning Studio that should be able to predict whether a Telco-customer churn or not. Given that I have 19 variable features, e.g. monthly fee, usage length etc., how do I combine two useful algorithms? And how do I know these provide the highest Accuracy (Highest possible Accuracy needed), ie. which elements do I yet need to add and how should I use for predicting churn behaviour onto another dataset of a \"fresh\" set of customers? <\/p>\n\n<p>I have:\n1) Edit Metadata\nHaving excluded the User_ID variable I have used the Edit Metadata element to label the Attrition variable (Attrition is whether a customer has churned, i.e. Yes or No). Simultaneously I have transformed Attrition into a categorical variable, specifying that the selected values should be treated in two categories, i.e. Yes or No. <\/p>\n\n<p>Normalize data\nSince the three identified numerical variables (Usage_Length, Monthly_Fee and Total_Fee) a quite different in scale, e.g. Max(Monthly_Fee) is at 78,80 while Max(Total_Fee) is at 5.789,87, I have normalized Monthly_Fee and Total_Fee using the LogNormal Transformation method. <\/p>\n\n<p>Edit Metadata (2nd use)\nHaving normalized two of the numerical values, I have made all non-numerical features, e.g. User_Gender, Is_Senior etc., into categorical values to make them useful for the coming analysis. <\/p>\n\n<p>Split data\nOnce the above steps have been carried out, I have made a testing\/training split of 0.2 and 0.8, respectively on which I run the models.<\/p>\n\n<p>Choice of algorithm\nI have selected Two-class Boosed Decision Tree and Two-Class Decision Forest as they provide the highest possible individual Accuracy; 0.963 and 0.967, respectively. <\/p>\n\n<p>No coding used - only elements added. <\/p>\n\n<p>I expect the highest possible Accuracy, currently at 0.967 when combining the models into an Evaluation element<a href=\"https:\/\/i.stack.imgur.com\/HGPuI.png\" rel=\"nofollow noreferrer\">Current Model Screenshot<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":10,
        "Question_creation_time":1563790976267,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":39,
        "Owner_creation_time":1563790128347,
        "Owner_last_access_time":1565774206103,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":1563792544860,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57143923",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65044700,
        "Question_title":"Proper way to make a request to a model, deployed via Azure ML Designer",
        "Question_body":"<p>I am trying to make the POST request to the Azure ML Designer endpoint (model, I have deployed).\nHere is my code:<\/p>\n<pre><code>import requests\n\nscoring_uri = 'http:some-url\/score'\nkey = 'someKey'\n\nheaders = {'Content-Type': 'application\/json'}\nheaders['Authorization'] = f'Bearer {key}'\n\nresponse = requests.get('https:\/\/www.okino.ua\/media\/var\/news\/2019\/12\/04\/Quentin_Tarantino.jpg')\n\ninput_data = &quot;{\\&quot;data\\&quot;: [&quot; + str(response.content) + &quot;]}&quot;\nresp = requests.post(scoring_uri, data=response.content, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>And I receive and error:<\/p>\n<pre><code>{&quot;error&quot;: {&quot;code&quot;: 400, &quot;message&quot;: &quot;Input Data Error. Input data are inconsistent with schema.\\nSchema: {'WebServiceInput0': {'columnAttributes': [{'name': 'image', 'type': 'Bytes', 'isFeature': True, 'elementType': {'typeName': 'bytes', 'isNullable': False}, 'properties': {'mime_type': 'image\/png', 'image_ref': 'image_info'}}, {'name': 'id', 'type': 'Numeri\\nData: b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x00\\\\x10JFIF\\\\x00\\\\x01\\\\x01\\\\x01\\\\x01,\\\\x01,\\\\x00\\\\x00\\\\xff\\\\xfe\\\\x00[Copyright Shutterstock 2019;82139424;3600;2400;1563865756;Tue, 23 Jul 2019 07:09:16 GMT;0\\\\xff\\\\xed\\\\x04\\\\x16Photoshop 3.0\\\\x008BIM\\\\x04\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\xf9\\\\x1c\\\\x02\\\\x05\\\\x00\\\\n103\\nTraceback (most recent call last):\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 18, in run\\n    webservice_input, global_parameters = self.pre_process(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 45, in pre_process\\n    json_data = json.loads(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/json\/__init__.py\\&quot;, line 349, in loads\\n    s = s.decode(detect_encoding(s), 'surrogatepass')\\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\\n&quot;, &quot;details&quot;: &quot;&quot;}}\n\n<\/code><\/pre>\n<p>Is anyone aware of how I should pass image data to the exposed by Azure ML endpoint?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1606517768417,
        "Question_score":1,
        "Question_tags":"python|azure|computer-vision|classification|azure-machine-learning-service",
        "Question_view_count":264,
        "Owner_creation_time":1565038435857,
        "Owner_last_access_time":1606639837553,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1606785467360,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65044700",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73316652,
        "Question_title":"How to read and write a dataset using parametrized Pipeline in Azure ML",
        "Question_body":"<p>I'm new to Azure ML and trying to create a <code>parameterized Pipeline<\/code> which will read data from a datastore and after transformation, will save to a specified datastore.\nI followed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.graph.pipelineparameter?view=azure-ml-py\" rel=\"nofollow noreferrer\">PipelineParameter Class<\/a> documentation.<\/p>\n<p>Below is my code for <code>parameterized Pipeline<\/code><\/p>\n<pre><code>from azureml.core.datastore import Datastore\nfrom azureml.data import OutputFileDatasetConfig\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.core import PipelineParameter\nfrom azureml.data.datapath import DataPath, DataPathComputeBinding\n\ndefault_ds = ws.get_default_datastore()\ndefault_data_path = DataPath(datastore=default_ds, path_on_datastore=&quot;pipeline-data&quot;)\ninput_pipeline_data_param = PipelineParameter(name=&quot;raw_data&quot;, default_value=default_data_path)\ninput_pipeline_data = (input_pipeline_data_param, DataPathComputeBinding(mode='mount', overwrite=True))\n\n# output_data_path\noutput_pipeline_datapath = OutputFileDatasetConfig(name=&quot;pipeline_test&quot;,\n                                                   destination=(ws.get_default_datastore(), &quot;\/pipeline_output&quot;)).as_upload(overwrite=True)\n                              \nprep_step = PythonScriptStep(script_name=&quot;param_pipeline.py&quot;,\n                             source_directory=experiment_folder,\n                             inputs=[input_pipeline_data],\n                             outputs=[output_pipeline_datapath],\n                             compute_target = pipeline_cluster,\n                             runconfig = pipeline_run_config)\n\nprint(&quot;Pipeline steps defined&quot;)\n<\/code><\/pre>\n<p>And the python script <code>param_pipeline.py<\/code> is as followed:<\/p>\n<pre><code># Get the experiment run context\nrun = Run.get_context()\n\n# Get parameters\nparser = argparse.ArgumentParser()\nparser.add_argument(&quot;--input-dir&quot;, type=str, dest='input_dir', help='input dir')\nparser.add_argument(&quot;--output-dir&quot;, type=str, dest='output_dir', help='output dir')\nargs = parser.parse_args()\noutput_dir = args.output_dir\n\n# load the data file \nprint(&quot;Loading Data...&quot;)\ndf = run.input_datasets['raw_data'].to_pandas_dataframe()\n<\/code><\/pre>\n<p>I think the issue is bcz of how I'm passing the data in the above Pipeline &amp; accessing it using <code>run<\/code>. The reasoning behind this conclusion is I'm able to get the result with Standard pipeline code (shared below).<\/p>\n<pre><code>from azureml.data import OutputFileDatasetConfig\nfrom azureml.pipeline.steps import PythonScriptStep\n\n\n# Create an OutputFileDatasetConfig (temporary Data Reference)\npipelineOutput = OutputFileDatasetConfig(name=&quot;pipeline_test&quot;, \n                                         destination=(ws.get_default_datastore(), &quot;\/pipeline_output&quot;)).as_upload(overwrite=True)\n\n# Step 1, Run the data prep script\nprep_step = PythonScriptStep(name = &quot;Prepare Data&quot;,\n                             source_directory = experiment_folder,\n                             script_name = &quot;param_pipeline_test.py&quot;,\n                             arguments = ['--input-dir', pipeline_data.as_named_input('raw_data'),\n                                          '--output-dir', pipelineOutput],\n                             compute_target = pipeline_cluster,\n                             runconfig = pipeline_run_config,\n                             allow_reuse = True)\n\nprint(&quot;Pipeline steps defined&quot;)\n\n<\/code><\/pre>\n<p>In Standard Approach, I'm passing the input data as <code>pipeline_data.as_named_input('raw_data')<\/code> and then access it python script using <code>run.input_datasets['raw_data'].to_pandas_dataframe()<\/code> but I don't know how to achieve the same with parameterized pipeline.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1660202063943,
        "Question_score":0,
        "Question_tags":"python|azure|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":86,
        "Owner_creation_time":1532570708217,
        "Owner_last_access_time":1663943705933,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":159,
        "Owner_up_votes":45,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73316652",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70585667,
        "Question_title":"Azure ML - Model not registering, encountering WebServiceException",
        "Question_body":"<p>I've successfully registered a model with the following exact same code snippet before:<\/p>\n<pre><code>#register model\nfrom azureml.core.model import Model\n\nregister_model = Model.register(model_path = &quot;.\/models&quot;,\n                       model_name = &quot;cr_tools&quot;,\n                       description = &quot;Tools relating to the Customer Relations classifier.&quot;,\n                       workspace = ws)\n\nregister_model\n<\/code><\/pre>\n<p>But now it's not working for a different model (different <code>.\/models<\/code> directory), and I'm encountering the following error:<\/p>\n<pre><code>ServiceException: ServiceException:\n    Code: 504\n    Message: Operation returned an invalid status code 'Gateway Time-out'\n    Details:\n\n    Headers: {\n        &quot;Date&quot;: &quot;Tue, 04 Jan 2022 22:12:54 GMT&quot;,\n        &quot;Content-Type&quot;: &quot;text\/html&quot;,\n        &quot;Content-Length&quot;: &quot;160&quot;,\n        &quot;Connection&quot;: &quot;keep-alive&quot;,\n        &quot;Strict-Transport-Security&quot;: &quot;max-age=15724800; includeSubDomains; preload&quot;,\n        &quot;X-Content-Type-Options&quot;: &quot;nosniff&quot;,\n        &quot;x-request-time&quot;: &quot;60.019&quot;\n    }\n    InnerException: 504 Server Error: Gateway Time-out for url: https:\/\/eastus.experiments.azureml.net\/artifact\/v2.0\/subscriptions\/c450f3d1-583c-495f-b5d3-0b38b99e70c0\/resourceGroups\/ba-p-zeaus-group020-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/p-group020-aml-ws-001\/artifacts\/batch\/metadata\/LocalUpload\/220104T215629-7c0d42b6\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1641334481073,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":151,
        "Owner_creation_time":1513233137037,
        "Owner_last_access_time":1660060757103,
        "Owner_location":null,
        "Owner_reputation":399,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70585667",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48560183,
        "Question_title":"how to predict more multiple values in azure ml?",
        "Question_body":"<p>I am creating Azure ML experienment to predict multiple values. but in azure ml we can not train a model to predict multiple values. my question is how to bring multiple trained models in single experienment and create webout put that gives me multiple prediction.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1517479996490,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":666,
        "Owner_creation_time":1517479193607,
        "Owner_last_access_time":1525680129147,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1517995658060,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48560183",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45680457,
        "Question_title":"Is there any way to upload a file to Microsoft QnA Maker KB from visual studio?",
        "Question_body":"<p>I am trying to change the knowledge base of my QnA maker service in Microsoft QnA maker site. Is it possible to upload a file to this service from my code?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1502734142850,
        "Question_score":0,
        "Question_tags":"microsoft-cognitive|azure-machine-learning-studio|azure-language-understanding",
        "Question_view_count":1223,
        "Owner_creation_time":1502733867173,
        "Owner_last_access_time":1504074794777,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1502922984353,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45680457",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45485184,
        "Question_title":"\"Entry Point Not Found\" Error LightGBM R package in Azure",
        "Question_body":"<p>When using a LightGBM R package in Azure ML I get the following error:<\/p>\n\n<pre><code>[Error]         +++ NT HARD ERROR (0xc0000139) +++\n[Error]             Parameter 0: 0x4ad4bc8 [log2f]\n[Error]             Parameter 1: 0x4b5e2e8 [C:\\src\\lightgbm\\libs\\x64\\lib_lightgbm.dll]\n[Error]             Parameter 2: 0xffffffffc0000139\n[Error]         [FATAL] Exception: 0xc0000139 (!! HARD ERROR !!) {Params: 0x4ad4bc8, 0x4b5e2e8, 0xffffffffc0000139, 0x0}\n[Error]         [ERROR] A fatal error occurred in the running application. The application will be terminated. Code: 0xc0000139.\n<\/code><\/pre>\n\n<p>on <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/cc704588.aspx\" rel=\"nofollow noreferrer\">page<\/a> <code>0xc0000139<\/code> is described as \"Entry Point Not Found\". What does this error mean and how can I solve it?<\/p>\n\n<p>I used XGBoost in the same way in Azure ML and it worked. And it did not ask for external libraries (dlls). LightGBM on the contrary asks lots of libraries (dlls) and I think the problem is connected with the dlls, but this error does not indicate what is actually missing.<\/p>\n\n<p><strong>What I did:<\/strong> <br>Installed LightGBM R package  on a Virtual Machine with Windows Server 2016. For this I used:<\/p>\n\n<ul>\n<li>CMake<\/li>\n<li>C++ Development kit (installed almost all packages)<\/li>\n<li>RTools<\/li>\n<\/ul>\n\n<p>Included in lightgbm\\libs\\x64 are the following packages because I previously got error <code>0xc0000135<\/code> with the names of these libraries:<\/p>\n\n<ul>\n<li>msvcp140.dll<\/li>\n<li>vcomp140.dll<\/li>\n<li>vcruntime140.dll<\/li>\n<li>all api-ms-win-core-*.dll and all api-ms-win-crt-*.dll<\/li>\n<\/ul>\n\n<p>I tried to change the R version from Microsoft R Open 3.2.2 to CRAN R 3.1.0. It executes witout errors but does not execute code after library import.<\/p>\n\n<p>The full output of Azure ML R script:<\/p>\n\n<pre><code>Record Starts at UTC 08\/03\/2017 12:28:27:\n\nRun the job:\"\/dll \"LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\" \/Output0 \"..\\..\\Result Dataset\\Result Dataset.dataset\" \/Output1 \"..\\..\\R Device\\R Device.dataset\"  \/dataset1 \"..\\..\\Dataset1\\Dataset1.csv\"    \/bundlePath \"..\\..\\Script Bundle\\Script Bundle.zip\"  \/rStreamReader \"script.R\"  \/rLibVersion \"Microsoft R Open 3.2.2\"  \/ContextFile \"..\\..\\_context\\ContextFile.txt\"\"\n[Start] Program::Main\n[Start]     DataLabModuleDescriptionParser::ParseModuleDescriptionString\n[Stop]     DataLabModuleDescriptionParser::ParseModuleDescriptionString. Duration = 00:00:00.0045866\n[Start]     DllModuleMethod::DllModuleMethod\n[Stop]     DllModuleMethod::DllModuleMethod. Duration = 00:00:00.0000221\n[Start]     DllModuleMethod::Execute\n[Start]         DataLabModuleBinder::BindModuleMethod\n[Verbose]             moduleMethodDescription LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\n[Verbose]             assemblyFullName LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Start]             DataLabModuleBinder::LoadModuleAssembly\n[Verbose]                 Loaded moduleAssembly LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Stop]             DataLabModuleBinder::LoadModuleAssembly. Duration = 00:00:00.0093763\n[Verbose]             moduleTypeName Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS\n[Verbose]             moduleMethodName RunRSNR\n[Information]             Module FriendlyName : Execute R Script\n[Information]             Module Release Status : Release\n[Stop]         DataLabModuleBinder::BindModuleMethod. Duration = 00:00:00.0125213\n[Start]         ParameterArgumentBinder::InitializeParameterValues\n[Verbose]             parameterInfos count = 6\n[Verbose]             parameterInfos[0] name = dataset1 , type = Microsoft.Numerics.Data.Local.DataTable\n[Start]             DataTableCsvHandler::HandleArgumentString\n[Stop]             DataTableCsvHandler::HandleArgumentString. Duration = 00:00:00.2364734\n[Verbose]             parameterInfos[1] name = dataset2 , type = Microsoft.Numerics.Data.Local.DataTable\n[Verbose]             Set optional parameter dataset2 value to NULL\n[Verbose]             parameterInfos[2] name = bundlePath , type = System.String\n[Verbose]             parameterInfos[3] name = rStreamReader , type = System.IO.StreamReader\n[Verbose]             parameterInfos[4] name = seed , type = System.Nullable`1[System.Int32]\n[Verbose]             Set optional parameter seed value to NULL\n[Verbose]             parameterInfos[5] name = rLibVersion , type = Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS+ExecuteRScriptRVersion\n[Verbose]             Converted string 'Microsoft R Open 3.2.2' to enum of type Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS+ExecuteRScriptRVersion\n[Stop]         ParameterArgumentBinder::InitializeParameterValues. Duration = 00:00:00.3175225\n[Verbose]         Begin invoking method RunRSNR ... \n[ModuleOutput] Executing Against R 3.2.2.0\n[ModuleOutput] Executing Against R 3.2.2.0\n[Information]         Microsoft Drawbridge Console Host [Version 1.0.2108.0]\n[Error]         +++ NT HARD ERROR (0xc0000139) +++\n[Error]             Parameter 0: 0x4ad4bc8 [log2f]\n[Error]             Parameter 1: 0x4b5e2e8 [C:\\src\\lightgbm\\libs\\x64\\lib_lightgbm.dll]\n[Error]             Parameter 2: 0xffffffffc0000139\n[Error]         [FATAL] Exception: 0xc0000139 (!! HARD ERROR !!) {Params: 0x4ad4bc8, 0x4b5e2e8, 0xffffffffc0000139, 0x0}\n[Error]         [ERROR] A fatal error occurred in the running application. The application will be terminated. Code: 0xc0000139.\n[Information]         [1] 56000\n[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                            Name  Length                Date\n[Information]         1 data.table_1.10.4.zip 1487417 2017-07-07 16:48:00\n[Information]         2            lgb1.model   45142 2017-08-02 17:38:00\n[Information]         3            lgb2.model   83455 2017-08-02 17:38:00\n[Information]         4    lightgbm_2.0.4.zip 1350111 2017-08-03 14:26:00\n[Information]         5      magrittr_1.5.zip  152732 2017-07-07 15:34:00\n[Information]         6                R6.zip  317766 2017-08-03 10:33:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'magrittr' successfully unpacked and MD5 sums checked\n[Information]         package 'R6' successfully unpacked and MD5 sums checked\n[Information]         package 'data.table' successfully unpacked and MD5 sums checked\n[Information]         package 'lightgbm' successfully unpacked and MD5 sums checked\n[Information]         data.table 1.10.4\n[Information]           The fastest way to learn (by data.table authors): https:\/\/www.datacamp.com\/courses\/data-analysis-the-data-table-way\n[Information]           Documentation: ?data.table, example(data.table) and browseVignettes(\"data.table\")\n[Information]           Release notes, videos and slides: http:\/\/r-datatable.com\n[Error]         Process returned with non-zero exit code -1073741511\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:14.8676292\n[Critical]     Error: Error 1000: RPackage library exception: Attempting to obtain R output before invoking execution process\n[Critical]     {\"InputParameters\":{\"DataTable\":[{\"Rows\":50,\"Columns\":131,\"estimatedSize\":16928768,...........\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 1000: RPackage library exception: Attempting to obtain R output before invoking execution process ---&gt; Microsoft.Analytics.Modules.R.ErrorHandling.RInvalidOperationException: Attempting to obtain R output before invoking execution process\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.NewRWorker.GetProcessOutputs(Boolean scrub) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\TempWorkers\\\\NewRWorker.cs:line 459\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.ExecuteR(NewRWorker worker, DataTable dataset1, DataTable dataset2, IEnumerable`1 bundlePath, StreamReader rStreamReader, Nullable`1 seed) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 278\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS._RunImpl(NewRWorker worker, DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptExternalResource source, String url, ExecuteRScriptGitHubRepositoryType githubRepoType, SecureString accountToken) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 207\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.RunRSNR(DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptRVersion rLibVersion) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\REntryPoint.cs:line 105\\r\\n   --- End of inner exception stack trace ---\",\"Warnings\":[],\"Duration\":\"00:00:14.8605990\"}\nModule finished after a runtime of 00:00:15.3186157 with exit code -2\nModule failed due to negative exit code of -2\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1501765744790,
        "Question_score":0,
        "Question_tags":"c++|r|azure|dll|azure-machine-learning-studio",
        "Question_view_count":245,
        "Owner_creation_time":1399036511573,
        "Owner_last_access_time":1663941160840,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":2853,
        "Owner_up_votes":1981,
        "Owner_down_votes":6,
        "Owner_views":228,
        "Question_last_edit_time":1501769547343,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45485184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73234673,
        "Question_title":"Trying to work on R using Azure ML Studio Notebook and facing challenges with ODBC package",
        "Question_body":"<p>I am trying to work on R notebook on ML Studio. Using regular python is easy and works as expected but with R i am facing challenges.<\/p>\n<p>While trying to connect to MS SQL database using odbc() :<\/p>\n<pre><code>library(odbc)\ncon &lt;- dbConnect(odbc(),\n                 Driver = &quot;SQL Server&quot;,\n                 Server = &quot;server&quot;,\n                 Database = &quot;db&quot;,\n                 UID = &quot;user&quot;,\n                 PWD = &quot;password&quot;,\n                 Port = 1433)\n\n\n\nError: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found\n<\/code><\/pre>\n<p>As suggested in some posts, i have also tried replacing  Driver = &quot;SQL Server&quot;, with Driver = &quot;ODBC Driver 11 for SQL Server&quot;. But i see similar error<\/p>\n<pre><code>Error: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 11 for SQL Server' : file not found \nTraceback:\n<\/code><\/pre>\n<p>Please suggest a work around.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1659610475930,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-service",
        "Question_view_count":52,
        "Owner_creation_time":1496406450497,
        "Owner_last_access_time":1663656501120,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73234673",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62343056,
        "Question_title":"How to log a confusion matrix to azureml platform using python",
        "Question_body":"<p>Hello Stackoverflowers,<\/p>\n\n<p>I'm using azureml and I'm wondering if it is possible to log a confusion matrix of the xgboost model I'm training, together with the other metrics I'm already logging. Here's a sample of the code I'm using:<\/p>\n\n<pre><code>from azureml.core.model import Model\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nimport json\n\nwith open('.\/azureml.config', 'r') as f:\n    config = json.load(f)\n\nsvc_pr = ServicePrincipalAuthentication(\n   tenant_id=config['tenant_id'],\n   service_principal_id=config['svc_pr_id'],\n   service_principal_password=config['svc_pr_password'])\n\n\nws = Workspace(workspace_name=config['workspace_name'],\n                        subscription_id=config['subscription_id'],\n                        resource_group=config['resource_group'],\n                        auth=svc_pr)\n\ny_pred = model.predict(dtest)\n\nacc = metrics.accuracy_score(y_test, (y_pred&gt;.5).astype(int))\nrun.log(\"accuracy\",  acc)\nf1 = metrics.f1_score(y_test, (y_pred&gt;.5).astype(int), average='binary')\nrun.log(\"f1 score\",  f1)\n\n\ncmtx = metrics.confusion_matrix(y_test,(y_pred&gt;.5).astype(int))\nrun.log_confusion_matrix('Confusion matrix', cmtx)\n<\/code><\/pre>\n\n<p>The above code raises this kind of error:<\/p>\n\n<pre><code>TypeError: Object of type ndarray is not JSON serializable\n<\/code><\/pre>\n\n<p>I already tried to transform the matrix in a simpler one, but another error occurred as before I logged a \"manual\" version of it (<code>cmtx = [[30000, 50],[40, 2000]]<\/code>).<\/p>\n\n<pre><code>run.log_confusion_matrix('Confusion matrix', [list([int(y) for y in x]) for x in cmtx])\n\nAzureMLException: AzureMLException:\n    Message: UserError: Resource Conflict: ArtifactId ExperimentRun\/dcid.3196bf92-4952-4850-9a8a-    c5103b205379\/Confusion matrix already exists.\n    InnerException None\n    ErrorResponse \n{\n    \"error\": {\n        \"message\": \"UserError: Resource Conflict: ArtifactId ExperimentRun\/dcid.3196bf92-4952-4850-9a8a-c5103b205379\/Confusion matrix already exists.\"\n    }\n}\n<\/code><\/pre>\n\n<p>This makes me think that I'm not properly handling the command <code>run.log_confusion_matrix()<\/code>. So, again, which is the best way I can log a confusion matrix to my azureml experiments?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1591960207257,
        "Question_score":3,
        "Question_tags":"python|azure|xgboost|confusion-matrix|azure-machine-learning-service",
        "Question_view_count":1418,
        "Owner_creation_time":1506516283190,
        "Owner_last_access_time":1663256383867,
        "Owner_location":"Torino, TO, Italia",
        "Owner_reputation":875,
        "Owner_up_votes":28,
        "Owner_down_votes":3,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I eventually found a solution thanks to colleague of mine. I'm hence answering myself, in order to close the question and, maybe, help somebody else.<\/p>\n<p>You can find the proper function in this link: <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#log-confusion-matrix-name--value--description----\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#log-confusion-matrix-name--value--description----<\/a>.<\/p>\n<p>Anyway, you also have to consider that, apparently, Azure doesn't work with the standard confusion matrix format returned by sklearn. It accepts indeed ONLY list of list, instead of numpy array, populated with numpy.int64 elements. So you also have to transform the matrix in a simpler format (for the sake of simplicity I used the nested list comprehension in the command below:<\/p>\n<pre><code>cmtx = metrics.confusion_matrix(y_test,(y_pred&gt;.5).astype(int))\ncmtx = {\n\n&quot;schema_type&quot;: &quot;confusion_matrix&quot;,\n&quot;parameters&quot;: params,\n &quot;data&quot;: {&quot;class_labels&quot;: [&quot;0&quot;, &quot;1&quot;],\n          &quot;matrix&quot;: [[int(y) for y in x] for x in cmtx]}\n}\nrun.log_confusion_matrix('Confusion matrix - error rate', cmtx)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1593519812260,
        "Answer_score":6.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62343056",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60202243,
        "Question_title":"Read\/Mount a csv file inside train.py of Azure ML Pipeline",
        "Question_body":"<p>We are collecting data from Eventhub and AppInsight and storing it in azure blob. By using AzureML pipeline I want to pass my dataset into train.py going through two different logics(one for ml, another for fraud analysis).<\/p>\n\n<p>But I couldnt read the csv file for further processing from inside the <code>train.py<\/code> <\/p>\n\n<p>This is my <code>train.py<\/code> which is running through <code>PythonScriptStep<\/code> in Azure Machine Learning Pipeline<\/p>\n\n<pre><code>import argparse\nimport os\nimport pandas as pd\n\nprint(\"In train.py\")\n\nparser = argparse.ArgumentParser(\"train\")\n\nparser.add_argument(\"--input_data\", type=str, help=\"input data\")\nparser.add_argument(\"--output_train\", type=str, help=\"output_train directory\")\n\nargs = parser.parse_args()\n\nprint(\"Argument 1: %s\" % args.input_data)\ndf = pd.read_csv(args.input_data)\nprint(df.head())\n\nprint(\"Argument 2: %s\" % args.output_train)\n\nif not (args.output_train is None):\n    os.makedirs(args.output_train, exist_ok=True)\n    print(\"%s created\" % args.output_train)\n<\/code><\/pre>\n\n<p>And this is the code for running the Pipeline<\/p>\n\n<pre><code>ws = Workspace.from_config()\ndef_blob_store = Datastore(ws, \"basic_data_store\")\naml_compute_target = \"test-cluster\"\ntry:\n    aml_compute = AmlCompute(ws, aml_compute_target)\n    print(\"found existing compute target.\")\nexcept ComputeTargetException:\n    print(\"Error\")\n\nsource_directory = '.\/train'\n\nblob_input_data = DataReference(\n    datastore=def_blob_store,\n    data_reference_name=\"device_data\",\n    path_on_datastore=\"_fraud_data\/test.csv\")\ntrainStep = PythonScriptStep(\n    script_name=\"train.py\", \n    arguments=[\"--input_data\", blob_input_data, \"--output_train\", processed_data1],\n    inputs=[blob_input_data],\n    outputs=[processed_data1],\n    compute_target=aml_compute, \n    source_directory=source_directory,\n    runconfig=run_config\n)\npipeline1 = Pipeline(workspace=ws, steps=[compareStep])\npipeline_run1 = Experiment(ws, 'Data_dependency').submit(pipeline1)\n<\/code><\/pre>\n\n<p>Down below in the output trace, you can see the output <code>Argument 1<\/code> is printing the path of the file<\/p>\n\n<p><code>Argument 1: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv<\/code><\/p>\n\n<p>So I have successfully pass the dataset but cant read the file inside train.py on line <code>pd.read_csv(args.input_data)<\/code>.  It is showing <\/p>\n\n<p><code>FileNotFoundError: [Errno 2] File b'\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv'<\/code> <\/p>\n\n<p>this is the full trace from <code>70_driver_log.txt<\/code> which I have downloaded from azureml log,<\/p>\n\n<pre><code>Preparing to call script [ train.py ] with arguments: ['--input_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv', '--output_train', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/processed_data1']\nAfter variable expansion, calling script [ train.py ] with arguments: ['--input_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv', '--output_train', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/processed_data1']\n\nIn train.py\nArgument 1: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv\n\n\nThe experiment failed. Finalizing run...\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.001172780990600586 seconds\nStarting the daemon thread to refresh tokens in background for process with pid = 136\nTraceback (most recent call last):\n  File \"train.py\", line 18, in &lt;module&gt;\n    df = pd.read_csv(args.input_data) #str()\n  File \"\/azureml-envs\/azureml_eb042e80b9a6abdb5821a78683153a38\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 685, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"\/azureml-envs\/azureml_eb042e80b9a6abdb5821a78683153a38\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 457, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"\/azureml-envs\/azureml_eb042e80b9a6abdb5821a78683153a38\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 895, in __init__\n    self._make_engine(self.engine)\n  File \"\/azureml-envs\/azureml_eb042e80b9a6abdb5821a78683153a38\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 1135, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"\/azureml-envs\/azureml_eb042e80b9a6abdb5821a78683153a38\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 1917, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas\/_libs\/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas\/_libs\/parsers.pyx\", line 689, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] File b'\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv' does not exist: b'\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline-shohoz\/azureml\/d92be2ab-e63f-4883-a14b-a64fa5bb431d\/mounts\/basic_data_store\/_fraud_data\/test.csv'\n<\/code><\/pre>\n\n<p>I have tried the relative path <\/p>\n\n<p><code>azureml\/8d2b7bee-6cc5-4c8c-a685-1300a240de8f\/mounts\/basic_data_store\/_fraud_data\/test.csv<\/code> <\/p>\n\n<p>and also the Uri <\/p>\n\n<p><code>wasbs:\/\/shohoz-container@shohozds.blob.core.windows.net\/azureml\/azureml\/8d2b7bee-6cc5-4c8c-a685-1300a240de8f\/mounts\/basic_data_store\/_fraud_data\/test.csv<\/code><\/p>\n\n<p>but ending with the same <code>FileNotFoundError<\/code> result. I am banging my head on the wall for last 3-4 days. Any help will save my brain.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1581577721350,
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":1072,
        "Owner_creation_time":1337959444690,
        "Owner_last_access_time":1663815843037,
        "Owner_location":"Dhaka, Dhaka Division, Bangladesh",
        "Owner_reputation":6262,
        "Owner_up_votes":68,
        "Owner_down_votes":6,
        "Owner_views":988,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60202243",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65343319,
        "Question_title":"Azure Wide and Deep Recommender real inference pipeline error - Invalid graph: You have required input port(s) unconnected",
        "Question_body":"<p>It seems like there is bug in create real-time endpoints for &quot;Wide &amp; Deep Recommender&quot; module at least with the sample workflow.  I kept getting &quot;Invalid graph: You have requested input port(s) unconnected&quot;.  Does anyone know how to get around this issue?<\/p>\n<p>Repro Steps:<\/p>\n<ol>\n<li><p>Go to Azure ML -&gt; Designer -&gt; &quot;Wide &amp; Deep based Recommendation - Restaurant&quot;\n<a href=\"https:\/\/i.stack.imgur.com\/QMT42.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QMT42.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Train the model -&gt; Create &quot;Real-time inference pipeline&quot; -&gt; in Real-time inference pipeline, click &quot;Submit&quot; -&gt; Error occurs<\/p>\n<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/QmyJi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QmyJi.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1608217771983,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":134,
        "Owner_creation_time":1446232229117,
        "Owner_last_access_time":1641407543500,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65343319",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60638587,
        "Question_title":"How to get insights in exceptions and logging of AzureML endpoint deployment",
        "Question_body":"<p>Because of a faulty score.py file in my InferenceConfig, a Model.Deploy failed to Azure Machine Learning, using ACI.  I wanted to create the endpoint in the cloud, but the only state I can see in the portal is Unhealthy.  My local script to deploy the model (using ) keeps running, until it times out. (using the <code>service.wait_for_deployment(show_output=True)<\/code>statement).<\/p>\n\n<p>Is there an option to get more insights in the actual reason\/error message of the deployment turning \"Unhealthy\"?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1583937572180,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":364,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":1584215688010,
        "Answer_body":"<p>Usually the timeout is caused by an error in init() function in scoring script. You can get the detailed logs using <code>print(service.get_logs())<\/code> to find the Python error.<\/p>\n\n<p>For more comprehensive troubleshooting guide, see:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1584133364177,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60638587",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44000208,
        "Question_title":"Azure ML - How to retrain a model (classic web service)",
        "Question_body":"<p>I followed this guide to retrain a model (Guide: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-retrain-a-classic-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-retrain-a-classic-web-service<\/a>)<\/p>\n\n<p>Still there are some questions left. So before retraining a model, do I have to upload the new dataset into my  blob container storage ? If yes how do I do that via http ?<\/p>\n\n<p>Maybe is it possible to send the new dataset via the PATCH-call in the http body?<\/p>\n\n<p>Thanks in Advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1494934026127,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":537,
        "Owner_creation_time":1467130084653,
        "Owner_last_access_time":1663925192090,
        "Owner_location":null,
        "Owner_reputation":915,
        "Owner_up_votes":19,
        "Owner_down_votes":1,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44000208",
        "Question_exclusive_tag":"Azure Machine Learning"
    }
]