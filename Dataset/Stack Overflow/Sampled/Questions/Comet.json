[
    {
        "Question_id":61642549,
        "Question_title":"How to disable crash output in comet ml?",
        "Question_body":"<p>Every time my script is crashing I have such output:<\/p>\n\n<pre><code>COMET INFO:     sys.cpu.percent.43       : (0.0, 0.0)\nCOMET INFO:     sys.cpu.percent.44       : (1.8, 1.8)\nCOMET INFO:     sys.cpu.percent.avg      : (6.579545454545454, 6.579545454545454)\nCOMET INFO:     sys.gpu.0.free_memory    : (34089664512.0, 34089664512.0)\nCOMET INFO:     sys.gpu.0.gpu_utilization: (0.0, 0.0)\nCOMET INFO:     sys.gpu.0.total_memory   : (34089730048.0, 34089730048.0)\nCOMET INFO:     sys.gpu.0.used_memory    : (65536.0, 65536.0)\nCOMET INFO:     sys.load.avg             : (39.42, 39.42)\nCOMET INFO:     sys.ram.total            : (1621711745024.0, 1621711745024.0)\nCOMET INFO:     sys.ram.used             : (78552326144.0, 78552326144.0)\nCOMET INFO:   Other [count]:\nCOMET INFO:     offline_experiment: True\n<\/code><\/pre>\n\n<p>How can I disable it?<\/p>\n\n<p>In comet-ml docs I found but probably it's not what I look for:<\/p>\n\n<blockquote>\n  <p>by setting the environmental variable COMET_DISABLE_AUTO_LOGGING to 1<\/p>\n<\/blockquote>\n\n<pre><code>$ export COMET_DISABLE_AUTO_LOGGING=1                                                                                             \n$ echo $COMET_DISABLE_AUTO_LOGGING \n1\n<\/code><\/pre>\n\n<p>But it didn't help me.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1588789562853,
        "Question_score":1,
        "Question_tags":"python|pytorch|comet|comet-ml",
        "Question_view_count":94,
        "Owner_creation_time":1446931610417,
        "Owner_last_access_time":1662985332847,
        "Owner_location":"Moscow, \u0420\u043e\u0441\u0441\u0438\u044f",
        "Owner_reputation":7659,
        "Owner_up_votes":395,
        "Owner_down_votes":3,
        "Owner_views":776,
        "Question_last_edit_time":1588796193240,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61642549",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":56881430,
        "Question_title":"Is it possible to visualize gradients in comet-ml?",
        "Question_body":"<p>It is straightforward to set up TensorBoard in Keras (it's just a <a href=\"https:\/\/keras.io\/callbacks\/#tensorboard\" rel=\"noreferrer\">callback<\/a>!) and then it is possible to visualize the distribution and magnitude of the weights and gradients. Is it possible to do the same with <a href=\"https:\/\/www.comet.ml\" rel=\"noreferrer\">comet.ml<\/a>? Comet.ml is easy to set up, but visualizes only the loss and accuracy evolution... Is there a way to \"restore\" all the TensorBoard features in comet.ml?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_time":1562219704473,
        "Question_score":6,
        "Question_tags":"python-3.x|tensorflow|keras|tf.keras|comet-ml",
        "Question_view_count":117,
        "Owner_creation_time":1557443756590,
        "Owner_last_access_time":1664031547383,
        "Owner_location":null,
        "Owner_reputation":606,
        "Owner_up_votes":589,
        "Owner_down_votes":211,
        "Owner_views":91,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56881430",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":69642600,
        "Question_title":"Conda UnsatisfiableError of glibc when trying to install Comet ML 3.18 in Dockerfile",
        "Question_body":"<p>I'm trying to install Comet ML version <code>3.18<\/code> in a Dockerfile using Anaconda but the build fails with the following error:<\/p>\n<pre><code>Found conflicts! Looking for incompatible packages.\nThis can take several minutes.  Press CTRL-C to abort.\nfailed\n\nUnsatisfiableError: The following specifications were found to be incompatible with each other:\n\nOutput in format: Requested package -&gt; Available versionsThe following specifications were found to be incompatible with your system:\n\n  - feature:\/linux-64::__glibc==2.31=0\n  - python=3.8 -&gt; libgcc-ng[version='&gt;=7.5.0'] -&gt; __glibc[version='&gt;=2.17']\n\nYour installed version is: 2.31\n<\/code><\/pre>\n<p>Isn't my installed version exactly what is needed according to these lines?! I've googled this issue over and over again but couldn't find a solution that's why I'm now asking it here. Sorry if this is a duplicate but it's driving me nuts! (Had a similar issue trying to install Comet ML on the cluster directly using Anaconda - without Docker - and there the error was with <code>glibc 2.17<\/code>.)<\/p>\n<p>Any help is appreciated!<\/p>\n<hr \/>\n<p>Here's the <strong>full Dockerfile<\/strong>:<\/p>\n<pre><code>FROM continuumio\/anaconda3:latest\n\nRUN conda install -c comet_ml comet_ml=3.18 -y\n\nENTRYPOINT [ &quot;\/bin\/bash&quot; ]\n<\/code><\/pre>\n<p>I also have a version where I install Anaconda manually in Ubuntu 20.04 but it throws the same error and I thought a more concise Dockerfile would be nicer.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_time":1634718135840,
        "Question_score":1,
        "Question_tags":"python|docker|glibc|anaconda3|comet-ml",
        "Question_view_count":499,
        "Owner_creation_time":1389012600070,
        "Owner_last_access_time":1663689374297,
        "Owner_location":"Berlin, Germany",
        "Owner_reputation":3054,
        "Owner_up_votes":299,
        "Owner_down_votes":4,
        "Owner_views":487,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69642600",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":47855236,
        "Question_title":"How to configure comet (comet.ml) to create pull requests on GitHub?",
        "Question_body":"<p>Ive followed this this to link my comet.ml project to GitHub - <a href=\"https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/blob\/master\/github-pullrequest\/README.md\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n\n<p>and had some models already trained (using keras)in my project<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/L44Bi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/L44Bi.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Ive linked my GitHub account and when creating a pull request I get error <\/p>\n\n<p><strong>Cant create pull request<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/zlkYy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zlkYy.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>please advise<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1513514834923,
        "Question_score":1,
        "Question_tags":"github|keras|comet-ml",
        "Question_view_count":73,
        "Owner_creation_time":1389089640833,
        "Owner_last_access_time":1513514332643,
        "Owner_location":null,
        "Owner_reputation":303,
        "Owner_up_votes":35,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47855236",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":60839122,
        "Question_title":"ModuleNotFoundError: No module named 'comet_ml'",
        "Question_body":"<p>I am working in a conda environment. If i do<\/p>\n\n<p>(pytorch_env)  sudo pip3 freeze | grep comet<\/p>\n\n<p>I get<\/p>\n\n<p>comet-git-pure==0.19.15\ncomet-ml==3.1.3<\/p>\n\n<p>But on running the python file I get<\/p>\n\n<p>pytorch_env) ubuntu@ Traceback (most recent call last):\n  File \"vgg_11.py\", line 5, in \n    from comet_ml import Experiment \nModuleNotFoundError: No module named 'comet_ml'<\/p>\n\n<p>The code is just this <\/p>\n\n<pre><code>from comet_ml import Experiment\nfrom comet_ml.utils import ConfusionMatrix\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1585083094440,
        "Question_score":1,
        "Question_tags":"python-3.x|comet-ml",
        "Question_view_count":507,
        "Owner_creation_time":1458546810273,
        "Owner_last_access_time":1655861032703,
        "Owner_location":null,
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":1585083746283,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60839122",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":46368389,
        "Question_title":"How to configure comet (comet.ml) to log Tensorflow?",
        "Question_body":"<p>Im trying to set comet (<a href=\"https:\/\/www.comet.ml\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml<\/a>) to track my Tensorflow experiment, after I create an Experiment and log the data set i dont get the accuracy in my report.<\/p>\n\n<p>my code:<\/p>\n\n<pre><code>mnist = get_data()\ntrain_step, cross_entropy, accuracy, x, y, y_ = build_model_graph(hyper_params)\n\nexperiment = Experiment(api_key=\"XXXX\", log_code=True)\nexperiment.log_multiple_params(hyper_params)\nexperiment.log_dataset_hash(mnist)\n<\/code><\/pre>\n\n<p>in the example account : <a href=\"https:\/\/www.comet.ml\/view\/Jon-Snow\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml\/view\/Jon-Snow<\/a> I see that accuracy is reported<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1506094686057,
        "Question_score":3,
        "Question_tags":"tensorflow|machine-learning|comet-ml",
        "Question_view_count":338,
        "Owner_creation_time":1506066897167,
        "Owner_last_access_time":1506108624433,
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1514341154200,
        "Answer_body":"<p>you can report accuracy using this method:<\/p>\n\n<ul>\n<li><code>experiment.log_accuracy(train_accuracy)<\/code><\/li>\n<\/ul>\n\n<p>take a look at the full Tensorflow example in our guide:<\/p>\n\n<ul>\n<li><a href=\"https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow\" rel=\"nofollow noreferrer\">https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1506100257933,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1513514205487,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46368389",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":61239274,
        "Question_title":"Google Colab freezes my browser and pc when trying to reconnect to a notebook",
        "Question_body":"<p>I am training a Machine learning model in google colab, to be more specific I am training a GAN with PyTorch-lightning. The problem occurs is when I get disconnected from my current runtime due to inactivity. When I try to reconnect my Browser(tried on firefox and chrome) becomes first laggy and than freezes, my pc starts to lag so that I am not able to close my browser and it doesn't go away. I am forced to press the power button of my PC in order to restart the PC.\nI have no clue why this happens.\nI tried various batch sizes(also the size 1) but it still happens. It can't be that my dataset is too big either(since i tried it on a dataset with 10images for testing puposes).\nI hope someone can help me.<\/p>\n\n<p>Here is my code (For using the code you will need comet.nl and enter the comet.ml api key):<\/p>\n\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision  \nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\n\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nimport pytorch_lightning as pl\nfrom pytorch_lightning import loggers\n\nimport numpy as np\nfrom numpy.random import choice\n\nfrom PIL import Image\n\nimport os\nfrom pathlib import Path\nimport shutil\n\nfrom collections import OrderedDict\n\n# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\n# randomly flip some labels\ndef noisy_labels(y, p_flip=0.05):  # # flip labels with 5% probability\n    # determine the number of labels to flip\n    n_select = int(p_flip * y.shape[0])\n    # choose labels to flip\n    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n    # invert the labels in place\n    y[flip_ix] = 1 - y[flip_ix]\n    return y\n\nclass AddGaussianNoise(object):\n    def __init__(self, mean=0.0, std=0.1):\n        self.std = std\n        self.mean = mean\n\n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\ndef get_valid_labels(img):\n  return (0.8 - 1.1) * torch.rand(img.shape[0], 1, 1, 1) + 1.1  # soft labels\n\ndef get_unvalid_labels(img):\n  return noisy_labels((0.0 - 0.3) * torch.rand(img.shape[0], 1, 1, 1) + 0.3)  # soft labels\n\nclass Generator(nn.Module):\n    def __init__(self, ngf, nc, latent_dim):\n        super(Generator, self).__init__()\n        self.ngf = ngf\n        self.latent_dim = latent_dim\n        self.nc = nc\n\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n             nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\nclass Discriminator(nn.Module):\n    def __init__(self, ndf, nc):\n        super(Discriminator, self).__init__()\n        self.nc = nc\n        self.ndf = ndf\n\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\nclass DCGAN(pl.LightningModule):\n\n    def __init__(self, hparams, logger, checkpoint_folder, experiment_name):\n        super().__init__()\n        self.hparams = hparams\n        self.logger = logger  # only compatible with comet_logger at the moment\n        self.checkpoint_folder = checkpoint_folder\n        self.experiment_name = experiment_name\n\n        # networks\n        self.generator = Generator(ngf=hparams.ngf, nc=hparams.nc, latent_dim=hparams.latent_dim)\n        self.discriminator = Discriminator(ndf=hparams.ndf, nc=hparams.nc)\n        self.generator.apply(weights_init)\n        self.discriminator.apply(weights_init)\n\n        # cache for generated images\n        self.generated_imgs = None\n        self.last_imgs = None\n\n        # For experience replay\n        self.exp_replay_dis = torch.tensor([])\n\n        # creating checkpoint folder\n        dirpath = Path(self.checkpoint_folder)\n        if not dirpath.exists():\n          os.makedirs(dirpath, 0o755)\n\n    def forward(self, z):\n        return self.generator(z)\n\n    def adversarial_loss(self, y_hat, y):\n        return F.binary_cross_entropy(y_hat, y)\n\n    def training_step(self, batch, batch_nb, optimizer_idx):\n        # For adding Instance noise for more visit: https:\/\/www.inference.vc\/instance-noise-a-trick-for-stabilising-gan-training\/\n        std_gaussian = max(0, self.hparams.level_of_noise - ((self.hparams.level_of_noise * 1.5) * (self.current_epoch \/ self.hparams.epochs)))\n        AddGaussianNoiseInst = AddGaussianNoise(std=std_gaussian) # the noise decays over time\n\n        imgs, _ = batch\n        imgs = AddGaussianNoiseInst(imgs) # Adding instance noise to real images\n        self.last_imgs = imgs\n\n        # train generator\n        if optimizer_idx == 0:\n            # sample noise\n            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1)\n\n            # generate images\n            self.generated_imgs = self(z)\n            self.generated_imgs = AddGaussianNoiseInst(self.generated_imgs) # Adding instance noise to fake images\n\n            # Experience replay\n            # for discriminator\n            perm = torch.randperm(self.generated_imgs.size(0))  # Shuffeling\n            r_idx = perm[:max(1, self.hparams.experience_save_per_batch)]  # Getting the index\n            self.exp_replay_dis = torch.cat((self.exp_replay_dis, self.generated_imgs[r_idx]), 0).detach()  # Add our new example to the replay buffer\n\n            # ground truth result (ie: all fake)\n            g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs), get_valid_labels(self.generated_imgs)) # adversarial loss is binary cross-entropy\n\n            tqdm_dict = {'g_loss': g_loss}\n            log = {'g_loss': g_loss, \"std_gaussian\": std_gaussian}\n            output = OrderedDict({\n                'loss': g_loss,\n                'progress_bar': tqdm_dict,\n                'log': log\n            })\n            return output\n\n        # train discriminator\n        if optimizer_idx == 1:\n            # Measure discriminator's ability to classify real from generated samples\n            # how well can it label as real?\n            real_loss = self.adversarial_loss(self.discriminator(imgs), get_valid_labels(imgs))\n\n            # Experience replay\n            if self.exp_replay_dis.size(0) &gt;= self.hparams.experience_batch_size:\n              fake_loss = self.adversarial_loss(self.discriminator(self.exp_replay_dis.detach()), get_unvalid_labels(self.exp_replay_dis))  # train on already seen images\n\n              self.exp_replay_dis = torch.tensor([]) # Reset experience replay\n\n              # discriminator loss is the average of these\n              d_loss = (real_loss + fake_loss) \/ 2\n\n              tqdm_dict = {'d_loss': d_loss}\n              log = {'d_loss': d_loss, \"d_exp_loss\": fake_loss, \"std_gaussian\": std_gaussian}\n              output = OrderedDict({\n                  'loss': d_loss,\n                  'progress_bar': tqdm_dict,\n                  'log': log\n              })\n              return output\n\n            else:\n              fake_loss = self.adversarial_loss(self.discriminator(self.generated_imgs.detach()), get_unvalid_labels(self.generated_imgs))  # how well can it label as fake?\n\n              # discriminator loss is the average of these\n              d_loss = (real_loss + fake_loss) \/ 2\n\n              tqdm_dict = {'d_loss': d_loss}\n              log = {'d_loss': d_loss, \"std_gaussian\": std_gaussian}\n              output = OrderedDict({\n                  'loss': d_loss,\n                  'progress_bar': tqdm_dict,\n                  'log': log\n              })\n              return output\n\n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        b1 = self.hparams.b1\n        b2 = self.hparams.b2\n\n        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n        return [opt_g, opt_d], []\n\n    def train_dataloader(self):\n        transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.5], [0.5])])\n        dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n        return DataLoader(dataset, batch_size=self.hparams.batch_size)\n        # transform = transforms.Compose([transforms.Resize((self.hparams.image_size, self.hparams.image_size)),\n        #                                 transforms.ToTensor(),\n        #                                 transforms.Normalize([0.5], [0.5])\n        #                                 ])\n\n        # train_dataset = torchvision.datasets.ImageFolder(\n        #     root=\".\/drive\/My Drive\/datasets\/ghibli_dataset_small_overfit\/\",\n        #     transform=transform\n        # )\n        # return DataLoader(train_dataset, num_workers=self.hparams.num_workers, shuffle=True, batch_size=self.hparams.batch_size)\n\n    def on_epoch_end(self):\n        z = torch.randn(4, self.hparams.latent_dim, 1, 1)\n        # match gpu device (or keep as cpu)\n        if self.on_gpu:\n            z = z.cuda(self.last_imgs.device.index)\n\n        # log sampled images\n        sample_imgs = self.generator(z)\n        sample_imgs = sample_imgs.view(-1, self.hparams.nc, self.hparams.image_size, self.hparams.image_size)\n        grid = torchvision.utils.make_grid(sample_imgs, nrow=2)\n        self.logger.experiment.log_image(grid.permute(1, 2, 0), f'generated_images_epoch{self.current_epoch}', step=self.current_epoch)\n\n        # save model\n        if self.current_epoch % self.hparams.save_model_every_epoch == 0:\n          trainer.save_checkpoint(self.checkpoint_folder + \"\/\" + self.experiment_name + \"_epoch_\" + str(self.current_epoch) + \".ckpt\")\n          comet_logger.experiment.log_asset_folder(self.checkpoint_folder, step=self.current_epoch)\n\n          # Deleting the folder where we saved the model so that we dont upload a thing twice\n          dirpath = Path(self.checkpoint_folder)\n          if dirpath.exists() and dirpath.is_dir():\n                shutil.rmtree(dirpath)\n\n          # creating checkpoint folder\n          access_rights = 0o755\n          os.makedirs(dirpath, access_rights)\n\nfrom argparse import Namespace\n\nargs = {\n    'batch_size': 48,\n    'lr': 0.0002,\n    'b1': 0.5,\n    'b2': 0.999,\n    'latent_dim': 128, # tested value which worked(in V4_1): 100\n    'nc': 1,\n    'ndf': 32,\n    'ngf': 32,\n    'epochs': 10,\n    'save_model_every_epoch': 5,\n    'image_size': 64,\n    'num_workers': 2,\n    'level_of_noise': 0.15,\n    'experience_save_per_batch': 1, # this value should be very low; tested value which works: 1\n    'experience_batch_size': 50 # this value shouldnt be too high; tested value which works: 50\n}\nhparams = Namespace(**args)\n\n# Parameters\nexperiment_name = \"DCGAN_V4_2_MNIST\"\ndataset_name = \"MNIST\"\ncheckpoint_folder = \"DCGAN\/\"\ntags = [\"DCGAN\", \"MNIST\", \"OVERFIT\", \"64x64\"]\ndirpath = Path(checkpoint_folder)\n\n# init logger\ncomet_logger = loggers.CometLogger(\n    api_key=\"\",\n    rest_api_key=\"\",\n    project_name=\"gan\",\n    experiment_name=experiment_name,\n    #experiment_key=\"f23d00c0fe3448ee884bfbe3fc3923fd\"  # used for resuming trained id can be found in comet.ml\n)\n\n#defining net\nnet = DCGAN(hparams, comet_logger, checkpoint_folder, experiment_name)\n\n#logging\ncomet_logger.experiment.set_model_graph(str(net))\ncomet_logger.experiment.add_tags(tags=tags)\ncomet_logger.experiment.log_dataset_info(dataset_name)\n\ntrainer = pl.Trainer(#resume_from_checkpoint=\"GHIBLI_DCGAN_OVERFIT_64px_epoch_6000.ckpt\",\n                     logger=comet_logger,\n                     max_epochs=args[\"epochs\"]\n                     )\ntrainer.fit(net)\ncomet_logger.experiment.end()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1586987562523,
        "Question_score":0,
        "Question_tags":"crash|google-colaboratory|freeze|comet-ml",
        "Question_view_count":1013,
        "Owner_creation_time":1493314794173,
        "Owner_last_access_time":1658745180780,
        "Owner_location":"Germany",
        "Owner_reputation":844,
        "Owner_up_votes":241,
        "Owner_down_votes":6,
        "Owner_views":170,
        "Question_last_edit_time":1587130797010,
        "Answer_body":"<p>I fixed it with importing this:<\/p>\n\n<pre><code>from IPython.display import clear_output \n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1587034953183,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61239274",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":46359436,
        "Question_title":"How to configure comet (comet.ml) to track Keras?",
        "Question_body":"<p>im trying to setup <a href=\"https:\/\/www.comet.ml\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml<\/a> to log my experiment details <\/p>\n\n<p>getting strange error:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"train.py\", line 7, in &lt;module&gt;\n    from comet_ml import Experiment\nImportError: No module named comet_ml\n<\/code><\/pre>\n\n<p>trying in python 2 and python3<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1506066265147,
        "Question_score":3,
        "Question_tags":"python|keras|comet|comet-ml",
        "Question_view_count":1208,
        "Owner_creation_time":1505841491573,
        "Owner_last_access_time":1506108675090,
        "Owner_location":null,
        "Owner_reputation":55,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1506066568087,
        "Answer_body":"<p>it seems like comet isn't installed on your machine.<\/p>\n\n<p>you can use :<\/p>\n\n<pre><code>pip3 install comet_ml\npip install comet_ml\n<\/code><\/pre>\n\n<p>take a look at the example projects at: <\/p>\n\n<p><a href=\"https:\/\/github.com\/comet-ml\/comet-quickstart-guide\" rel=\"nofollow noreferrer\">https:\/\/github.com\/comet-ml\/comet-quickstart-guide<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1506066553020,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1513514919393,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46359436",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":46352435,
        "Question_title":"comet (comet-ml) fails to run with Keras",
        "Question_body":"<p>Im running the keras examples from <a href=\"https:\/\/github.com\/comet-ml\/comet-keras-example\/blob\/master\/comet_keras_example.py\" rel=\"nofollow noreferrer\">Comet github project<\/a> .<\/p>\n\n<p>I add the import and create a new experiment:<\/p>\n\n<pre><code>def train(x_train,y_train,x_test,y_test):\nmodel = build_model_graph()\n\nfrom comet_ml import Experiment\n\nexperiment = Experiment(api_key=\"XXXX\", log_code=True)\n\nmodel.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\n<\/code><\/pre>\n\n<p>and when i run my training code it fails.<\/p>\n\n<p>error:<\/p>\n\n<pre><code>Using TensorFlow backend.\nTraceback (most recent call last):\n  File \"\/Users\/nimrodlahav\/Code\/semantica\/experiment-logger-client\/train-examples\/keras-example.py\", line 21, in &lt;module&gt;\n    from comet_ml import Experiment\n  File \"..\/.\/comet-client-lib\/comet_ml\/__init__.py\", line 3, in &lt;module&gt;\n    from .comet import Experiment\n  File \"..\/.\/comet-client-lib\/comet_ml\/comet.py\", line 29, in &lt;module&gt;\n    from comet_ml import keras_logger\n  File \"..\/.\/comet-client-lib\/comet_ml\/keras_logger.py\", line 31, in &lt;module&gt;\n    raise SyntaxError(\"Please import Comet before importing any keras modules\")\nSyntaxError: Please import Comet before importing any keras modules\n<\/code><\/pre>\n\n<p>what am I missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1506024659377,
        "Question_score":2,
        "Question_tags":"python|tensorflow|keras|comet|comet-ml",
        "Question_view_count":601,
        "Owner_creation_time":1505841491573,
        "Owner_last_access_time":1506108675090,
        "Owner_location":null,
        "Owner_reputation":55,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1506491876827,
        "Answer_body":"<p>I don't see start of the code but it looks like you have imported Keras before you have imported Comet.<\/p>\n\n<p>From the error message it looks like just need to switch the import lines (Comet first Keras second), like in your example:<\/p>\n\n<pre><code>from comet_ml import Experiment\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop \n<\/code><\/pre>\n\n<p>view the full source code <a href=\"https:\/\/github.com\/comet-ml\/comet-keras-example\" rel=\"nofollow noreferrer\">example<\/a> .<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1506026797450,
        "Answer_score":3.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1506066589407,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46352435",
        "Question_exclusive_tag":"Comet"
    },
    {
        "Question_id":64640949,
        "Question_title":"How to suppress \"Comet.ml Experiment Summary\" console output in the beginning",
        "Question_body":"<p>I'm using <code>comet.ml<\/code> to display learning results of my machine learning models on <code>jupyter<\/code>.<\/p>\n<p>Initializing an experiment as follows<\/p>\n<pre><code>experiment = Experiment(project_name='...', auto_metric_logging=False)\nexperiment.add_tag('...')\n<\/code><\/pre>\n<p>the following information is shown (with light red color background) in the beginning every time:<\/p>\n<pre><code>COMET INFO: ----------------------------\nCOMET INFO: Comet.ml Experiment Summary:\nCOMET INFO:   Data:\nCOMET INFO:     url: https:\/\/www.comet.ml\/...\nCOMET INFO:   Metrics [count] (min, max):\nCOMET INFO:     loss_D_fake [210]            : (1.4689682722091675, 1.999974250793457)\n... 50+ lines ...\nCOMET INFO:     sys.ram.total [8]            : (269603381248.0, 269603381248.0)\nCOMET INFO:     sys.ram.used [8]             : (60270231552.0, 64912928768.0)\nCOMET INFO:   Uploads:\nCOMET INFO:     git-patch: 1\nCOMET INFO: ----------------------------\nCOMET INFO: Experiment is live on comet.ml https:\/\/www.comet.ml\/...\n<\/code><\/pre>\n<p>All I want to see is the last line that shows the URL for this experiment and that seems not to be included in the 'Comet.ml Experiment Summary' block. How can we suppress other information?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1604299707030,
        "Question_score":0,
        "Question_tags":"python|jupyter|comet-ml",
        "Question_view_count":156,
        "Owner_creation_time":1469364547800,
        "Owner_last_access_time":1663732990757,
        "Owner_location":"Kyoto Prefecture, Japan",
        "Owner_reputation":343,
        "Owner_up_votes":219,
        "Owner_down_votes":15,
        "Owner_views":60,
        "Question_last_edit_time":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64640949",
        "Question_exclusive_tag":"Comet"
    }
]