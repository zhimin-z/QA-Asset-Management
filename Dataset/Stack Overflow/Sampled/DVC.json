[
    {
        "Question_id":58952962,
        "Question_title":"How to use different remotes for different folders?",
        "Question_body":"<p>I want my data and models stored in separate Google Cloud buckets. The idea is that I want to be able to share the data with others without sharing the models.<\/p>\n\n<p>One idea I can think of is using separate git submodules for data and models. But that feels cumbersome and imposes some additional requirements from the end user (e.g. having to do <code>git submodule update<\/code>).<\/p>\n\n<p>So can I do this without using git submodules?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-11-20 11:10:29.42 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":12,
        "Question_tags":"dvc",
        "Question_view_count":1984,
        "Owner_creation_date":"2011-07-22 10:25:49.88 UTC",
        "Owner_last_access_date":"2022-09-21 15:11:42.327 UTC",
        "Owner_reputation":3784,
        "Owner_up_votes":472,
        "Owner_down_votes":0,
        "Owner_views":342,
        "Answer_body":"<p>You can first add the different <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\" rel=\"nofollow noreferrer\">DVC remotes<\/a> you want to establish (let's say you call them <code>data<\/code> and <code>models<\/code>, each one pointing to a different <a href=\"https:\/\/cloud.google.com\/storage\/docs\/json_api\/v1\/buckets\" rel=\"nofollow noreferrer\">GC bucket<\/a>). <strong>But don't set any remote as the project's default<\/strong>; This way, <a href=\"https:\/\/dvc.org\/doc\/command-reference\/push\" rel=\"nofollow noreferrer\"><code>dvc push<\/code><\/a> won't work without the <code>-r<\/code> (or <code>--remote<\/code>) option.<\/p>\n<p>You would then need to push each directory or file individually to the appropriate remote, like <code>dvc push data\/ -r data<\/code> and <code>dvc push model.dat -r models<\/code>.<\/p>\n<p>Note that a feature request to configure this exists on the DVC repo too. See <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/2095\" rel=\"nofollow noreferrer\">Specify file types that can be pushed to remote<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-11-20 16:31:15.363 UTC",
        "Answer_score":13.0,
        "Owner_location":"Tel Aviv",
        "Answer_last_edit_date":"2022-01-18 17:46:31.693 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58952962",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72333237,
        "Question_title":"Why I got an invalid bucket name error using dvc mlflow on macos",
        "Question_body":"<p>Could anyone tell what's the reason for error:<\/p>\n<p>botocore.exceptions.ParamValidationError: Parameter validation failed:\nInvalid bucket name &quot;&quot;: Bucket name must match the regex &quot;^[a-zA-Z0-9.-_]{1,255}$&quot; or be an ARN matching the regex &quot;^arn:(aws).<em>:(s3|s3-object-lambda):[a-z-0-9]<\/em>:[0-9]{12}:accesspoint[\/:][a-zA-Z0-9-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z-0-9]+:[0-9]{12}:outpost[\/:][a-zA-Z0-9-]{1,63}[\/:]accesspoint[\/:][a-zA-Z0-9-]{1,63}$&quot;<\/p>\n<p>I try to use mlflow with docker.\n.env file contains:<\/p>\n<pre><code>AWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_S3_BUCKET=vla...rts\nMLFLOW_S3_ENDPOINT_URL=http:\/\/localhost:9000\nMLFLOW_TRACKING_URI=http:\/\/127.0.0.1:5000\nPOSTGRES_USER=...\nPOSTGRES_PASSWORD=...\nPOSTGRES_DB=test_db\n<\/code><\/pre>\n<p>Also tried to use:<\/p>\n<pre><code>AWS_ACCESS_KEY_ID=...\nAWS_SECRET_ACCESS_KEY=...\nAWS_S3_BUCKET=vla...rts\nMLFLOW_S3_ENDPOINT_URL=http:\/\/localhost:9000\nMLFLOW_TRACKING_URI=http:\/\/localhost:5000\nPOSTGRES_USER=...\nPOSTGRES_PASSWORD=...\nPOSTGRES_DB=test_db\n<\/code><\/pre>\n<p>docker-compose contains:<\/p>\n<pre><code>... \n   mlflow:\n        restart: always\n        image: mlflow_server\n        container_name: mlflow_server\n        ports:\n          - &quot;5000:5000&quot;\n        networks:\n          - postgres\n          - s3\n        environment:\n          - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\n          - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n          - MLFLOW_S3_ENDPOINT_URL=http:\/\/nginx:9000\n        command: mlflow server --backend-store-uri postgresql:\/\/${POSTGRES_USER}:${POSTGRES_PASSWORD}@db\/${POSTGRES_DB} --default-artifact-root s3:\/\/${AWS_S3_BUCKET}\/ --host 0.0.0.0\n...\n<\/code><\/pre>\n<p>As I understood, I get an exception cause bucket name is empty (&quot;&quot;). But in .env file I set bucket name as <code>vla...rts<\/code><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_date":"2022-05-21 21:10:53.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-24 06:16:27.987 UTC",
        "Question_score":0,
        "Question_tags":"docker|mlflow|mlops|dvc",
        "Question_view_count":117,
        "Owner_creation_date":"2019-12-29 15:05:47.33 UTC",
        "Owner_last_access_date":"2022-09-20 12:21:31.067 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Saint Petersburg",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72333237",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":60527213,
        "Question_title":"How does DVC store differences on the directory level into DVC cache?",
        "Question_body":"<p>Can someone explain how DVC stores differences on the directory level into DVC cache. <\/p>\n\n<p>I understand that the DVC-files (.dvc) are metafiles to track data, models and reproduce pipeline stages. However, it is not clear for me how the process of creating branches, commiting them and switching back to a master file is exactly saved in differences. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-04 13:28:05.69 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-04 14:30:01.397 UTC",
        "Question_score":4,
        "Question_tags":"version-control|dvc",
        "Question_view_count":623,
        "Owner_creation_date":"2020-03-04 07:53:32.843 UTC",
        "Owner_last_access_date":"2020-04-23 11:10:57.24 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60527213",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":60861593,
        "Question_title":"How do I specify encryption type when using s3remote for DVC",
        "Question_body":"<p>I have just started to explore DVC. I am trying with s3 as my DVC remote. I am getting <\/p>\n\n<p>But when I run the <code>dvc push<\/code> command, I get the generic error saying <\/p>\n\n<pre><code>An error occurred (AccessDenied) when calling the PutObject operation: Access Denied\n<\/code><\/pre>\n\n<p>which I know for a fact that I get that error when I don't specify the encryption.<\/p>\n\n<p>It is similar to running <code>aws s3 cp<\/code> with <code>--sse<\/code> flag or specifying <code>ServerSideEncryption<\/code> when using boto3 library. How can I specify the encryption type when using DVC. Coz underneath DVC uses boto3 so there must be an easy way to do this.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-26 05:45:08.167 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":293,
        "Owner_creation_date":"2017-04-11 13:31:59.307 UTC",
        "Owner_last_access_date":"2022-03-29 20:52:48.753 UTC",
        "Owner_reputation":1756,
        "Owner_up_votes":82,
        "Owner_down_votes":5,
        "Owner_views":199,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60861593",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":68771979,
        "Question_title":"problems installing a DVC lower version [0.9.4]",
        "Question_body":"<p>I need to install an older version of DVC, namely 0.9.4, in a Python virtual environment.<\/p>\n<p>I used the command:<\/p>\n<pre><code>pip install dvc==0.9.4\n<\/code><\/pre>\n<p>Everything seemed to work fine. However, when I try to run a <code>dvc pull<\/code> command, I get the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\runpy.py&quot;, line 193, in _run_module_as_main\n    &quot;__main__&quot;, mod_spec)\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\runpy.py&quot;, line 85, in _run_code\n    exec(code, run_globals)\n  File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\Scripts\\dvc.exe\\__main__.py&quot;, line 4, in &lt;module&gt;\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\main.py&quot;, line 2, in &lt;module&gt;\n    from dvc.cli import parse_args\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\cli.py&quot;, line 8, in &lt;module&gt;\n    from dvc.command.init import CmdInit\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\command\\init.py&quot;, line 1, in &lt;module&gt;\n    from dvc.project import Project\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\project.py&quot;, line 15, in &lt;module&gt;\n    from dvc.cloud.data_cloud import DataCloud\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\cloud\\data_cloud.py&quot;, line 11, in &lt;module&gt;\n    from dvc.cloud.gcp import DataCloudGCP\n  File &quot;c:\\users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\cloud\\gcp.py&quot;, line 4, in &lt;module&gt;\n    from google.cloud import storage as gc\nModuleNotFoundError: No module named 'google.cloud'\n<\/code><\/pre>\n<p>When I print the dvc version, I see:<\/p>\n<pre><code>0.9.4+6bb66e.mod\n<\/code><\/pre>\n<p>Can anyone please help? Thanks.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-13 12:01:16.7 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-13 19:21:41.66 UTC",
        "Question_score":2,
        "Question_tags":"python|google-cloud-storage|dvc",
        "Question_view_count":234,
        "Owner_creation_date":"2019-09-30 10:15:09.623 UTC",
        "Owner_last_access_date":"2022-09-19 14:01:39.763 UTC",
        "Owner_reputation":95,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68771979",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":71378280,
        "Question_title":"Error with DVC on Google Colab - dvc.scm.CloneError: Failed to clone repo",
        "Question_body":"<p>I'm having a problem trying to run &quot;dvc pull&quot; on Google Colab. I have two repositories (let's call them A and B) where repository A is for my machine learning codes and repository B is for my dataset.<\/p>\n<p>I've successfully pushed my dataset to repository B with DVC (using gdrive as my remote storage) and I also managed to successfully run &quot;dvc import&quot; (as well as &quot;dvc pull\/update&quot;) on my local project of repository A.<\/p>\n<p>The problem comes when I use colab to run my project. So what I did was the following:<\/p>\n<ol>\n<li>Created a new notebook on colab<\/li>\n<li>Successfully git-cloned my machine learning project (repository A)<\/li>\n<li>Ran &quot;!pip install dvc&quot;<\/li>\n<li>Ran &quot;!dvc pull -v&quot; (This is what causes the error)<\/li>\n<\/ol>\n<p>On step 4, I got the error (this is the full stack trace. Note that I changed the repo URL in the stack trace for confidentiality reasons)<\/p>\n<pre><code>2022-03-08 08:53:31,863 DEBUG: Adding '\/content\/&lt;my_project_A&gt;\/.dvc\/config.local' to gitignore file.\n2022-03-08 08:53:31,866 DEBUG: Adding '\/content\/&lt;my_project_A&gt;\/.dvc\/tmp' to gitignore file.\n2022-03-08 08:53:31,866 DEBUG: Adding '\/content\/&lt;my_project_A&gt;\/.dvc\/cache' to gitignore file.\n2022-03-08 08:53:31,916 DEBUG: Creating external repo https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git@3a3f4559efabff8ec74486da39b86688d1b98d75\n2022-03-08 08:53:31,916 DEBUG: erepo: git clone 'https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git' to a temporary dir\nEverything is up to date.\n2022-03-08 08:53:32,154 ERROR: failed to pull data from the cloud - Failed to clone repo 'https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git' to '\/tmp\/tmp2x7y7xgedvc-clone'\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/scmrepo\/git\/backend\/gitpython.py&quot;, line 185, in clone\n    tmp_repo = clone_from()\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/git\/repo\/base.py&quot;, line 1148, in clone_from\n    return cls._clone(git, url, to_path, GitCmdObjectDB, progress, multi_options, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/git\/repo\/base.py&quot;, line 1079, in _clone\n    finalize_process, decode_streams=False)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/git\/cmd.py&quot;, line 176, in handle_process_output\n    return finalizer(process)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/git\/util.py&quot;, line 386, in finalize_process\n    proc.wait(**kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/git\/cmd.py&quot;, line 502, in wait\n    raise GitCommandError(remove_password_if_present(self.args), status, errstr)\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(128)\n  cmdline: git clone -v --no-single-branch --progress https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git \/tmp\/tmp2x7y7xgedvc-clone\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/scm.py&quot;, line 104, in clone\n    return Git.clone(url, to_path, progress=pbar.update_git, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/scmrepo\/git\/__init__.py&quot;, line 121, in clone\n    backend.clone(url, to_path, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/scmrepo\/git\/backend\/gitpython.py&quot;, line 190, in clone\n    raise CloneError(url, to_path) from exc\nscmrepo.exceptions.CloneError: Failed to clone repo 'https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git' to '\/tmp\/tmp2x7y7xgedvc-clone'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/command\/data_sync.py&quot;, line 41, in run\n    glob=self.args.glob,\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/__init__.py&quot;, line 49, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/pull.py&quot;, line 38, in pull\n    run_cache=run_cache,\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/__init__.py&quot;, line 49, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/fetch.py&quot;, line 50, in fetch\n    revs=revs,\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/__init__.py&quot;, line 437, in used_objs\n    with_deps=with_deps,\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/repo\/index.py&quot;, line 190, in used_objs\n    filter_info=filter_info,\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/stage\/__init__.py&quot;, line 660, in get_used_objs\n    for odb, objs in out.get_used_objs(*args, **kwargs).items():\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/output.py&quot;, line 918, in get_used_objs\n    return self.get_used_external(**kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/output.py&quot;, line 973, in get_used_external\n    return dep.get_used_objs(**kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/dependency\/repo.py&quot;, line 94, in get_used_objs\n    used, _ = self._get_used_and_obj(**kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/dependency\/repo.py&quot;, line 108, in _get_used_and_obj\n    locked=locked, cache_dir=local_odb.cache_dir\n  File &quot;\/usr\/lib\/python3.7\/contextlib.py&quot;, line 112, in __enter__\n    return next(self.gen)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/external_repo.py&quot;, line 35, in external_repo\n    path = _cached_clone(url, rev, for_write=for_write)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/external_repo.py&quot;, line 155, in _cached_clone\n    clone_path, shallow = _clone_default_branch(url, rev, for_write=for_write)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/funcy\/decorators.py&quot;, line 45, in wrapper\n    return deco(call, *dargs, **dkwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/funcy\/flow.py&quot;, line 274, in wrap_with\n    return call()\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/funcy\/decorators.py&quot;, line 66, in __call__\n    return self._func(*self._args, **self._kwargs)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/external_repo.py&quot;, line 220, in _clone_default_branch\n    git = clone(url, clone_path)\n  File &quot;\/usr\/local\/lib\/python3.7\/dist-packages\/dvc\/scm.py&quot;, line 106, in clone\n    raise CloneError(str(exc))\ndvc.scm.CloneError: Failed to clone repo 'https:\/\/gitlab.com\/&lt;my-dataset-repo-B&gt;.git' to '\/tmp\/tmp2x7y7xgedvc-clone'\n------------------------------------------------------------\n2022-03-08 08:53:32,161 DEBUG: Analytics is enabled.\n2022-03-08 08:53:32,192 DEBUG: Trying to spawn '['daemon', '-q', 'analytics', '\/tmp\/tmp4x5js0dk']'\n2022-03-08 08:53:32,193 DEBUG: Spawned '['daemon', '-q', 'analytics', '\/tmp\/tmp4x5js0dk']'\n<\/code><\/pre>\n<p>And btw this is how I cloned my git repository (repo A)<\/p>\n<pre><code>!git config - global user.name &quot;Zharfan&quot;\n!git config - global user.email &quot;zharfan@myemail.com&quot;\n!git clone https:\/\/&lt;MyTokenName&gt;:&lt;MyToken&gt;@link-to-my-repo-A.git\n<\/code><\/pre>\n<p>Does anyone know why? Any help would be greatly appreciated. Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":12,
        "Question_creation_date":"2022-03-07 08:32:28.613 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-18 06:52:58.06 UTC",
        "Question_score":1,
        "Question_tags":"git|dataset|google-colaboratory|dvc",
        "Question_view_count":707,
        "Owner_creation_date":"2018-05-02 02:10:15.313 UTC",
        "Owner_last_access_date":"2022-09-22 10:20:20.31 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>To summarize the discussion in the comments thread.<\/p>\n<p>Most likely it's happening since DVC can't get access to a private repo on GitLab. (The error message is obscure and should be fixed.)<\/p>\n<p>The same way you would not be able to run:<\/p>\n<pre><code>!git clone https:\/\/gitlab.com\/org\/&lt;private-repo&gt;\n<\/code><\/pre>\n<p>It also returns a pretty obscure error:<\/p>\n<pre><code>Cloning into '&lt;private-repo&gt;'...\nfatal: could not read Username for 'https:\/\/gitlab.com': No such device or address\n<\/code><\/pre>\n<p>(I think it's something related to how tty is setup in Colab?)<\/p>\n<p>The best approach to solve this is to use SSH like described <a href=\"https:\/\/medium.com\/@sadiaafrinpurba\/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f\" rel=\"nofollow noreferrer\">here<\/a> for example.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-03-11 18:08:34.533 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71378280",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":52871630,
        "Question_title":"Resolving paths in mingw fails with Data Version Control",
        "Question_body":"<p>I am following the <a href=\"https:\/\/blog.dataversioncontrol.com\/data-version-control-tutorial-9146715eda46\" rel=\"nofollow noreferrer\">tutorial<\/a> about <a href=\"https:\/\/github.com\/iterative\/dvc\" rel=\"nofollow noreferrer\">Data Version Control<\/a> using <code>mingw32<\/code> on Windows 7.<\/p>\n\n<p>I am getting very strange error when I try to use <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/run\" rel=\"nofollow noreferrer\">run<\/a>:<\/p>\n\n<pre><code>$ dvc run -v echo \"hello\"\nDebug: updater is not old enough to check for updates\nDebug: PRAGMA user_version;\nDebug: fetched: [(2,)]\nDebug: CREATE TABLE IF NOT EXISTS state (inode INTEGER PRIMARY KEY, mtime TEXT NOT NULL, md5 TEXT NOT NULL, timestamp TEXT NOT NULL)\nDebug: CREATE TABLE IF NOT EXISTS state_info (count INTEGER)\nDebug: CREATE TABLE IF NOT EXISTS link_state (path TEXT PRIMARY KEY, inode INTEGER NOT NULL, mtime TEXT NOT NULL)\nDebug: INSERT OR IGNORE INTO state_info (count) SELECT 0 WHERE NOT EXISTS (SELECT * FROM state_info)\nDebug: PRAGMA user_version = 2;\nRunning command:\n        echo hello\n\/c: \/c: Is a directory\nDebug: SELECT count from state_info WHERE rowid=1\nDebug: fetched: [(1,)]\nDebug: UPDATE state_info SET count = 1 WHERE rowid = 1\nError: Traceback (most recent call last):\n  File \"dvc\\command\\run.py\", line 18, in run\n  File \"dvc\\project.py\", line 265, in run\n  File \"dvc\\stage.py\", line 435, in run\nStageCmdFailedError: Stage 'Dvcfile' cmd echo hello failed\n\nError: Failed to run command: Stage 'Dvcfile' cmd echo hello failed\n<\/code><\/pre>\n\n<h3>Question:<\/h3>\n\n<p>Where does the <code>\/c: \/c: Is a directory<\/code> come from?  How can I fix it? <\/p>\n\n<h3>My findings<\/h3>\n\n<ol>\n<li><p>I supposed that it was resolving path to echo, but ech is a builtin.<\/p>\n\n<pre><code>$ type echo\necho is a shell builtin\n<\/code><\/pre>\n\n<p>I tried also with <code>exit<\/code> and <code>cd<\/code> but I am getting the same error.<\/p><\/li>\n<li><p>Calling commands without dvc works fine.<\/p><\/li>\n<li><p><code>dvc<\/code> with <code>--no-exec<\/code> flag works fine, but when later executed with <code>repro<\/code> gives the same error. <\/p><\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-18 10:04:46.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-10-18 16:44:38.543 UTC",
        "Question_score":4,
        "Question_tags":"windows|mingw|dvc",
        "Question_view_count":109,
        "Owner_creation_date":"2017-10-17 09:04:07.66 UTC",
        "Owner_last_access_date":"2022-09-18 22:22:48.267 UTC",
        "Owner_reputation":860,
        "Owner_up_votes":658,
        "Owner_down_votes":18,
        "Owner_views":118,
        "Answer_body":"<p>I'm one of the dvc developers. Similar error has affected dvc running on cygwin. We've released a fix for it in <code>0.20.0<\/code>. Please upgrade.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-10-27 08:34:28.433 UTC",
        "Answer_score":4.0,
        "Owner_location":"Krak\u00f3w, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52871630",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70478173,
        "Question_title":"How to track the big data stored in Gdrive through DVC?",
        "Question_body":"<p>I am currently working on the ML project and the data size is around 10 GB. The data I stored in google drive. Its impossible for me to download it on my local machine. So, how to use the DVC (data version control) to track that data? Thank you in advance for your time.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-25 05:32:27.58 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-25 06:04:47.833 UTC",
        "Question_score":2,
        "Question_tags":"machine-learning|version-control|mlops|dvc",
        "Question_view_count":47,
        "Owner_creation_date":"2019-08-30 19:13:36.523 UTC",
        "Owner_last_access_date":"2022-09-15 22:06:51.567 UTC",
        "Owner_reputation":85,
        "Owner_up_votes":76,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70478173",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":65824766,
        "Question_title":"SSH automation in jenkins",
        "Question_body":"<p>So I've been working on the automation of processes and it includes fetching data from an external source through DVC(data version control) for which I am using SSH client to pull and push changes. For automation, I'm using <strong>Jenkins<\/strong> and the problem I'm facing is that for ssh we need to give a password on runtime, and in automation that's not an option. I've tried multiple ways to specify passwords for ssh like sshpass and ssh config but it turns out Jenkins when building creates some file name <strong>script.sh<\/strong> in a directory <em>repoName@tmp<\/em> in var\/lib\/jenkins\/.... and therefore it is giving permission denied error. no matter what I try. If anyone could give any suggestions to this problem it would be appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-21 09:44:15.303 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"jenkins|ssh|dvc",
        "Question_view_count":121,
        "Owner_creation_date":"2017-04-25 06:32:01.29 UTC",
        "Owner_last_access_date":"2022-09-23 21:22:32.03 UTC",
        "Owner_reputation":133,
        "Owner_up_votes":31,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>You could use key-based auth for SSH instead instead of password auth so that your Jenkins user can access your SSH DVC remote without needing to specify a password.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-01-21 11:20:29.327 UTC",
        "Answer_score":2.0,
        "Owner_location":"Pakistan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65824766",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":68284742,
        "Question_title":"DVC experiment is restoring deleted files",
        "Question_body":"<p>I am using DVC to run experiments in my project using<\/p>\n<pre><code>dvc exp run\n<\/code><\/pre>\n<p>Now when i make changes to a file(example train.py) and run &quot;dvc exp run&quot; everything goes well,\nbut my problem is that when making changes by <strong>deleting<\/strong> a file(example train.py or an image in the data folder) as soon as i run the &quot;dvc exp run&quot; the file is restored.\nhow to stop that from happening?<\/p>\n<p>This is my dvc.yaml:<\/p>\n<pre><code>stages:\n  train:\n    cmd: python train.py\n    deps:\n    - train.py\n    metrics:\n    - metrics.txt:\n        cache: false\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":9,
        "Question_creation_date":"2021-07-07 10:57:32.383 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"dvc",
        "Question_view_count":272,
        "Owner_creation_date":"2019-05-08 11:22:43.687 UTC",
        "Owner_last_access_date":"2022-02-21 23:18:39.443 UTC",
        "Owner_reputation":113,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Tunis, Tunisia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68284742",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70939675,
        "Question_title":"DVC Push KeyError fileSize",
        "Question_body":"<p>I've added a large list of CSV files to my dvc repository but when I try to do DVC push it complains with<\/p>\n<pre><code>ERROR: unexpected error - KeyError('fileSize')\n<\/code><\/pre>\n<p><strong>Edit<\/strong>\nSo searching around it seem that it might help to include the verbose log with regards to the error.<\/p>\n<pre><code>T11:27:08~\/documents\/*****\/data$ dvc push -v\n2022-02-01 11:32:13,186 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/config.local' to gitignore file.\n2022-02-01 11:32:13,199 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp' to gitignore file.\n2022-02-01 11:32:13,200 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to gitignore file.\n2022-02-01 11:32:14,102 DEBUG: Preparing to transfer data from '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to '*********'\n2022-02-01 11:32:14,102 DEBUG: Preparing to collect status from '********'\n2022-02-01 11:32:14,103 DEBUG: Collecting status from '*******'\n2022-02-01 11:32:14,439 DEBUG: GDrive remote auth with config '{'client_config_backend': 'settings', 'client_config_file': 'client_secrets.json', 'save_credentials': True, 'oauth_scope': ['https:\/\/www.googleapis.com\/auth\/drive', 'https:\/\/www.googleapis.com\/auth\/drive.appdata'], 'save_credentials_backend': 'file', 'save_credentials_file': '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp\/gdrive-user-credentials.json', 'get_refresh_token': True, 'client_config': {'client_id': '*****.apps.googleusercontent.com', 'client_secret': '****************', 'auth_uri': 'https:\/\/accounts.google.com\/o\/oauth2\/auth', 'token_uri': 'https:\/\/oauth2.googleapis.com\/token', 'revoke_uri': 'https:\/\/oauth2.googleapis.com\/revoke', 'redirect_uri': ''}}'.\n2022-02-01 11:32:14,994 DEBUG: Estimated remote size: 256 files\n2022-02-01 11:32:14,995 DEBUG: Querying '316' hashes via traverse\n2022-02-01 11:32:15,325 ERROR: unexpected error - KeyError('fileSize')\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 226, in __getitem__\n    return dict.__getitem__(self, key)\nKeyError: 'fileSize'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/main.py&quot;, line 55, in main\n    ret = cmd.do_run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/base.py&quot;, line 45, in do_run\n    return self.run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/data_sync.py&quot;, line 57, in run\n    processed_files_count = self.repo.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/__init__.py&quot;, line 49, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/push.py&quot;, line 56, in push\n    pushed += self.cloud.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/data_cloud.py&quot;, line 85, in push\n    return transfer(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/transfer.py&quot;, line 153, in transfer\n    status = compare_status(src, dest, obj_ids, check_deleted=False, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 158, in compare_status\n    dest_exists, dest_missing = status(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 131, in status\n    exists.update(odb.hashes_exist(hashes, name=odb.fs_path, **kwargs))\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 499, in hashes_exist\n    remote_hashes = set(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 334, in _list_hashes_traverse\n    yield from itertools.chain.from_iterable(in_remote)\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 611, in result_iterator\n    yield fs.pop().result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 439, in result\n    return self.__get_result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 388, in __get_result\n    raise self._exception\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 324, in list_with_update\n    return list(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 215, in _list_hashes\n    for path in self._list_paths(prefix, progress_callback):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 195, in _list_paths\n    for file_info in self.fs.find(fs_path, prefix=prefix):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/fs\/fsspec_wrapper.py&quot;, line 107, in find\n    yield from self.fs.find(path)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/fs\/spec.py&quot;, line 323, in find\n    &quot;size&quot;: int(item[&quot;fileSize&quot;]),\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 229, in __getitem__\n    raise KeyError(e)\nKeyError: KeyError('fileSize')\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_date":"2022-02-01 11:16:50.58 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-01 11:40:42.69 UTC",
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":54,
        "Owner_creation_date":"2012-04-08 18:08:56.53 UTC",
        "Owner_last_access_date":"2022-09-24 13:24:30.7 UTC",
        "Owner_reputation":884,
        "Owner_up_votes":185,
        "Owner_down_votes":3,
        "Owner_views":59,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"London, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70939675",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73602927,
        "Question_title":"Best method to compress large dataset features",
        "Question_body":"<p>10TB featurs which stored on aws s3 bucket.\nin order to decrease costs , we are looking for a loseless compression method for those features (current features are images but it can changed between projects)<\/p>\n<p>I heard about hdf5, but is it the best method nowadays?\nCan the the extraction be paralleled?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-09-04 21:28:12.39 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|compression|hdf5|dvc",
        "Question_view_count":37,
        "Owner_creation_date":"2019-11-15 19:21:01.88 UTC",
        "Owner_last_access_date":"2022-09-24 22:24:49.083 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Israel",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73602927",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67122683,
        "Question_title":"DVC Files Incomplete",
        "Question_body":"<p>I'm in a team using dvc with git to version-control data files. We are using dvc 1.3.1, with the an S3 bucket remote. I'm getting this error when executing <code>dvc fetch<\/code> or <code>dvc pull<\/code> on a colleague's branch:<\/p>\n<pre><code>ERROR: failed to fetch data from the cloud - DVC-file 'C:\\Users\\blah\\Documents\\repo\\data\\processed_data.dvc' format error: extra keys not allowed @ data['outs'][0]['size']\n<\/code><\/pre>\n<p>When I check the dvc file for a cached file with which I have no problem I see this:<\/p>\n<pre><code>md5: ded591aacbe363f0518ceb9c3bc1836b\nouts:\n- md5: efdab20e8b59903b9523cc188ff727e5\n  path: completion_header.p\n  cache: true\n  metric: false\n  persist: false\n<\/code><\/pre>\n<p>but a problematic file only has this:<\/p>\n<pre><code>outs:\n- md5: f4e15187d9a0bbb328e629eabd8d1784.dir\n  size: 112007\n  nfiles: 3\n  path: processed_data\n<\/code><\/pre>\n<p>In all cases, files are added to dvc with the command <code>dvc add %dirname%<\/code>. This is the second time I've seen this on a colleague's branch (2 different people).<\/p>\n<p>Since posting, I have realized that my colleague dvc'd a directory. I have attempted creating the directory first, then calling <code>dvc fetch<\/code>, but get the same error.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-16 09:30:00.113 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-04-19 09:59:01.417 UTC",
        "Question_score":2,
        "Question_tags":"git|dvc",
        "Question_view_count":548,
        "Owner_creation_date":"2012-09-20 14:07:14.833 UTC",
        "Owner_last_access_date":"2022-09-22 13:21:24.933 UTC",
        "Owner_reputation":2400,
        "Owner_up_votes":66,
        "Owner_down_votes":12,
        "Owner_views":263,
        "Answer_body":"<blockquote>\n<p>In all cases, files are added to dvc with the command dvc add %filename%.<\/p>\n<\/blockquote>\n<p>It seems like there is a high chance that one of the dvc files created in newer versions of dvc and you are trying to operate with an older version. Are all of your colleagues use the same dvc version when adding new files?<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2021-04-16 09:48:37.71 UTC",
        "Answer_score":2.0,
        "Owner_location":"Glasgow, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67122683",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":62529867,
        "Question_title":"Data version control (DVC) commands not working ---> TypeError: public() got an unexpected keyword argument 'SEP'",
        "Question_body":"<p>All of a sudden, dvc has stopped functioning.\nAny command typed fails and throws an exception.\nexample. dvc remote list results in -<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/home\/dev2\/.local\/bin\/dvc&quot;, line 5, in &lt;module&gt;\n    from dvc.main import main\n  File &quot;\/home\/dev2\/.local\/lib\/python3.6\/site-packages\/dvc\/main.py&quot;, line 6, in &lt;module&gt;\n    from dvc import analytics\n  File &quot;\/home\/dev2\/.local\/lib\/python3.6\/site-packages\/dvc\/analytics.py&quot;, line 16, in &lt;module&gt;\n    from dvc.lock import Lock, LockError\n  File &quot;\/home\/dev2\/.local\/lib\/python3.6\/site-packages\/dvc\/lock.py&quot;, line 8, in &lt;module&gt;\n    import flufl.lock\n  File &quot;\/home\/dev2\/.local\/lib\/python3.6\/site-packages\/flufl\/lock\/__init__.py&quot;, line 3, in &lt;module&gt;\n    from flufl.lock._lockfile import (\n  File &quot;\/home\/dev2\/.local\/lib\/python3.6\/site-packages\/flufl\/lock\/_lockfile.py&quot;, line 54, in &lt;module&gt;\n    public(SEP=SEP)\nTypeError: public() got an unexpected keyword argument 'SEP'\n \n<\/code><\/pre>\n<p>Any suggestions will be of great help.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2020-06-23 07:48:46.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"linux|git|dvc",
        "Question_view_count":307,
        "Owner_creation_date":"2018-08-13 13:04:32.313 UTC",
        "Owner_last_access_date":"2022-09-19 22:24:23.697 UTC",
        "Owner_reputation":449,
        "Owner_up_votes":3,
        "Owner_down_votes":2,
        "Owner_views":80,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62529867",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72473641,
        "Question_title":"How do launch experiments in DVC?",
        "Question_body":"<p>I want to launch some experiments in DVC. But when I set values of experiment parameters, DVC deletes file 'params.yaml', and experiment doesn't set in queue.<\/p>\n<p>Simplified code for example:\nPython file 'test.py':<\/p>\n<pre><code>import numpy as np\nimport json\nimport yaml\n\nparams = yaml.safe_load(open('params.yaml'))[&quot;test&quot;]\n\nprecision = np.random.random()\nrecall = params['value']\naccuracy = np.random.random()\n \n\nrows = {'precision': precision,\n        'recall': recall,\n        'accuracy': accuracy}\n\n\nwith open(params['metrics_path'], 'w') as outfile:\n    json.dump(rows, outfile)\n\nfpr = 10*np.random.random((1,10)).tolist()\ntpr = 10*np.random.random((1,10)).tolist()\n\nwith open('plot.json', 'w') as outfile2:\n    json.dump(\n      {\n        &quot;roc&quot;: [ {&quot;fpr&quot;: f, &quot;tpr&quot;: t} for f, t in zip(fpr, tpr) ]\n      }, \n      outfile2\n      )\n<\/code><\/pre>\n<p>params.yaml:<\/p>\n<pre><code>test:\n  metrics_path: &quot;scores.json&quot;\n  value: 1\n<\/code><\/pre>\n<p>dvc.yaml:<\/p>\n<pre><code>stages:\n  test:\n    cmd: python test.py\n    deps:\n    - test.py\n    params:\n    - test.metrics_path\n    - test.value\n    metrics:\n    - scores.json:\n        cache: false\n    plots:\n    - plot.json:\n        cache: false\n        x: fpr\n        y: tpr\n<\/code><\/pre>\n<p>It is strange behavior. Is it possible to fix it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_date":"2022-06-02 09:10:42.84 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|dvc",
        "Question_view_count":167,
        "Owner_creation_date":"2021-06-12 15:13:14.51 UTC",
        "Owner_last_access_date":"2022-09-23 11:35:31.3 UTC",
        "Owner_reputation":95,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>I solved my problem. It is necessary, that all files (executable scripts, 'dvc.yaml', 'params.yaml') be tracked by git. In this case <code>dvc exp run<\/code> command works correctly.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-03 08:28:54.587 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72473641",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72641284,
        "Question_title":"Undo changes in pandas Dataframe(column drops, row drops, edits performed on a single cell)",
        "Question_body":"<p>I am currently working on developing a 'undo' operation for my interface that deals with changes performed on csv files. I want to provide an option for the user to revert the changes that he had done to the csv file, these changes include edit a cell, deleting column, deleting row, adding row, adding column etc. For this I want to know, does version control works in this scenario? If yes, which data version control should I prefer? If not, please suggest me an another alternative.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-06-16 06:15:34.273 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-20 09:15:41.577 UTC",
        "Question_score":1,
        "Question_tags":"python|pandas|git|version-control|dvc",
        "Question_view_count":39,
        "Owner_creation_date":"2022-06-16 06:09:28.507 UTC",
        "Owner_last_access_date":"2022-07-21 05:33:22.853 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72641284",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70752204,
        "Question_title":"How to resolve DVC Pull Error on Pycharm?",
        "Question_body":"<p>When I execute 'DVC Pull', I get the following error<\/p>\n<pre><code>&gt; dvc pull ERROR: unexpected error - invalid syntax (tz.py, line 78)    \n&gt; Traceback (most recent call last):   File\n&gt; &quot;\/home\/jasma\/miniconda3\/envs\/earth\/lib\/python3.10\/site-packages\/dvc\/main.py&quot;,\n&gt; line 55, in main\n&gt;     ret = cmd.do_run()   File &quot;\/home\/jasma\/miniconda3\/envs\/earth\/lib\/python3.10\/site-packages\/dvc\/command\/base.py&quot;,\n &quot;\/home\/jasma\/miniconda3\/envs\/earth\/lib\/python3.10\/site-packages\/dateutil\/tz.py&quot;,\n&gt; line 78\n&gt;     `self._name`,\n&gt;     ^ SyntaxError: invalid syntax\n<\/code><\/pre>\n<p><a href=\"https:\/\/github.com\/jasma-balasangameshwara\/ml-heroku-fastapi\" rel=\"nofollow noreferrer\">How to resolve it? The link to the Github repository is <\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-01-18 08:10:42.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|dvc",
        "Question_view_count":105,
        "Owner_creation_date":"2020-01-18 12:11:33.753 UTC",
        "Owner_last_access_date":"2022-05-09 16:52:24.133 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70752204",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":68743071,
        "Question_title":"dvc.api.read() raises an \"UnicodeDecodeError\"",
        "Question_body":"<p>I am trying to acess a DICOM file [image saved in the Digital Imaging and Communications in Medicine (DICOM) format]:<\/p>\n<pre><code>import dvc.api\n\npath = 'dir\/image.dcm'\nremote = 'remote_name'\nrepo = 'git_repo'\nmode = 'r'\n\ndata = dvc.api.read(path = path, remote = remote, repo = repo, mode = mode)\n<\/code><\/pre>\n<p>When I run the previous code, and after the &quot;downloading progress bar&quot; is complete, I get the following error:<\/p>\n<pre><code>Traceback (most recent call last): File &quot;draft.py&quot;, line 7, in &lt;module&gt; mode ='r') File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\api.py&quot;, line 91, in read return fd.read() File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\encodings\\cp1252.py&quot;, line 23, in decode return codecs.charmap_decode(input,self.errors,decoding_table)[0] UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 764: character maps to &lt;undefined&gt;\n<\/code><\/pre>\n<p>I tried to overcome this issue by using the encoding argument:<\/p>\n<pre><code>data = dvc.api.read(path = path, remote = remote, repo = repo, mode = mode, encoding='ANSI')\n<\/code><\/pre>\n<p>Since, when I open a DICOM file using for example Notepad++, this is the encoding specified. However, it raises the error:<\/p>\n<pre><code>Exception ignored in: &lt;bound method Pool.__del__ of &lt;dvc.fs.pool.Pool object at 0x0000021D1347A160&gt;&gt; Traceback (most recent call last): File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\fs\\pool.py&quot;, line 42, in __del__ File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\fs\\pool.py&quot;, line 46, in close File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\dvc\\fs\\ssh\\connection.py&quot;, line 71, in close File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\paramiko\\sftp_client.py&quot;, line 194, in close File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\paramiko\\sftp_client.py&quot;, line 185, in _log File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\site-packages\\paramiko\\sftp.py&quot;, line 158, in _log File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\logging\\__init__.py&quot;, line 1372, in log File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\logging\\__init__.py&quot;, line 1441, in _log File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\my_env\\lib\\logging\\__init__.py&quot;, line 1411, in makeRecord TypeError: 'NoneType' object is not callable\n<\/code><\/pre>\n<p>I also tried <code>encoding = 'utf-8'<\/code>, but the &quot;UnicodeDecodeError&quot; continues to appear:<\/p>\n<pre><code>Traceback (most recent call last): File &quot;draft.py&quot;, line 7, in &lt;module&gt; mode ='r', encoding='utf-8') File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\ccab_env_dev\\lib\\site-packages\\dvc\\api.py&quot;, line 91, in read return fd.read() File &quot;C:\\Users\\lbrandao\\anaconda3\\envs\\ccab_env_dev\\lib\\codecs.py&quot;, line 321, in decode (result, consumed) = self._buffer_decode(data, self.errors, final) UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd0 in position 140: invalid continuation byte\n<\/code><\/pre>\n<p>Can anyone please help? Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2021-08-11 13:32:25.447 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-11 15:09:10.723 UTC",
        "Question_score":1,
        "Question_tags":"python|encoding|dvc",
        "Question_view_count":186,
        "Owner_creation_date":"2019-09-30 10:15:09.623 UTC",
        "Owner_last_access_date":"2022-09-19 14:01:39.763 UTC",
        "Owner_reputation":95,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68743071",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":58541260,
        "Question_title":"Difference between git-lfs and dvc",
        "Question_body":"<p>What is the difference between these two? We used git-lfs in my previous job and we are starting to use dvc alongside git in my current one. They both place some kind of index instead of file and can be downloaded on demand. Has dvc some improvements over the former one?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-24 12:19:46.097 UTC",
        "Question_favorite_count":5.0,
        "Question_last_edit_date":null,
        "Question_score":27,
        "Question_tags":"git|git-lfs|dvc",
        "Question_view_count":6255,
        "Owner_creation_date":"2013-07-12 12:04:03.25 UTC",
        "Owner_last_access_date":"2022-09-24 13:14:35.13 UTC",
        "Owner_reputation":382,
        "Owner_up_votes":185,
        "Owner_down_votes":1,
        "Owner_views":11,
        "Answer_body":"<p>DVC is a better replacement for <code>git-lfs<\/code>. <\/p>\n\n<p>Unlike git-lfs, DVC doesn't require installing a dedicated server; It can be used on-premises (NAS, SSH, for example) or with any major cloud provider (S3, Google Cloud, Azure).<\/p>\n\n<p>For more information: <a href=\"https:\/\/dvc.org\/doc\/use-cases\/data-and-model-files-versioning\" rel=\"noreferrer\">https:\/\/dvc.org\/doc\/use-cases\/data-and-model-files-versioning<\/a><\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2019-10-24 13:54:37.763 UTC",
        "Answer_score":10.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58541260",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67209146,
        "Question_title":"DVC - make scheduled csv dumps",
        "Question_body":"<p>Suppose we got some database (any database, that supports csv dumping), collecting raw data in real time for further usage in ML.\nOn the other side, we got DVC, that can work with csv files.<\/p>\n<p>I want to organize a scheduled run of stored SELECT to that DB with datetime parameters (and also support a manual run), to make a new csv files, and send them to DVC.<\/p>\n<p>In DVC documentation and examples I found, csv file already exists.<\/p>\n<p>Can I make this interaction with database with DVC itself, or I got something wrong, and there is a separate tool for csv dump?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-22 08:01:27.02 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"export-to-csv|dvc",
        "Question_view_count":65,
        "Owner_creation_date":"2020-02-05 20:03:01.007 UTC",
        "Owner_last_access_date":"2022-09-21 07:19:14.923 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>There are 3 steps in this process:<\/p>\n<ol>\n<li>Create a CSV dump. Many DBs have these tools but DVC does not support this natively.<\/li>\n<li>Version the CSV dump and move it to some storage. DVC does this job.<\/li>\n<li>Schedule periodical dump. You can use Cron (easy), AirFlow (not easy) or <a href=\"https:\/\/docs.github.com\/en\/actions\/reference\/events-that-trigger-workflows\" rel=\"nofollow noreferrer\">periodical jobs in GitHub Actions<\/a>\/<a href=\"https:\/\/docs.gitlab.com\/ee\/ci\/pipelines\/schedules.html\" rel=\"nofollow noreferrer\">GitLab CI\/CD<\/a>. Another project from the DVC team can help with CI\/CD option: <a href=\"https:\/\/cml.dev\" rel=\"nofollow noreferrer\">https:\/\/cml.dev<\/a>.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-22 08:56:43.75 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-04-22 09:49:00.03 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67209146",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":69725612,
        "Question_title":"Is the default DVC behavior to store connection data in git?",
        "Question_body":"<p>I've recently started to play with <a href=\"https:\/\/dvc.org\" rel=\"nofollow noreferrer\">DVC<\/a>, and I was a bit surprised to see the <a href=\"https:\/\/dvc.org\/doc\/start\/data-and-model-versioning#storing-and-sharing\" rel=\"nofollow noreferrer\">getting started docs<\/a> are suggesting to store <code>.dvc\/config<\/code> in git.<\/p>\n<p>This seemed like a fine idea at first, but then I noticed that my Azure Blob Storage account (i.e. my Azure username) is also stored in .dvc\/config, which means it would end up in git. Making it not ideal for team collaboration scenarios.<\/p>\n<p>What's even less ideal (read: really scary) is that connection strings entered using <code>dvc remote modify blah connection_string ...<\/code> also end up in <code>.dvc\/config<\/code>, making them end up in git and, in the case of open source projects, making them end up in <strong>very<\/strong> interesting places.<\/p>\n<p>Am I doing something obviously wrong? I wouldn't expect the getting started docs to go very deep into security issues, but I wouldn't expect them to store connection strings in source control either.<\/p>\n<p>My base assumption is that I'm misunderstanding\/misconfiguring something, I'd be curious to know what.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-26 15:07:48.803 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":77,
        "Owner_creation_date":"2009-08-13 10:15:52.417 UTC",
        "Owner_last_access_date":"2022-09-22 11:46:38.323 UTC",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Answer_body":"<p>DVC has few &quot;levels&quot; of config, that can be controlled with proper flag:<\/p>\n<ul>\n<li><code>--local<\/code> - repository level, ignored by git by default - designated for project-scope, sensitive data<\/li>\n<li>project - same as above, not ignored - designated to specify non-sensitive data (it is the default)<\/li>\n<li><code>--global<\/code> \/ <code>--system<\/code> - for common config for more repositories.<\/li>\n<\/ul>\n<p>More information can be found in the <a href=\"https:\/\/dvc.org\/doc\/command-reference\/config#description\" rel=\"nofollow noreferrer\">docs<\/a>.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-10-27 11:01:01.183 UTC",
        "Answer_score":1.0,
        "Owner_location":"Romania",
        "Answer_last_edit_date":"2021-10-27 11:06:04.02 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69725612",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73700203,
        "Question_title":"ERROR: Cannot add 'folder-path', because it is overlapping with other DVC tracked output:",
        "Question_body":"<p>Goal: <code>add<\/code> <code>commit<\/code> <code>push<\/code> all contents of <code>project_model\/data\/<\/code> to <strong>dvcstore<\/strong>.<\/p>\n<p>I don't have any <code>.dvc<\/code> files in my project.<\/p>\n<pre><code>$ dvc add .\/project_model\/data\/\nERROR: Cannot add '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images', because it is overlapping with other DVC tracked output: '\/home\/me\/PycharmProjects\/project\/project_model\/data'.\nTo include '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images' in '\/home\/me\/PycharmProjects\/project\/project_model\/data', run 'dvc commit project_model\/data.dvc'\n\n$ dvc commit project_model\/data.dvc\nERROR: failed to commit project_model\/data.dvc - 'project_model\/data.dvc' does not exist\n<\/code><\/pre>\n<p>I've deleted contents from <code>.dvc\/cache\/<\/code> and <strong>S3<\/strong> <code>s3:\/\/foo\/bar\/dvcstore\/<\/code>, with no luck.<\/p>\n<hr \/>\n<pre><code>$ dvc -V\n2.10.2\n<\/code><\/pre>\n<pre><code>$ dvc doctor\nDVC version: 2.10.2 (pip)\n---------------------------------\nPlatform: Python 3.9.12 on Linux-5.15.0-47-generic-x86_64-with-glibc2.35\nSupports:\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        s3 (s3fs = 2022.5.0, boto3 = 1.21.21)\nCache types: hardlink, symlink\nCache directory: ext4 on \/dev\/nvme0n1p5\nCaches: local\nRemotes: s3\nWorkspace directory: ext4 on \/dev\/nvme0n1p5\nRepo: dvc, git\n<\/code><\/pre>\n<p>Please let me know if there's anything else I can add to post.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-13 09:00:18.623 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"git|amazon-s3|caching|pycharm|dvc",
        "Question_view_count":31,
        "Owner_creation_date":"2021-09-07 12:58:02.98 UTC",
        "Owner_last_access_date":"2022-09-23 15:24:35.073 UTC",
        "Owner_reputation":234,
        "Owner_up_votes":708,
        "Owner_down_votes":14,
        "Owner_views":155,
        "Answer_body":"<p>In my case, the problem was in <code>dvc.yaml<\/code>.<\/p>\n<p>For a few <code>stages<\/code>, I had cyclical dependencies, where a file-path was mentioned in both the <code>deps<\/code> and <code>outs<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-09-14 10:05:11.323 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73700203",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72622280,
        "Question_title":"How does one add individual files with DVC?",
        "Question_body":"<p>Suppose I run the following commands:<\/p>\n<pre><code># set up DVC\n\nmkdir foo\ncd foo &amp;&amp; git init\ndvc init\ngit add * &amp;&amp; git commit -m &quot;dvc init&quot;\n\n\n# make a data file\n\nmkdir -p bar\/biz\ntouch bar\/biz\/boz\n\n\n# add the data file\n\ndvc add bar\/biz\/boz\n<\/code><\/pre>\n<p>And DVC outputs the following:<\/p>\n<pre><code>To track the changes with git, run:\n\n  git add bar\/biz\/.gitignore bar\/biz\/boz.dvc\n<\/code><\/pre>\n<hr \/>\n<p>This last part is what I would like to avoid.  Preferably, DVC would only change the top level <code>.gitignore<\/code> (located at the project root, where <code>git init<\/code> was executed), and will change only DVC files at the top level.<\/p>\n<p><strong>And here's why:<\/strong><\/p>\n<p>I have a rather large dataset developed in an original work more or less ad-hoc. This data is not systematically organized, nor do I want to organize it as-is.<\/p>\n<p>Instead, I want to incrementally add this old, bespoke data to the DVC directory tree.  And each time I add some of the data to the tree, I want to check it in with DVC as I would if I were modifying code or mixing one project's code into another.<\/p>\n<p>However, DVC wants to create a local file and gitignore at every location I add.  This creates a mess and I have no reasonable faith that it will be easy to maintain all of these atomic and distributed datastores.<\/p>\n<hr \/>\n<p><strong>The question:<\/strong><\/p>\n<p>What is the preferred way to incrementally add data in DVC so that DVC uses the root gitignore and root DVC files\/items?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-14 19:16:44.993 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"git|dvc",
        "Question_view_count":112,
        "Owner_creation_date":"2014-07-13 14:36:30.02 UTC",
        "Owner_last_access_date":"2022-09-23 21:23:45.423 UTC",
        "Owner_reputation":26244,
        "Owner_up_votes":434,
        "Owner_down_votes":35,
        "Owner_views":1383,
        "Answer_body":"<p>Assuming bar\/ is the dataset directory you're incrementally adding to, you can instead<\/p>\n<pre><code>dvc add bar\n<\/code><\/pre>\n<p>This creates a bar.dvc file and writes to .gitignore at the top level.<\/p>\n<p>When you update content in bar\/, <code>dvc add<\/code> it again or use <code>dvc commit<\/code> to register the new dataset version. The new files get added to the project cache and the .dvc file gets an updated <code>md5<\/code> hash that identifies to the latest directory structure.<\/p>\n<p>Some docs:<br \/>\n<a href=\"https:\/\/dvc.org\/doc\/start\/data-management#making-changes\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/start\/data-management#making-changes<\/a><br \/>\n<a href=\"https:\/\/dvc.org\/doc\/command-reference\/add\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/add<\/a><br \/>\n<a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-16 03:22:11.16 UTC",
        "Answer_score":0.0,
        "Owner_location":"Atlanta, GA",
        "Answer_last_edit_date":"2022-06-16 03:27:16.863 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72622280",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67635688,
        "Question_title":"Installation DVC on MinIO storage",
        "Question_body":"<p>Does anybody install DVC on MinIO storage?<\/p>\n<p>I have read <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type\" rel=\"nofollow noreferrer\">docs<\/a> but not all clear for me.<\/p>\n<p>Which command should I use for setup MinIO storage with this entrance parameters:<\/p>\n<p>storage url: <a href=\"https:\/\/minio.mysite.com\/minio\/bucket-name\/\" rel=\"nofollow noreferrer\">https:\/\/minio.mysite.com\/minio\/bucket-name\/<\/a>\nlogin: my_login\npassword: my_password<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-21 11:09:40.413 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-05-21 18:33:28.697 UTC",
        "Question_score":5,
        "Question_tags":"python|minio|dvc",
        "Question_view_count":1547,
        "Owner_creation_date":"2018-05-16 14:36:56.047 UTC",
        "Owner_last_access_date":"2022-09-23 08:33:51.783 UTC",
        "Owner_reputation":85,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p><strong>Install<\/strong><\/p>\n<p>I usually use it as a Python package, int this case you need to install:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>pip install &quot;dvc[s3]&quot;\n<\/code><\/pre>\n<p><strong>Setup remote<\/strong><\/p>\n<p>By default DVC supports AWS S3 storages and they work fine.<br \/>\nAlso they support &quot;S3-compatible storage&quot;, but setup for this type of remotes is nod described properly. In particular case of MinIO you have <strong>bucket<\/strong> - directory on MinIO server where actual data stores (it is similar to AWS bucket), but DVC uses AWS CLI to authenticate. In case of MinIO you need to pass them explicitly.<\/p>\n<p>Then follow commands to setup your DVC remote:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code># setup default remote (change &quot;bucket-name&quot; to your minio backet name)\ndvc remote add -d minio s3:\/\/bucket-name -f\n\n# add information about storage url (where &quot;https:\/\/minio.mysite.com&quot; your url)\ndvc remote modify minio endpointurl https:\/\/minio.mysite.com\n\n#  add info about login and password\ndvc remote modify minio access_key_id my_login\ndvc remote modify minio secret_access_key my_password\n<\/code><\/pre>\n<p><strong>If you move from old remote<\/strong>, use follow command to move your data:<\/p>\n<p>Before setup (download all old remote cache to local machine):<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc pull -r &lt;old_remote_name&gt; --all-commits --all-tags --all-branches\n<\/code><\/pre>\n<p>After setup (upload all cache to a new remote):<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc push -r &lt;new_remote_name&gt; --all-commits --all-tags --all-branches\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-21 12:14:45.543 UTC",
        "Answer_score":6.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67635688",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":60365473,
        "Question_title":"By how much can i approx. reduce disk volume by using dvc?",
        "Question_body":"<p>I want to classify ~1m+ documents and have a Version Control System for in- and Output of the corresponding model. <\/p>\n\n<p>The data changes over time:<\/p>\n\n<ul>\n<li>sample size increases over time<\/li>\n<li>new Features might appear<\/li>\n<li>anonymization procedure might Change over time<\/li>\n<\/ul>\n\n<p>So basically \"everything\" might change: amount of observations, Features and the values.\nWe are interested in making the ml model Building reproducible without using 10\/100+ GB \nof disk volume, because we save all updated versions of Input data. Currently the volume size of the data is ~700mb.<\/p>\n\n<p>The most promising tool i found is: <a href=\"https:\/\/github.com\/iterative\/dvc\" rel=\"noreferrer\">https:\/\/github.com\/iterative\/dvc<\/a>. Currently the data\nis stored in a database in loaded in R\/Python from there.<\/p>\n\n<p><strong>Question:<\/strong><\/p>\n\n<p>How much disk volume can be (very approx.) saved by using dvc? <\/p>\n\n<p>If one can roughly estimate that. I tried to find out if only the \"diffs\" of the data are saved. I didnt find much info by reading through: <a href=\"https:\/\/github.com\/iterative\/dvc#how-dvc-works\" rel=\"noreferrer\">https:\/\/github.com\/iterative\/dvc#how-dvc-works<\/a> or other documentation. <\/p>\n\n<p><strong>I am aware that this is a very vague question. And it will highly depend on the dataset. However, i would still be interested in getting a very approximate idea.<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-23 18:31:41.247 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":"2020-02-23 19:28:48.287 UTC",
        "Question_score":7,
        "Question_tags":"python|sql|r|git|dvc",
        "Question_view_count":689,
        "Owner_creation_date":"2017-08-30 12:46:30.907 UTC",
        "Owner_last_access_date":"2022-03-11 18:10:58.673 UTC",
        "Owner_reputation":1365,
        "Owner_up_votes":145,
        "Owner_down_votes":3,
        "Owner_views":193,
        "Answer_body":"<p>Let me try to summarize how does DVC store data and I hope you'll be able to figure our from this how much space will be saved\/consumed in your specific scenario.<\/p>\n\n<p><strong>DVC is storing and deduplicating data on the individual <em>file level<\/em>.<\/strong> So, what does it usually mean from a practical perspective.<\/p>\n\n<p>I will use <code>dvc add<\/code> as an example, but the same logic applies to all commands that save data files or directories into DVC cache - <code>dvc add<\/code>, <code>dvc run<\/code>, etc.<\/p>\n\n<h2>Scenario 1: Modifying file<\/h2>\n\n<p>Let's imagine I have a single 1GB XML file. I start tracking it with DVC:<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>$ dvc add data.xml\n<\/code><\/pre>\n\n<p>On the modern file system (or if <code>hardlinks<\/code>, <code>symlinks<\/code> are enabled, see <a href=\"https:\/\/dvc.org\/doc\/user-guide\/large-dataset-optimization\" rel=\"noreferrer\">this<\/a> for more details) after this command we still consume 1GB (even though file is moved into DVC cache and is still present in the workspace).<\/p>\n\n<p>Now, let's change it a bit and save it again:<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>$ echo \"&lt;test\/&gt;\" &gt;&gt; data.xml\n$ dvc add data.xml\n<\/code><\/pre>\n\n<p>In this case we will have 2GB consumed. <strong>DVC does not do diff between two versions of the same file<\/strong>, neither it splits files into chunks or blocks to understand that only small portion of data has changed.<\/p>\n\n<blockquote>\n  <p>To be precise, it calculates <code>md5<\/code> of each file and save it in the content addressable key-value storage. <code>md5<\/code> of the files serves as a key (path of the file in cache) and value is the file itself:<\/p>\n  \n  <pre class=\"lang-sh prettyprint-override\"><code>(.env) [ivan@ivan ~\/Projects\/test]$ md5 data.xml\n0c12dce03223117e423606e92650192c\n\n(.env) [ivan@ivan ~\/Projects\/test]$ tree .dvc\/cache\n.dvc\/cache\n\u2514\u2500\u2500 0c\n   \u2514\u2500\u2500 12dce03223117e423606e92650192c\n\n1 directory, 1 file\n\n(.env) [ivan@ivan ~\/Projects\/test]$ ls -lh data.xml\ndata.xml ----&gt; .dvc\/cache\/0c\/12dce03223117e423606e92650192c (some type of link)\n<\/code><\/pre>\n<\/blockquote>\n\n<h2>Scenario 2: Modifying directory<\/h2>\n\n<p>Let's now imagine we have a single large 1GB directory <code>images<\/code> with a lot of files:<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>$ du -hs images\n1GB\n\n$ ls -l images | wc -l\n1001\n\n$ dvc add images\n<\/code><\/pre>\n\n<p>At this point we still consume 1GB. Nothing has changed. But if we modify the directory by adding more files (or removing some of them):<\/p>\n\n<pre><code>$ cp \/tmp\/new-image.png images\n\n$ ls -l images | wc -l\n1002\n\n$ dvc add images\n<\/code><\/pre>\n\n<p>In this case, after saving the new version we <strong>still close to 1GB<\/strong> consumption. <strong>DVC calculates diff on the directory level.<\/strong> It won't be saving all the files that were existing before in the directory.<\/p>\n\n<p>The same logic applies to all commands that save data files or directories into DVC cache - <code>dvc add<\/code>, <code>dvc run<\/code>, etc.<\/p>\n\n<p>Please, let me know if it's clear or we need to add more details, clarifications.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-02-23 19:57:47.857 UTC",
        "Answer_score":12.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60365473",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":56285351,
        "Question_title":"Updating tracked dir in DVC",
        "Question_body":"<p>According to <a href=\"https:\/\/dvc.org\/doc\/user-guide\/update-tracked-file\" rel=\"nofollow noreferrer\">this tutorial<\/a> when I update file I should remove file from under DVC control first (i.e. execute <code>dvc unprotect &lt;myfile&gt;.dvc<\/code> or <code>dvc remove &lt;myfile&gt;.dvc<\/code>) and then add it again via <code>dvc add &lt;mifile&gt;<\/code>. However It's not clear if I should apply the same workflow for the directories.<\/p>\n\n<p>I have the directory under DVC control with the following structure:<\/p>\n\n<pre><code>data\/\n    1.jpg\n    2.jpg\n<\/code><\/pre>\n\n<p>Should I run <code>dvc unprotect data<\/code> every time the directory content is updated?<\/p>\n\n<p>More specifically I'm interested if I should run <code>dvc unprotect data<\/code> in the following use cases:<\/p>\n\n<ul>\n<li><strong>New file is added.<\/strong> For example if I put <code>3.jpg<\/code> image in the data dir<\/li>\n<li><strong>File is deleted.<\/strong> For example if I delete <code>2.jpg<\/code> image in the <code>data<\/code> dir<\/li>\n<li><strong>File is updated.<\/strong> For example if I edit <code>1.jpg<\/code> image via graphic editor.<\/li>\n<li>A combination of the previous use cases (i.e. some files are updated, other deleted and new files are added)<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-24 03:10:22.49 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-05-24 14:39:32.617 UTC",
        "Question_score":4,
        "Question_tags":"dvc",
        "Question_view_count":995,
        "Owner_creation_date":"2018-03-28 16:31:38.71 UTC",
        "Owner_last_access_date":"2022-09-23 10:08:33.687 UTC",
        "Owner_reputation":784,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":77,
        "Answer_body":"<p>Only when file is updated - i.e. edit <code>1.jpg<\/code> with your editor <strong>AND<\/strong> only if hadrlink or symlink cache type is enabled.<\/p>\n\n<p>Please, check this <a href=\"https:\/\/dvc.org\/doc\/user-guide\/update-tracked-file\" rel=\"nofollow noreferrer\">link<\/a>:<\/p>\n\n<blockquote>\n  <p>updating tracked files has to be carried out with caution to avoid data corruption when the DVC config option cache.type is set to hardlink or\/and symlink<\/p>\n<\/blockquote>\n\n<p>I would strongly recommend reading this document: <a href=\"https:\/\/dvc.org\/doc\/user-guide\/cache-file-linking\" rel=\"nofollow noreferrer\">Performance Optimization for Large Files<\/a> it explains benefits of using hardlinks\/symlinks.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-05-24 05:04:26.68 UTC",
        "Answer_score":2.0,
        "Owner_location":"Russia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56285351",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":68082912,
        "Question_title":"git-ignore dvc.lock in repositories where only the DVC pipelines are used",
        "Question_body":"<p>I want to use the pipeline functionality of dvc in a git repository. The data is managed otherwise and should not be versioned by dvc. The only functionality which is needed is that dvc reproduces the needed steps of the pipeline when <code>dvc repro<\/code> is called. Checking out the repository on a new system should lead to an 'empty' repository, where none of the pipeline steps are stored.<\/p>\n<p>Thus, - if I understand correctly - there is no need to track the dvc.lock file in the repository. However, adding dvc.lock to the .gitginore file leads to an error message:<\/p>\n<pre><code>ERROR: 'dvc.lock' is git-ignored.\n<\/code><\/pre>\n<p>Is there any way to disable the dvc.lock in .gitignore check for this usecase?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-22 11:40:30.233 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"dvc",
        "Question_view_count":493,
        "Owner_creation_date":"2018-11-18 10:45:00.087 UTC",
        "Owner_last_access_date":"2022-09-23 13:41:40.713 UTC",
        "Owner_reputation":147,
        "Owner_up_votes":69,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>This is definitely possible, as DVC features are loosely coupled to one another. You can do pipelining by writing your dvc.yaml file(s), but avoid data management\/versioning by using <code>cache: false<\/code> in the stage outputs (<a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/pipelines-files#output-subfields\" rel=\"nofollow noreferrer\"><code>outs<\/code> field<\/a>). See also helper <code>dvc stage add -O<\/code> (<a href=\"https:\/\/dvc.org\/doc\/command-reference\/stage\/add#options\" rel=\"nofollow noreferrer\">big O<\/a>, alias of <code>--outs-no-cache<\/code>).<\/p>\n<p>And the same for initial data dependencies, you can <code>dvc add --no-commit<\/code> them (<a href=\"https:\/\/dvc.org\/doc\/command-reference\/add#options\" rel=\"nofollow noreferrer\">ref<\/a>).<\/p>\n<p>You do want to track <a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/pipelines-files#dvclock-file\" rel=\"nofollow noreferrer\">dvc.lock<\/a> in Git though, so that DVC can determine the latest stage of the pipeline associated with the Git commit in every repo copy or branch.<\/p>\n<p>You'll be responsible for placing the right data files\/dirs (matching .dvc files and dvc.lock) in the workspace for <code>dvc repro<\/code> or <code>dvc exp run<\/code> to behave as expected. <code>dvc checkout<\/code> won't be able to help you.<\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2021-06-22 20:24:47.733 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68082912",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":71663330,
        "Question_title":"What is the advantage of DVC, git-annex, git-lfs for large or binary files over git?",
        "Question_body":"<p>If I have different versions of a file, e.g., in different branches, and I try to reconcile those, git will has great mechanisms for that. However, in order to do the reconciliations, e.g., in a merge, git requires access to the &quot;inside&quot; of the file. Thus files should be text files.<\/p>\n<p>If I change a version controlled file, git does not save the delta between those files, but safes and entire snapshot of the file. If one makes a change, even a small change, to a large file, the entire files will be stored twice by git. Thus files should be small.<\/p>\n<p>Files that are either large or binary (or both), they should not be tracked by Git. If I still need them in my project, I should use something like DVC, git-annex, git-lfs.<\/p>\n<p>As far as I understand, all three of those keep the those other files outside of git, and keep a reference, which is tracked by git. I will use DVC as a stand-in, as I know even less about the other two.<\/p>\n<ol>\n<li><p>In DVC, the reference is a text file and thus, git will not get confused. However, since it is only a reference, there is not much merging to be done by git anyways. So, git's reconciliation-capabilities are not really required. What is the advantage of using DVC then regarding this aspect? Can't I just use git and just not use those mechanisms?<\/p>\n<\/li>\n<li><p>In DVC, it seems that if I change a large file, just like in git, a snapshot of that file is created (not a delta saved). So, how does this improve the situation compared to git? I still get lots of (near) copies of this big file.<\/p>\n<\/li>\n<\/ol>\n<p>I understand from <a href=\"https:\/\/stackoverflow.com\/a\/35578715\/4533188\">here<\/a> that git-lfs keeps most of the (near) copies of my file in the remote storage. Only if I checkout the respective version of the large file, the files is downloaded. In that case, while I would be correct about my point 2, at least it is only a &quot;problem&quot; of the server (in terms of space), but not on my local disk space and also not for the internet bandwidth usage. This might be the same for DVC.<\/p>\n<p>Are my &quot;objections&quot; or &quot;caveats&quot; of the points 1 and 2 valid?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_date":"2022-03-29 13:52:24.137 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"git|git-lfs|dvc|git-annex",
        "Question_view_count":370,
        "Owner_creation_date":"2015-02-05 13:50:19.917 UTC",
        "Owner_last_access_date":"2022-09-23 12:45:06.05 UTC",
        "Owner_reputation":11374,
        "Owner_up_votes":415,
        "Owner_down_votes":2,
        "Owner_views":845,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71663330",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70560288,
        "Question_title":"DVC Shared Windows Directory Setup",
        "Question_body":"<p>I have one Linux machine and one Windows machine for developments. For data sharing, we have set up a shared Windows directory in another Windows machine, which both my Linux and Windows can access.<\/p>\n<p>I am now using <a href=\"https:\/\/dvc.org\/\" rel=\"nofollow noreferrer\">DVC<\/a> for version control of the shared data. To make it easy, I mount the shared Windows folder both in Windows and in Linux development machine. In Windows, it looks like<\/p>\n<pre><code> [core]\n    analytics = false\n    remote = remote_storage\n['remote &quot;remote_storage&quot;']\n    url = \\\\my_shared_storage\\project_dir\n<\/code><\/pre>\n<p>In Linux, it looks like:<\/p>\n<pre><code>[core]\n    analytics = false\n    remote = remote_storage\n['remote &quot;remote_storage&quot;']\n    url = \/mnt\/mount_point\/project_dir\n<\/code><\/pre>\n<p>As you can see, Windows and Linux have different mounting points. So my question is: is there a way to make that both Windows and Linux have the same <code>\u00f9rl<\/code> in the DVC configuration file?<\/p>\n<p>If this is impossible, is there another alternative solution for DVC keeps data in remote shared Windows folder? Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-02 22:41:03.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-03 08:44:24.667 UTC",
        "Question_score":1,
        "Question_tags":"linux|dvc",
        "Question_view_count":128,
        "Owner_creation_date":"2012-03-12 11:50:57.367 UTC",
        "Owner_last_access_date":"2022-09-23 13:23:56.043 UTC",
        "Owner_reputation":10643,
        "Owner_up_votes":1174,
        "Owner_down_votes":7,
        "Owner_views":504,
        "Answer_body":"<p>If you are using a local remote this way, you won't be able to have to the same <code>url<\/code> on both platforms since the mount points are different (as you already realized).<\/p>\n<p>The simplest way to configure this would be to pick one (Linux or Windows) <code>url<\/code> to use as your default case that gets git-committed into <code>.dvc\/config<\/code>. On the other platform you (or your users) can override that <code>url<\/code> in the local configuration file: <code>.dvc\/config.local<\/code>.<\/p>\n<p>(Note that <code>.dvc\/config.local<\/code> is a git-ignored file and will not be included in any commits)<\/p>\n<p>So if you wanted Windows to be the default case, in <code>.dvc\/config<\/code> you would have:<\/p>\n<pre><code> [core]\n    analytics = false\n    remote = remote_storage\n['remote &quot;remote_storage&quot;']\n    url = \\\\my_shared_storage\\project_dir\n<\/code><\/pre>\n<p>and on your Linux machine you would add the file <code>.dvc\/config.local<\/code> containing:<\/p>\n<pre><code>['remote &quot;remote_storage&quot;']\n    url = \/mnt\/mount_point\/project_dir\n<\/code><\/pre>\n<p>See the DVC docs for <code>dvc config --local<\/code> and <code>dvc remote modify --local<\/code> for more details:<\/p>\n<ul>\n<li><a href=\"https:\/\/dvc.org\/doc\/command-reference\/config#description\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/config#description<\/a><\/li>\n<li><a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#command-options-flags\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#command-options-flags<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-03 03:08:55.767 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70560288",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72665109,
        "Question_title":"dvc.exceptions.CyclicGraphError: Pipeline has a cycle involving: load_extract_save",
        "Question_body":"<pre><code>stages:\n  load_extract_save: \n    cmd: python src\/stage_01_load_extract_save.py --config=config\/config.yaml\n    deps:\n      - config\/config.yaml\n      - src\/utils\/all_utils.py\n      - src\/stage_01_load_extract_save.py\n      - artifacts\/data\n    outs:\n      - artifacts\/data\n      - artifacts\/clean_data\/X.npy\n      - artifacts\/clean_data\/Y.npy\n\n  train_test_split_save:\n    cmd: python src\/stage_02_train_test_split_save.py --config=config\/config.yaml --params=params.yaml\n    deps:\n      - artifacts\/clean_data\/X.npy\n      - artifacts\/clean_data\/Y.npy\n      - src\/utils\/all_utils.py\n      - params.yaml\n      - config\/config.yaml\n      - src\/stage_02_train_test_split_save.py\n    outs:\n      - artifacts\/train_data\/X_train.npy\n      - artifacts\/train_data\/Y_train.npy\n      - artifacts\/test_data\/X_test.npy\n      - artifacts\/test_data\/Y_test.npy\n  \n  train_model:\n    cmd:  python src\/stage_03_train.py --config=config\/config.yaml --params=params.yaml\n    deps:\n      - artifacts\/train_data\/X_train.npy\n      - artifacts\/train_data\/Y_train.npy\n      - artifacts\/test_data\/X_test.npy\n      - artifacts\/test_data\/Y_test.npy\n      - src\/stage_03_train.py\n      - src\/utils\/all_utils.py\n      - config\/config.yaml\n      - params.yaml\n    outs:\n      - artifacts\/checkpoints\n      - artifacts\/model\n  \n  metrics:\n    cmd: python src\/stage_04_metrics.py --config=config\/config.yaml\n    deps:\n      - src\/stage_04_metrics.py\n      - config\/config.yaml\n      - src\/utils\/all_utils.py\n      - artifacts\/test_data\/X_test.npy\n      - artifacts\/test_data\/Y_test.npy\n      - artifacts\/checkpoints\n      - artifacts\/model\n    outs:\n      - confusion_matrix.png\n<\/code><\/pre>\n<p>This is my DVC.yaml.<\/p>\n<p>I have created Github workflow to reproduce it, but whenever I run it it gives me the following error - <code>... ERROR: Pipeline has a cycle involving: load_extract_save.<\/code><\/p>\n<p>The error looks <a href=\"https:\/\/i.stack.imgur.com\/1mt1Y.png\" rel=\"nofollow noreferrer\">like this<\/a>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-17 21:48:47.92 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-18 03:55:59.503 UTC",
        "Question_score":2,
        "Question_tags":"python|dvc",
        "Question_view_count":38,
        "Owner_creation_date":"2020-04-19 15:08:15.27 UTC",
        "Owner_last_access_date":"2022-09-22 19:13:07.327 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>Stage <code>load_extract_save<\/code> both outputs and depends on the same path (<code>artifacts\/data<\/code>). That's a cycle.<\/p>\n<p>Pipeline structures should be <a href=\"https:\/\/dvc.org\/doc\/command-reference\/dag#directed-acyclic-graph\" rel=\"nofollow noreferrer\">directed <strong>acyclical<\/strong> graphs<\/a>, otherwise <code>dvc repro<\/code> could execute that stage over and over forever.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-18 03:51:17.717 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72665109",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":61386810,
        "Question_title":"Data version control (DVC) edit files in place results in cyclic dependency",
        "Question_body":"<p>we have a larger dataset and have several preprocessing scripts.\nThese scripts alter data in place.\nIt seems when I try to register it with <code>dvc run<\/code> it complains about cyclic dependencies (input is the same as output).\nI would assume this is a very common use case.<\/p>\n\n<p>What is the best practice here ?<\/p>\n\n<p>Tried to google around but i did not see any solution to this (besides creating another folder for the output).<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2020-04-23 12:04:31.83 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"dvc",
        "Question_view_count":45,
        "Owner_creation_date":"2018-06-26 18:15:36.153 UTC",
        "Owner_last_access_date":"2022-06-24 08:39:18.773 UTC",
        "Owner_reputation":121,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61386810",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67744934,
        "Question_title":"Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?",
        "Question_body":"<p>My team has a set up wherein we track datasets and models in DVC, and have a GitLab repository for tracking our code and DVC metadata files. We have a job in our dev GitLab pipeline (run on each push to a merge request) that has the goal of checking to be sure that the developer remembered to run <code>dvc push<\/code> to keep DVC remote storage up-to-date. Right now, the way we do this is by running <code>dvc pull<\/code> on the GitLab runner, which will fail with errors telling you which files (new files or latest versions of existing files) were not found.<\/p>\n<p>The downside to this approach is that we are loading the entirety of our data stored in DVC onto a GitLab runner, and we've run into out-of-memory issues, not to mention lengthy run time to download all that data. Since the path and md5 hash of the objects are stored in the DVC metadata files, I would think that's all the information that DVC would need to be able to answer the question &quot;is the remote storage system up-to-date&quot;.<\/p>\n<p>It seems like <code>dvc status<\/code> is similar to what I'm asking for, but compares the cache or workspace and remote storage. In other words, it requires the files to actually be present on whatever filesystem is making the call.<\/p>\n<p>Is there some way to achieve the goal I laid out above (&quot;inform the developer that they need to run <code>dvc push<\/code>&quot;) without pulling everything from DVC?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-28 20:10:29.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-29 03:04:51.983 UTC",
        "Question_score":5,
        "Question_tags":"git|gitlab|continuous-integration|dvc",
        "Question_view_count":488,
        "Owner_creation_date":"2021-04-12 19:17:42.697 UTC",
        "Owner_last_access_date":"2022-02-22 18:42:26.683 UTC",
        "Owner_reputation":75,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<blockquote>\n<p>It seems like dvc status is similar to what I'm asking for<\/p>\n<\/blockquote>\n<p><code>dvc status --cloud<\/code> will give you a list of &quot;new&quot; files if they that haven't been pushed to the (default) remote. It won't error out though, so your CI script should fail depending on the stdout message.<\/p>\n<p>More info: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/status#options\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/status#options<\/a><\/p>\n<p>I'd also ask everyone to run <code>dvc install<\/code>, which will setup some Git hooks, including automatic <code>dvc push<\/code> with <code>git push<\/code>.<\/p>\n<p>See <a href=\"https:\/\/dvc.org\/doc\/command-reference\/install\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/install<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-05-29 03:09:19.21 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-05-31 23:24:13.297 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67744934",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":56881619,
        "Question_title":"What are the pros and cons of using DVC and Pachyderm?",
        "Question_body":"<p>What are the pros and cons of using either of these?<\/p>\n\n<p><a href=\"https:\/\/github.com\/iterative\/dvc\" rel=\"nofollow noreferrer\">https:\/\/github.com\/iterative\/dvc<\/a><\/p>\n\n<p><a href=\"https:\/\/github.com\/pachyderm\/pachyderm\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pachyderm\/pachyderm<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-07-04 06:12:59.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"machine-learning|version-control|data-science|dvc|pachyderm",
        "Question_view_count":1635,
        "Owner_creation_date":"2019-07-04 06:06:43.123 UTC",
        "Owner_last_access_date":"2019-07-18 00:21:59.09 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56881619",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72651603,
        "Question_title":"Adding files that rely on pipeline outputs",
        "Question_body":"<p>In my workflow, I do the following:<\/p>\n<ol>\n<li>Acquire raw data (e.g. a video containing people)<\/li>\n<li>Transform it (e.g. automatically extract all crops with faces)<\/li>\n<li>Manually label them (e.g. identify the person in each crop). The labels are stored in json files along with the crops.<\/li>\n<li>Train a model on these data.<\/li>\n<\/ol>\n<p><strong>How should I track this pipeline with DVC?<\/strong><\/p>\n<p>My concerns:<\/p>\n<ol>\n<li>If stage 2 is changed (e.g. crops are extracted with a different size), the manual data should be invalidated (and so should the final model).<\/li>\n<li>The 3rd step is manual and therefore not precisely reproducible. But I do need its input to be reproducible.<\/li>\n<li>Stage 4 has an element of randomness, so it's not precisely reproducible either.<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-06-16 20:34:25.79 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-16 21:37:07.55 UTC",
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":39,
        "Owner_creation_date":"2011-07-22 10:25:49.88 UTC",
        "Owner_last_access_date":"2022-09-21 15:11:42.327 UTC",
        "Owner_reputation":3784,
        "Owner_up_votes":472,
        "Owner_down_votes":0,
        "Owner_views":342,
        "Answer_body":"<p>Stage 3 is manual so you can't really codify it or automate it, nor guarantee its reproducibility (due to possible human error). But there's a way to get you as close as possible:<\/p>\n<p>You could replace it with a helper script that just checks whether all the labels are annotated. If so, output a text file with content &quot;green&quot;, otherwise &quot;red&quot; (for example) and error out.<\/p>\n<p>Stage 4 should depend on both the inputs from stages 2 and 3, so it will only run if BOTH the face crops changed AND if they are thoroughly annotated.\nInternally, it first checks the semaphore file (from 3) and dies on red. On green, it trains the model :)<\/p>\n<p>The <a href=\"https:\/\/dvc.org\/doc\/command-reference\/dag#directed-acyclic-graph\" rel=\"nofollow noreferrer\">DAG<\/a> looks like this:<\/p>\n<pre><code>          +-----------+       \n          | 1-acquire |       \n          +-----------+       \n                *          \n                *          \n                *          \n          +---------+       \n          | 2-xform |       \n          +---------+       \n you      **        **     \n   --&gt;  **            **   \n       *                ** \n+---------+               *\n| 3-check |             ** \n+---------+           **   \n          **        **     \n            **    **       \n              *  *         \n          +---------+      \n          | 4-train |      \n          +---------+      \n<\/code><\/pre>\n<blockquote>\n<p>re randomness: while not ideal, non-determinism technically only <a href=\"https:\/\/dvc.org\/doc\/command-reference\/run#avoiding-unexpected-behavior\" rel=\"nofollow noreferrer\">affects intermediate stages<\/a> of the pipeline, because it causes everything after that to always run. In this case, since it's in the last stage, it won't affect DVC's job.<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-18 03:39:31.8 UTC",
        "Answer_score":2.0,
        "Owner_location":"Tel Aviv",
        "Answer_last_edit_date":"2022-06-20 06:21:51.94 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72651603",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67891465,
        "Question_title":"ERROR: bad DVC file name 'Training_Batch_Files\\Wafer12_20012.csv.dvc' is git-ignored",
        "Question_body":"<p>Getting the error &quot;<em>ERROR: bad DVC file name 'Training_Batch_Files\\Wafer12_20012.csv.dvc' is git-ignored.<\/em>&quot; while trying to add local files for tracking<\/p>\n<p>Python Version : 3.7<\/p>\n<p>Library used:<\/p>\n<p><code>pip install dvc  pip install dvc[gdrive]   dvc init   <\/code><\/p>\n<p><strong>dvc add -R Training_Batch_Files<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AVw9i.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AVw9i.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-06-08 17:00:03.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|git|dvc",
        "Question_view_count":1844,
        "Owner_creation_date":"2020-07-05 12:42:44.623 UTC",
        "Owner_last_access_date":"2022-09-24 08:16:50.69 UTC",
        "Owner_reputation":139,
        "Owner_up_votes":23,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67891465",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73727709,
        "Question_title":"Can we connect oracle database with DVC ? and if yes then how?",
        "Question_body":"<p>I was trying to connect dvc with oracle database but unable to do it. So, Please can anyone help me with that.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-09-15 08:13:03.107 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"oracle|dvc",
        "Question_view_count":20,
        "Owner_creation_date":"2022-09-15 08:08:11.407 UTC",
        "Owner_last_access_date":"2022-09-23 09:55:49.987 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73727709",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70711015,
        "Question_title":"Is there an alternative to DVC pipelines to create a DAG which is also aware of inputs\/outputs to nodes to cache results?",
        "Question_body":"<p>I recently started to use DVC pipelines to create DAG in my application. I work on Machine Learning projects, and I need to experiment a lot with different nodes of my system. For example:<\/p>\n<p><code>Data preprocessing -&gt; feature extraction -&gt; model training -&gt; model evaluation<\/code><\/p>\n<p>Each node produces an output, and the output of each node is used in another node. What DVC allows me to do is to create a pipeline in which I can specify dependencies between nodes. I also use <code>.yaml<\/code> files to configure parameters of my application, and you can also specify these parameters as dependencies for different nodes. So, whenever a dependency changes between nodes (it can be either configuration parameters or inputs\/outputs specified), DVC is able to detect this, and run the necessary parts of the pipeline. If a dependency hasn't changed for a particular node, DVC can use its cache to skip that step. This is really useful for me, since some nodes take really long time to execute, and they don't always need to be ran (if their dependencies hasn't changed).<\/p>\n<p>I also started to use hydra to manage my config files, and to be honest, DVC doesn't work well with hydra. It expects a static config to specify parameter dependencies, and with hydra it is a bit tricky to do, and complicate things.<\/p>\n<p>My question is: is there any alternative to DVC Pipelines which also goes well with hydra?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-01-14 13:05:07.82 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pipeline|directed-acyclic-graphs|dvc|hydra-core",
        "Question_view_count":181,
        "Owner_creation_date":"2019-01-21 07:32:05.357 UTC",
        "Owner_last_access_date":"2022-09-24 17:03:22.623 UTC",
        "Owner_reputation":551,
        "Owner_up_votes":9,
        "Owner_down_votes":2,
        "Owner_views":35,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Warsaw, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70711015",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":64456396,
        "Question_title":"How do I unit test a function in the CI pipeline that uses model files that are not part of the git remote?",
        "Question_body":"<p>I am developing machine learning repositories that require fairly large trained model files to run. These files are not part of the git remote but is tracked by DVC and is saved in a separate remote storage. I am running into issues when I am trying to run unit tests in the CI pipeline for functions that require these model files to make their prediction. Since I don't have access them in the git remote, I can't test them.<\/p>\n<p>What is the best practice that people usually do in this situation? I can think of couple of options -<\/p>\n<ul>\n<li>Pull the models from the DVC remote inside the CI pipeline. I don't want to do this becasue downloading models every time you want to run push some code will quickly eat up my usage minutes for CI and is an expensive option.<\/li>\n<li>Use <code>unittest.mock<\/code> to simulate the output of from the model prediction and test other parts of my code. This is what I am doing now but it's sort of a pain with unittest's mock functionalities. That module wasn't really developed with ML in mind from what I can tell. It's missing (or is hard to find) some functionalities that I would have really liked. Are there any good tools for doing this geared specifically towards ML?<\/li>\n<li>Do weird reformatting of the function definition that allows me to essentially do option 2 but without a mock module. That is, just test the surrounding logic and don't worry about the model output.<\/li>\n<li>Just put the model files in the git remote and be done with it. Only use DVC to track data.<\/li>\n<\/ul>\n<p>What do people usually do in this situation?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-21 03:48:13.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-21 18:45:23.907 UTC",
        "Question_score":4,
        "Question_tags":"unit-testing|machine-learning|mocking|continuous-integration|dvc",
        "Question_view_count":289,
        "Owner_creation_date":"2015-11-05 18:07:20.593 UTC",
        "Owner_last_access_date":"2022-09-25 05:32:55.707 UTC",
        "Owner_reputation":2545,
        "Owner_up_votes":845,
        "Owner_down_votes":386,
        "Owner_views":382,
        "Answer_body":"<p>If we talk about unit tests, I think it's indeed better to do a mock. It's best to have unit tests small, testing actual logic of the unit, etc. It's good to have other tests though that would pull the model and run some logic on top of that - I would call them integration tests.<\/p>\n<p>It's not black and white though. If you for some reason see that it's easier to use an actual model (e.g. it changes a lot and it is easier to use it instead of maintaining and updating stubs\/fixtures), you could potentially cache it.<\/p>\n<p>I think, to help you with the mock, you would need to share some technical details- how does the function look like, what have you tried, what breaks, etc.<\/p>\n<blockquote>\n<p>to do this because downloading models every time you want to run push some code will quickly eat up my usage minutes for CI and is an expensive option.<\/p>\n<\/blockquote>\n<p>I think you can potentially utilize CI systems cache to avoid downloading it over and over again. This is the GitHub Actions related <a href=\"https:\/\/github.com\/actions\/cache#cache-limits\" rel=\"nofollow noreferrer\">repository<\/a>, this is <a href=\"https:\/\/circleci.com\/docs\/2.0\/caching\" rel=\"nofollow noreferrer\">CircleCI<\/a>. The idea is the same across all common CI providers. Which one are considering to use, btw?<\/p>\n<blockquote>\n<p>Just put the model files in the git remote and be done with it. Only use DVC to track data.<\/p>\n<\/blockquote>\n<p>This can be the way, but if models are large enough you will pollute Git history significantly. On some CI systems it can become even slower since they will be fetching this with regular <code>git clone<\/code>. Effectively, downloading models anyway.<\/p>\n<p>Btw, if you use DVC or not take a look at another open-source project that is made specifically to do CI\/CD for ML - <a href=\"https:\/\/cml.dev\" rel=\"nofollow noreferrer\">CML<\/a>.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-10-21 21:04:50.77 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-10-22 00:09:09.59 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64456396",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70693420,
        "Question_title":"DVC(Data Version Control) keeps stuck at \"dvc add xxx\" with \"Collecting stages from the workspace\" in the terminal?",
        "Question_body":"<p>I used : <code>dvc[webhdfs]==2.9.3<\/code>, installed by <code>pip install dvc[webhdfs]<\/code><\/p>\n<p>Then the repo is already cloned by git.<\/p>\n<p>I have also typed : <code>dvc remote add -d storage webhdfs:\/\/xxx\/dvc<\/code> and <code>git add .dvc\/config<\/code><\/p>\n<p>But the command <code>dvc add .\/assets\/xxx\/*<\/code> was still stuck...<\/p>\n<p>The command line window keeps showing : <code>Collecting stages from the workspace<\/code><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-01-13 08:24:36.767 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-13 10:11:54.663 UTC",
        "Question_score":1,
        "Question_tags":"python|deployment|continuous-integration|dvc",
        "Question_view_count":115,
        "Owner_creation_date":"2019-03-24 03:57:13.283 UTC",
        "Owner_last_access_date":"2022-07-29 12:48:42.787 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Beijing",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70693420",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67393339,
        "Question_title":"dvc push, change the names of files on the remote storage",
        "Question_body":"<p>I'm working on a project with DVC (Data Version Control), when I push files in my remote storage, the name of the files are changed. How I can conserve the names?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-04 23:20:53.717 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-04 23:30:22.37 UTC",
        "Question_score":2,
        "Question_tags":"dvc",
        "Question_view_count":447,
        "Owner_creation_date":"2013-09-20 14:02:00.45 UTC",
        "Owner_last_access_date":"2022-09-21 22:02:08.603 UTC",
        "Owner_reputation":43,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>Short answer: there is no way to do that.<\/p>\n<p>Long answer:\nDvc remote is a content-based storage, so names are not preserved. Dvc creates metafiles (*.dvc files) in your workspace that contain names and those files are usually tracked by git, so you need to use git remote and dvc remote together to have both filenames and their contents. Here is a more detailed explanation about the format of local and remote storage <a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory\" rel=\"noreferrer\">https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory<\/a> . Also, checkout <a href=\"https:\/\/dvc.org\/doc\/use-cases\/sharing-data-and-model-files\" rel=\"noreferrer\">https:\/\/dvc.org\/doc\/use-cases\/sharing-data-and-model-files<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-04 23:40:51.067 UTC",
        "Answer_score":5.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67393339",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":63374869,
        "Question_title":"Initializing a DVC repository throws an error",
        "Question_body":"<p>I'm trying to use <a href=\"https:\/\/dvc.org\/\" rel=\"nofollow noreferrer\">DVC<\/a> and I'm following this kaggle tutorial as explained in this <a href=\"https:\/\/www.kaggle.com\/kurianbenoy\/introduction-to-data-version-control-dvc\" rel=\"nofollow noreferrer\">notebook<\/a> . Whenever I try to use the command <code>! dvc init<\/code>, I get the following error:<\/p>\n<pre><code>'dvc' is not recognized as an internal or external command,\noperable program or batch file.\n<\/code><\/pre>\n<p>I've installed and reinstalled dvc. I'm using python 3.6 and windows 8.1.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2020-08-12 10:43:58.987 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|python-3.x|version-control|dvc",
        "Question_view_count":1361,
        "Owner_creation_date":"2018-03-31 13:15:46.213 UTC",
        "Owner_last_access_date":"2022-09-07 02:28:21.417 UTC",
        "Owner_reputation":149,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Manipal, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63374869",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":57966851,
        "Question_title":"Undo 'dvc add' operation",
        "Question_body":"<p>I <code>dvc add<\/code>-ed a file I did not mean to add. I have not yet committed.<\/p>\n\n<p>How do I undo this operation? In Git, you would do <code>git rm --cached &lt;filename&gt;<\/code>.<\/p>\n\n<p>To be clear: I want to make DVC forget about the file, and I want the file to remain untouched in my working tree. This is the opposite of what <code>dvc remove<\/code> does.<\/p>\n\n<p>One <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1524\" rel=\"nofollow noreferrer\">issue<\/a> on the DVC issue tracker suggests that <code>dvc unprotect<\/code> is the right command. But reading the <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/unprotect\" rel=\"nofollow noreferrer\">manual page<\/a> suggests otherwise.<\/p>\n\n<p>Is this possible with DVC?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-17 03:12:07.047 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"dvc",
        "Question_view_count":1304,
        "Owner_creation_date":"2013-11-05 00:28:27 UTC",
        "Owner_last_access_date":"2022-09-24 23:19:30.95 UTC",
        "Owner_reputation":10846,
        "Owner_up_votes":1581,
        "Owner_down_votes":95,
        "Owner_views":984,
        "Answer_body":"<p>As per mroutis on the DVC Discord server:<\/p>\n\n<ol>\n<li><code>dvc unprotect<\/code> the file; this won't be necessary if you don't use <code>symlink<\/code> or <code>hardlink<\/code> caching, but it can't hurt.<\/li>\n<li>Remove the .dvc file<\/li>\n<li>If you need to delete the cache entry itself, run <code>dvc gc<\/code>, or look up the MD5 in <code>data.dvc<\/code> and manually remove it from <code>.dvc\/cache<\/code>.<\/li>\n<\/ol>\n\n<p><em>Edit<\/em> -- there is now an issue on their Github page to add this to the manual: <a href=\"https:\/\/github.com\/iterative\/dvc.org\/issues\/625\" rel=\"nofollow noreferrer\">https:\/\/github.com\/iterative\/dvc.org\/issues\/625<\/a><\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2019-09-17 04:18:09.197 UTC",
        "Answer_score":7.0,
        "Owner_location":"New York",
        "Answer_last_edit_date":"2019-09-17 13:12:46.083 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57966851",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72551630,
        "Question_title":"How to setup a DVC shared cache without git repository between different services in minikube?",
        "Question_body":"<p>I need to setup a shared cache in minikube in such a way that different services can use that cache to pull and update DVC models and data needed for training Machine Learning models. The structure of the project is to use 1 pod to periodically update the cache with new models and outputs. Then, multiple pods can read the cache to recreate the updated models and data. So I need to be able to update the local cache directory and pull from it using DVC commands, so that all the services have consistent view on the latest models and data created by a service.<\/p>\n<p>More specifically, I have a docker image called <code>inference-service<\/code> that should only <code>dvc pull<\/code> or some how use the info in the shared dvc cache to get the latest model and data locally in <code>models<\/code> and <code>data<\/code> folders (see dockerfile) in minikube. I have another image called <code>test-service<\/code> that\nruns the ML pipeline using <code>dvc repro<\/code> which creates the models and data that DVC needs (dvc.yaml) to track and store in the shared cache. So <code>test-service<\/code> should push created outputs from the ML pipeline into the shared cache so that <code>inference-service<\/code> can pull it and use it instead of running dvc repro by itself. <code>test-service<\/code> should only re-train and write the updated models and data into the shared cache while <code>inference-service<\/code> should only read and recreate the updated\/latest models and data from the shared cache.<\/p>\n<p><em><strong>Problem: the cache does get mounted on the minikube VM, but the inference service does not pull (using <code>dvc pull -f<\/code>) the data and models after the test service is done with <code>dvc repro<\/code> and results the following warnings and failures:<\/strong><\/em><\/p>\n<p><em>relevant kubernetes pod log of inference-service<\/em><\/p>\n<pre><code>WARNING: Output 'data\/processed\/train_preprocessed.pkl'(stage: 'preprocess') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit preprocess` to associate existing 'data\/processed\/train_preprocessed.pkl' with stage: 'preprocess'.\nWARNING: Output 'data\/processed\/validation_preprocessed.pkl'(stage: 'preprocess') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit preprocess` to associate existing 'data\/processed\/validation_preprocessed.pkl' with stage: 'preprocess'.\nWARNING: Output 'data\/processed\/test_preprocessed.pkl'(stage: 'preprocess') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit preprocess` to associate existing 'data\/processed\/test_preprocessed.pkl' with stage: 'preprocess'.\nWARNING: Output 'data\/interim\/train_featurized.pkl'(stage: 'featurize') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit featurize` to associate existing 'data\/interim\/train_featurized.pkl' with stage: 'featurize'.\nWARNING: Output 'data\/interim\/validation_featurized.pkl'(stage: 'featurize') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit featurize` to associate existing 'data\/interim\/validation_featurized.pkl' with stage: 'featurize'.\nWARNING: Output 'data\/interim\/test_featurized.pkl'(stage: 'featurize') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nYou can also use `dvc commit featurize` to associate existing 'data\/interim\/test_featurized.pkl' with stage: 'featurize'.\nWARNING: Output 'models\/mlb.pkl'(stage: 'featurize') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nWARNING: Output 'models\/tfidf_vectorizer.pkl'(stage: 'featurize') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nWARNING: Output 'models\/model.pkl'(stage: 'train') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nWARNING: Output 'reports\/scores.json'(stage: 'evaluate') is missing version info. Cache for it will not be collected. Use `dvc repro` to get your pipeline up to date.\nWARNING: No file hash info found for '\/root\/models\/model.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/reports\/scores.json'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/processed\/train_preprocessed.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/processed\/validation_preprocessed.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/processed\/test_preprocessed.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/interim\/train_featurized.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/interim\/validation_featurized.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/data\/interim\/test_featurized.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/models\/mlb.pkl'. It won't be created.\nWARNING: No file hash info found for '\/root\/models\/tfidf_vectorizer.pkl'. It won't be created.\n10 files failed\nERROR: failed to pull data from the cloud - Checkout failed for following targets:\n\/root\/models\/model.pkl\n\/root\/reports\/scores.json\n\/root\/data\/processed\/train_preprocessed.pkl\n\/root\/data\/processed\/validation_preprocessed.pkl\n\/root\/data\/processed\/test_preprocessed.pkl\n\/root\/data\/interim\/train_featurized.pkl\n\/root\/data\/interim\/validation_featurized.pkl\n\/root\/data\/interim\/test_featurized.pkl\n\/root\/models\/mlb.pkl\n\/root\/models\/tfidf_vectorizer.pkl\nIs your cache up to date?\n<\/code><\/pre>\n<p><em>relevant kubernetes pod log of test-service<\/em><\/p>\n<pre><code>Stage 'preprocess' is cached - skipping run, checking out outputs\nGenerating lock file 'dvc.lock'\nUpdating lock file 'dvc.lock'\nStage 'featurize' is cached - skipping run, checking out outputs\nUpdating lock file 'dvc.lock'\nStage 'train' is cached - skipping run, checking out outputs\nUpdating lock file 'dvc.lock'\nStage 'evaluate' is cached - skipping run, checking out outputs\nUpdating lock file 'dvc.lock'\nUse `dvc push` to send your updates to remote storage.\n<\/code><\/pre>\n<p><strong>Project Tree<\/strong><\/p>\n<pre><code>\u251c\u2500 .dvc\n\u2502  \u251c\u2500 .gitignore\n\u2502  \u251c\u2500 config\n\u2502  \u2514\u2500 tmp\n\u251c\u2500 deployment\n\u2502  \u251c\u2500 docker-compose\n\u2502  \u2502  \u251c\u2500 docker-compose.yml\n\u2502  \u251c\u2500 minikube-dep\n\u2502  \u2502  \u251c\u2500 inference-test-services_dep.yaml\n\u2502  \u251c\u2500 startup_minikube_with_mount.sh.sh\n\u251c\u2500 Dockerfile # for inference service\n\u251c\u2500 dvc-cache # services should push and pull from this cache folder and see this as the DVC repo\n\u251c- dvc.yaml\n\u251c- params.yaml\n\u251c\u2500 src\n\u2502  \u251c\u2500 build_features.py\n|  \u251c\u2500 preprocess_data.py\n|  \u251c\u2500 serve_model.py\n|  \u251c\u2500 startup.sh  \n|  \u251c\u2500 requirements.txt\n\u251c\u2500 test_dep\n\u2502  \u251c\u2500 .dvc # same as .dvc in the root folder\n|  |  \u251c\u2500...\n\u2502  \u251c\u2500 Dockerfile # for test service\n\u2502  \u251c\u2500 dvc.yaml\n|  \u251c\u2500 params.yaml\n\u2502  \u2514\u2500 src\n\u2502     \u251c\u2500 build_features.py # same as root src folder\n|     \u251c\u2500 preprocess_data.py # same as root src folder\n|     \u251c\u2500 serve_model.py # same as root src folder\n|     \u251c\u2500 startup_test.sh  \n|     \u251c\u2500 requirements.txt  # same as root src folder\n<\/code><\/pre>\n<p><strong>dvc.yaml<\/strong><\/p>\n<pre><code>stages:\n  preprocess:\n    cmd: python ${preprocess.script}\n    params:\n      - preprocess\n    deps:\n      - ${preprocess.script}\n      - ${preprocess.input_train}\n      - ${preprocess.input_val}\n      - ${preprocess.input_test}\n    outs:\n      - ${preprocess.output_train}\n      - ${preprocess.output_val}\n      - ${preprocess.output_test}\n  featurize:\n    cmd: python ${featurize.script}\n    params:\n      - preprocess\n      - featurize\n    deps:\n      - ${featurize.script}\n      - ${preprocess.output_train}\n      - ${preprocess.output_val}\n      - ${preprocess.output_test}\n    outs:\n      - ${featurize.output_train}\n      - ${featurize.output_val}\n      - ${featurize.output_test}\n      - ${featurize.mlb_out}\n      - ${featurize.tfidf_vectorizer_out}\n  train:\n    cmd: python ${train.script}\n    params:\n      - featurize\n      - train\n    deps:\n      - ${train.script}\n      - ${featurize.output_train}\n    outs:\n      - ${train.model_out}\n  evaluate:\n    cmd: python ${evaluate.script}\n    params:\n      - featurize\n      - train\n      - evaluate\n    deps:\n      - ${evaluate.script}\n      - ${train.model_out}\n      - ${featurize.output_val}\n    metrics:\n      - ${evaluate.scores_path}\n<\/code><\/pre>\n<p><strong>params.yaml<\/strong><\/p>\n<pre><code>preprocess:\n  script: src\/preprocess\/preprocess_data.py\n  input_train: data\/raw\/train.tsv\n  input_val: data\/raw\/validation.tsv\n  input_test: data\/raw\/test.tsv\n  output_train: data\/processed\/train_preprocessed.pkl\n  output_val: data\/processed\/validation_preprocessed.pkl\n  output_test: data\/processed\/test_preprocessed.pkl\n\nfeaturize:\n  script: src\/features\/build_features.py\n  output_train: data\/interim\/train_featurized.pkl\n  output_val: data\/interim\/validation_featurized.pkl\n  output_test: data\/interim\/test_featurized.pkl\n  mlb_out: models\/mlb.pkl\n  tfidf_vectorizer_out: models\/tfidf_vectorizer.pkl\n\ntrain:\n  script: src\/models\/train_model.py\n  model_out: models\/model.pkl\n\nevaluate:\n  script: src\/models\/evaluate_model.py\n  scores_path: reports\/scores.json\n  roc_json: reports\/roc_plot.json\n  prc_json: reports\/prc_plot.json\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-08 20:07:48.09 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-13 21:50:56.467 UTC",
        "Question_score":0,
        "Question_tags":"docker|kubernetes|minikube|dvc",
        "Question_view_count":196,
        "Owner_creation_date":"2019-07-06 08:50:39.337 UTC",
        "Owner_last_access_date":"2022-08-02 18:08:37.997 UTC",
        "Owner_reputation":298,
        "Owner_up_votes":14,
        "Owner_down_votes":1,
        "Owner_views":47,
        "Answer_body":"<p>After running <code>dvc repro<\/code> in <code>test-service<\/code>, a new <code>dvc.lock<\/code> will be created, containing the file hashes relative to your pipeline (i.e. the hash for <code>models\/model.pkl<\/code> etc).<\/p>\n<p>If you're running a shared cache, <code>inference-service<\/code> should have access to the updated <code>dvc.lock<\/code>. If that is present, it will be sufficient to run <code>dvc checkout<\/code> to populate the workspace with the files corresponding to the hashes in the shared cache.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-06-10 15:37:00.463 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72551630",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":68004538,
        "Question_title":"Is dvc.yaml supposed to be written or generated by dvc run command?",
        "Question_body":"<p>Trying to understand <a href=\"https:\/\/dvc.org\/doc\/start\" rel=\"nofollow noreferrer\">dvc<\/a>, most tutorials mention generation of dvc.yaml by running <code>dvc run<\/code> command.<\/p>\n<p>But at the same time, dvc.yaml which defines the DAG is also <a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/pipelines-files\" rel=\"nofollow noreferrer\">well documented<\/a>. Also the fact that it is a yaml format and human readable\/writable would point to the fact that it is meant to be a DSL for specifying your data pipeline.<\/p>\n<p>Can somebody clarify which is the better practice?\nWriting the dvc.yaml or let it be generated by <code>dvc run<\/code> command?\nOr is it left to user's choice and there is no technical difference?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-16 14:19:55.94 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-06-16 19:58:05.37 UTC",
        "Question_score":5,
        "Question_tags":"directed-acyclic-graphs|data-pipeline|dvc",
        "Question_view_count":1101,
        "Owner_creation_date":"2009-05-27 17:42:14.993 UTC",
        "Owner_last_access_date":"2022-09-23 06:17:58.327 UTC",
        "Owner_reputation":1547,
        "Owner_up_votes":28,
        "Owner_down_votes":9,
        "Owner_views":212,
        "Answer_body":"<p>I'd recommend manual editing as the main route! (I believe that's officially recommended since <a href=\"https:\/\/dvc.org\/blog\/dvc-2-0-release\" rel=\"nofollow noreferrer\">DVC 2.0<\/a>)<\/p>\n<p><code>dvc stage add<\/code> can still be very helpful for programmatic generation of pipelines files, but it doesn't support all the features of <code>dvc.yaml<\/code>, for example setting <code>vars<\/code> values or defining <a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/pipelines-files#foreach-stages\" rel=\"nofollow noreferrer\"><code>foreach<\/code> stages<\/a>.<\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2021-06-16 16:00:05.94 UTC",
        "Answer_score":4.0,
        "Owner_location":"Gothenburg, Sweden",
        "Answer_last_edit_date":"2021-06-16 20:39:37.407 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68004538",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67505910,
        "Question_title":"Problem running a Docker container in Gitlab CI\/CD",
        "Question_body":"<p>I am trying to build and run my Docker image using Gitlab CI\/CD, but there is one issue I can't fix even though locally everything works well.<\/p>\n<p>Here's my Dockerfile:<\/p>\n<pre><code>FROM &lt;internal_docker_repo_image&gt;\nRUN apt update &amp;&amp; \\\n    apt install --no-install-recommends -y build-essential gcc\nCOPY requirements.txt \/requirements.txt\n\nRUN pip install --no-cache-dir --user -r \/requirements.txt\n\nCOPY . \/src\nWORKDIR \/src\nENTRYPOINT [&quot;python&quot;, &quot;-m&quot;, &quot;dvc&quot;, &quot;repro&quot;]\n<\/code><\/pre>\n<p>This is how I run the container:<\/p>\n<p><code>docker run --volume ${PWD}:\/src --env=GOOGLE_APPLICATION_CREDENTIALS=&lt;path_to_json&gt; &lt;image_name&gt; .\/dvc_configs\/free\/dvc.yaml --force<\/code><\/p>\n<p>Everything works great when running this locally, but it fails when run on Gitlab CI\/CD.<\/p>\n<pre><code>stages:\n  - build_image\n\nbuild_image:\n  stage: build_image\n  image: &lt;internal_docker_repo_image&gt;\n  script:\n    - echo &quot;Building Docker image...&quot;\n    - mkdir ~\/.docker\n    - cat $GOOGLE_CREDENTIALS &gt; ${CI_PROJECT_DIR}\/key.json\n    - docker build . -t &lt;image_name&gt;\n    - docker run --volume ${PWD}:\/src --env=GOOGLE_APPLICATION_CREDENTIALS=&lt;path_to_json&gt; &lt;image_name&gt; .\/dvc_configs\/free\/dvc.yaml --force\n  artifacts:\n        paths:\n          - &quot;.\/data\/*csv&quot;\n        expire_in: 1 week\n\n<\/code><\/pre>\n<p>This results in the following error:\n<code>ERROR: you are not inside of a DVC repository (checked up to mount point '\/src')<\/code><\/p>\n<p>Just in case you don't know what DVC is, this is a tool used in machine learning for versioning your models, datasets, metrics, and, in addition, setting up your pipelines, which I use it for in my case.<\/p>\n<p>Essentially, it requires two folders <code>.dvc<\/code> and <code>.git<\/code> in the directory from which <code>dvc repro<\/code> is executed.<\/p>\n<p>In this particular case, I have no idea why it's not able to run this command given that the contents of the folders are exactly the same and both <code>.dvc<\/code> and <code>.git<\/code> exist.<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-12 14:44:55.847 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"docker|continuous-integration|gitlab-ci|dvc",
        "Question_view_count":746,
        "Owner_creation_date":"2016-01-07 12:19:30.337 UTC",
        "Owner_last_access_date":"2022-09-24 05:18:01.01 UTC",
        "Owner_reputation":576,
        "Owner_up_votes":431,
        "Owner_down_votes":4,
        "Owner_views":68,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67505910",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67215839,
        "Question_title":"Use parameters from additional configs in dvc 2.0",
        "Question_body":"<p>Using dvc version 2.0.18 and python 3.9.2 I want to use parameters defined in a config file different from params.yaml when configuring the parameters of the stages in <code>dvc.yaml<\/code>. However, it does not work as I expected.<\/p>\n<p>MWE:\nGit repo + dvc init:<\/p>\n<pre><code>.\n\u251c\u2500\u2500 dvc.yaml\n\u251c\u2500\u2500 preproc.yaml\n\u2514\u2500\u2500 test.py\n<\/code><\/pre>\n<p>dvc.yaml:<\/p>\n<pre><code>vars:\n  - preproc.yaml\nstages:\n  test:\n    cmd: python test.py\n    deps:\n      - test.py\n    params:\n      - important_parameter\n<\/code><\/pre>\n<p>preproc.yaml:<\/p>\n<pre><code>important_parameter: 123\n<\/code><\/pre>\n<p>Running <code>dvc repro<\/code> lead to the following error:<\/p>\n<pre><code>ERROR: failed to reproduce 'dvc.yaml': dependency 'params.yaml' does not exist\n<\/code><\/pre>\n<p>Creating a dummy params.yaml without content gives:<\/p>\n<pre><code>WARNING: 'params.yaml' is empty.\nERROR: failed to reproduce 'dvc.yaml': Parameters 'important_parameter' are missing from 'params.yaml'.\n<\/code><\/pre>\n<p>What am I missing? Is this possible at all with the templating feature?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-04-22 15:00:54.467 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|dvc",
        "Question_view_count":588,
        "Owner_creation_date":"2018-11-18 10:45:00.087 UTC",
        "Owner_last_access_date":"2022-09-23 13:41:40.713 UTC",
        "Owner_reputation":147,
        "Owner_up_votes":69,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>I think you don't need the templating feature in this case. As shown in this <a href=\"https:\/\/dvc.org\/doc\/command-reference\/params#examples-python-parameters-file\" rel=\"nofollow noreferrer\">example<\/a>:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>stages:\n  train:\n    cmd: python train.py\n    deps:\n      - users.csv\n    params:\n      - params.py:\n          - BOOL\n          - INT\n          - TrainConfig.EPOCHS\n          - TrainConfig.layers\n    outs:\n      - model.pkl\n<\/code><\/pre>\n<p>The way to redefine the default <code>params.yaml<\/code> is to specify the file name explicitly in the <code>params:<\/code> section:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>params:\n  - preproc.yaml:\n    - important_parameter\n<\/code><\/pre>\n<p>Also, when you create a stage either with <a href=\"https:\/\/dvc.org\/doc\/command-reference\/run\" rel=\"nofollow noreferrer\"><code>dvc run<\/code><\/a> (not recommended) or <a href=\"https:\/\/dvc.org\/doc\/command-reference\/stage\/add\" rel=\"nofollow noreferrer\"><code>dvc stage add<\/code><\/a>, you can provide the params file name explicitly as a prefix:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc run -n train -d train.py -d logs\/ -o users.csv -f \\\n          -p parse_params.yaml:threshold,classes_num \\\n          python train.py\n<\/code><\/pre>\n<p>Here ^^ <code>parse_params.yaml<\/code> is a custom params file.<\/p>\n<p>Please, let me know if it solves the problem and if you have any other questions :)<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-04-22 21:34:02.127 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67215839",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67421254,
        "Question_title":"How to add a file to a dvc-tracked folder without pulling the whole folder's content?",
        "Question_body":"<p>Let's say I am working inside a git\/dvc repo. There is a folder <code>data<\/code> containing 100k small files. I track it with DVC as a single element, as recommended by the doc:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc add data\n<\/code><\/pre>\n<p>and because in my experience, DVC is kinda slow when tracking that many files one by one.<\/p>\n<p>I clone the repo on another workspace, and now I have the <code>data.dvc<\/code> file locally but none of the actual files inside yet. I want to add a file named <code>newfile.txt<\/code> to the <code>data<\/code> folder and track it with DVC. Is there a way to do this <em>without pulling the whole content of <code>data<\/code> locally<\/em> ?<\/p>\n<p>What I have tried for now:<\/p>\n<ol>\n<li><p>Adding the <code>data<\/code> folder again:<\/p>\n<pre><code>mkdir data\nmv path\/to\/newfile.txt data\/newfile.txt\ndvc add data\n<\/code><\/pre>\n<p>The <code>data.dvc<\/code> file is built again from the local state of <code>data<\/code> which only contains <code>newfile.txt<\/code> so this doesn't work.<\/p>\n<\/li>\n<li><p>Adding the file as a single element in <code>data<\/code> folder:<\/p>\n<pre><code> dvc add data\/newfile.txt\n<\/code><\/pre>\n<p>I get :<\/p>\n<pre><code> Cannot add 'data\/newfile.txt', because it is overlapping with other DVC tracked output: 'data'. \n To include 'data\/newfile.txt' in 'data', run 'dvc commit data.dvc'\n<\/code><\/pre>\n<\/li>\n<li><p>Using dvc commit as suggested<\/p>\n<pre><code> mkdir data\n mv path\/to\/newfile.txt data\/newfile.txt\n dvc commit data.dvc\n<\/code><\/pre>\n<p>Similarly as 1., the <code>data.dvc<\/code> is rebuilt again from local state of <code>data<\/code>.<\/p>\n<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-06 15:25:19.22 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-06 15:28:32.033 UTC",
        "Question_score":3,
        "Question_tags":"dvc",
        "Question_view_count":1781,
        "Owner_creation_date":"2021-05-06 14:35:20.937 UTC",
        "Owner_last_access_date":"2021-07-20 09:38:49.723 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67421254",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":56035696,
        "Question_title":"Version control for machine learning data set with large amount of images?",
        "Question_body":"<p>We starting to use <a href=\"https:\/\/dvc.org\/\" rel=\"noreferrer\">dvc<\/a>  with git to control versioning of machine learning projects.\nFor dvc remote storage  we use google cloud storage.<\/p>\n\n<p>Our data set is OCR data set with more than 100000 small images, total size is about 200 MB.\nUsing  dvc to track this data set we encountered with next  problems:<\/p>\n\n<ol>\n<li>It took a lot of time to add data set for tracking.<\/li>\n<li>Very slow upload.<\/li>\n<li>Very slow download.<\/li>\n<li>Update\/delete\/add just one image in data set cause dvc to recompute\na lot of things : hashes etc....<\/li>\n<\/ol>\n\n<p>From another way if we zipping our data set and track it as single file  dvc work fast enough.But the problem is in this way we can't track changes for particular file.<\/p>\n\n<p>The goal is to have version control for data set with large amount of files with next functionality.<\/p>\n\n<ol>\n<li>Tracking for each single file.<\/li>\n<li>Committing only changes and not whole data set.<\/li>\n<li>Fast checkout\/pull<\/li>\n<\/ol>\n\n<p>Any suggestion for better solution acceptable.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":8,
        "Question_creation_date":"2019-05-08 07:33:24.753 UTC",
        "Question_favorite_count":5.0,
        "Question_last_edit_date":null,
        "Question_score":10,
        "Question_tags":"git|machine-learning|google-cloud-storage|dvc",
        "Question_view_count":856,
        "Owner_creation_date":"2014-07-09 13:28:02.227 UTC",
        "Owner_last_access_date":"2020-11-15 16:01:42.947 UTC",
        "Owner_reputation":321,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56035696",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":70928144,
        "Question_title":"Multiple users in DVC",
        "Question_body":"<p>I would like to ask if it is possible to use DVC with several accounts on the same machine. At the moment, all commands (<code>dvc pull<\/code>, <code>dvc push<\/code>, ...) are executed under my name. But after several people joined this project too, I do not want them to execute commands under my name.<\/p>\n<p>When I was alone on this project I generated ssh key:<\/p>\n<pre><code>ssh-keygen\n<\/code><\/pre>\n<p>Connected to server where DVC remote data is stored:<\/p>\n<pre><code>ssh-copy-id username@server_IP\n<\/code><\/pre>\n<p>Created config file which lets me execute all <code>dvc<\/code> commands using ssh:<\/p>\n<pre><code>[core]\n    remote = storage_server\n['remote &quot;storage_server&quot;']\n    url = ssh:\/\/username@server_IP:\/home\/DVC_remote\/DVC_project\n<\/code><\/pre>\n<p>What I should do so that several people could execute commands on their own name?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-31 15:03:42.88 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"dvc",
        "Question_view_count":181,
        "Owner_creation_date":"2016-03-08 20:35:01.7 UTC",
        "Owner_last_access_date":"2022-09-15 06:24:00.44 UTC",
        "Owner_reputation":585,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":54,
        "Answer_body":"<p>You need to make the &quot;username&quot; part of the config personalized based on who is running the command. There are a few options to do this (based on <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type\" rel=\"nofollow noreferrer\">this document<\/a>, see the SSH part):<\/p>\n<h2>Basic options are:<\/h2>\n<ul>\n<li>User defined in the SSH config file (e.g. <code>~\/.ssh\/config<\/code>) for this host (URL);<\/li>\n<li>Current system user;<\/li>\n<\/ul>\n<p>So, the simplest even options could be just remove it from the URL and rely on the current system user?<\/p>\n<h2>Local (git-ignored or per-project DVC config) config<\/h2>\n<p>You could do is to remove the <code>username<\/code> part from the <code>url<\/code> and run something like this:<\/p>\n<pre><code>dvc remote modify --local storage_server user username\n<\/code><\/pre>\n<p><code>--local<\/code> here means that DVC will create a separate additional config that will be ignored by Git. This way if every user runs this command in every project they use they will customize the username.<\/p>\n<hr \/>\n<p>Let me know if that helps or something doesn't work. I'll try to help.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-01-31 17:45:43.317 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70928144",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":56818930,
        "Question_title":"\"dvc push\" after several local commits",
        "Question_body":"<p>I work on a project with DVC (Data version control). Let's say I make a lot of local commits. Something like this:<\/p>\n\n<pre><code># make changes for experiment 1\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 1\"\n\n# make changes for experiment 2\n# which change both code and data\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 2\"\n\n# make changes for experiment 3\n# which change both code and data\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 3\"\n\n# Finally I'm done\n# push changes:\ndvc push\ngit push\n<\/code><\/pre>\n\n<p>However there is one problem: <code>dvc push<\/code> will only push data from experiment 3. Is there any way to push data from all local commits (i.e. starting from the first commit diverged from remote branch)?<\/p>\n\n<p>Currently I see two options:<\/p>\n\n<ol>\n<li>Tag each commit and push it with <code>dvc push -T<\/code><\/li>\n<li>After \"expermient 3\" commit execute <code>git checkout commit-hash &amp;&amp; dvc push<\/code> for all local commits not yet pushed to remote.<\/li>\n<\/ol>\n\n<p>Both these options seem cumbersome and error-prone. Is there any better way to do it?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-29 15:55:34.517 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"git|dvc",
        "Question_view_count":916,
        "Owner_creation_date":"2018-03-28 16:31:38.71 UTC",
        "Owner_last_access_date":"2022-09-23 10:08:33.687 UTC",
        "Owner_reputation":784,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":77,
        "Answer_body":"<p>@NShiny, there is a related ticket:<\/p>\n\n<p><a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1691\" rel=\"nofollow noreferrer\">support push\/pull\/metrics\/gc, etc across different commits<\/a>.<\/p>\n\n<p>Please, give it a vote so that we know how to prioritize it.<\/p>\n\n<p>As a workaround, I would recommend to run <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/install\" rel=\"nofollow noreferrer\"><code>dvc install<\/code><\/a>. It installs a <code>pre-push<\/code> GIt hook and runs <code>dvc push<\/code> automatically:<\/p>\n\n<pre><code>Git pre-push hook executes dvc push before git push to upload files and directories under DVC control to remote.\n<\/code><\/pre>\n\n<p>It means, though you need to run <code>git push<\/code> after every <code>git commit<\/code> :(<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-06-29 21:10:49.417 UTC",
        "Answer_score":2.0,
        "Owner_location":"Russia",
        "Answer_last_edit_date":"2019-06-29 22:32:19.15 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56818930",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":58511529,
        "Question_title":"Highlight.js not respecting parent regex of a sub mode",
        "Question_body":"<p>I need to write a lexer which highlights my command-line tool commands properly.<\/p>\n\n<pre><code>$ dvc add file.csv\n$ dvc pipeline list\n<\/code><\/pre>\n\n<p>So the command starts with <code>dvc<\/code> and it may have one or two subcommands - <code>add<\/code> or <code>pipeline list<\/code> respectively.<\/p>\n\n<p>Therefore, it should highlight <code>dvc add<\/code> and <code>dvc pipeline list<\/code> in first and second case respectively.<\/p>\n\n<pre><code>contains: [\n          {\n            begin: \/^\\s*\\$\\s(dvc|git) [a-z-]+\/,\n            returnBegin: true,\n            contains: [\n              {\n                begin: \/dvc [a-z-]+ ?\/,\n                lexemes: '[a-z-]+',\n                keywords: {\n                  built_in:\n                    'dvc'\n                },\n                contains: [\n                  {\n                    begin: \/\\w+(?![\\S])\/,\n                    keywords: {\n                      built_in: 'list'\n                    }\n                  }\n                ],\n                className: 'strong'\n              }\n            ]\n          }\n        ]\n<\/code><\/pre>\n\n<p>It matches <code>dvc pipeline list<\/code> even though the parent regex i.e. <code>\/^\\s*\\$\\s(dvc|git) [a-z-]+\/<\/code> should only match till <code>dvc pipeline<\/code>. How is it exactly functioning?<\/p>\n\n<p>How does <code>\/dvc [a-z-]+ ?\/<\/code> override it and continues matching the expression?<\/p>\n\n<p>Please refer to this library docs here: <a href=\"https:\/\/highlightjs.readthedocs.io\/en\/latest\/reference.html\" rel=\"nofollow noreferrer\">https:\/\/highlightjs.readthedocs.io\/en\/latest\/reference.html<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_date":"2019-10-22 20:02:30.387 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2019-10-26 00:03:06.933 UTC",
        "Question_score":3,
        "Question_tags":"javascript|syntax-highlighting|highlight|highlight.js|dvc",
        "Question_view_count":177,
        "Owner_creation_date":"2019-07-07 20:04:39.143 UTC",
        "Owner_last_access_date":"2021-07-07 17:33:03.4 UTC",
        "Owner_reputation":209,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58511529",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":67407702,
        "Question_title":"Corrupted dvc.lock",
        "Question_body":"<p>I'm using DAGsHub storage as a remote and running into the following error message (when trying to DVC pull):<\/p>\n<blockquote>\n<p>ERROR: Lockfile 'bias_tagging_model\/dvc.lock' is corrupted.<\/p>\n<\/blockquote>\n<p>I thought I might have messed something up, but when cloning the git repo again and DVC pulling I am still running into this.\nThe data looks ok when viewed in the browser.\nIf you have any ideas, I would appreciate your help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-05 19:35:18.287 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"dvc",
        "Question_view_count":362,
        "Owner_creation_date":"2021-05-04 12:52:20.443 UTC",
        "Owner_last_access_date":"2022-01-11 19:04:00.7 UTC",
        "Owner_reputation":75,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Usually, the reason for this error is the DVC version.<\/p>\n<p>If the dvc.lock file has a DVC 2.* schema and you are using a lower version, it will throw this error.<\/p>\n<p>Upgrade your DVC version, and it should work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-06 09:13:21.493 UTC",
        "Answer_score":4.0,
        "Owner_location":"New York, NY, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67407702",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":65847574,
        "Question_title":"Failed to pull existing files from SSH DVC Remote",
        "Question_body":"<p>After running <code>dvc push data.csv<\/code> (to ssh-remote), when i try to dvc-pull the same file on another machine from the same remote, it won't get pulled. Below are the logs and the error:<\/p>\n<pre><code>2021-01-21 22:17:26,643 DEBUG: checking if 'data.csv'('HashInfo(name='md5', value='279936268f488e1e613f81a537f29055', dir_info=None, size=1458311, nfiles=None)') has changed.\n2021-01-21 22:17:26,643 DEBUG: 'data.csv' doesn't exist.\n2021-01-21 22:17:26,644 WARNING: Cache 'HashInfo(name='md5', value='279936268f488e1e613f81a537f29055', dir_info=None, size=1458311, nfiles=None)' not found. File 'data.csv' won't be created.\n2021-01-21 22:17:26,644 DEBUG: cache '\/usr\/src\/bohr\/.dvc\/cache\/27\/9936268f488e1e613f81a537f29055' expected 'HashInfo(name='md5', value='279936268f488e1e613f81a537f29055', dir_info=None, size=1458311, nfiles=None)' actual 'None'\n...\n2021-01-21 22:17:26,660 ERROR: failed to pull data from the cloud - Checkout failed for following targets:\ndata.csv\n<\/code><\/pre>\n<p>However, the file is present on the remote:<\/p>\n<pre><code>$ ls -la ~\/.dvcstorage\/bohr\/27\/9936268f488e1e613f81a537f29055\n-rw-rw-r-- 1 hbabii hbabii 1458311 Jan 22 00:19 \/home\/hbabii\/.dvcstorage\/bohr\/27\/9936268f488e1e613f81a537f29055\n<\/code><\/pre>\n<p>I double-checked that I am pulling from and pushing to the same remote. I am using DVC v1.11.11.<\/p>\n<p>Could you please give me any hints on what could be wrong?<\/p>\n<p>Cheers, Hlib<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2021-01-22 15:02:32.36 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"dvc",
        "Question_view_count":1715,
        "Owner_creation_date":"2012-12-08 21:33:12.777 UTC",
        "Owner_last_access_date":"2022-09-17 21:27:48.853 UTC",
        "Owner_reputation":530,
        "Owner_up_votes":282,
        "Owner_down_votes":3,
        "Owner_views":91,
        "Answer_body":"<p>In the end, the problem was that I indeed was pulling from the wrong remote (I had multiple remotes, their configuration was tricky, and local configurations differed on different machines).<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-03-18 15:52:36.537 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bolzano, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65847574",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":66505949,
        "Question_title":"problem with dvc import-url from google spreadsheet export",
        "Question_body":"<p>I'm in the process of converting a Makefile-based data workflow to dvc. I have a Google spreadsheet that I'm using in a data workflow to make it easy to update a few things in a makeshift database. Currently this works with something like this:<\/p>\n<pre><code># Makefile\ndata.csv:\n    curl -L https:\/\/docs.google.com\/spreadsheets\/d\/MY-GOOGLE-DOC-ID\/export?exportFormat=csv &gt; data.csv\n<\/code><\/pre>\n<p>Of course, I can incorporate the same step into my dvc pipeline directly with <code>dvc run<\/code>, but my understanding is that something like <code>dvc import-url<\/code> would be more appropriate but I'm getting an error:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ poetry run dvc import-url https:\/\/docs.google.com\/spreadsheets\/d\/MY-GOOGLE-DOC-ID\/export?exportFormat=csv data.csv\nImporting 'https:\/\/docs.google.com\/spreadsheets\/d\/MY-GOOGLE-DOC-ID\/export?exportFormat=csv' -&gt; 'data.csv'\nERROR: unexpected error - 'NoneType' object has no attribute 'endswith'\n<\/code><\/pre>\n<p>My guess is that this is because the response data from the Google Spreadsheet export url doesn't have a filename suffix associated with it. Is there a way to work around this problem? Is there a better way to pull data from a google spreadsheet into a dvc workflow?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-03-06 13:05:20.157 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"google-sheets|google-sheets-api|dvc",
        "Question_view_count":59,
        "Owner_creation_date":"2011-01-05 23:08:56.687 UTC",
        "Owner_last_access_date":"2022-08-27 16:39:52.827 UTC",
        "Owner_reputation":2893,
        "Owner_up_votes":294,
        "Owner_down_votes":1,
        "Owner_views":168,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Chicago, IL",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66505949",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":66925614,
        "Question_title":"How to access DVC-controlled files from Oracle?",
        "Question_body":"<p>I have been storing my large files in CLOBs within Oracle, but I am thinking of storing my large files in a shared drive, then having a column in Oracle contain pointers to the files. This would use DVC.<\/p>\n<p>When I do this,<\/p>\n<p>(a) are the paths in Oracle paths that point to the files in my shared drive, as in, the actual files themselves?<\/p>\n<p>(b) or do the paths in Oracle point somehow to the DVC metafile?<\/p>\n<p>Any insight would help me out!<\/p>\n<p>Thanks :)\nJustin<\/p>\n<hr \/>\n<p>EDIT to provide more clarity:<\/p>\n<p>I checked here (<a href=\"https:\/\/dvc.org\/doc\/api-reference\/open\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/api-reference\/open<\/a>), and it helped, but I'm not fully there yet ...<\/p>\n<p>I want to pull a file from a remote dvc repository using python (which I have connected to the Oracle database). So, if we can make that work, I think I will be good. But, I am confused. If I specify 'remote' below, then how do I name the file (e.g., 'activity.log') when the remote files are all encoded?<\/p>\n<pre><code>with dvc.api.open(\n        'activity.log',\n        repo='location\/of\/dvc\/project',\n        remote='my-s3-bucket'\n        ) as fd:\n    for line in fd:\n        match = re.search(r'user=(\\w+)', line)\n        # ... Process users activity log\n<\/code><\/pre>\n<p>(NOTE: For testing purposes, my &quot;remote&quot; DVC directory is just another folder on my MacBook.)<\/p>\n<p>I feel like I'm missing a key concept about getting remote files ...<\/p>\n<p>I hope that adds more clarity. Any help figuring out remote file access is appreciated! :)<\/p>\n<p>Justin<\/p>\n<hr \/>\n<p>EDIT to get insights on 'rev' parameter:<\/p>\n<p>Before my question, some background\/my setup:\n(a) I have a repo on my MacBook called 'basics'.\n(b) I copied into 'basics' a directory of 501 files (called 'surface_files') that I subsequently pushed to a remote storage folder called 'gss'. After the push, 'gss' contains 220 hash directories.<\/p>\n<p>The steps I used to get here are as follows:<\/p>\n<pre><code>&gt; cd ~\/Desktop\/Work\/basics\n&gt; git init\n&gt; dvc init\n&gt; dvc add ~\/Desktop\/Work\/basics\/surface_files\n&gt; git add .gitignore surface_files.dvc\n&gt; git commit -m &quot;Add raw data&quot;\n&gt; dvc remote add -d remote_storage ~\/Desktop\/Work\/gss\n&gt; git commit .dvc\/config -m &quot;Configure remote storage&quot;\n&gt; dvc push\n&gt; rm -rf .\/.dvc\/cache\n&gt; rm -rf .\/surface_files\n<\/code><\/pre>\n<p>Next, I ran the following Python code to take one of my surface files, named <code>surface_100141.dat<\/code>, and used <code>dvc.api.get_url()<\/code> to get the corresponding remote storage file name. I then copied this remote storage file into my desktop under the file's original name, i.e., <code>surface_100141.dat<\/code>.<\/p>\n<p>The code that does all this is as follows, but FIRST, MY QUESTION --- when I run the code as it is shown below, no problems; but when I uncomment the 'rev=' line, it fails. I am not sure why this is happening. I used <code>git log<\/code> and <code>cat .git\/refs\/heads\/master<\/code> to make sure that I was getting the right hash. WHY IS THIS FAILING? That is my question.<\/p>\n<p>(In full disclosure, my git knowledge is not too strong yet. I'm getting there, but it's still a work in progress! :))<\/p>\n<pre><code>import dvc.api\nimport os.path\nfrom os import path\nimport shutil\n\nfilename = 'surface_100141.dat' # This file name would be stored in my Oracle database\nhome_dir = os.path.expanduser('~')+'\/' # This simply expanding '~' into '\/Users\/ricej\/'\n\nresource_url = dvc.api.get_url(\n    path=f'surface_files\/{filename}', # Works when 'surface_files.dvc' exists, even when 'surface_files' directory and .dvc\/cache do not\n    repo=f'{home_dir}Desktop\/Work\/basics',\n    # rev='5c92710e68c045d75865fa24f1b56a0a486a8a45', # Commit hash, found using 'git log' or 'cat .git\/refs\/heads\/master'\n    remote='remote_storage')\nresource_url = home_dir+resource_url\nprint(f'Remote file: {resource_url}')\n\nnew_dir = f'{home_dir}Desktop\/' # Will copy fetched file to desktop, for demonstration\nnew_file = new_dir+filename\nprint(f'Remote file copy: {new_file}')\n\nif path.exists(new_file):\n    os.remove(new_file)\n    \ndest = shutil.copy(resource_url, new_file) # Check your desktop after this to see remote file copy\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-04-02 21:45:23.477 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-04-05 17:22:23.263 UTC",
        "Question_score":1,
        "Question_tags":"python|oracle|dvc",
        "Question_view_count":389,
        "Owner_creation_date":"2014-08-03 18:46:34.73 UTC",
        "Owner_last_access_date":"2022-06-08 02:07:15.42 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":"<p>I'm not 100% sure that I understand the question (it would be great to expand it a bit on the actual use case you are trying to solve with this database), but I can share a few thoughts.<\/p>\n<p>When we talk about DVC, I think you need to specify a few things to identify the file\/directory:<\/p>\n<ol>\n<li>Git commit + path (actual path like <code>data\/data\/xml<\/code>). Commit (or to be precise any Git revision) is needed to identify the version of the data file.<\/li>\n<li>Or path in the DVC storage (<code>\/mnt\/shared\/storage\/00\/198493ef2343ao<\/code> ...<code>) + actual name of this file. This way you would be saving info that <\/code>.dvc` files have.<\/li>\n<\/ol>\n<p>I would say that second way is <em>not<\/em> recommended since to some extent it's an implementation detail - how does DVC store files internally. The public interface to DVC organized data storage is its repository URL + commit + file name.<\/p>\n<p>Edit (example):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with dvc.api.open(\n        'activity.log',\n        repo='location\/of\/dvc\/project',\n        remote='my-s3-bucket'\n        ) as fd:\n    for line in fd:\n        match = re.search(r'user=(\\w+)', line)\n        # ... Process users activity log\n<\/code><\/pre>\n<p><code>location\/of\/dvc\/project<\/code> this path must point to an actual Git repo. This repo should have a <code>.dvc<\/code> or <code>dvc.lock<\/code> file that has <code>activity.log<\/code> name in it + its hash in the remote storage:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>outs:\n  - md5: a304afb96060aad90176268345e10355\n    path: activity.log\n<\/code><\/pre>\n<p>By reading this Git repo and analyzing let's say <code>activity.log.dvc<\/code> DVC will be able to create the right path <code>s3:\/\/my-bucket\/storage\/a3\/04afb96060aad90176268345e10355<\/code><\/p>\n<p><code>remote='my-s3-bucket'<\/code> argument is optional. By default it will use the one that is defined in the repo itself.<\/p>\n<p>Let's take another real example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with dvc.api.open(\n        'get-started\/data.xml',\n        repo='https:\/\/github.com\/iterative\/dataset-registry'\n        ) as fd:\n    for line in fd:\n        match = re.search(r'user=(\\w+)', line)\n        # ... Process users activity log\n<\/code><\/pre>\n<p>In the <code>https:\/\/github.com\/iterative\/dataset-registry<\/code> you could find the <a href=\"https:\/\/github.com\/iterative\/dataset-registry\/blob\/master\/get-started\/data.xml.dvc\" rel=\"nofollow noreferrer\"><code>.dvc<\/code> file<\/a> that is enough for DVC to create a path to the file by also analyzing its <a href=\"https:\/\/github.com\/iterative\/dataset-registry\/blob\/master\/.dvc\/config\" rel=\"nofollow noreferrer\">config<\/a><\/p>\n<pre><code>https:\/\/remote.dvc.org\/dataset-registry\/a3\/04afb96060aad90176268345e10355\n<\/code><\/pre>\n<p>you could run <code>wget<\/code> on this file to download it<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2021-04-02 23:07:02.54 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-04-03 19:28:34.567 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66925614",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73651050,
        "Question_title":"DVC imports authentication to blob storage",
        "Question_body":"<p>I'm using <a href=\"https:\/\/dvc.org\/\" rel=\"nofollow noreferrer\">DVC<\/a> to track and version data that is stored locally on the file system and in Azure Blob storage.<\/p>\n<p>My setup is as follows:<\/p>\n<ul>\n<li><p><code>DataProject1<\/code>, it uses a local file location as a remote therefore it does not require any authentication.<\/p>\n<\/li>\n<li><p><code>DataProject2<\/code>, it uses Azure Blob Storage as a remote, it is using sas_token for authentication, I can push pull data to\/from the remote when I'm within this project.<\/p>\n<\/li>\n<li><p><code>MLProject<\/code>, it uses dvc import to import data from <code>DataProjec1<\/code> and <code>DataProject2<\/code>.<\/p>\n<\/li>\n<\/ul>\n<p>When I run the import with the command against <code>DataProject1<\/code> everything works fine:<\/p>\n<p><code>dvc import -o 'data\/project1' 'https:\/\/company.visualstudio.com\/DefaultCollection\/proj\/_git\/DataProject1' 'data\/project1'<\/code> - Successful<\/p>\n<p>Howevever when I run a similar command against <code>DataProject2<\/code> the command fails:<\/p>\n<p><code>dvc import -o 'data\/project2' 'https:\/\/company.visualstudio.com\/DefaultCollection\/proj\/_git\/DataProject2' 'data\/project2'<\/code> - it fails with:<\/p>\n<blockquote>\n<p>ERROR: unexpected error - Operation returned an invalid status 'This\nrequest is not authorized to perform this operation using this\npermission.'  ErrorCode:AuthorizationPermissionMismatch.<\/p>\n<\/blockquote>\n<p>I would like to configure the <code>dvc import<\/code> so that I can set the required <code>sas_token<\/code> but I cannot find a way to do that.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-09-08 14:48:49.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-08 15:18:57.133 UTC",
        "Question_score":1,
        "Question_tags":"python|dvc|dvc-import",
        "Question_view_count":34,
        "Owner_creation_date":"2009-07-24 16:26:11.43 UTC",
        "Owner_last_access_date":"2022-09-24 08:02:55.38 UTC",
        "Owner_reputation":3317,
        "Owner_up_votes":466,
        "Owner_down_votes":8,
        "Owner_views":296,
        "Answer_body":"<p>This happens since DVC is not using <code>MLProject<\/code>'s config when it clones and does <code>dvc fetch<\/code> in the <code>DataProject2<\/code> during the <code>import<\/code>. And it doesn't know where it can find the token (clearly, it's not in the Git repo, right?).<\/p>\n<p>There are a few ways to specify it: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/config#--system\" rel=\"nofollow noreferrer\"><code>global\/system<\/code> configs<\/a> and\/or <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#authenticate-with-environment-variables\" rel=\"nofollow noreferrer\">environment variables<\/a>.<\/p>\n<p>To implement the first option:<\/p>\n<p>On a machine where you do <code>dvc import<\/code>, you could create a remote in the <code>--global<\/code>, or <code>--system<\/code> configs with the same name and specify the token there. Global config fields will be merged with the config in the <code>DataProject2<\/code> repo when DVC is pulling data to import.<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>dvc remote add --global &lt;DataProject2-remote-name&gt; azure:\/\/DataProject2\/storage\ndvc remote modify --global &lt;DataProject2-remote-name&gt; account_name &lt;name&gt;\ndvc remote modify --global &lt;DataProject2-remote-name&gt; sas_token &lt;token&gt;\n<\/code><\/pre>\n<p>The second option:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>export AZURE_STORAGE_SAS_TOKEN='mysecret'\nexport AZURE_STORAGE_ACCOUNT='myaccount'\n<\/code><\/pre>\n<p>Please give it a try, let me know if that works or not.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-09-08 16:54:50.387 UTC",
        "Answer_score":2.0,
        "Owner_location":"London, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73651050",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":69254525,
        "Question_title":"ERROR: bad DVC file name 'my_server\\models\\*.tar.gz.dvc' is git-ignored",
        "Question_body":"<p>I just started with DVC. I have a git repo in which there are heavy models that i want to push to dvc. So I initialized the dvc by<\/p>\n<pre><code>dvc init\n<\/code><\/pre>\n<p>and then configured the bucket<\/p>\n<pre><code>dvc remote add -d storage s3:\/\/mybucket\/dvcstore\n<\/code><\/pre>\n<p>Now there is <code>\/models<\/code> folders, in which there was <code>.gitkeep<\/code> file and trained models. Following entry was in my <code>.gitignore<\/code><\/p>\n<pre><code>*.tar.gz\n<\/code><\/pre>\n<p>I ran the following command<\/p>\n<pre><code>git rm -r --cached my_server\\models\n<\/code><\/pre>\n<p>and added the following in the <code>.gitignore<\/code><\/p>\n<pre><code>models\n<\/code><\/pre>\n<p>I want to add all the <code>tar.gz<\/code> files to push on dvc<\/p>\n<p>so i tried<\/p>\n<pre><code>dvc add .\/my_server\/models\/*.tar.gz\n<\/code><\/pre>\n<p>but this is showing<\/p>\n<pre><code>ERROR: bad DVC file name 'my_server\\models\\*.tar.gz.dvc' is git-ignored.\n<\/code><\/pre>\n<p>If I do\ndvc add .\/my_server\/models\/<\/p>\n<p>then this folder is added and a <code>models.dvc<\/code> file gets created. then git code shows for the changes.<\/p>\n<p>what is the correct way, do i need to mention <code>*.dvc<\/code> to <code>.gitignore<\/code> as well?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2021-09-20 12:34:56.913 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-09-21 15:08:06.743 UTC",
        "Question_score":2,
        "Question_tags":"git|dvc",
        "Question_view_count":760,
        "Owner_creation_date":"2013-03-15 04:43:52.587 UTC",
        "Owner_last_access_date":"2022-09-25 05:38:43.07 UTC",
        "Owner_reputation":13237,
        "Owner_up_votes":2454,
        "Owner_down_votes":19,
        "Owner_views":2675,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Chandigarh, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69254525",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73126208,
        "Question_title":"Python: Ssl Certificate verify failed",
        "Question_body":"<p>I have installed <code>dvc<\/code> on my <code>ubuntu-18.04-LTS<\/code> system and while trying to download the <code>data<\/code> files from github using dvc, it fails with below error.<\/p>\n<pre><code>$ dvc get https:\/\/github.com\/iterative\/dataset-registry get-started\/data.xml -o data\/data.xml -v\n\n2022-07-22 12:55:22,260 DEBUG: Creating external repo https:\/\/github.com\/iterative\/dataset-registry@None\n2022-07-22 12:55:22,260 DEBUG: erepo: git clone 'https:\/\/github.com\/iterative\/dataset-registry' to a temporary dir\n2022-07-22 12:55:23,683 DEBUG: Removing '\/dvc\/dvc_test\/data\/.UEeAzwmJCY3q85YQuCeahx'\n2022-07-22 12:55:23,684 ERROR: failed to get 'get-started\/data.xml' from 'https:\/\/github.com\/iterative\/dataset-registry' - Failed to clone repo 'https:\/\/github.com\/iterative\/dataset-registry' to '\/tmp\/tmpvmrmu9qsdvc-clone'\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;urllib3\/connectionpool.py&quot;, line 703, in urlopen\n  File &quot;urllib3\/connectionpool.py&quot;, line 386, in _make_request\n  File &quot;urllib3\/connectionpool.py&quot;, line 1042, in _validate_conn\n  File &quot;urllib3\/connection.py&quot;, line 414, in connect\n  File &quot;urllib3\/util\/ssl_.py&quot;, line 449, in ssl_wrap_socket\n  File &quot;urllib3\/util\/ssl_.py&quot;, line 493, in _ssl_wrap_socket_impl\n  File &quot;ssl.py&quot;, line 500, in wrap_socket\n  File &quot;ssl.py&quot;, line 1040, in _create\n  File &quot;ssl.py&quot;, line 1309, in do_handshake\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;dvc\/scm.py&quot;, line 145, in clone\n  File &quot;scmrepo\/git\/__init__.py&quot;, line 143, in clone\n  File &quot;scmrepo\/git\/backend\/dulwich\/__init__.py&quot;, line 199, in clone\nscmrepo.exceptions.CloneError: Failed to clone repo 'https:\/\/github.com\/iterative\/dataset-registry' to '\/tmp\/tmpvmrmu9qsdvc-clone'\n<\/code><\/pre>\n<p>Already our corporate proxy certificate has been installed and traffic to <code>github.com<\/code> allowed I'm able to clone above repository separately on CLI. But with <code>dvc<\/code>the above errors are occurring, Even the below couldn't solve the issue.<\/p>\n<pre><code>$ python -c &quot;import ssl; print(ssl.get_default_verify_paths())&quot;\n\nDefaultVerifyPaths(cafile=None, capath='\/usr\/lib\/ssl\/certs', openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='\/usr\/lib\/ssl\/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='\/usr\/lib\/ssl\/certs')\n<\/code><\/pre>\n<pre><code>export SSL_CERT_DIR=\/etc\/ssl\/certs\/\nexport REQUESTS_CA_BUNDLE=\/usr\/local\/lib\/python2.7\/dist-packages\/certifi\/cacert.pem\npip install --upgrade certifi\nexport PYTHONHTTPSVERIFY=0\n\nsudo apt install ca-certificates\nsudo update-ca-certificates --fresh\n<\/code><\/pre>\n<pre><code>$ python --version\nPython 2.7.17\n\n$ dvc doctor\nDVC version: 2.13.0 (deb)\n---------------------------------\nPlatform: Python 3.8.3 on Linux-5.4.0-92-generic-x86_64-with-glibc2.14\nSupports:\n        azure (adlfs = 2022.7.0, knack = 0.9.0, azure-identity = 1.10.0),\n        gdrive (pydrive2 = 1.10.1),\n        gs (gcsfs = 2022.5.0),\n        hdfs (fsspec = 2022.5.0, pyarrow = 8.0.0),\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.1),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.1),\n        s3 (s3fs = 2022.5.0, boto3 = 1.21.21),\n        ssh (sshfs = 2022.6.0),\n        oss (ossfs = 2021.8.0),\n        webdav (webdav4 = 0.9.7),\n        webdavs (webdav4 = 0.9.7)\n<\/code><\/pre>\n<p>Tp bypass the ssl validation in git we have <code>git config http.sslVerify &quot;false&quot;<\/code> Similarly do we have option in dvc?<\/p>\n<p>Further what should i update to resolve this issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-07-26 15:36:20.953 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-27 05:01:17.49 UTC",
        "Question_score":1,
        "Question_tags":"python|ssl|pip|ssl-certificate|dvc",
        "Question_view_count":157,
        "Owner_creation_date":"2015-05-28 11:02:07.473 UTC",
        "Owner_last_access_date":"2022-09-25 03:23:10.223 UTC",
        "Owner_reputation":1609,
        "Owner_up_votes":68,
        "Owner_down_votes":0,
        "Owner_views":447,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73126208",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72069555,
        "Question_title":"Second dvc push on AWS Batch using IAM role gets \"Unable to locate credentials\"",
        "Question_body":"<p>I'm running a job on AWS Batch, and this job prepares some data and versions it using <code>dvc<\/code>. Secondly, the job does some transformation generating new data, and it should save this new data using <code>dvc<\/code> again. Also, in this case, i'm setting a instance-profile role to enable the AWS Batch to persist on my S3 bucket.<\/p>\n<p>The first <code>dvc push<\/code> works perfectly. But the second one generates the error <code>Unable to locate credentials<\/code><\/p>\n<p>I have also changed the script to just touch a file, add to dvc and push, and then repeat the process in with other file, and could replicate the problem.<\/p>\n<p>I have already solved, changing the command <code>dvc push<\/code> to <code>dvc push especific-file-to-push<\/code>, but I'm now trying to understand what is the problem with <code>dvc push<\/code> command without the parameter specifying the file.<\/p>\n<p>Does anybody know?<\/p>\n<p>I'm using dvc <code>dvc==2.9.5<\/code> and <code>boto3==1.21.21<\/code><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_date":"2022-04-30 14:56:26.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-30 15:10:34.543 UTC",
        "Question_score":2,
        "Question_tags":"amazon-s3|boto3|amazon-iam|aws-batch|dvc",
        "Question_view_count":152,
        "Owner_creation_date":"2013-09-19 22:56:26.42 UTC",
        "Owner_last_access_date":"2022-09-15 12:21:12.72 UTC",
        "Owner_reputation":101,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Rio de Janeiro, Brazil",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72069555",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73580703,
        "Question_title":"DVC | Permission denied ERROR: failed to reproduce stage: failed to run: .py, exited with 126",
        "Question_body":"<p>Goal: run <code>.py<\/code> files via. <code>dvc.yaml<\/code>.<\/p>\n<p>There are stages before it, in <code>dvc.yaml<\/code>, that don't produce the error.<\/p>\n<p><code>dvc exp run<\/code>:<\/p>\n<pre><code>(venv) me@ubuntu-pcs:~\/PycharmProjects\/project$ dvc exp run\nStage 'inference' didn't change, skipping\nRunning stage 'load_data':\n&gt; load_data.py\n\/bin\/bash: line 1: load_data.py: Permission denied\nERROR: failed to reproduce 'load_data': failed to run: load_data.py, exited with 126\n<\/code><\/pre>\n<p><code>dvc repro<\/code>:<\/p>\n<pre><code>(venv) me@ubuntu-pcs:~\/PycharmProjects\/project$ dvc repro\nStage 'predict' didn't change, skipping                                                                                                                                                                                                                        \nStage 'evaluate' didn't change, skipping\nStage 'inference' didn't change, skipping\nRunning stage 'load_data':\n&gt; load_data.py\n\/bin\/bash: line 1: load_data.py: Permission denied\nERROR: failed to reproduce 'load_data': failed to run: pdl1_lung_model\/load_data.py, exited with 126\n<\/code><\/pre>\n<hr \/>\n<p><code>dvc doctor<\/code>:<\/p>\n<pre><code>DVC version: 2.10.2 (pip)\n---------------------------------\nPlatform: Python 3.9.12 on Linux-5.15.0-46-generic-x86_64-with-glibc2.35\nSupports:\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        s3 (s3fs = 2022.5.0, boto3 = 1.21.21)\nCache types: hardlink, symlink\nCache directory: ext4 on \/dev\/nvme0n1p5\nCaches: local\nRemotes: s3\nWorkspace directory: ext4 on \/dev\/nvme0n1p5\nRepo: dvc, git\n<\/code><\/pre>\n<p><code>dvc exp run -v<\/code>:<\/p>\n<p><a href=\"https:\/\/gist.github.com\/danielbellsa\/3f2fe05c1535d494a8677e54cddf684a\" rel=\"nofollow noreferrer\">output.txt<\/a><\/p>\n<p><code>dvc exp run -vv<\/code>:<\/p>\n<p><a href=\"https:\/\/gist.github.com\/danielbellsa\/a124cf28b3f0252556deb90b042b7cec\" rel=\"nofollow noreferrer\">output2.txt<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-02 09:45:17.277 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-05 09:06:49.863 UTC",
        "Question_score":1,
        "Question_tags":"python-3.x|permission-denied|dvc",
        "Question_view_count":77,
        "Owner_creation_date":"2021-09-07 12:58:02.98 UTC",
        "Owner_last_access_date":"2022-09-23 15:24:35.073 UTC",
        "Owner_reputation":234,
        "Owner_up_votes":708,
        "Owner_down_votes":14,
        "Owner_views":155,
        "Answer_body":"<h3>Solution 1<\/h3>\n<p><code>.py<\/code> files weren't running as scripts.<\/p>\n<p>They need to be; if you want to run one <code>.py<\/code> file per <code>stage<\/code> in <code>dvc.yaml<\/code>.<\/p>\n<p>To do so, you want to append <strong>Boiler-plate code<\/strong>, at the bottom of each <code>.py<\/code> file.<\/p>\n<pre><code>if __name__ == &quot;__main__&quot;:\n    # invoke primary function() in .py file, w\/ params\n<\/code><\/pre>\n<h3>Solution 2<\/h3>\n<pre><code>chmod 777 ....py\n<\/code><\/pre>\n<h3>Soution 3<\/h3>\n<p>I forgot the <code>python<\/code> in <code>cmd:<\/code><\/p>\n<pre><code>  load_data:\n    cmd: python pdl1_lung_model\/load_data.py\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-09-02 10:34:04.133 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-09-05 09:05:53.113 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73580703",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":64653042,
        "Question_title":"Control tracked version of external dependency",
        "Question_body":"<p>I am trying to set up a DVC repository for machine learning data with different tagged versions of the dataset. I do this with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd \/raid\/ml_data  # folder on a data drive\n$ git init\n$ dvc init\n$ [add data]\n$ [commit to dvc, git]\n$ git tag -a 1.0.0\n$ [add or change data]\n$ [commit to dvc, git]\n$ git tag -a 1.1.0\n<\/code><\/pre>\n<p>I have multiple projects that each need to reference some version of this dataset. The problem is I can't figure out how to set up those projects to reference a specific version. I'm able to track the <code>HEAD<\/code> of the repo with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd ~\/my_proj  # different drive than the remote\n$ mkdir data\n$ git init\n$ dvc init\n$ dvc remote add -d local \/raid\/ml_data  # add the remote on my data drive\n$ dvc cache dir \/raid\/ml_data\/.dvc\/cache  # tell DVC to use the remote cache\n$ dvc checkout\n$ dvc run --external -d \/raid\/ml_data -o data\/ cp -r \/raid\/ml_data data\n<\/code><\/pre>\n<p>This gets me the latest version of the dataset, symlinked into my <code>data<\/code> folder, but what if I want some projects to use the <code>1.0.0<\/code> version and some to use the <code>1.1.0<\/code> version, or another version? Or for that matter, if I update the dataset to <code>2.0.0<\/code> but don't want my existing projects to necessarily track <code>HEAD<\/code> and instead keep the version with which they were set up?<\/p>\n<p>It's important to me to not create a ton of local copies of my dataset as the <code>\/home<\/code> drive is much smaller than the <code>\/raid<\/code> drive and some of these datasets are huge.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-02 20:42:34.297 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-11-02 23:50:23.337 UTC",
        "Question_score":2,
        "Question_tags":"version-control|dvc",
        "Question_view_count":139,
        "Owner_creation_date":"2013-06-07 18:26:33.7 UTC",
        "Owner_last_access_date":"2022-09-14 18:00:36.65 UTC",
        "Owner_reputation":11685,
        "Owner_up_votes":2855,
        "Owner_down_votes":47,
        "Owner_views":1329,
        "Answer_body":"<p>I think you are looking for the <a href=\"https:\/\/dvc.org\/doc\/start\/data-access\" rel=\"nofollow noreferrer\">data access<\/a> set of commands.<\/p>\n<p>In your particular case, <code>dvc import<\/code> makes sense:<\/p>\n<pre><code>$ dvc import \/raid\/ml_data data\n<\/code><\/pre>\n<p>if you want to get the most recent version (HEAD). Then you will be able to update it with the <code>dvc update<\/code> command (if 2.0.0 is released, for example).<\/p>\n<pre><code>$ dvc import \/raid\/ml_data data --rev 1.0.0\n<\/code><\/pre>\n<p>if you'd like to &quot;fix&quot; it to the specific version.<\/p>\n<h3>Avoiding copies<\/h3>\n<p>Make sure also, that <code>symlinks<\/code> are set for the second project, as described in the <a href=\"https:\/\/dvc.org\/doc\/user-guide\/large-dataset-optimization\" rel=\"nofollow noreferrer\">Large Dataset Optimization<\/a>:<\/p>\n<pre><code>$ dvc config cache.type reflink,hardlink,symlink,copy\n<\/code><\/pre>\n<p>(there are config modifiers <code>--global<\/code>, <code>--local<\/code>, <code>--system<\/code> to set this setting for everyone at once, or just for one project, etc)<\/p>\n<p>Check the details instruction <a href=\"https:\/\/dvc.org\/doc\/user-guide\/large-dataset-optimization#configuring-dvc-cache-file-link-type\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<hr \/>\n<p>Overall, it's a great setup, and looks like you got pretty much everything right. Please, don't hesitate to follow up and\/or create other questions here- we'll help you with this.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-11-02 21:12:41.433 UTC",
        "Answer_score":1.0,
        "Owner_location":"Colorado Springs, CO",
        "Answer_last_edit_date":"2020-11-03 00:16:03.343 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64653042",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":69265000,
        "Question_title":"DVC - Forbidden: An error occurred (403) when calling the HeadObject operation",
        "Question_body":"<p>I just started with DVC. following are the steps I am doing to push my models on S3<\/p>\n<p>Initialize<\/p>\n<pre><code>dvc init\n<\/code><\/pre>\n<p>Add bucket url<\/p>\n<pre><code>dvc remote add -d storage s3:\/\/mybucket\/dvcstore\n<\/code><\/pre>\n<p>add some files<\/p>\n<pre><code>dvc add somefiles\n<\/code><\/pre>\n<p>Add aws keys<\/p>\n<pre><code>dvc remote modify storage access_key_id AWS_ACCESS_KEY_ID\ndvc remote modify storage secret_access_key AWS_SECRET_ACCESS_KEY\n<\/code><\/pre>\n<p>now when I push<\/p>\n<pre><code>dvc push\n<\/code><\/pre>\n<p>it shows<\/p>\n<pre><code>ERROR: unexpected error - Forbidden: An error occurred (403) when calling the HeadObject operation: Forbidden\n<\/code><\/pre>\n<p>Am i missing something?<\/p>\n<p><strong>update1<\/strong><\/p>\n<p>result of <code>dvc doctor<\/code><\/p>\n<pre><code>C:\\my-server&gt;dvc doctor\nDVC version: 2.7.4 (pip)\n---------------------------------\nPlatform: Python 3.8.0 on Windows-10-10.0.19041-SP0\nSupports:\n        http (aiohttp = 3.7.4.post0, aiohttp-retry = 2.4.5),\n        https (aiohttp = 3.7.4.post0, aiohttp-retry = 2.4.5),\n        s3 (s3fs = 2021.8.1, boto3 = 1.17.106)\nCache types: hardlink\nCache directory: NTFS on C:\\\nCaches: local\nRemotes: s3\nWorkspace directory: NTFS on C:\\\nRepo: dvc, git\n<\/code><\/pre>\n<p>and the <code>dvc push-vv<\/code><\/p>\n<pre><code>C:\\my-server&gt;dvc push -vv  \n2021-09-21 13:21:38,382 TRACE: Namespace(all_branches=False, all_commits=False, all_tags=False, cd='.', cmd='push', cprofile=False, cprofile_dump=None, func=&lt;class 'dvc.command.data_sync.CmdDataPush'&gt;, glob=False, instrument=False, instrument_open=False, jobs=None, pdb=False, quiet=0, recursive=False, remote=None, run_cache=False, targets=[], verbose=2, version=None, with_deps=False)\n2021-09-21 13:21:39,293 TRACE: Assuming 'C:\\my-server\\.dvc\\cache\\02\\5b196462b86d2f10a9f659e2224da8.dir' is unchanged since \nit is read-only\n2021-09-21 13:21:39,296 TRACE: Assuming 'C:\\my-server\\.dvc\\cache\\02\\5b196462b86d2f10a9f659e2224da8.dir' is unchanged since \nit is read-only\n2021-09-21 13:21:40,114 DEBUG: Preparing to transfer data from '.dvc\\cache' to 's3:\/\/my-bucket\/models'\n2021-09-21 13:21:40,117 DEBUG: Preparing to collect status from 's3:\/\/my-bucket\/models'\n2021-09-21 13:21:40,119 DEBUG: Collecting status from 's3:\/\/my-bucket\/models'\n2021-09-21 13:21:40,121 DEBUG: Querying 1 hashes via object_exists\n2021-09-21 13:21:44,840 ERROR: unexpected error - Forbidden: An error occurred (403) when calling the HeadObject operation: Forbidden\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 248, in _call_s3\n    out = await method(**additional_kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\aiobotocore\\client.py&quot;, line 155, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (InvalidAccessKeyId) when calling the ListObjectsV2 operation: The AWS Access Key Id you provided does not exist in our records.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 1080, in _info\n    out = await self._simple_info(path)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 993, in _simple_info\n    out = await self._call_s3(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 268, in _call_s3\n    raise err\nPermissionError: The AWS Access Key Id you provided does not exist in our records.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 248, in _call_s3\n    out = await method(**additional_kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\aiobotocore\\client.py&quot;, line 155, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (403) when calling the HeadObject operation: Forbidden\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\main.py&quot;, line 55, in main\n    ret = cmd.do_run()\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\command\\base.py&quot;, line 45, in do_run\n    return self.run()\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\command\\data_sync.py&quot;, line 57, in run\n    processed_files_count = self.repo.push(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\repo\\__init__.py&quot;, line 50, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\repo\\push.py&quot;, line 48, in push\n    pushed += self.cloud.push(obj_ids, jobs, remote=remote, odb=odb)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\data_cloud.py&quot;, line 85, in push\n    return transfer(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\transfer.py&quot;, line 153, in transfer\n    status = compare_status(src, dest, obj_ids, check_deleted=False, **kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\status.py&quot;, line 160, in compare_status\n    dest_exists, dest_missing = status(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\status.py&quot;, line 122, in status\n    exists = hashes.intersection(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\status.py&quot;, line 48, in _indexed_dir_hashes\n    dir_exists.update(odb.list_hashes_exists(dir_hashes - dir_exists))\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\db\\base.py&quot;, line 415, in list_hashes_exists\n    ret = list(itertools.compress(hashes, in_remote))\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py&quot;, line 611, in result_iterator\n    yield fs.pop().result()\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py&quot;, line 439, in result\n    return self.__get_result()\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\_base.py&quot;, line 388, in __get_result\n    raise self._exception\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\concurrent\\futures\\thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\objects\\db\\base.py&quot;, line 406, in exists_with_progress\n    ret = self.fs.exists(path_info)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\dvc\\fs\\fsspec_wrapper.py&quot;, line 97, in exists\n    return self.fs.exists(self._with_bucket(path_info))\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\fsspec\\asyn.py&quot;, line 88, in wrapper\n    return sync(self.loop, func, *args, **kwargs)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\fsspec\\asyn.py&quot;, line 69, in sync\n    raise result[0]\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\fsspec\\asyn.py&quot;, line 25, in _runner\n    result[0] = await coro\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 820, in _exists\n    await self._info(path, bucket, key, version_id=version_id)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 1084, in _info\n    out = await self._version_aware_info(path, version_id)\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 1027, in _version_aware_info\n    out = await self._call_s3(\n  File &quot;c:\\users\\sgarg\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\s3fs\\core.py&quot;, line 268, in _call_s3\n    raise err\nPermissionError: Forbidden\n------------------------------------------------------------\n2021-09-21 13:21:45,178 DEBUG: Version info for developers:\nDVC version: 2.7.4 (pip)\n---------------------------------\nPlatform: Python 3.8.0 on Windows-10-10.0.19041-SP0\nSupports:\n        http (aiohttp = 3.7.4.post0, aiohttp-retry = 2.4.5),\n        https (aiohttp = 3.7.4.post0, aiohttp-retry = 2.4.5),\n        s3 (s3fs = 2021.8.1, boto3 = 1.17.106)\nCache types: hardlink\nCache directory: NTFS on C:\\\nCaches: local\nRemotes: s3\nWorkspace directory: NTFS on C:\\\nRepo: dvc, git\n\nHaving any troubles? Hit us up at https:\/\/dvc.org\/support, we are always happy to help!\n2021-09-21 13:21:45,185 DEBUG: Analytics is enabled.\n2021-09-21 13:21:45,446 DEBUG: Trying to spawn '['daemon', '-q', 'analytics', 'C:\\\\Users\\\\sgarg\\\\AppData\\\\Local\\\\Temp\\\\tmpm_p9f3eq']'\n2021-09-21 13:21:45,456 DEBUG: Spawned '['daemon', '-q', 'analytics', 'C:\\\\Users\\\\sgarg\\\\AppData\\\\Local\\\\Temp\\\\tmpm_p9f3eq']'\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-21 07:31:07.14 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-09-21 15:07:53.617 UTC",
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":816,
        "Owner_creation_date":"2013-03-15 04:43:52.587 UTC",
        "Owner_last_access_date":"2022-09-25 05:38:43.07 UTC",
        "Owner_reputation":13237,
        "Owner_up_votes":2454,
        "Owner_down_votes":19,
        "Owner_views":2675,
        "Answer_body":"<p>Could you please run <code>dvc doctor<\/code> and rerun <code>dvc push<\/code> and add <code>-vv<\/code> flag. And give the two results?<\/p>\n<pre><code>PermissionError: The AWS Access Key Id you provided does not exist in our records.\n<\/code><\/pre>\n<p>Does the <code>aws cli<\/code> works correctly for you? First setup <code>AWS_ACCESS_KEY_ID<\/code> and <code>AWS_SECRET_ACCESS_KEY<\/code> in envs then<\/p>\n<pre><code>aws s3 ls s3:\/\/mybucket\/dvcstore\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2021-09-21 07:49:25.513 UTC",
        "Answer_score":3.0,
        "Owner_location":"Chandigarh, India",
        "Answer_last_edit_date":"2021-09-21 08:10:31.43 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69265000",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73565648,
        "Question_title":"DVC shows files not tracked in source control in visual studio code",
        "Question_body":"<p>I'm using DVC extension in VScode inside a python project. The problem is that dvc shows files not tracked by dvc in the source control panel! As in the following picture.\nDVC track only data folder and not the src folder. How can I fix it? Have you also encountered these problems?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-01 07:31:06.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-01 08:31:32.697 UTC",
        "Question_score":0,
        "Question_tags":"visual-studio-code|dvc",
        "Question_view_count":39,
        "Owner_creation_date":"2020-02-02 18:40:04.397 UTC",
        "Owner_last_access_date":"2022-09-24 14:57:14.117 UTC",
        "Owner_reputation":498,
        "Owner_up_votes":453,
        "Owner_down_votes":9,
        "Owner_views":66,
        "Answer_body":"<p>The files shown are completely untracked. They are shown in both SCM trees so you can add them to either Git or DVC using inline actions.\nOnce the files are tracked by one of the tools they should only show up under the appropriate tree.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-09-01 08:59:16.173 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-09-01 09:01:56.69 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73565648",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":65416056,
        "Question_title":"Data Version Control: Absolute Paths and Project Paths in the Pipeline Parameters?",
        "Question_body":"<p>In DVC one may define pipelines.  In Unix, one typically does not work at the root level.  Further, DVC expects files to be inside the git repository.<\/p>\n<p>So, this seems like a typical problem.<\/p>\n<p>Suppose I have the following:<\/p>\n<pre><code>\/home\/user\/project\/content-folder\/data\/data-type\/cfg.json\n\/home\/user\/project\/content-folder\/app\/foo.py\n<\/code><\/pre>\n<p>Git starts at <code>\/home\/user\/project\/<\/code><\/p>\n<pre><code>cd ~\/project\/content-folder\/data\/data-type\n..\/..\/app\/foo.py do-this --with cfg.json --dest $(pwd) \n<\/code><\/pre>\n<p>Seems reasonable to me: the script takes a configuration, which is stored in a particular location, runs it against some encapsulated functionality, and outputs it to the destination using an absolute path.<\/p>\n<p>The default behavior of <code>--dest<\/code> is to output to the current working directory.  This seems like another reasonable default.<\/p>\n<hr \/>\n<p>Next, I go to configure the <code>params.yaml<\/code> file for <code>dvc<\/code>, and I am immediately confusing and unsure what is going to happen.  I write:<\/p>\n<pre><code>foodoo:\n  params: do-this --with ????\/cfg.json --dest ????\n<\/code><\/pre>\n<p>What I want to write (and would in a shell script):<\/p>\n<pre><code>#!\/usr\/bin\/env bash\norigin:=$(git rev-parse --show-toplevel)\n\nverb=do-this\nparams=--with $(origin)\/content-folder\/data\/data-type\/cfg.json --dest $(origin)\/content-folder\/data\/data-type\n<\/code><\/pre>\n<hr \/>\n<p>But, in DVC, the pathing seems to be implicit, and I do not know where to start as either:<\/p>\n<ol>\n<li>DVC will calculate the path to my script locally<\/li>\n<li>Not calculate the path to my script locally<\/li>\n<\/ol>\n<p>Which is fine -- I can discover that.  But I am reasonably sure that DVC will absolutely not prefix the directory and file params in my params.yaml with the path to my project.<\/p>\n<hr \/>\n<p>How does one achieve path control that does not assume a fixed project location, like I would in BASH?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-22 21:32:10.887 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"git|path|dvc",
        "Question_view_count":448,
        "Owner_creation_date":"2014-07-13 14:36:30.02 UTC",
        "Owner_last_access_date":"2022-09-23 21:23:45.423 UTC",
        "Owner_reputation":26244,
        "Owner_up_votes":434,
        "Owner_down_votes":35,
        "Owner_views":1383,
        "Answer_body":"<p>By default, DVC will run your stage command from the same directory as the <a href=\"https:\/\/dvc.org\/doc\/user-guide\/dvc-files#dvcyaml-file\" rel=\"nofollow noreferrer\">dvc.yaml<\/a> file. If you need to run the command from a different location, you can specify an alternate working directory via <code>wdir<\/code>, which should be a path relative to <code>dvc.yaml<\/code>'s location.<\/p>\n<p>Paths for everything else in your stage (like <code>params.yaml<\/code>) should be specified as relative to <code>wdir<\/code> (or relative to <code>dvc.yaml<\/code> if <code>wdir<\/code> is not provided).<\/p>\n<p>Looking at your example, there also seems to be a bit of confusion on parameters in DVC. In a DVC stage, <code>params<\/code> is for specifying <a href=\"https:\/\/dvc.org\/doc\/command-reference\/params\" rel=\"nofollow noreferrer\">parameter dependencies<\/a>, not used for specifying command-line flags. The full command including flags\/options should be included  the <code>cmd<\/code> section for your stage. If you wanted to make sure that your stage was rerun every time certain values in <code>cfg.json<\/code> have changed, your stage's <code>params<\/code> section would look something like:<\/p>\n<pre><code>params:\n  &lt;relpath from dvc.yaml&gt;\/cfg.json:\n    - param1\n    - param2\n    ...\n<\/code><\/pre>\n<p>So your example <code>dvc.yaml<\/code> would look something like:<\/p>\n<pre><code>stages:\n  foodoo:\n    cmd: &lt;relpath from dvc.yaml&gt;\/foo.py do-this --with &lt;relpath from dvc.yaml&gt;\/cfg.json --dest &lt;relpath from dvc.yaml&gt;\/...\n    deps:\n      &lt;relpath from dvc.yaml&gt;\/foo.py\n    params:\n      &lt;relpath from dvc.yaml&gt;\/cfg.json:\n        ...\n    ...\n<\/code><\/pre>\n<p>This would make the command <code>dvc repro<\/code> rerun your stage any time that the code in foo.py has changed, or the specified parameters in <code>cfg.json<\/code> have changed.<\/p>\n<p>You may also want to refer to the docs for <a href=\"https:\/\/dvc.org\/doc\/command-reference\/run#run\" rel=\"nofollow noreferrer\">dvc run<\/a>, which can be used to generate or update a <code>dvc.yaml<\/code> stage (rather than writing <code>dvc.yaml<\/code> by hand)<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-12-23 01:27:49.86 UTC",
        "Answer_score":2.0,
        "Owner_location":"Atlanta, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65416056",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73567700,
        "Question_title":"What DVC does when git merge is executed?",
        "Question_body":"<p>I have two git branches (master and develop). DVC maps a data folder in both of them. When I go into master and merging with develop is correct that DVC does not add any new file inside the data folder created in the develop branch but leaves the folder as it is unchanged?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-01 10:15:31.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-02 05:40:50.203 UTC",
        "Question_score":1,
        "Question_tags":"git|dvc",
        "Question_view_count":40,
        "Owner_creation_date":"2020-02-02 18:40:04.397 UTC",
        "Owner_last_access_date":"2022-09-24 14:57:14.117 UTC",
        "Owner_reputation":498,
        "Owner_up_votes":453,
        "Owner_down_votes":9,
        "Owner_views":66,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73567700",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":73025023,
        "Question_title":"DVC pull returns ERROR: configuration error - Failed to authenticate GDrive remote: name: drive version: v2",
        "Question_body":"<p>I ran this github actions workflow with several variations, but I cannot pull the data from DVC.<\/p>\n<pre><code>name: auto-testing\non: [push]\njobs:\n  run:\n    runs-on: [ubuntu-latest]\n    steps:\n      - uses: actions\/checkout@v2\n      - uses: iterative\/setup-dvc@v1\n      - name: Get data\n        run: |\n          echo '---'\n          echo GDRIVE_CREDENTIALS_DATA: $GDRIVE_CREDENTIALS_DATA\n          echo '---'\n          #pip list\n          dvc remote default storage\n          #dvc remote modify storage --local gdrive_use_service_account true\n          #dvc remote modify storage --local gdrive_service_account_json_file_path .dvc\/gdrive-access.json\n          dvc pull\n        env:\n          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          #GDRIVE_CREDENTIALS_DATA : ${{ secrets.GDRIVE_CREDENTIALS_DATA }}   \n      - name: Install requirements\n        run: |\n          pip install -r requirements.txt\n      - name: Run tests\n        run: python src\/test.py  \n<\/code><\/pre>\n<p>GDRIVE_CREDENTIALS_DATA is populated with the contents of the json file that I donwloaded from google and it was tested on two other computers. I tried using the environment variable as well as adding the json file to the repo to see if it would work. But no. I am getting this error message:<\/p>\n<blockquote>\n<p>ERROR: configuration error - Failed to authenticate GDrive remote: name: drive  version: v2\nERROR: Failed to authenticate GDrive remote\nLearn more about configuration settings at <a href=\"https:\/\/man.dvc.org\/remote\/modify\" rel=\"nofollow noreferrer\">https:\/\/man.dvc.org\/remote\/modify<\/a>.\nError: Process completed with exit code 251.<\/p>\n<\/blockquote>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-18 15:41:49.77 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"dvc",
        "Question_view_count":129,
        "Owner_creation_date":"2015-10-16 01:35:39.707 UTC",
        "Owner_last_access_date":"2022-09-22 23:31:19.043 UTC",
        "Owner_reputation":6513,
        "Owner_up_votes":1296,
        "Owner_down_votes":60,
        "Owner_views":1057,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73025023",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":66409283,
        "Question_title":"updating data in dvc registry from other projects",
        "Question_body":"<p>I have a couple of projects that are using and updating the same data sources. I recently learned about <a href=\"https:\/\/dvc.org\/doc\/use-cases\/data-registries\" rel=\"nofollow noreferrer\">dvc's data registries<\/a>, which sound like a great way of versioning data across these different projects (e.g. scrapers, computational pipelines).<\/p>\n<p>I have put all of the relevant data into <code>data-registry<\/code> and then I imported the relevant files into the scraper project with:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ poetry run dvc import https:\/\/github.com\/username\/data-registry raw\n<\/code><\/pre>\n<p>where <code>raw<\/code> is a directory that stores the scraped data. This seems to have worked properly, but then when I went to build <a href=\"https:\/\/dvc.org\/doc\/start\/data-pipelines\" rel=\"nofollow noreferrer\">a dvc pipeline<\/a> that <em>outputted<\/em> data into a file that was already tracked by dvc, I got an error:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ dvc run -n menu_items -d src\/ -o raw\/menu_items\/restaurant.jsonl scrapy crawl restaurant\nERROR: Paths for outs:                                                \n'raw'('raw.dvc')\n'raw\/menu_items\/restaurant.jsonl'('menu_items')\noverlap. To avoid unpredictable behaviour, rerun command with non overlapping outs paths.\n<\/code><\/pre>\n<p>Can someone help me understand what is going on here? <strong>What is the best way to use data registries to share and update data across projects?<\/strong><\/p>\n<p>I would ideally like to update the data-registry with new data from the scraper project and then allow other dependent projects to update their data when they are ready to do so.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-02-28 12:51:53.937 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-03-02 15:33:38.993 UTC",
        "Question_score":3,
        "Question_tags":"data-management|dvc",
        "Question_view_count":388,
        "Owner_creation_date":"2011-01-05 23:08:56.687 UTC",
        "Owner_last_access_date":"2022-08-27 16:39:52.827 UTC",
        "Owner_reputation":2893,
        "Owner_up_votes":294,
        "Owner_down_votes":1,
        "Owner_views":168,
        "Answer_body":"<p>When you <code>import<\/code> (or <code>add<\/code>) something into your project, a .dvc file is created with that lists that something (in this case the <code>raw\/<\/code> dir) as an &quot;output&quot;.<\/p>\n<p>DVC doesn't allow overlapping outputs among .dvc files or dvc.yaml stages, meaning that your &quot;menu_items&quot; stage shouldn't write to <code>raw\/<\/code> since it's already under the control of <code>raw.dvc<\/code>.<\/p>\n<p>Can you make a separate directory for the pipeline outputs? E.g. use <code>processed\/menu_items\/restaurant.jsonl<\/code><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-02-28 18:34:51.72 UTC",
        "Answer_score":1.0,
        "Owner_location":"Chicago, IL",
        "Answer_last_edit_date":"2021-03-02 15:29:48.013 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66409283",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":62441146,
        "Question_title":"Revert a dvc remove -p command",
        "Question_body":"<p>I have just removed a DVC tracking file by mistake using the command <code>dvc remove training_data.dvc -p<\/code>, which led to all my training dataset gone completely. I know in Git, we can easily revert a deleted branch based on its hash. Does anyone know how to revert all my lost data in DVC?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-18 02:00:22.65 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"dvc",
        "Question_view_count":687,
        "Owner_creation_date":"2016-07-08 02:05:15.393 UTC",
        "Owner_last_access_date":"2022-09-25 05:18:34.54 UTC",
        "Owner_reputation":173,
        "Owner_up_votes":97,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":"<p>You should be safe (at least data is not gone) most likely. From the <code>dvc remove<\/code> <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remove\" rel=\"nofollow noreferrer\">docs<\/a>:<\/p>\n\n<blockquote>\n  <p>Note that it does not remove files from the DVC cache or remote storage (see dvc gc). However, remember to run <code>dvc push<\/code> to save the files you actually want to use or share in the future.<\/p>\n<\/blockquote>\n\n<p>So, if you created <code>training_data.dvc<\/code> as with <code>dvc add<\/code> and\/or <code>dvc run<\/code> and <code>dvc remove -p<\/code> didn't ask\/warn you about anything, means that data is cached similar to Git in the <code>.dvc\/cache<\/code>. <\/p>\n\n<p>There are ways to retrieve it, but I would need to know a little bit more details - how exactly did you add your dataset? Did you commit <code>training_data.dvc<\/code> or it's completely gone? Was it the only data you have added so far? (happy to help you in comments).<\/p>\n\n<h2>Recovering a directory<\/h2>\n\n<p>First of all, <a href=\"https:\/\/dvc.org\/doc\/user-guide\/dvc-files-and-directories#structure-of-cache-directory\" rel=\"nofollow noreferrer\">here<\/a> is the document that describes briefly how DVC stores directories in the cache.<\/p>\n\n<p>What we can do is to find all <code>.dir<\/code> files in the <code>.dvc\/cache<\/code>:<\/p>\n\n<p><code>find .dvc\/cache -type f -name \"*.dir\"<\/code><\/p>\n\n<p>outputs something like:<\/p>\n\n<pre><code>.dvc\/cache\/20\/b786b6e6f80e2b3fcf17827ad18597.dir\n.dvc\/cache\/00\/db872eebe1c914dd13617616bb8586.dir\n.dvc\/cache\/2d\/1764cb0fc973f68f31f5ff90ee0883.dir\n<\/code><\/pre>\n\n<p>(if the local cache is lost and we are restoring data from the remote storage, the same logic applies, commands (e.g. to find files on S3 with .dir extension) look different)<\/p>\n\n<p>Each <code>.dir<\/code> file is a JSON with a content of one version of a directory (file names, hashes, etc). It has all the information needed to restore it. The next thing we need to do is to understand which one do we need. There is no one single rule for that, what I would recommend to check (and pick depending on your use case):<\/p>\n\n<ul>\n<li>Check the date modified (if you remember when this data was added).<\/li>\n<li>Check the content of those files - if you remember a specific file name that was present only in the directory you are looking for - just grep it.<\/li>\n<li>Try to restore them one by one and check the directory content.<\/li>\n<\/ul>\n\n<p>Okay, now let's imagine we decided that we want to restore <code>.dvc\/cache\/20\/b786b6e6f80e2b3fcf17827ad18597.dir<\/code>, (e.g. because content of it looks like:<\/p>\n\n<pre><code>[\n{\"md5\": \"6f597d341ceb7d8fbbe88859a892ef81\", \"relpath\": \"test.tsv\"}, {\"md5\": \"32b715ef0d71ff4c9e61f55b09c15e75\", \"relpath\": \"train.tsv\"}\n]\n<\/code><\/pre>\n\n<p>and we want to get a directory with <code>train.tsv<\/code>).<\/p>\n\n<p>The only thing we need to do is to create a <code>.dvc<\/code> file that references this directory:<\/p>\n\n<pre class=\"lang-yaml prettyprint-override\"><code>outs:\n- md5: 20b786b6e6f80e2b3fcf17827ad18597.dir\n  path: my-directory\n<\/code><\/pre>\n\n<p>(note, that path \/20\/b786b6e6f80e2b3fcf17827ad18597.dir became a hash value: 20b786b6e6f80e2b3fcf17827ad18597.dir)<\/p>\n\n<p>And run <code>dvc pull<\/code> on this file.<\/p>\n\n<p>That should be it.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-18 05:17:16.92 UTC",
        "Answer_score":3.0,
        "Owner_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Answer_last_edit_date":"2020-06-18 16:15:29.89 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62441146",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":71155959,
        "Question_title":"How to merge data (CSV) files from multiple branches (Git and DVC)?",
        "Question_body":"<p><strong>Background<\/strong>: In my projects I'm using GIT and <a href=\"https:\/\/dvc.org\/\" rel=\"nofollow noreferrer\">DVC<\/a> to keep track of versions:<\/p>\n<ul>\n<li>GIT - only for source codes<\/li>\n<li>DVC - for dataset, model objects and outputs<\/li>\n<\/ul>\n<p>I'm testing different approaches in separate branches, i.e:<\/p>\n<ul>\n<li>random_forest<\/li>\n<li>neural_network_1<\/li>\n<li>...<\/li>\n<\/ul>\n<p>Typically as an output I'm keeping predictions in csv file with standarised name (i.e.: pred_test.csv). As a consequence in different branches I've different pred_test.csv files. The structure of the file is very simple, it contains two columns:<\/p>\n<ul>\n<li>ID<\/li>\n<li>Prediction<\/li>\n<\/ul>\n<p><strong>Question<\/strong>: What is the best way to merge those prediction files into single big file?<\/p>\n<p>I would like to obtain a file with structure:<\/p>\n<ul>\n<li>ID<\/li>\n<li>Prediction_random_forest<\/li>\n<li>Prediction_neural_network_1<\/li>\n<li>Prediction_...<\/li>\n<\/ul>\n<p>My main issue is how to access files with predictions which are in different branches?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2022-02-17 10:01:04.283 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-02-17 21:13:50.277 UTC",
        "Question_score":0,
        "Question_tags":"git|data-science|dvc",
        "Question_view_count":274,
        "Owner_creation_date":"2010-02-09 19:11:11.2 UTC",
        "Owner_last_access_date":"2022-07-26 11:14:45.253 UTC",
        "Owner_reputation":2735,
        "Owner_up_votes":190,
        "Owner_down_votes":7,
        "Owner_views":552,
        "Answer_body":"<p>I would try to use <a href=\"https:\/\/dvc.org\/doc\/command-reference\/get\" rel=\"nofollow noreferrer\"><code>dvc get<\/code><\/a> in this case:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc get -o random_forest_pred.csv --rev random_forest . pred_test.csv\n<\/code><\/pre>\n<p>It should bring the <code>pred_test.csv<\/code> from the <code>random_forest<\/code> branch.<\/p>\n<blockquote>\n<p>Mind the <code>.<\/code> before the <code>pred_test.csv<\/code> please, it's needed and it means that &quot;use the current repo&quot;, since <code>dvc get<\/code> could also be used on other repos (e.g. GitHub URL)<\/p>\n<\/blockquote>\n<p>Then I think you could use some CLI or write a script to join the files:<\/p>\n<p><a href=\"https:\/\/unix.stackexchange.com\/questions\/293775\/merging-contents-of-multiple-csv-files-into-single-csv-file\">https:\/\/unix.stackexchange.com\/questions\/293775\/merging-contents-of-multiple-csv-files-into-single-csv-file<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-02-17 15:51:31.963 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71155959",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":65771384,
        "Question_title":"Data Version Control (dvc) cannot push to remote storage because querying cache",
        "Question_body":"<p>I am setting up a remote storage with dvc using webdavs<\/p>\n<p>I can connect to the remote storage from Finder.<\/p>\n<p>I added the new remote and I see it when I check (dvc remote list)<\/p>\n<p>But when I try to push data, I have the request for password with 0% Querying cache<\/p>\n<p>It stays 0% forever. And when I enter the password, it ends with the following error:<\/p>\n<p>ERROR: unexpected error - No connection with LINK_OF_REMOTE_STORAGE<\/p>\n<p>The only thing I am thinking about is how to check if I can connect to the server from dvc and why querying cache never ends (maybe never starts even)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-01-18 08:57:03.987 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-18 09:20:48.253 UTC",
        "Question_score":0,
        "Question_tags":"dvc",
        "Question_view_count":436,
        "Owner_creation_date":"2014-09-25 09:26:32.833 UTC",
        "Owner_last_access_date":"2022-03-31 00:43:52.467 UTC",
        "Owner_reputation":175,
        "Owner_up_votes":19,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65771384",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":53213596,
        "Question_title":"How to execute python from conda environment by dvc run",
        "Question_body":"<p>I have an environment of conda configurated with python 3.6 and dvc is installed there, but when I try to execute dvc run with python, dvc call the python version of main installation of conda and not find the installed libraries.<\/p>\n\n<pre><code>$ conda activate py36\n$ python --version\nPython 3.6.6 :: Anaconda custom (64-bit)\n$ dvc run python --version\nRunning command:\n    python --version\nPython 3.7.0\nSaving information to 'Dvcfile'.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2018-11-08 17:59:32.677 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":6,
        "Question_tags":"python|anaconda|conda|dvc",
        "Question_view_count":351,
        "Owner_creation_date":"2015-01-09 01:04:40.79 UTC",
        "Owner_last_access_date":"2022-09-19 19:03:26.113 UTC",
        "Owner_reputation":340,
        "Owner_up_votes":477,
        "Owner_down_votes":2,
        "Owner_views":61,
        "Answer_body":"<p>The version 0.24.3 of dvc correct this problem.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-02-06 00:55:31.5 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53213596",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":56456463,
        "Question_title":"Unable to ignore .DS_Store files in DVC",
        "Question_body":"<p>I use DVC to track my media files. I use MacOS and I want\".DS_Store\" files to be ignored by DVC. According to DVC documentation I can achieve it with  <a href=\"https:\/\/dvc.org\/doc\/user-guide\/dvcignore\" rel=\"nofollow noreferrer\">.dvcignore<\/a>. I created <code>.dvcignore<\/code> file with \".DS_Store\" rule. However every time \".DS_Store\" is created <code>dvc status<\/code> still says that content has changed<\/p>\n\n<p>Here is the little test to reproduce my issue:<\/p>\n\n<pre><code>$ git init\n$ dvc init\n\n# create directory to store data\n# and track it's content with DVC\n$ mkdir data\n$ dvc add data\n\n# Ignore .DS_Store files created by MacOS\n$ echo \".DS_Store\" &gt; .dvcignore\n\n# create .DS_Store in data dir\n$ touch \"data\/.DS_Store\"\n<\/code><\/pre>\n\n<p>If I understand DVC documentation correctly then <code>dvc status<\/code> should print something like \"Pipeline is up to date. Nothing to reproduce\". However <code>dvc status<\/code> gives me:<\/p>\n\n<pre><code>data.dvc:\n        changed outs:\n                modified:           data\n<\/code><\/pre>\n\n<p>How I can really ignore \".DS_Store\" files?<\/p>\n\n<p><strong>UPDATE:<\/strong> The .dvcignore support noticeably improved in latest versions and the problem is no more relevant.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2019-06-05 08:07:00.69 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-20 02:59:15.943 UTC",
        "Question_score":3,
        "Question_tags":"dvc",
        "Question_view_count":326,
        "Owner_creation_date":"2018-03-28 16:31:38.71 UTC",
        "Owner_last_access_date":"2022-09-23 10:08:33.687 UTC",
        "Owner_reputation":784,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":77,
        "Answer_body":"<p>The current implementation of <code>.dvcignore<\/code> is very limited. Read more on it <a href=\"https:\/\/dvc.org\/doc\/user-guide\/dvcignore\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>Please, mention that you are interested in this feature here - <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1876\" rel=\"nofollow noreferrer\">https:\/\/github.com\/iterative\/dvc\/issues\/1876<\/a>. That would help our team to prioritize issues properly.<\/p>\n\n<p>The possible workaround for now would be to use one of these approaches - <a href=\"https:\/\/stackoverflow.com\/questions\/18015978\/how-to-stop-creating-ds-store-on-mac\">How to stop creating .DS_Store on Mac?<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-05 18:09:37.417 UTC",
        "Answer_score":3.0,
        "Owner_location":"Russia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56456463",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":72451922,
        "Question_title":"How can dvc pipeline recognize when to use encoding pipeline while new data added for the modeling?",
        "Question_body":"<p>I have created separate pipelines for feature encoding and feature scaling in DVC.\nNow, when I will input new data from my flask API, how these DVC pipelines will automatically run and encode and scale data for modelling?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-05-31 17:24:05.533 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"machine-learning|pipeline|mlops|dvc",
        "Question_view_count":25,
        "Owner_creation_date":"2022-05-31 17:05:18.443 UTC",
        "Owner_last_access_date":"2022-09-24 10:05:19.797 UTC",
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72451922",
        "Question_exclusive_tag":"DVC"
    },
    {
        "Question_id":71338160,
        "Question_title":"DVC Experiment management workflow",
        "Question_body":"<p>I'm struggling with the DVC experiment management. Suppose the following scenario:<\/p>\n<p>I have <code>params.yaml<\/code> file:<\/p>\n<pre><code>recommendations:\n  k: 66\n  q: 5\n<\/code><\/pre>\n<p>I run the experiment with <code>dvc exp run -n exp_66<\/code>, and then I do <code>dvc exp push origin exp_66<\/code>. After this, I modify <code>params.yaml<\/code> file:<\/p>\n<pre><code>recommendations:\n  k: 99\n  q: 5\n<\/code><\/pre>\n<p>and then run another experiment <code>dvc exp run -n exp_99<\/code>, after which I commit with <code>dvc exp push origin exp_99<\/code>.<\/p>\n<p>Now, when I pull the corresponding branch with Git, I try to pull <code>exp_66<\/code> from dvc by running <code>dvc exp pull origin exp_66<\/code>. This does the pull (no error messages), but the content of the <code>params.yaml<\/code> file is with <code>k: 99<\/code> (and I would expect <code>k: 66<\/code>). What am I doing wrong? Does <code>git push<\/code> have to be executed after <code>dvc push<\/code>? Apart from that, I also found <code>dvc exp apply exp_66<\/code>, but I'm not sure what it does (it is suggested that after <code>apply<\/code> one should execute <code>git add .<\/code>, then <code>git commit<\/code>?<\/p>\n<p>I would really appreciate if you could write down the workflow with committing different experiments, pushing, pulling, applying, etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-03 13:38:53.127 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"git|dvcs|dvc",
        "Question_view_count":152,
        "Owner_creation_date":"2022-01-28 12:42:49.633 UTC",
        "Owner_last_access_date":"2022-09-21 13:14:46.48 UTC",
        "Owner_reputation":67,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>You did everything alright. In the end, after pulling, you can see that when using <code>dvc exp show<\/code> your experiments will be there. To restore the experiment available from your experiment list into your workspace, you simply need to run <code>dvc exp apply exp_66<\/code>. DVC will make sure that the changes corresponding to this experiment will be checked out.<\/p>\n<p>Your workflow seems correct so far. One addition: once you make sure one of the experiments is what you want to &quot;keep&quot; in git history, you can use <code>dvc exp branch {exp_id} {branch_name}<\/code> to create a separate branch for this experiment. Then you can use <code>git<\/code> commands to save the changes.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2022-03-03 15:05:59.073 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71338160",
        "Question_exclusive_tag":"DVC"
    }
]