[
    {
        "Question_id":59642900,
        "Question_title":"Unable to connect Mlflow server to my mlflow project image",
        "Question_body":"<p>My final purpose is to run experiment from  an Api.<\/p>\n\n<p>the experiment come from :\n<a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/tensorflow\/tf2\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/tensorflow\/tf2<\/a>\nbut export the file in my custom git where I clone it, in the image below -><\/p>\n\n<p>I have 2 images in my docker compose :\ntree project : <\/p>\n\n<pre><code>|_app\/\n| |_Dockerfile\n|\n|_mlflow\/\n| |_Dockerfile\n|\n|_docker-compose.yml\n\n<\/code><\/pre>\n\n<p>app\/Dockerfile<\/p>\n\n<pre><code>FROM continuumio\/anaconda3\n\nENV APP_HOME .\/\nWORKDIR ${APP_HOME}\nRUN conda config --append channels conda-forge\nRUN conda install --quiet --yes \\\n    'mlflow' \\\n    'psycopg2' \\\n    'tensorflow'\nRUN pip install pylint\nRUN pwd;ls \\\n&amp;&amp; git clone https:\/\/github.com\/MChrys\/QuickSign.git \nRUN pwd;ls \\\n    &amp;&amp; cd QuickSign \\\n    &amp;&amp; pwd;ls\n\nCOPY . .\n\n#RUN conda install jupyter \n#CMD jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --no-browser\nCMD cd QuickSign &amp;&amp; mlflow run .\n<\/code><\/pre>\n\n<p>mlflow\/Dockerfile<\/p>\n\n<pre><code>FROM python:3.7.0\n\nRUN pip install mlflow\n\nRUN mkdir \/mlflow\/\n\nCMD mlflow server \\\n    --backend-store-uri \/mlflow \\\n    --host 0.0.0.0\n<\/code><\/pre>\n\n<p>docker-compose.yml<\/p>\n\n<pre><code>version: '3'\nservices:\n  notebook:\n    build:\n      context: .\/app\n    ports:\n      - \"8888:8888\"\n    depends_on: \n      - mlflow\n    environment: \n      MLFLOW_TRACKING_URI: 'http:\/\/mlflow:5000'\n  mlflow:\n    build:\n      context: .\/mlflow\n    expose: \n      - \"5000\"\n    ports:\n      - \"5000:5000\"\n<\/code><\/pre>\n\n<p>when I <code>docker-compose up<\/code> the image I obtain  :<\/p>\n\n<pre><code>notebook_1_74059cdc20ce |     response = requests.request(**kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/api.py\", line 60, in request\nnotebook_1_74059cdc20ce |     return session.request(method=method, url=url, **kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 533, in request\nnotebook_1_74059cdc20ce |     resp = self.send(prep, **send_kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 646, in send\nnotebook_1_74059cdc20ce |     r = adapter.send(request, **kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 516, in send\nnotebook_1_74059cdc20ce |     raise ConnectionError(e, request=request)\nnotebook_1_74059cdc20ce | requests.exceptions.ConnectionError: HTTPConnectionPool(host='mlflow', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7fd5db4edc50&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n\n<\/code><\/pre>\n\n<p>The problem look like that I run a project which is not found in the server images, as I run it in the app image, but I don't know how figure it out I have to trigger  the experiment from a futur flask app <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-08 09:28:18.63 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-01-08 09:55:26.563 UTC",
        "Question_score":0,
        "Question_tags":"docker|docker-compose|mlflow",
        "Question_view_count":2937,
        "Owner_creation_date":"2016-04-02 19:35:23.203 UTC",
        "Owner_last_access_date":"2022-03-27 00:55:04.593 UTC",
        "Owner_reputation":56,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":39,
        "Answer_body":"<p>The problem came from  docker for windows, I was unable to make working docker compose on it but there are no problem to build it when I run it on virtual machine with ubuntu.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-04-09 12:53:57.59 UTC",
        "Answer_score":0.0,
        "Owner_location":"Grenoble, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59642900",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59856641,
        "Question_title":"How can I throw an exception from within an MLflow project?",
        "Question_body":"<p>I have an Mlflow project that raises an exception. I execute that function using <code>mlflow.run<\/code>, but I get <code>mlflow.exceptions.ExecutionException(\"Run (ID '&lt;run_id&gt;') failed\")<\/code>. <\/p>\n\n<p>Is there any way I could get the exception that is being raised where I am executing <code>mlflow.run<\/code>? <\/p>\n\n<p>Or is it possible to send an <code>mlflow.exceptions.ExecutionException<\/code> with custom message set from within the project?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-22 09:41:00.327 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|exception|mlflow",
        "Question_view_count":428,
        "Owner_creation_date":"2016-09-03 19:53:45.4 UTC",
        "Owner_last_access_date":"2021-06-15 09:20:57.057 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Unfortunately not at the moment. mlflow run starts a new process and there is no protocol for exception passing right now. In general the other project does not even have to be in the same language. <\/p>\n\n<p>One workaround I can think of is to pass the exception via mlflow by setting run tag. E.g.:<\/p>\n\n<pre><code>try:\n    ...\nexcept Exception as ex:\n    mlflow.set_tag(\"exception\", str(ex))\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-01-22 18:56:59.647 UTC",
        "Answer_score":0.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":"2020-01-22 21:30:48.287 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59856641",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71846804,
        "Question_title":"How to I track loss at epoch using mlflow\/tensorflow?",
        "Question_body":"<p>I want to use mlflow to track the development of a TensorFlow model. How do I log the loss at each epoch? I have written the following code:<\/p>\n<pre><code>mlflow.set_tracking_uri(tracking_uri)\n\nmlflow.set_experiment(&quot;\/deep_learning&quot;)\nwith mlflow.start_run():\n    mlflow.log_param(&quot;batch_size&quot;, batch_size)\n    mlflow.log_param(&quot;learning_rate&quot;, learning_rate)\n    mlflow.log_param(&quot;epochs&quot;, epochs)\n    mlflow.log_param(&quot;Optimizer&quot;, opt)\n    mlflow.log_metric(&quot;train_loss&quot;, train_loss)\n    mlflow.log_metric(&quot;val_loss&quot;, val_loss)\n    mlflow.log_metric(&quot;test_loss&quot;, test_loss)\n    mlflow.log_metric(&quot;test_mse&quot;, test_mse)\n    mlflow.log_artifacts(&quot;.\/model&quot;)\n<\/code><\/pre>\n<p>If I change the train_loss and val_loss to<\/p>\n<pre><code>train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<pre><code>mlflow.exceptions.MlflowException: Got invalid value [12.041399002075195] for metric 'train_loss' (timestamp=1649783654667). Please specify value as a valid double (64-bit floating point)\n<\/code><\/pre>\n<p>How to I save the the loss and the val_loss at all epochs, so I can visualise a learning curve within mlflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-12 17:19:23.393 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|tensorflow|keras|tf.keras|mlflow",
        "Question_view_count":320,
        "Owner_creation_date":"2017-10-10 14:24:52.477 UTC",
        "Owner_last_access_date":"2022-06-13 10:15:22.463 UTC",
        "Owner_reputation":77,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":"<p>As you can read <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.keras.html#module-mlflow.keras\" rel=\"nofollow noreferrer\">here<\/a>. You can use <code>mlflow.tensorflow.autolog()<\/code> and this, (from doc):<\/p>\n<blockquote>\n<p>Enables (or disables) and configures autologging from Keras to MLflow. Autologging captures the following information:<\/p>\n<blockquote>\n<p>fit() or fit_generator() parameters; optimizer name; learning rate; epsilon\n...<\/p>\n<\/blockquote>\n<\/blockquote>\n<p>For example:<\/p>\n<pre><code># !pip install mlflow\nimport tensorflow as tf\nimport mlflow\nimport numpy as np\n\n\nX_train = np.random.rand(100,100)\ny_train = np.random.randint(0,10,100)\n    \n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.Input(100,))\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(rate=.4))\nmodel.add(tf.keras.layers.Dense(10, activation='sigmoid'))        \nmodel.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              optimizer='Adam', \n              metrics=['accuracy'])\nmodel.summary()\n\n\nmlflow.tensorflow.autolog()\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=50)\n<\/code><\/pre>\n<p>Or as you mention in the comment you can use <code>mlflow.set_tracking_uri()<\/code> like below:<\/p>\n<pre><code>mlflow.set_tracking_uri('http:\/\/127.0.0.1:5000')\ntracking_uri = mlflow.get_tracking_uri()\nwith mlflow.start_run(run_name='PARENT_RUN') as parent_run:\n    batch_size=50\n    history = model.fit(X_train, y_train, epochs=2, batch_size=batch_size)\n    mlflow.log_param(&quot;batch_size&quot;, batch_size)  \n<\/code><\/pre>\n<p>For getting results:<\/p>\n<pre><code>!mlflow ui\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>[....] [...] [INFO] Starting gunicorn 20.1.0\n[....] [...] [INFO] Listening at: http:\/\/127.0.0.1:5000 (****)\n[....] [...] [INFO] Using worker: sync\n[....] [...] [INFO] Booting worker with pid: ****\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XXoi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XXoi.png\" alt=\"enter image description here\" \/><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/V2tvM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/V2tvM.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-04-13 00:26:28.953 UTC",
        "Answer_score":1.0,
        "Owner_location":"Liverpool, UK",
        "Answer_last_edit_date":"2022-04-14 00:22:12.377 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71846804",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60641337,
        "Question_title":"mlflow R installation MLFLOW_PYTHON_BIN",
        "Question_body":"<p>I am trying to install mlflow in R and im getting this error message saying <\/p>\n\n<blockquote>\n  <p>mlflow::install_mlflow()\n  Error in mlflow_conda_bin() :\n    Unable to find conda binary. Is Anaconda installed?\n    If you are not using conda, you can set the environment variable MLFLOW_PYTHON_BIN to the path of yourpython executable.<\/p>\n<\/blockquote>\n\n<p>I have tried the following<\/p>\n\n<pre><code>export MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\" \nsource ~\/.bashrc\necho $MLFLOW_PYTHON_BIN  -&gt; this prints the \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>or in R,<\/p>\n\n<pre><code>sys.setenv(MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\")\nsys.getenv() -&gt; prints MLFLOW_PYTHON_BIN is set to \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>however, it still does not work<\/p>\n\n<p>I do not want to use conda environment.<\/p>\n\n<p>how to I get past this error?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-11 17:17:32.94 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-17 00:07:46.973 UTC",
        "Question_score":5,
        "Question_tags":"r|mlflow|system-variable",
        "Question_view_count":1141,
        "Owner_creation_date":"2018-10-10 22:41:41.843 UTC",
        "Owner_last_access_date":"2022-09-24 01:18:25.137 UTC",
        "Owner_reputation":117,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>The install_mlflow command only works with conda right now, sorry about the confusing message. You can either:<\/p>\n<ul>\n<li>install conda - this is the recommended way of installing and using mlflow<\/li>\n<\/ul>\n<p>or<\/p>\n<ul>\n<li>install mlflow python package yourself via pip<\/li>\n<\/ul>\n<p>To install mlflow yourself, pip install correct (matching the the R package) python version of mlflow and set the MLFLOW_PYTHON_BIN environment variable as well as MLFLOW_BIN evn variable: e.g.<\/p>\n<pre><code>library(mlflow)\nsystem(paste(&quot;pip install -U mlflow==&quot;, mlflow:::mlflow_version(), sep=&quot;&quot;))\nSys.setenv(MLFLOW_BIN=system(&quot;which mlflow&quot;))\nSys.setenv(MLFLOW_PYTHON_BIN=system(&quot;which python&quot;))\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-03-18 18:03:05.177 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-06-20 15:16:15.903 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60641337",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57199472,
        "Question_title":"Is it possible to set\/change mlflow run name after run initial creation?",
        "Question_body":"<p>I could not find a way yet of setting the runs name after the first start_run for that run (we can pass a name there). <\/p>\n\n<p>I Know we can use tags but that is not the same thing. I would like to add a run relevant name, but very often we know the name only after run evaluation or while we're running the run interactively in notebook for example.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-25 10:09:51.49 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-07-31 00:38:47.097 UTC",
        "Question_score":11,
        "Question_tags":"mlflow",
        "Question_view_count":7689,
        "Owner_creation_date":"2014-02-22 09:53:28.773 UTC",
        "Owner_last_access_date":"2021-04-14 22:23:03.79 UTC",
        "Owner_reputation":133,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>It is possible to edit run names from the MLflow UI. First, click into the run whose name you'd like to edit.<\/p>\n\n<p>Then, edit the run name by clicking the dropdown next the run name (i.e. the downward-pointing caret in this image):<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/sl6Qs.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sl6Qs.png\" alt=\"Rename run dropdown\"><\/a><\/p>\n\n<p>There's currently no stable public API for setting run names - however, you can programmatically set\/edit run names by setting the tag with key <code>mlflow.runName<\/code>, which is what the UI (currently) does under the hood.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-07-29 06:02:35.503 UTC",
        "Answer_score":9.0,
        "Owner_location":"Portugal",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57199472",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":55822637,
        "Question_title":"Is there a way to get log the descriptive stats of a dataset using MLflow?",
        "Question_body":"<p>Is there a way to get log the descriptive stats of a dataset using MLflow? If any could you please share the details?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-24 04:52:09.53 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|mlflow",
        "Question_view_count":4592,
        "Owner_creation_date":"2014-09-22 04:46:57.027 UTC",
        "Owner_last_access_date":"2022-09-03 08:12:58.187 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":41,
        "Owner_down_votes":3,
        "Owner_views":123,
        "Answer_body":"<p>Generally speaking you can log arbitrary output from your code using the mlflow_log_artifact() function.  From <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"noreferrer\">the docs<\/a>:<\/p>\n<blockquote>\n<p><strong>mlflow.log_artifact(local_path, artifact_path=None)<\/strong>\nLog a local file or directory as an artifact of the currently active run.<\/p>\n<\/blockquote>\n<blockquote>\n<p><strong>Parameters:<\/strong><br \/>\n<em>local_path<\/em> \u2013 Path to the file to write.\n<em>artifact_path<\/em> \u2013 If provided, the directory in artifact_uri to write to.<\/p>\n<\/blockquote>\n<p>As an example, say you have your statistics in a pandas dataframe, <code>stat_df<\/code>.<\/p>\n<pre><code>## Write csv from stats dataframe\nstat_df.to_csv('dataset_statistics.csv')\n\n## Log CSV to MLflow\nmlflow.log_artifact('dataset_statistics.csv')\n<\/code><\/pre>\n<p>This will show up under the artifacts section of this MLflow run in the Tracking UI.  If you explore the docs further you'll see that you can also log an entire directory and the objects therein.  In general, MLflow provides you a lot of flexibility - anything you write to your file system you can track with MLflow.  Of course that doesn't mean you should. :)<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-05-08 01:32:42.457 UTC",
        "Answer_score":9.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":"2021-01-26 04:34:50.617 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55822637",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71135260,
        "Question_title":"Python assert a function is called within a certain `with` statement's context",
        "Question_body":"<p>In python I would like to check that a given function is called within a <code>with<\/code> statement of a given type<\/p>\n<pre><code>class Bar:\n def __init__(self, x):\n  self.x = x\n def __enter__(self):\n  return self\n def __exit__(self, *a, **k):\n  pass\n\ndef foo(x):\n # assert that the enclosing context is an instance of bar\n # assert isinstance('enclosed context', Bar)\n print(x*2)\n\nwith Bar(1) as bar:\n foo(bar.x)\n<\/code><\/pre>\n<p>I could do something like enforcing an arg passed into <code>foo<\/code> and wrapping functions in a decorator i.e.<\/p>\n<pre><code>class Bar:\n def __init__(self, x):\n  self.x = x\n def __enter__(self):\n  return self\n def __exit__(self, *a, **k):\n  pass\n\ndef assert_bar(func):\n def inner(bar, *a, **k):\n  assert isinstance(bar, Bar)\n  return func(*a, **k)\n return inner\n\n\n@assert_bar\ndef foo(x):\n print(x*2)\n\nwith Bar(1) as bar:\n foo(bar, bar.x)\n\n<\/code><\/pre>\n<p>but then I would have to pass around <code>bar<\/code> everywhere.<\/p>\n<p>As a result I'm trying to see if there's a way to access the <code>with<\/code> context<\/p>\n<p>Note: The real world application of this is ensuring that <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#mlflow.pyfunc.log_model\" rel=\"nofollow noreferrer\"><code>mlflow.pyfunc.log_model<\/code><\/a> is called within an <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.ActiveRun\" rel=\"nofollow noreferrer\"><code>mlflow.ActiveRun<\/code><\/a> context, or it leaves an <code>ActiveRun<\/code> open, causing problems later on<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2022-02-16 01:03:09.773 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":77,
        "Owner_creation_date":"2016-09-06 20:29:03.197 UTC",
        "Owner_last_access_date":"2022-07-09 22:04:27.333 UTC",
        "Owner_reputation":617,
        "Owner_up_votes":21,
        "Owner_down_votes":2,
        "Owner_views":75,
        "Answer_body":"<p>Here's an ugly way to do it: global state.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Bar:\n    active = 0\n    def __init__(self, x):\n        self.x = x\n    def __enter__(self):\n        Bar.active += 1\n        return self\n    def __exit__(self, *a, **k):\n        Bar.active -= 1\n\nfrom functools import wraps\n\ndef assert_bar(func):\n    @wraps(func)\n    def wrapped(*vargs, **kwargs):\n        if Bar.active &lt;= 0:\n            # raises even if asserts are disabled\n            raise AssertionError()\n        return func(*vargs, **kwargs)\n    return wrapped\n<\/code><\/pre>\n<p>Unfortunately I don't think there is any non-ugly way to do it. If you aren't going to pass around a <code>Bar<\/code> instance yourself then you must rely on some state existing somewhere else to tell you that a <code>Bar<\/code> instance exists and is currently being used as a context manager.<\/p>\n<p>The only way you can avoid that global state is to store the state in the instance, which means the decorator needs to be an instance method and the instance needs to exist before the function is declared:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from functools import wraps\n\nclass Bar:\n    def __init__(self, x):\n        self.x = x\n        self.active = 0\n    def __enter__(self):\n        self.active += 1\n        return self\n    def __exit__(self, *a, **k):\n        self.active -= 1\n    def assert_this(self, func):\n        @wraps(func)\n        def wrapped(*vargs, **kwargs):\n            if self.active &lt;= 0:\n                raise AssertionError()\n            return func(*vargs, **kwargs)\n        return wrapped\n\nbar = Bar(1)\n\n@bar.assert_this\ndef foo(x):\n    print(x + 1)\n\nwith bar:\n    foo(1)\n<\/code><\/pre>\n<p>This is still &quot;global state&quot; in the sense that the function <code>foo<\/code> now holds a reference to the <code>Bar<\/code> instance that holds the state. But it may be more palatable if <code>foo<\/code> is only ever going to be a local function.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-02-16 01:13:37.813 UTC",
        "Answer_score":2.0,
        "Owner_location":"London, United Kingdom",
        "Answer_last_edit_date":"2022-02-16 01:21:18.49 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71135260",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63255631,
        "Question_title":"MLflow: INVALID_PARAMETER_VALUE: Unsupported URI '.\/mlruns' for model registry store",
        "Question_body":"<p>I got this error when I was trying to have a model registered in the model registry. Could someone help me?<\/p>\n<pre><code>RestException: INVALID_PARAMETER_VALUE: Unsupported URI '.\/mlruns' for model registry store. \nSupported schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. \nSee https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to setup a compatible server.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-04 21:54:55.187 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2020-08-30 19:18:05.667 UTC",
        "Question_score":10,
        "Question_tags":"python|mlflow",
        "Question_view_count":12594,
        "Owner_creation_date":"2014-12-26 18:42:31.727 UTC",
        "Owner_last_access_date":"2022-02-07 21:07:16.15 UTC",
        "Owner_reputation":125,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>Mlflow required DB as datastore for Model Registry\nSo you have to run tracking server with DB as backend-store and log model to this tracking server.\nThe easiest way to use DB is to use SQLite.<\/p>\n<pre><code>mlflow server \\\n    --backend-store-uri sqlite:\/\/\/mlflow.db \\\n    --default-artifact-root .\/artifacts \\\n    --host 0.0.0.0\n<\/code><\/pre>\n<p>And set MLFLOW_TRACKING_URI environment variable to <em>http:\/\/localhost:5000<\/em> or<\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\n<\/code><\/pre>\n<p>After got to http:\/\/localhost:5000 and you can register a logged model from UI or from the code.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2020-08-05 11:19:29.48 UTC",
        "Answer_score":27.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63255631",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73320708,
        "Question_title":"Set run description programmatically in mlflow",
        "Question_body":"<p>Similar to <a href=\"https:\/\/stackoverflow.com\/questions\/57199472\/is-it-possible-to-set-change-mlflow-run-name-after-run-initial-creation#:%7E:text=It%20is%20possible%20to%20edit,you%27d%20like%20to%20edit.&amp;text=There%27s%20currently%20no%20stable%20public,the%20tag%20with%20key%20mlflow.\">this question<\/a>, I'd like to edit\/set the description of a run via code, instead of editing it via UI.<\/p>\n<p>To clarify, I don't want to set the description of my entire experiment, only of a single run.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" alt=\"Image showing what I want to edit\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-11 12:32:23.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|artificial-intelligence|mlflow",
        "Question_view_count":89,
        "Owner_creation_date":"2018-05-28 16:43:18.183 UTC",
        "Owner_last_access_date":"2022-09-24 22:46:27.093 UTC",
        "Owner_reputation":736,
        "Owner_up_votes":829,
        "Owner_down_votes":8,
        "Owner_views":57,
        "Answer_body":"<p>There are two ways to set the description.<\/p>\n<h3>1. <code>description<\/code> parameter<\/h3>\n<p>You can set a description using a markdown string for your run in <code>mlflow.start_run()<\/code> using <code>description<\/code> parameter. Here is an example.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    with mlflow.start_run(description=run_description) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>2. <code>mlflow.note.content<\/code> tag<\/h3>\n<p>You can set\/edit run names by setting the tag with the key <code>mlflow.note.content<\/code>, which is what the UI (currently) does under the hood.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    tags = {\n        'mlflow.note.content': run_description\n    }\n\n    with mlflow.start_run(tags=tags) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>Result<\/h3>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" alt=\"output of the given example\" \/><\/a><\/p>\n<hr \/>\n<p>If you set <code>description<\/code> parameter and <code>mlflow.note.content<\/code> tag in <code>mlflow.start_run()<\/code>, you'll get this error.<\/p>\n<pre><code>Description is already set via the tag mlflow.note.content in tags.\nRemove the key mlflow.note.content from the tags or omit the description.\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-08-11 15:21:04.753 UTC",
        "Answer_score":1.0,
        "Owner_location":"Sarajevo, Bosnia and Herzegovina",
        "Answer_last_edit_date":"2022-08-12 12:36:55.687 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73320708",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68402406,
        "Question_title":"MLflow webserver returns 400 status, \"Incompatible input types for column X. Can not safely convert float64 to <U0.\"",
        "Question_body":"<p>I am implementing an anomaly detection web service using <code>MLflow<\/code> and <code>sklearn.pipeline.Pipeline()<\/code>. The aim of the model is to detect web crawlers using server log and <code>response_length<\/code> column is one of my features. After serving model, for testing the web service I send below request that contains the 20 first columns of the train data.<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ curl  --location --request POST '127.0.0.1:8000\/invocations'\n        --header 'Content-Type: text\/csv' \\\n        --data-binary 'datasets\/test.csv'\n<\/code><\/pre>\n<p>But response of the web server has status code 400 (BAD REQUEST) and this JSON body:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;error_code&quot;: &quot;BAD_REQUEST&quot;,\n    &quot;message&quot;: &quot;Incompatible input types for column response_length. Can not safely convert float64 to &lt;U0.&quot;\n}\n<\/code><\/pre>\n<p>Here is the model compilation MLflow Tracking component log:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>[Pipeline] ......... (step 1 of 3) Processing transform, total=11.8min\n[Pipeline] ............... (step 2 of 3) Processing pca, total=   4.8s\n[Pipeline] ........ (step 3 of 3) Processing rule_based, total=   0.0s\n2021\/07\/16 04:55:12 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n2021\/07\/16 04:55:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: &quot;\/home\/matin\/workspace\/Rahnema College\/venv\/lib\/python3.8\/site-packages\/mlflow\/models\/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values &lt;https:\/\/www.mlflow.org\/docs\/latest\/models.html#handling-integers-with-missing-values&gt;`_ for more details.&quot;\nLogged data and model in run: 8843336f5c31482c9e246669944b1370\n\n---------- logged params ----------\n{'memory': 'None',\n 'pca': 'PCAEstimator()',\n 'rule_based': 'RuleBasedEstimator()',\n 'steps': &quot;[('transform', &lt;log_transformer.LogTransformer object at &quot;\n          &quot;0x7f05a8b95760&gt;), ('pca', PCAEstimator()), ('rule_based', &quot;\n          'RuleBasedEstimator())]',\n 'transform': '&lt;log_transformer.LogTransformer object at 0x7f05a8b95760&gt;',\n 'verbose': 'True'}\n\n---------- logged metrics ----------\n{}\n\n---------- logged tags ----------\n{'estimator_class': 'sklearn.pipeline.Pipeline', 'estimator_name': 'Pipeline'}\n\n---------- logged artifacts ----------\n['model\/MLmodel',\n 'model\/conda.yaml',\n 'model\/model.pkl',\n 'model\/requirements.txt']\n<\/code><\/pre>\n<p>Could anyone tell me exactly how I can fix this model serve problem?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-16 01:21:39.507 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-10 12:27:37.947 UTC",
        "Question_score":1,
        "Question_tags":"scikit-learn|webserver|mlflow",
        "Question_view_count":787,
        "Owner_creation_date":"2019-03-20 13:27:18.367 UTC",
        "Owner_last_access_date":"2022-09-24 21:19:57.82 UTC",
        "Owner_reputation":415,
        "Owner_up_votes":300,
        "Owner_down_votes":2,
        "Owner_views":37,
        "Answer_body":"<p>The problem caused by <code>mlflow.utils.autologging_utils<\/code> WARNING.<\/p>\n<p>When the model is created, data input signature is saved on the <code>MLmodel<\/code> file with some.\nYou should change <code>response_length<\/code> signature input type from <code>string<\/code> to <code>double<\/code> by replacing<\/p>\n<pre><code>{&quot;name&quot;: &quot;response_length&quot;, &quot;type&quot;: &quot;double&quot;}\n<\/code><\/pre>\n<p>instead of<\/p>\n<pre><code>{&quot;name&quot;: &quot;response_length&quot;, &quot;type&quot;: &quot;string&quot;}\n<\/code><\/pre>\n<p>so it doesn't need to be converted. After serving the model with edited <code>MLmodel<\/code> file, the web server worked as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-07-16 01:21:39.507 UTC",
        "Answer_score":1.0,
        "Owner_location":"Tehran, Tehran Province, Iran",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68402406",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73621446,
        "Question_title":"Log Any Type of Model in MLflow",
        "Question_body":"<p>I am trying to create a wrapper function that allows my Data Scientists to log their models in MLflow.<\/p>\n<p>This is what the function looks like,<\/p>\n<pre><code>def log_model(self, params, metrics, model, run_name, artifact_path, artifacts=None):\n\n    with mlflow.start_run(run_name=run_name):\n        run_id = mlflow.active_run().info.run_id\n        mlflow.log_params(params)\n        mlflow.log_metrics(metrics)\n\n        if model:\n            mlflow.lightgbm.log_model(model, artifact_path=artifact_path)\n\n        if artifacts:\n            for artifact in artifacts:\n                mlflow.log_artifact(artifact, artifact_path=artifact_path)\n\n    return run_id\n<\/code><\/pre>\n<p>It can be seen here that the model is being logged as a <code>lightgbm<\/code> model, however, the <code>model<\/code> parameter that is passed into this function can be of any type.<\/p>\n<p>How can I update this function, so that it will be able to log any kind of model?<\/p>\n<p>As far as I know, there is no <code>log_model<\/code> function that comes with <code>mlflow<\/code>. It's always <code>mlflow.&lt;model_type&gt;.log_model<\/code>.<\/p>\n<p>How can I go about handling this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-06 11:40:47.387 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":39,
        "Owner_creation_date":"2018-03-24 01:53:05.82 UTC",
        "Owner_last_access_date":"2022-09-24 16:46:35.903 UTC",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Answer_body":"<p>I was able to solve this using the following approach,<\/p>\n<pre><code>def log_model(model, artifact_path):\n    model_class = get_model_class(model).split('.')[0]\n\n    try:\n        log_model = getattr(mlflow, model_class).log_model\n        log_model(model, artifact_path)\n    except AttributeError:\n        logger.info('The log_model function is not available as expected!')\n\ndef get_model_class(model):\n    klass = model.__class__\n    module = klass.__module__\n\n    if module == 'builtins':\n        return klass.__qualname__\n    return module + '.' + klass.__qualname__\n<\/code><\/pre>\n<p>From what I have seen, this will be able to handle most cases. The <code>get_model_class()<\/code> method will return the class used to develop the model and based on this, we can use the <code>getattr()<\/code> method to extract the relevant <code>log_model()<\/code> method.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-09-20 01:11:58.523 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73621446",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69689266,
        "Question_title":"How to set a tag at the experiment level in MLFlow",
        "Question_body":"<p>I can see that an experiment in MLFlow can have tags (like runs can have tags).\nI'm able to set a run's tag using <code>mlflow.set_tag<\/code>, but how do I set it for an experiment?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-10-23 14:52:36.82 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-10-23 16:16:05.867 UTC",
        "Question_score":2,
        "Question_tags":"python|mlflow",
        "Question_view_count":1047,
        "Owner_creation_date":"2009-06-14 12:54:00.077 UTC",
        "Owner_last_access_date":"2022-09-23 21:20:51.75 UTC",
        "Owner_reputation":13408,
        "Owner_up_votes":306,
        "Owner_down_votes":12,
        "Owner_views":687,
        "Answer_body":"<p>If you look into the Python API, the very <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html\" rel=\"nofollow noreferrer\">first example<\/a> in <code>mlflow.tracking package<\/code> that shows how to create the <code>MLflowClient<\/code> is really showing how to tag experiment using the <code>client.set_experiment_tag<\/code> function (<a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.tracking.MlflowClient.set_experiment_tag\" rel=\"nofollow noreferrer\">doc<\/a>):<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from mlflow.tracking import MlflowClient\n\n# Create an experiment with a name that is unique and case sensitive.\nclient = MlflowClient()\nexperiment_id = client.create_experiment(&quot;Social NLP Experiments&quot;)\nclient.set_experiment_tag(experiment_id, &quot;nlp.framework&quot;, &quot;Spark NLP&quot;)\n<\/code><\/pre>\n<p>you can also set it for model version with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.client.MlflowClient.set_model_version_tag\" rel=\"nofollow noreferrer\">set_model_version_tag<\/a> function, and for registered model with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.client.html#mlflow.tracking.MlflowClient.set_registered_model_tag\" rel=\"nofollow noreferrer\">set_registered_model_tag<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-10-23 18:00:53.31 UTC",
        "Answer_score":3.0,
        "Owner_location":"New York, NY",
        "Answer_last_edit_date":"2022-09-23 18:46:32.437 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69689266",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70098779,
        "Question_title":"How to connect to MLFlow tracking server that has auth?",
        "Question_body":"<p>I want to connect to remote tracking server (<a href=\"http:\/\/123.456.78.90\" rel=\"nofollow noreferrer\">http:\/\/123.456.78.90<\/a>) that requires authentication<\/p>\n<p>When I do this:<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>import mlflow\nmlflow.set_tracking_uri(\"http:\/\/123.456.78.90\")\nmlflow.set_experiment(\"my-experiment\")<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>I get an error<\/p>\n<p><em>MlflowException: API request to endpoint \/api\/2.0\/mlflow\/experiments\/list failed with error code 401 != 200.\nResponse body: 401 Authorization Required<\/em><\/p>\n<p>I understand that I need to log in first but I have no idea how to do it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-24 15:30:11.31 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"authorization|tracking|mlflow",
        "Question_view_count":2102,
        "Owner_creation_date":"2021-11-24 15:07:17.853 UTC",
        "Owner_last_access_date":"2022-09-22 09:41:34.783 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p><a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#logging-to-a-tracking-server\" rel=\"nofollow noreferrer\">MLflow documentation<\/a> says:<\/p>\n<blockquote>\n<p><code>MLFLOW_TRACKING_USERNAME<\/code> and <code>MLFLOW_TRACKING_PASSWORD<\/code> - username and password to use with HTTP Basic authentication. To use Basic authentication, you must set both environment variables.<\/p>\n<\/blockquote>\n<p>So you just need to set these variables in your code using <code>os.environ<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>os.environ['MLFLOW_TRACKING_USERNAME'] = 'name'\nos.environ['MLFLOW_TRACKING_PASSWORD'] = 'pass'\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-11-24 17:01:13.483 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70098779",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72780102,
        "Question_title":"Treatment of Existing Models in a Stage When Transitioning Models",
        "Question_body":"<p>With the MLflow client library, it is possible to transition models through stages as shown below,<\/p>\n<pre><code>client = MlflowClient()\nclient.transition_model_version_stage(\n    name=&quot;sk-learn-random-forest-reg-model&quot;,\n    version=3,\n    stage=&quot;Production&quot;\n)\n<\/code><\/pre>\n<p>Upon doing some testing, I noticed that this does not in any way affect the model(s) that are currently in the stage that the model was transitioned to.<\/p>\n<p>For example, let's say version 2 of a given model is in Production. This will remain tagged as a Production model, even if I were to move version 3 to Production as well.<\/p>\n<p>Is there any way that I can control what happens to models that exist in a stage when making transitions using the above code?<\/p>\n<p>Basically, I only want one version of a model to be in a given stage at a time.<\/p>\n<p>This functionality is available when transitioning models through the Databricks UI,\n<a href=\"https:\/\/i.stack.imgur.com\/aycvC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aycvC.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-28 02:25:33.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":26,
        "Owner_creation_date":"2018-03-24 01:53:05.82 UTC",
        "Owner_last_access_date":"2022-09-24 16:46:35.903 UTC",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Answer_body":"<p>I have missed the <code>archive_existing_versions=True<\/code> that comes with the <code>transition_model_version_stage<\/code> function.<\/p>\n<p>This flag defaults to <code>False<\/code>.<\/p>\n<p>The documentation is available here,\n<br>\n<a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.transition_model_version_stage\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.transition_model_version_stage<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-30 18:31:45.027 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72780102",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64164367,
        "Question_title":"Nginx authentication issues when building mlflow through docker-compose",
        "Question_body":"<p>I'm trying to dockerize <a href=\"https:\/\/mlflow.org\/\" rel=\"nofollow noreferrer\">mlflow<\/a> with PostgreSQL and nginx configurations for Google Cloud Run (GCR) on the Google Cloud Platform (GCP).<\/p>\n<p>Before deploying anything to GCP however, I wanted to get a local deployment working. I found <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">this<\/a> guide that details the process of setting up the environment. Having followed the guide (excluding the SQL part), I can see the  mlflow UI on <code>localhost:80<\/code> as nginx redirects traffic on port 80 to 5000. To add authentication, I found <a href=\"https:\/\/www.digitalocean.com\/community\/tutorials\/how-to-set-up-password-authentication-with-nginx-on-ubuntu-14-04\" rel=\"nofollow noreferrer\">here<\/a> that I can do it using <code>sudo htpasswd -c .htpasswd &lt;username&gt;<\/code> in the <code>etc\/nginx\/<\/code> directory and then adding<\/p>\n<pre><code>location \\ {\n   auth_basic &quot;Private Property&quot;;\n   auth_basic_user_file .htpasswd;\n}\n<\/code><\/pre>\n<p>to the <code>nginx.conf<\/code> (or <code>mlflow.conf<\/code> in this case) to make it appear online. Trouble is, when I go to <code>localhost:80<\/code> <em>now<\/em> and enter in my username\/password, I continue to see<\/p>\n<pre><code>[error] 6#6: *1 open() &quot;\/etc\/nginx\/.htpasswd&quot; failed (2: No such file or directory)\n<\/code><\/pre>\n<p>in the <code>docker-compose up<\/code> logs as they are printed to the terminal, and as such <em>I'm not able to see the mlflow UI<\/em> on <code>localhost:80<\/code> (either a blank screen or nginx 403 error).<\/p>\n<p>Now, I've looked at several other posts (such as <a href=\"https:\/\/stackoverflow.com\/questions\/2010677\/nginx-and-auth-basic\">this one<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/16510374\/403-forbidden-nginx-using-correct-credentials\">this one<\/a>) and it seems to me that nginx doesn't have the right permissions to read the <code>.htpasswd<\/code> in the <code>etc\/nginx\/<\/code> directory file or that the path of the file isn't correct, i.e. the path has to be in reference to the <code>nginx.conf<\/code> file.<\/p>\n<p>Even though I made these corrections to the above towards-data-science files, the problem still persists.  I've been stuck for a while on this. Any particular reasons why this may be happening?<\/p>\n<p>Edit:\nHere is my directory structure in case it may help:<\/p>\n<pre><code>mlflow-docker\/:\n  mlflow\/:\n    Dockerfile\n  nginx\/:\n    Dockerfile\n    mlflow.conf\n    nginx.conf\n  docker-compose.yml\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-10-01 23:21:36.277 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-02 05:30:21.33 UTC",
        "Question_score":0,
        "Question_tags":"docker|debugging|nginx|google-cloud-platform|mlflow",
        "Question_view_count":841,
        "Owner_creation_date":"2018-04-23 00:36:28.58 UTC",
        "Owner_last_access_date":"2022-09-23 22:58:19.597 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>You need to add the .htpasswd file inside your container's file system.<\/p>\n<p>Generate the password file in your project's nginx folder.<\/p>\n<pre><code>sudo htpasswd -c .htpasswd sammy\n<\/code><\/pre>\n<p>Copy the password file to the nginx container's directory. Add following line in nginx dockerfile.<\/p>\n<pre><code>COPY .htpasswd \/etc\/nginx\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-02 06:05:48.113 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-10-02 06:16:06.397 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64164367",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72745109,
        "Question_title":"No FileSystem for scheme \"s3\" exception when using spark with mlflow",
        "Question_body":"<p>we are running a Spark job against our Kubernetes cluster and try to log the model to MLflow. We are running Spark 3.2.1 and MLflow 1.26.1 and we are using the following jars to communicate with s3 <code>hadoop-aws-3.2.2.jar<\/code> and <code>aws-java-sdk-bundle-1.11.375.jar<\/code> and configure our spark-submit job with the following parameters:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>  --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider \\\n  --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n  --conf spark.hadoop.fs.s3a.fast.upload=true \\\n<\/code><\/pre>\n<p>When we try to save our Spark model with <code>mlflow.spark.log_model()<\/code> we are getting the following exception:<\/p>\n<pre class=\"lang-java prettyprint-override\"><code>22\/06\/24 13:27:21 ERROR Instrumentation: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme &quot;s3&quot;\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n    at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n    at org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:673)\n    at org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n    at org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n    at org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n    at org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n    at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n    at scala.util.Try$.apply(Try.scala:213)\n    at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n    at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n    at java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n    at java.base\/java.lang.reflect.Method.invoke(Unknown Source)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:282)\n    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    at py4j.commands.CallCommand.execute(CallCommand.java:79)\n    at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n    at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n    at java.base\/java.lang.Thread.run(Unknown Source)\n<\/code><\/pre>\n<p>We tried to start our MLflow server with <code>-default-artifact-root<\/code> set to <code>s3a:\/\/...<\/code> but when we run our spark job and we call <code>mlflow.get_artifact_uri()<\/code> (which is also used to construct the upload uri in <code>mlflow.spark.log_model()<\/code>) the result starts with <code>s3<\/code> which probably cause the former mentioned exception.\nSince Hadoop dropped support for the <code>s3:\/\/<\/code> filesystem does anyone know how to log spark models to s3 using MLflow?<\/p>\n<p>Cheers<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-06-24 13:52:05.497 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-25 14:06:10.247 UTC",
        "Question_score":1,
        "Question_tags":"apache-spark|amazon-s3|pyspark|mlflow",
        "Question_view_count":148,
        "Owner_creation_date":"2015-09-19 07:52:59.16 UTC",
        "Owner_last_access_date":"2022-09-22 17:32:09.817 UTC",
        "Owner_reputation":773,
        "Owner_up_votes":380,
        "Owner_down_votes":6,
        "Owner_views":58,
        "Answer_body":"<p>Additional to the <code>spark.hadoop.fs.s3a.impl<\/code> config parameter, you can try to also set <code>spark.hadoop.fs.s3.impl<\/code> to <code>org.apache.hadoop.fs.s3a.S3AFileSystem<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-27 11:49:11.533 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72745109",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69227917,
        "Question_title":"Connect MLflow server to minio in local",
        "Question_body":"<p>I am trying to connect mlflow with Minio server, both are running on my local machine, I am able to connect my client code to minio by adding the below lines to the code,<\/p>\n<pre><code>os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] =&quot;xxxx&quot;\nos.environ['AWS_SECRET_ACCESS_KEY'] =&quot;xxxxxx&quot; \nos.environ['MLFLOW_TRACKING_URI'] = 'http:\/\/localhost:5000'\n<\/code><\/pre>\n<p>But the mlflow server is not getting connected to Minio. To run Mlflow server, command I use:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 -p 5000 --default-artifact-root s3:\/\/mlbucket --backend-store-uri sqlite:\/\/\/mlflow.db\n<\/code><\/pre>\n<p>The mlflow server runs, but while accessing the artifacts page the server, it throws the error:<\/p>\n<pre><code>raise NoCredentialsError()\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>\n<p>So how can I pass the credentials of the Minio to the mlflow server command?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2021-09-17 18:17:06.293 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|minio|mlflow",
        "Question_view_count":1136,
        "Owner_creation_date":"2011-07-17 08:59:45.21 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:29.02 UTC",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Answer_body":"<p>Just add the below environment variables:<\/p>\n<pre><code>export AWS_ACCESS_KEY_ID=&lt;your-aws-access-key-id&gt;\nexport AWS_SECRET_ACCESS_KEY = &lt;your-aws-secret-access-key&gt;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-20 15:29:11.773 UTC",
        "Answer_score":1.0,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69227917",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56647549,
        "Question_title":"MLflow Error while deploying the Model to local REST server",
        "Question_body":"<blockquote>\n  <p><strong>System Details:<\/strong><\/p>\n  \n  <p>Operating System: Ubuntu 19.04<\/p>\n  \n  <p>Anaconda version: 2019.03<\/p>\n  \n  <p>Python version: 3.7.3<\/p>\n  \n  <p>mlflow version: 1.0.0<\/p>\n<\/blockquote>\n\n<p><strong>Steps to Reproduce:<\/strong> <a href=\"https:\/\/mlflow.org\/docs\/latest\/tutorial.html\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tutorial.html<\/a><\/p>\n\n<p><strong>Error at line\/command:<\/strong> <code>mlflow models serve -m [path_to_model] -p 1234<\/code><\/p>\n\n<p><strong>Error:<\/strong>\nCommand 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1>&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1<\/p>\n\n<p><strong>Terminal Log:<\/strong><\/p>\n\n<pre><code>(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# mlflow models serve -m $(pwd) -p 1234\n2019\/06\/18 16:15:16 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2019\/06\/18 16:15:17 INFO mlflow.pyfunc.backend: === Running command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app'\nbash: activate: No such file or directory\nTraceback (most recent call last):\n  File \"\/root\/anaconda3\/envs\/mlflow\/bin\/mlflow\", line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 43, in serve\n    host=host)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 76, in serve\n    command_env=command_env)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 147, in _execute_in_conda_env\n    command, rc\nException: Command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1\n(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-18 10:56:39.15 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python-3.x|deployment|mlflow",
        "Question_view_count":1840,
        "Owner_creation_date":"2017-08-29 10:04:18.09 UTC",
        "Owner_last_access_date":"2021-09-06 18:21:49.9 UTC",
        "Owner_reputation":2101,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>Following the steps mentioned in the GitHub Issue <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">1507<\/a> (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/1507<\/a>) I was able to resolve this issue.<\/p>\n\n<p>In reference to this post, the \"<strong>anaconda\/bin\/<\/strong>\" directory is never added to the list of environment variables i.e. PATH variable. In order to resolve this issue, add the \"<strong>else<\/strong>\" part of conda initialize code block from ~\/.bashrc file to your PATH variable.<\/p>\n\n<pre><code># &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'conda init' !!\n__conda_setup=\"$('\/home\/atulk\/anaconda3\/bin\/conda' 'shell.bash' 'hook' 2&gt; \/dev\/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\" ]; then\n        . \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\"\n    else\n        export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n<\/code><\/pre>\n\n<p>In this case, I added <strong>export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"<\/strong> to the PATH variable. However, this is just a temporary fix until the issue is fixed in the project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-28 14:02:54.53 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56647549",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70005957,
        "Question_title":"Logging the git_sha as a parameter on Mlflow using Kedro hooks",
        "Question_body":"<p>I would like to log the git_sha parameter on Mlflow as shown in the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/07_extend_kedro\/02_hooks.html?highlight=run_params#add-metrics-tracking-to-your-model\" rel=\"nofollow noreferrer\">documentation<\/a>. What appears to me here, is that simply running the following portion of code should be enough to get git_sha logged in the Mlflow UI. Am I right ?<\/p>\n<pre><code>@hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n<\/code><\/pre>\n<p>But this does not work as I get all but the git_sha parameter. And when I look at the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/_modules\/kedro\/framework\/hooks\/specs.html?highlight=run_params#\" rel=\"nofollow noreferrer\">hooks specs<\/a>, it seems that this param is not part of run_params (anymore?)<\/p>\n<p>Is there a way I could get the git sha (maybe from the context journal ?) and add it to the logged parameters ?<\/p>\n<p>Thank you in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-17 14:13:41.443 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-17 14:19:26.987 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow|kedro|mlops",
        "Question_view_count":172,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>Whilst it's heavily encouraged to use git with Kedro it's not required and as such no part of Kedro (except <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro-starters\" rel=\"nofollow noreferrer\">kedro-starters<\/a> if we're being pedantic) is 'aware' of git.<\/p>\n<p>In your <code>before_pipeline_hook<\/code> there it is pretty easy for you to retrieve the info <a href=\"https:\/\/stackoverflow.com\/questions\/14989858\/get-the-current-git-hash-in-a-python-script\">via the techniques documented here<\/a>. It seems trivial for the whole codebase, a bit more involved if you want to say provide pipeline specific hashes.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-17 14:26:33.837 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70005957",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66814885,
        "Question_title":"Serve online learning models with mlflow",
        "Question_body":"<p>It is not clear to me if one could use mlflow to serve a model that is evolving continuously based on its previous predictions.<\/p>\n<p>I need to be able to query a model in order to make a prediction on a sample of data which is the basic use of mlflow serve. However I also want the model to be updated internaly now that it has seen new data.<\/p>\n<p>Is it possible or does it need a FR ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-26 10:12:57.11 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python-3.x|mlflow",
        "Question_view_count":360,
        "Owner_creation_date":"2018-01-05 12:55:59.093 UTC",
        "Owner_last_access_date":"2021-09-03 19:38:29.597 UTC",
        "Owner_reputation":76,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":"<p>I think that you should be able to do that by implementing the custom python model or custom flavor, as it's described in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">documentation<\/a>.  In this case you need to create a class that is inherited from <code>mlflow.pyfunc.PythonModel<\/code>, and implement the <code>predict<\/code> method, and inside that method you're free to do anything.  Here is just simple example from documentation:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class AddN(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, n):\n        self.n = n\n\n    def predict(self, context, model_input):\n        return model_input.apply(lambda column: column + self.n)\n<\/code><\/pre>\n<p>and this model is then could be saved &amp; loaded again just as normal models:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># Construct and save the model\nmodel_path = &quot;add_n_model&quot;\nadd5_model = AddN(n=5)\nmlflow.pyfunc.save_model(path=model_path, python_model=add5_model)\n\n# Load the model in `python_function` format\nloaded_model = mlflow.pyfunc.load_model(model_path)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-04-11 07:04:00.63 UTC",
        "Answer_score":0.0,
        "Owner_location":"Fairbanks, AK, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66814885",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70539698,
        "Question_title":"MlFlow - Unable to run with S3 as default-artifact-root",
        "Question_body":"<p>I am trying to store my model artifacts using mlflow to s3. In the API services, we use <code>MLFLOW_S3_ENDPOINT_URL<\/code> as the s3 bucket. In the mlflow service, we pass it as an environment variable. But, the mlflow container servicer fails with the below exception:<\/p>\n<pre><code>mflow_server  | botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: Not supported URL scheme s3\n<\/code><\/pre>\n<p>docker-compose file as below:<\/p>\n<pre><code>version: &quot;3.3&quot;\nservices:\n  prisim-api:\n    image: prisim-api:latest\n    container_name: prisim-api\n    expose:\n      - &quot;8000&quot;\n    environment: \n    - S3_URL=s3:\/\/mlflow-automation-artifacts\/\n    - MLFLOW_SERVER=http:\/\/mlflow:5000\n    - AWS_ID=xyz+\n    - AWS_KEY=xyz\n\n    networks:\n      - prisim \n    depends_on:\n      - mlflow\n    links:\n            - mlflow\n    volumes:\n      - app_data:\/usr\/data\n  mlflow:\n    image: mlflow_server:latest\n    container_name: mflow_server\n    ports:\n      - &quot;5000:5000&quot;    \n    environment:\n      - AWS_ACCESS_KEY_ID=xyz+\n      - AWS_SECRET_ACCESS_KEY=xyz\n      - MLFLOW_S3_ENDPOINT_URL=s3:\/\/mlflow-automation-artifacts\/\n    healthcheck:\n      test: [&quot;CMD&quot;, &quot;echo&quot;, &quot;mlflow server is running&quot;]\n      interval: 1m30s\n      timeout: 10s\n      retries: 3\n    networks:\n       - prisim \nnetworks:\n prisim:\nvolumes:\n  app_data:\n<\/code><\/pre>\n<p>Why the scheme s3 is not supported?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 06:46:29.943 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"amazon-s3|docker-compose|mlflow",
        "Question_view_count":932,
        "Owner_creation_date":"2011-07-17 08:59:45.21 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:29.02 UTC",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Answer_body":"<p>I found the solution.<\/p>\n<p>I have added <code>[&quot;AWS_DEFAULT_REGION&quot;]<\/code> to the environment variables and it worked.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-04 05:46:56.08 UTC",
        "Answer_score":0.0,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70539698",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58956459,
        "Question_title":"How to run authentication on a mlFlow server?",
        "Question_body":"<p>As I am logging my entire models and params into mlflow I thought it will be a good idea to have  it protected under a user name and password.<\/p>\n\n<p>I use the following code to run the mlflow server<\/p>\n\n<p><code>mlflow server --host 0.0.0.0 --port 11111<\/code>\nworks perfect,in mybrowser i type <code>myip:11111<\/code> and i see everything (which eventually is the problem)<\/p>\n\n<p>If I understood the documentation and the following <a href=\"https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8\" rel=\"noreferrer\">https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8<\/a> link here correct, I should use nginx to create the authentication.<\/p>\n\n<p>I installed <code>nginx open sourcre<\/code>  and <code>apache2-utils<\/code><\/p>\n\n<p>created <code>sudo htpasswd -c \/etc\/apache2\/.htpasswd user1<\/code> user and passwords.<\/p>\n\n<p>I edited my <code>\/etc\/nginx\/nginx.conf<\/code> to the following:<\/p>\n\n<pre><code>server {\n        listen 80;\n        listen 443 ssl;\n\n        server_name my_ip;\n        root NOT_SURE_WHICH_PATH_TO_PUT_HERE, THE VENV?;\n        location \/ {\n            proxy_pass                      my_ip:11111\/;\n            auth_basic                      \"Restricted Content\";\n            auth_basic_user_file \/home\/path to the password file\/.htpasswd;\n        }\n    }\n<\/code><\/pre>\n\n<p><strong>but no authentication appears.<\/strong><\/p>\n\n<p>if I change the conf to listen to  <code>listen 11111<\/code>\nI get an error that the port is already in use ( of course, by the mlflow server....)<\/p>\n\n<p>my wish is to have a authentication window before anyone can enter by the mlflow with a browser.<\/p>\n\n<p>would be happy to hear any suggestions.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-20 14:16:40.087 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":null,
        "Question_score":11,
        "Question_tags":"nginx|basic-authentication|mlflow",
        "Question_view_count":13870,
        "Owner_creation_date":"2019-04-03 13:42:48.017 UTC",
        "Owner_last_access_date":"2022-09-10 19:35:30.057 UTC",
        "Owner_reputation":1540,
        "Owner_up_votes":21,
        "Owner_down_votes":3,
        "Owner_views":118,
        "Answer_body":"<p>the problem here is that both <code>mlflow<\/code> and <code>nginx<\/code> are trying to run on the <strong>same port<\/strong>... <\/p>\n\n<ol>\n<li><p>first lets deal with nginx:<\/p>\n\n<p>1.1 in \/etc\/nginx\/sites-enable make a new file <code>sudo nano mlflow<\/code> and delete the exist default.<\/p>\n\n<p>1.2 in mlflow file:<\/p><\/li>\n<\/ol>\n\n<pre><code>server {\n    listen YOUR_PORT;\n    server_name YOUR_IP_OR_DOMAIN;\n    auth_basic           \u201cAdministrator\u2019s Area\u201d;\n    auth_basic_user_file \/etc\/apache2\/.htpasswd; #read the link below how to set username and pwd in nginx\n\n    location \/ {\n        proxy_pass http:\/\/localhost:8000;\n        include \/etc\/nginx\/proxy_params;\n        proxy_redirect off;\n    }\n}\n<\/code><\/pre>\n\n<p>1.3.  restart nginx <code>sudo systemctl restart nginx<\/code><\/p>\n\n<ol start=\"2\">\n<li>on your server run mlflow  <code>mlflow server --host localhost --port 8000<\/code><\/li>\n<\/ol>\n\n<p>Now if you try access the YOUR_IP_OR_DOMAIN:YOUR_PORT within your browser an auth popup should appear, enter your host and pass and now you in mlflow<\/p>\n\n<ol start=\"3\">\n<li><p>now there are 2 options to tell the mlflow server about it:<\/p>\n\n<p>3.1 set username and pwd as environment variable \n<code>export MLFLOW_TRACKING_USERNAME=user export MLFLOW_TRACKING_PASSWORD=pwd<\/code><\/p>\n\n<p>3.2 edit in your <code>\/venv\/lib\/python3.6\/site-packages\/mlflowpackages\/mlflow\/tracking\/_tracking_service\/utils.py<\/code> the function <\/p><\/li>\n<\/ol>\n\n<pre><code>def _get_rest_store(store_uri, **_):\n    def get_default_host_creds():\n        return rest_utils.MlflowHostCreds(\n            host=store_uri,\n            username=replace with nginx user\n            password=replace with nginx pwd\n            token=os.environ.get(_TRACKING_TOKEN_ENV_VAR),\n            ignore_tls_verification=os.environ.get(_TRACKING_INSECURE_TLS_ENV_VAR) == 'true',\n        )\n<\/code><\/pre>\n\n<p>in your .py file where you work with mlflow:<\/p>\n\n<pre><code>import mlflow\nremote_server_uri = \"YOUR_IP_OR_DOMAIN:YOUR_PORT\" # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\nmlflow.set_experiment(\"\/my-experiment\")\nwith mlflow.start_run():\n    mlflow.log_param(\"a\", 1)\n    mlflow.log_metric(\"b\", 2)\n<\/code><\/pre>\n\n<p>A link to nginx authentication doc <a href=\"https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/\" rel=\"noreferrer\">https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-12-13 16:37:32.617 UTC",
        "Answer_score":8.0,
        "Owner_location":"wondeland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58956459",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69703225,
        "Question_title":"Can I change the port of my MLflow tracking server?",
        "Question_body":"<p>I would like to know if I can change the port of my MLflow server.<\/p>\n<p>By default it is running on port 5000, but my company's VPN only allows HTTP (port 80) and HTTPS (port 443) traffic.<\/p>\n<p>This might be a very beginner's question, but is it possible, and if yes, is there any problem on running the MLflow server on port 83 (HTTP) ?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-25 05:27:12.427 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"http|port|mlflow",
        "Question_view_count":540,
        "Owner_creation_date":"2019-06-21 08:41:37.313 UTC",
        "Owner_last_access_date":"2022-08-21 05:17:54.15 UTC",
        "Owner_reputation":133,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>Yes, you can do that by passing the <code>-p port_number<\/code> command-line switch when starting MLflow server (see <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#cmdoption-mlflow-server-p\" rel=\"nofollow noreferrer\">docs<\/a>). Please note, that to be able to use ports below 1024, the server needs to be run as root.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-25 08:54:16.29 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69703225",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60695933,
        "Question_title":"MLflow: Why can't backend-store-uri be an s3 location?",
        "Question_body":"<p>I'm new to mlflow and I can't figure out why the <code>artifact store<\/code> can't be the same as the <code>backend store<\/code>? <\/p>\n\n<p>The only reason I can think of is to be able to query the experiments with SQL syntax... but since we can interact with the runs using <code>mlflow ui<\/code> I just don't understand why all artifacts and parameters can't go to a same location (which is what happens when using local storage).<\/p>\n\n<p>Can anyone shed some light on this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-15 17:51:33.613 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":768,
        "Owner_creation_date":"2018-06-09 20:04:00.85 UTC",
        "Owner_last_access_date":"2022-09-23 23:45:41.153 UTC",
        "Owner_reputation":133,
        "Owner_up_votes":10,
        "Owner_down_votes":2,
        "Owner_views":76,
        "Answer_body":"<p>MLflow's Artifacts are typically ML models, i.e. relatively large binary files. On the other hand, run data are typically a couple of floats.<\/p>\n<p>In the end it is not a question of what is possible or not (many things are possible if you put enough effort into it), but rather to follow good practices:<\/p>\n<ul>\n<li>storing large binary artifacts in an SQL database is possible but is bound the degrade the performance of the database sooner or later, and this in turn will degrade your user experience.<\/li>\n<li>storing a couple of floats from a SQL database for quick retrieval for display in a front-end or via command line is a robust industry-proven classic<\/li>\n<\/ul>\n<p>It remains true that the documentation of MLflow on the architecture design rationale could be improved (as of 2020)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-19 08:31:17.983 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60695933",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71262010,
        "Question_title":"Download model artefact from Databricks workspace",
        "Question_body":"<p>How can I download a mlflow model artefact in a docker container from databricks workspace?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-25 06:40:55.51 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-25 13:33:11.323 UTC",
        "Question_score":0,
        "Question_tags":"docker|databricks|azure-databricks|mlflow",
        "Question_view_count":370,
        "Owner_creation_date":"2014-09-22 04:46:57.027 UTC",
        "Owner_last_access_date":"2022-09-03 08:12:58.187 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":41,
        "Owner_down_votes":3,
        "Owner_views":123,
        "Answer_body":"<p>To download a model from Databricks workspace you need to do two things:<\/p>\n<ol>\n<li><p>Set MLFlow tracking URI to databricks using python API<\/p>\n<\/li>\n<li><p>Setup databricks authentication. I prefer authenticating by setting the following environment variables, you can also use databricks CLI to authenticate:<\/p>\n<pre><code>DATABRICKS_HOST\n\nDATABRICKS_TOKEN\n<\/code><\/pre>\n<\/li>\n<li><p>Here's a basic code snippet to download a model from Databricks workspace model registry:<\/p>\n<pre><code>import os\nimport mlflow\nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n\nmodel_name = &quot;example-model-name&quot;\nmodel_stage = &quot;Staging&quot;  # Should be either 'Staging' or 'Production'\n\nmlflow.set_tracking_uri(&quot;databricks&quot;)\n\nos.makedirs(&quot;model&quot;, exist_ok=True)\nlocal_path = ModelsArtifactRepository(\n    f'models:\/{model_name}\/{model_stage}').download_artifacts(&quot;&quot;, dst_path=&quot;model&quot;)\n\nprint(f'{model_stage} Model {model_name} is downloaded at {local_path}')\n<\/code><\/pre>\n<p>Running above python script will download an ML model in the model directory.<\/p>\n<p><strong>Containerizing MLFlow model serving with Docker<\/strong><\/p>\n<p>The next step is to package this downloaded model in a docker image and serve a model when you run the image.<\/p>\n<\/li>\n<\/ol>\n<p>Here's a basic Dockerfile to do the same:<\/p>\n<pre><code>FROM continuumio\/miniconda3\n\nENV MLFLOW_HOME \/opt\/mlflow\nENV MLFLOW_VERSION 1.12.1\nENV PORT 5000\n\nRUN conda install -c conda-forge mlflow=${MLFLOW_VERSION}\n\nCOPY model\/ ${MLFLOW_HOME}\/model\n\nWORKDIR ${MLFLOW_HOME}\n\nRUN mlflow models prepare-env -m ${MLFLOW_HOME}\/model\n\nRUN useradd -d ${MLFLOW_HOME} mlflow\nRUN chown mlflow: ${MLFLOW_HOME}\nUSER mlflow\n\nCMD mlflow models serve -m ${MLFLOW_HOME}\/model --host 0.0.0.0 --port ${PORT}\n<\/code><\/pre>\n<p>For more information you can follow this <a href=\"https:\/\/dev.to\/itachiredhair\/downloading-mlflow-model-from-databricks-and-serving-with-docker-38ip\" rel=\"nofollow noreferrer\">article<\/a> from Akshay Milmile<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-02-25 08:12:59.603 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":"2022-02-25 13:32:17.627 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71262010",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62320331,
        "Question_title":"Sagemaker API to list Hyperparameters",
        "Question_body":"<p>I'm currently trying to implement MLFlow Tracking into my training pipeline and would like to log the hyperparameters of my hyperparameter Tuning of each training job.<\/p>\n\n<p>Does anyone know, how to pull the list of hyperparameters that can be seen on the sagemaker training job interface (on the AWS console)? Is there any other smarter way to list how models perform in comparison in Sagemaker (and displayed)?<\/p>\n\n<p>I would assume there must be an easy and Pythonic way to do this (either boto3 or the sagemaker api) to get this data. I wasn't able to find it in Cloudwatch.<\/p>\n\n<p>Many thanks in advance!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-11 08:38:22.897 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|amazon-web-services|amazon-sagemaker|mlflow",
        "Question_view_count":484,
        "Owner_creation_date":"2016-07-28 15:35:17.217 UTC",
        "Owner_last_access_date":"2022-03-28 15:52:24.487 UTC",
        "Owner_reputation":43,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>there is indeed a rather pythonic way in the SageMaker python SDK:<\/p>\n\n<pre><code>tuner = sagemaker.tuner.HyperparameterTuner.attach('&lt; your tuning jobname&gt;')\n\nresults = tuner.analytics().dataframe()  # all your tuning metadata, in pandas!\n<\/code><\/pre>\n\n<p>See full example here <a href=\"https:\/\/github.com\/aws-samples\/amazon-sagemaker-tuneranalytics-samples\/blob\/master\/SageMaker-Tuning-Job-Analytics.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws-samples\/amazon-sagemaker-tuneranalytics-samples\/blob\/master\/SageMaker-Tuning-Job-Analytics.ipynb<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-06-14 22:27:30.467 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62320331",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72425907,
        "Question_title":"How to log a tensorflow model with mlflow.tensorflow.log_model (error module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants')",
        "Question_body":"<p>I am trying to log a trained model with MLFlow using mlflow.tensorflow.log_model.<\/p>\n<p>After training a simple sequential tf model<\/p>\n<pre><code>history = binary_model.fit(train_ds, validation_data=val_ds, epochs=num_epochs)\n<\/code><\/pre>\n<p>I am trying to log it:<\/p>\n<pre><code>    from tensorflow.python.saved_model import signature_constants\n    tag=[tf.saved_model.tag_constants.SERVING]\n    key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n\n    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n                                tf_meta_graph_tags=tag,\n                                tf_signature_def_key=key,\n                                artifact_path=&quot;tf-models&quot;,\n                                registered_model_name=model_name)\n<\/code><\/pre>\n<p>but I get the error:<\/p>\n<pre><code>    AttributeError                            Traceback (most recent call last)\n    \/var\/folders\/2k\/g7p7j2gx6v54vkwv3v401h2m0000gn\/T\/ipykernel_73638\/562549064.py in &lt;module&gt;\n          1 from tensorflow.python.saved_model import signature_constants\n    ----&gt; 2 tag=[tf.saved_model.tag_constants.SERVING]\n          3 key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n          4 \n          5 mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n\n    AttributeError: module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants'\n<\/code><\/pre>\n<p>Any idea how to get the tags and keys correctly from the model to log it in MLFlow?<\/p>\n<p>Many thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-05-29 17:36:29.63 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|tensorflow|mlflow",
        "Question_view_count":319,
        "Owner_creation_date":"2013-05-22 19:51:34.28 UTC",
        "Owner_last_access_date":"2022-09-21 19:50:10.223 UTC",
        "Owner_reputation":324,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":"<p>The <code>tag_constants<\/code> is in <code>tf.compat.v1.saved_model<\/code>.<\/p>\n<p>To resolve the error replace this line<\/p>\n<pre><code>tag=[tf.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>with this<\/p>\n<pre><code>tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>Please refer <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/compat\/v1\/saved_model\/tag_constants\" rel=\"nofollow noreferrer\">this<\/a> for more details.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-13 04:29:29.433 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72425907",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68533916,
        "Question_title":"what is features and how to interpret in RFormula",
        "Question_body":"<p>I am trying to understand what an RFormula is in MLflow or spark.<\/p>\n<p>I have found these:<\/p>\n<p><a href=\"https:\/\/george-jen.gitbook.io\/data-science-and-apache-spark\/rformula\" rel=\"nofollow noreferrer\">https:\/\/george-jen.gitbook.io\/data-science-and-apache-spark\/rformula<\/a>\n<a href=\"https:\/\/spark.apache.org\/docs\/latest\/api\/python\/reference\/api\/pyspark.ml.feature.RFormula.html\" rel=\"nofollow noreferrer\">https:\/\/spark.apache.org\/docs\/latest\/api\/python\/reference\/api\/pyspark.ml.feature.RFormula.html<\/a><\/p>\n<p>but still cannot understand how to interpret an RFormula fully. I am not sure how to interpret the below table\n<a href=\"https:\/\/i.stack.imgur.com\/guLyU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/guLyU.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>based on the formula &quot;y ~ x+ s&quot;, y is related to x and s, but in the table when y=0 and x=0 and s =a (i.e. third row), then the features is [0,1] and label is 0, so how shall I interpret this.<\/p>\n<p>I have found <a href=\"https:\/\/stackoverflow.com\/questions\/61290042\/spark-rformula-interpretation\">this<\/a> but still cannot understand my way through this problem.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-07-26 17:08:35.683 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-07-27 07:44:40.353 UTC",
        "Question_score":0,
        "Question_tags":"r|pyspark|mlflow",
        "Question_view_count":78,
        "Owner_creation_date":"2013-07-30 12:14:04.01 UTC",
        "Owner_last_access_date":"2022-09-10 08:19:49.807 UTC",
        "Owner_reputation":912,
        "Owner_up_votes":334,
        "Owner_down_votes":1,
        "Owner_views":288,
        "Answer_body":"<p>So your label is y. You parse x and s in rformula.<\/p>\n<p>x stays the same:<\/p>\n<pre><code>+-----------+---+\n|      x    | x |\n+-----------+---+\n|     1.0   |1.0|\n|     2.0   |2.0|\n|     0.0   |0.0|\n+-----------+---+\n<\/code><\/pre>\n<p>s:<\/p>\n<pre><code>+-----------+---+\n|       s   | s |\n+-----------+---+\n|       a   |1.0|\n|       b   |0.0|\n|       a   |1.0|\n+-----------+---+\n<\/code><\/pre>\n<p>I hope I could answer you question.\nRformula just converts the strings, standarize them and parse them into a vector.<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2021-07-26 21:16:04.713 UTC",
        "Answer_score":0.0,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":"2021-07-26 21:28:52.66 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68533916",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68527422,
        "Question_title":"mlflow.pyfunc.spark_udf and vector struct type",
        "Question_body":"<p>My <em>PySpark<\/em> dataset contains categorical data.<\/p>\n<p>To train a model on this data, I followed this <a href=\"https:\/\/docs.databricks.com\/_static\/notebooks\/binary-classification.html\" rel=\"nofollow noreferrer\">example notebook<\/a>. Especially, see the <em>Preprocess Data<\/em> section for the encoding part.<\/p>\n<p>I now need to use this model somewhere else; hence, I followed <em>Databricks<\/em> recommendation to save and load this model.<\/p>\n<p>It's working fine with <em>Pandas<\/em> (cf. code below).<\/p>\n<pre><code>logged_model = 'runs:\/e905f5759d434a1391bbe1e54a2b\/best-model'\n\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(logged_model)\n\n# Predict on a Pandas DataFrame.\nimport pandas as pd\nloaded_model.predict(pd.DataFrame(data))\n<\/code><\/pre>\n<p>However the dataframe is to big to be converted to <em>Pandas<\/em>. Hence I need to make it work in <em>Spark<\/em>:<\/p>\n<pre><code>import mlflow\nlogged_model = 'runs:\/e905f5759d434a131bbe1e54a2b\/best-model'\n\n# Load model as a Spark UDF.\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)\n\n# Predict on a Spark DataFrame.\ndf.withColumn('predictions', loaded_model(*columns)).collect()\n<\/code><\/pre>\n<p>But this snippet is producing:<\/p>\n<pre><code>java.lang.UnsupportedOperationException: Unsupported data type: struct&amp;lt;type:tinyint,size:int,indices:array&amp;lt;int&amp;gt;,values:array&amp;lt;double&amp;gt;&amp;gt;\n<\/code><\/pre>\n<p>My feeling is that the udf doesn't accept this type of data as input.\nIs there a way to fix it ?\nAnother solution ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-07-26 09:23:08.767 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pyspark|databricks|mlflow",
        "Question_view_count":790,
        "Owner_creation_date":"2016-11-29 05:56:02.23 UTC",
        "Owner_last_access_date":"2022-09-24 11:32:25.87 UTC",
        "Owner_reputation":440,
        "Owner_up_votes":21,
        "Owner_down_votes":4,
        "Owner_views":56,
        "Answer_body":"<p>Have you tried using the <code>mlflow.spark.load_model<\/code>?<\/p>\n<p>I'm having a very similar issue over here, but but using the spark method. I tried using the <code>mlflow.spark.load_model('runs:\/run-id\/my-model')<\/code> method and I got this weird error:<\/p>\n<pre><code>FileNotFoundError: [Errno 2] No such file or directory: '\/dbfs\/tmp\/mlflow\/weird-id-folder'\n<\/code><\/pre>\n<p>Searching for the docs, I see the problem that we are facing (which seems to be different), seems to be a signature problem.<\/p>\n<p>According with other part of the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-signature\" rel=\"nofollow noreferrer\">docs<\/a> we have that the signature logged with the model will help to define what type of input the model has. The problem for me here is that my input is a Spark Sparse Vector -- which is not supported... Right now I'm trying to convert that into a column-based signature.<\/p>\n<p>Have you tried something like this?<\/p>\n<hr \/>\n<p>UPDATE:<\/p>\n<p>I would like to add that in my case adding the signature did solve the problem. All I did was ignore the vectors and consider only the input data and output data.<\/p>\n<p>I took a look into the notebook, but haven't seen any mlflow logs, anyway, I do suppose you are logging your experiment according to <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/tracking.html#log-runs-to-a-notebook-or-workspace-experiment\" rel=\"nofollow noreferrer\">this<\/a> and using the <code>mlflow.spark<\/code> flavor.<\/p>\n<p>If so, consider using all your data transformation and model fit in the same pipeline, using <code>from pyspark.ml import Pipeline<\/code>. Before logging the model, consider going under signature and registering the model schema.<\/p>\n<pre><code>import mlflow.spark\nfrom mlflow.models.signature import infer_signature\n\nwith mlflow.start_run():\n    [...]\n    # executing train &amp; test pipelines:\n    model = pipeline.fit(train_features) # training model\n    predictions = model.transform(test_features) # testing model\n    train_signature = train_features.select('input_data') # ignores all other features created on the pipeline\n    prediction_signature = predictions.select('input_data', 'prediction') # ignores all other features created on the training pipeline \n    signature = infer_signature(train_signature, prediction_signature) # register model schema\n    mlflow.spark.log_model(model, 'transactions-classification', signature=signature) # logging model to mlflow\n    [...]\n<\/code><\/pre>\n<p>After logging the model to the experiment, in a different notebook, you can use the load_model function as:<\/p>\n<pre><code># importing model\nimport mlflow.spark\nmodel_path = 'runs:\/run-id'\nmodel = mlflow.spark.load_model(model_path)\n<\/code><\/pre>\n<p>And it will work! :D<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-08-19 13:07:40.77 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-08-31 22:03:50.98 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68527422",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58995329,
        "Question_title":"Artifact storage and MLFLow on remote server",
        "Question_body":"<p>I am trying to get MLFlow on another machine in a local network to run and I would like to ask for some help because I don't know what to do now.<\/p>\n\n<p>I have a mlflow server running on a <em>server<\/em>. The mlflow server is running under my user on the <em>server<\/em> and has been started like this: <\/p>\n\n<pre><code>mlflow server --host 0.0.0.0 --port 9999 --default-artifact-root sftp:\/\/&lt;MYUSERNAME&gt;@&lt;SERVER&gt;:&lt;PATH\/TO\/DIRECTORY\/WHICH\/EXISTS&gt;\n<\/code><\/pre>\n\n<p>My program which should log all the data to the mlflow server looks like this:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from mlflow import log_metric, log_param, log_artifact, set_tracking_uri\n\nif __name__ == \"__main__\":\n    remote_server_uri = '&lt;SERVER&gt;' # this value has been replaced\n    set_tracking_uri(remote_server_uri)\n    # Log a parameter (key-value pair)\n    log_param(\"param1\", 5)\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(\"foo\", 1)\n    log_metric(\"foo\", 2)\n    log_metric(\"foo\", 3)\n\n    # Log an artifact (output file)\n    with open(\"output.txt\", \"w\") as f:\n        f.write(\"Hello world!\")\n    log_artifact(\"output.txt\")\n\n<\/code><\/pre>\n\n<p>The parameters get and metrics get transfered to the server but not the artifacts. Why is that so?<\/p>\n\n<p>Note on the SFTP part:\nI can log in via SFTP and the pysftp package is installed<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-22 13:32:02.373 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-11-22 14:43:48.62 UTC",
        "Question_score":9,
        "Question_tags":"python|mlflow",
        "Question_view_count":3483,
        "Owner_creation_date":"2014-03-21 14:59:04.963 UTC",
        "Owner_last_access_date":"2022-06-30 17:07:48.553 UTC",
        "Owner_reputation":422,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":13,
        "Answer_body":"<p>I don't know if I will get an answer to my problem but I did <em>solved<\/em> it this way.<\/p>\n\n<p>On the server I created the directory <code>\/var\/mlruns<\/code>. I pass this directory to mlflow via <code>--backend-store-uri file:\/\/\/var\/mlruns<\/code><\/p>\n\n<p>Then I mount this directory via e.g. <code>sshfs<\/code> on my local machine under the same path.<\/p>\n\n<p>I don't like this solution but it solved the problem good enough for now.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-12-10 08:50:01.237 UTC",
        "Answer_score":2.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58995329",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65937623,
        "Question_title":"Unable to serve an mlflow model locally",
        "Question_body":"<p>I have created an mlflow model with custom pyfunc. It shows the results when I send input to the loaded model in Jupyter notebook.\nHowever if I am trying to serve it to a local port<\/p>\n<pre><code>!mlflow models serve -m Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model -p 8001\n<\/code><\/pre>\n<p>I am getting this error<\/p>\n<pre><code> Traceback (most recent call last):\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/bin\/mlflow&quot;, line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 829, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 782, in main\n    rv = self.invoke(ctx)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 610, in invoke\n    return callback(*args, **kwargs)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py&quot;, line 56, in serve\n    install_mlflow=install_mlflow).serve(model_uri=model_uri, port=port,\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py&quot;, line 163, in _get_flavor_backend\n    append_to_uri_path(underlying_model_uri, &quot;MLmodel&quot;), output_path=tmp.path())\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/tracking\/artifact_utils.py&quot;, line 76, in _download_artifact_from_uri\n    artifact_path=artifact_path, dst_path=output_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py&quot;, line 67, in download_artifacts\n    return super(LocalArtifactRepository, self).download_artifacts(artifact_path, dst_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py&quot;, line 140, in download_artifacts\n    return download_file(artifact_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py&quot;, line 105, in download_file\n    self._download_file(remote_file_path=fullpath, local_path=local_file_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py&quot;, line 95, in _download_file\n    shutil.copyfile(remote_file_path, local_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/shutil.py&quot;, line 120, in copyfile\n    with open(src, 'rb') as fsrc:\nFileNotFoundError: [Errno 2] No such file or directory: 'Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model\/MLmodel'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-28 13:01:27.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"deployment|localhost|mlflow",
        "Question_view_count":1277,
        "Owner_creation_date":"2019-11-14 13:58:10.56 UTC",
        "Owner_last_access_date":"2022-09-23 08:37:32.563 UTC",
        "Owner_reputation":115,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Answer_body":"<p>From your error traceback, the model artifact can't be located. In your code, you are executing the 'mlflow' command from within a Jupyter Notebook. I would suggest trying the following:<\/p>\n<ol>\n<li>Check if your models artifacts are on the path you are using Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model<\/li>\n<li>Try opening a terminal, then <code>cd \/Home\/miniconda3\/envs<\/code> and  execute <code>mlflow models serve -m .\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model -p 8001<\/code><\/li>\n<li>MLFlow offers different solutions to serve a model, you can try to register your model and refer to it as &quot;models:\/{model_name}\/{stage}&quot; as mentioned in the Model Registry <a href=\"https:\/\/mlflow.org\/docs\/latest\/model-registry.html#serving-an-mlflow-model-from-model-registry\" rel=\"nofollow noreferrer\">docs<\/a><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-01-28 13:30:03.1 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65937623",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73074887,
        "Question_title":"'mlflow' has no attribute 'last_active_run'",
        "Question_body":"<p>For the first time, it is proceeding mlflow with port 5000.<\/p>\n<p>Testing Mlflow, problem is no attribute last_active_run in mlflow<\/p>\n<p>But, It was an example provided by Mlflow. <br \/>\nlink is here <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_autolog\" rel=\"nofollow noreferrer\">mlflow<\/a><\/p>\n<p>What is problem and how can I change code?<\/p>\n<p>shell<\/p>\n<pre><code>wget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/master\/examples\/sklearn_autolog\/utils.py\nwget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/master\/examples\/sklearn_autolog\/pipeline.py\n<\/code><\/pre>\n<p>pipeline.py<\/p>\n<pre><code>from pprint import pprint\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nimport mlflow\nfrom utils import fetch_logged_data\n\n\ndef main():\n    # enable autologging\n    mlflow.sklearn.autolog()\n\n    # prepare training data\n    X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n    y = np.dot(X, np.array([1, 2])) + 3\n\n    # train a model\n    pipe = Pipeline([(&quot;scaler&quot;, StandardScaler()), (&quot;lr&quot;, LinearRegression())])\n    pipe.fit(X, y)\n    run_id = mlflow.last_active_run().info.run_id\n    print(&quot;Logged data and model in run: {}&quot;.format(run_id))\n\n    # show logged data\n    for key, data in fetch_logged_data(run_id).items():\n        print(&quot;\\n---------- logged {} ----------&quot;.format(key))\n        pprint(data)\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>utils.py<\/p>\n<pre><code>import mlflow\nfrom mlflow.tracking import MlflowClient\n\n\ndef yield_artifacts(run_id, path=None):\n    &quot;&quot;&quot;Yield all artifacts in the specified run&quot;&quot;&quot;\n    client = MlflowClient()\n    for item in client.list_artifacts(run_id, path):\n        if item.is_dir:\n            yield from yield_artifacts(run_id, item.path)\n        else:\n            yield item.path\n\n\ndef fetch_logged_data(run_id):\n    &quot;&quot;&quot;Fetch params, metrics, tags, and artifacts in the specified run&quot;&quot;&quot;\n    client = MlflowClient()\n    data = client.get_run(run_id).data\n    # Exclude system tags: https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#system-tags\n    tags = {k: v for k, v in data.tags.items() if not k.startswith(&quot;mlflow.&quot;)}\n    artifacts = list(yield_artifacts(run_id))\n    return {\n        &quot;params&quot;: data.params,\n        &quot;metrics&quot;: data.metrics,\n        &quot;tags&quot;: tags,\n        &quot;artifacts&quot;: artifacts,\n    }\n<\/code><\/pre>\n<p>Error message<\/p>\n<pre><code>INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8cc3f4e03b4e417b95a64f1a9a41be63', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\nTraceback (most recent call last):\n  File &quot;\/Users\/taein\/Desktop\/mlflow\/pipeline.py&quot;, line 33, in &lt;module&gt;\n    main()\n  File &quot;\/Users\/taein\/Desktop\/mlflow\/pipeline.py&quot;, line 23, in main\n    run_id = mlflow.last_active_run().info.run_id\nAttributeError: module 'mlflow' has no attribute 'last_active_run'\n<\/code><\/pre>\n<p>Thanks for your helping<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-22 03:40:56.963 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|python-3.x|scikit-learn|mlflow",
        "Question_view_count":215,
        "Owner_creation_date":"2020-08-23 11:05:51.547 UTC",
        "Owner_last_access_date":"2022-09-23 03:21:56.017 UTC",
        "Owner_reputation":158,
        "Owner_up_votes":4,
        "Owner_down_votes":2,
        "Owner_views":29,
        "Answer_body":"<p>It's because of the mlflow version that you mentioned in the comments. <code>mlflow.last_active_run()<\/code> API was introduced in <a href=\"https:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v1.25.0\" rel=\"nofollow noreferrer\">mlflow 1.25.0\n<\/a>. So you should upgrade the mlflow or you can use the previous version of the code available <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<pre><code>wget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\/utils.py\nwget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\/pipeline.py\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-24 23:47:46.923 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seoul, Repulic of Korea",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73074887",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64209196,
        "Question_title":"How to update a previous run into MLFlow?",
        "Question_body":"<p>I would like to update previous runs done with MLFlow, ie. changing\/updating a parameter value to accommodate a change in the implementation. Typical uses cases:<\/p>\n<ul>\n<li>Log runs using a parameter A, and much later, log parameters A and B. It would be useful to update the value of parameter B of previous runs using its default value.<\/li>\n<li>&quot;Specialize&quot; a parameter. Implement a model using a boolean flag as a parameter. Update the implementation to take a string instead. Now we need to update the values of the parameter for the previous runs so that it stays consistent with the new behavior.<\/li>\n<li>Correct a wrong parameter value loggued in the previous runs.<\/li>\n<\/ul>\n<p>It is not always easy to trash the whole experiment as I need to keep the previous runs for statistical purpose. I would like also not to generate new experiments just for a single new parameter, to keep a single database of runs.<\/p>\n<p>What is the best way to do this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2020-10-05 13:04:07.533 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2020-12-12 16:01:03.85 UTC",
        "Question_score":6,
        "Question_tags":"logging|data-science|mlflow",
        "Question_view_count":2834,
        "Owner_creation_date":"2012-09-10 21:25:47.147 UTC",
        "Owner_last_access_date":"2022-09-24 18:14:33.217 UTC",
        "Owner_reputation":1022,
        "Owner_up_votes":1127,
        "Owner_down_votes":19,
        "Owner_views":66,
        "Answer_body":"<p>To add or correct a parameter, metric or artifact of an existing run, pass run_id instead of experiment_id to mlflow.start_run function<\/p>\n<pre><code>with mlflow.start_run(run_id=&quot;your_run_id&quot;) as run:\n    mlflow.log_param(&quot;p1&quot;,&quot;your_corrected_value&quot;)\n    mlflow.log_metric(&quot;m1&quot;,42.0) # your corrected metrics\n    mlflow.log_artifact(&quot;data_sample.html&quot;) # your corrected artifact file\n<\/code><\/pre>\n<p>You can correct, add to, or delete any MLflow run any time after it is complete. Get the run_id either from the UI or by using <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.search_runs\" rel=\"noreferrer\">mlflow.search_runs<\/a>.<\/p>\n<p>Source: <a href=\"https:\/\/towardsdatascience.com\/5-tips-for-mlflow-experiment-tracking-c70ae117b03f\" rel=\"noreferrer\">https:\/\/towardsdatascience.com\/5-tips-for-mlflow-experiment-tracking-c70ae117b03f<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-12-02 14:45:49.24 UTC",
        "Answer_score":10.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64209196",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60597319,
        "Question_title":"Running MLFlow on GCP VM",
        "Question_body":"<p>I have installed mlflow on GCP VM instance, \nnow I want to access mlflow UI with external IP.\nI tried setting up a firewall rule and opening the default port for mlflow, but not able to access it.\nCan someone give step by step process for just running mlflow on VM instance?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2020-03-09 08:59:47.613 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-03-10 09:27:00.66 UTC",
        "Question_score":4,
        "Question_tags":"python|google-cloud-platform|mlflow",
        "Question_view_count":1537,
        "Owner_creation_date":"2015-12-26 10:00:57.623 UTC",
        "Owner_last_access_date":"2022-09-24 13:39:24.72 UTC",
        "Owner_reputation":736,
        "Owner_up_votes":69,
        "Owner_down_votes":2,
        "Owner_views":234,
        "Answer_body":"<p>I've decided to check on my test VM and run mlflow server on GCE VM. Have a look at my steps below:<\/p>\n\n<ol>\n<li>create VM instance based on Ubuntu Linux 18.04 LTS<\/li>\n<li><p><a href=\"https:\/\/www.mlflow.org\/docs\/latest\/quickstart.html\" rel=\"noreferrer\">install MLflow<\/a>:<\/p>\n\n<pre><code>$ sudo apt update\n$ sudo apt upgrade\n$ cd ~\n$ git clone https:\/\/github.com\/mlflow\/mlflow\n$ cd mlflow\n$ sudo apt install python3-pip\n$ pip3 install mlflow\n$ python3 setup.py build\n$ sudo python3 setup.py install\n$ mlflow --version\nmlflow, version 1.7.1.dev0\n<\/code><\/pre><\/li>\n<li><p>run mlflow server on internal IP of VM instance (default 127.0.0.1):<\/p>\n\n<pre><code>$ ifconfig \nens4: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1460\ninet 10.XXX.15.XXX  netmask 255.255.255.255  broadcast 0.0.0.0\n...\n\n$ mlflow server --host 10.XXX.15.XXX\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Starting gunicorn 20.0.4\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Listening at: http:\/\/10.128.15.211:5000 (8631)\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Using worker: sync\n[2020-03-09 15:05:50 +0000] [8634] [INFO] Booting worker with pid: 8634\n[2020-03-09 15:05:51 +0000] [8635] [INFO] Booting worker with pid: 8635\n[2020-03-09 15:05:51 +0000] [8636] [INFO] Booting worker with pid: 8636\n[2020-03-09 15:05:51 +0000] [8638] [INFO] Booting worker with pid: 8638\n<\/code><\/pre><\/li>\n<li><p>check from VM instance (from second connection):<\/p>\n\n<pre><code>$ curl -I http:\/\/10.XXX.15.XXX:5000\nHTTP\/1.1 200 OK\nServer: gunicorn\/20.0.4\nDate: Mon, 09 Mar 2020 15:06:08 GMT\nConnection: close\nContent-Length: 853\nContent-Type: text\/html; charset=utf-8\nLast-Modified: Mon, 09 Mar 2020 14:57:11 GMT\nCache-Control: public, max-age=43200\nExpires: Tue, 10 Mar 2020 03:06:08 GMT\nETag: \"1583765831.3202355-853-3764264575\"\n<\/code><\/pre><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/add-remove-network-tags\" rel=\"noreferrer\">set network tag<\/a> <code>mlflow-server<\/code> <\/p><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/using-firewalls#creating_firewall_rules\" rel=\"noreferrer\">create firewall rule<\/a> to allow access on port 5000<\/p>\n\n<pre><code>$ gcloud compute --project=test-prj firewall-rules create mlflow-server --direction=INGRESS --priority=999 --network=default --action=ALLOW --rules=tcp:5000 --source-ranges=0.0.0.0\/0 --target-tags=mlflow-server\n<\/code><\/pre><\/li>\n<li><p>check from on-premises Linux machine <code>nmap -Pn 35.225.XXX.XXX<\/code><\/p>\n\n<pre><code>Starting Nmap 7.80 ( https:\/\/nmap.org ) at 2020-03-09 16:20 CET\nNmap scan report for 74.123.225.35.bc.googleusercontent.com (35.225.XXX.XXX)\nHost is up (0.20s latency).\nNot shown: 993 filtered ports\nPORT     STATE  SERVICE\n...\n5000\/tcp open   upnp\n...\n<\/code><\/pre><\/li>\n<li><p>go to web browser <a href=\"http:\/\/35.225.XXX.XXX:5000\/\" rel=\"noreferrer\">http:\/\/35.225.XXX.XXX:5000\/<\/a><\/p><\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" alt=\"mlflow\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-09 15:26:38.37 UTC",
        "Answer_score":5.0,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60597319",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70445997,
        "Question_title":"MLflow run within a docker container - Running with \"docker_env\" in MLflow project file",
        "Question_body":"<p>We are trying to develop an MLflow pipeline. We have our developing environment in a series of dockers (no local python environment &quot;whatsoever&quot;). This means that we have set up a docker container with MLflow and all requirements necessary to run pipelines. The issue we have is that when we write our MLflow project file we need to use &quot;docker_env&quot; to specify the environment. This figure illustrates what we want to achieve:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1tLuw.jpg\" rel=\"nofollow noreferrer\">MLflow run dind<\/a><\/p>\n<p>MLflow inside the docker needs to access the docker daemon\/service so that it can either use the &quot;docker-image&quot; in the MLflow project file or pull it from docker hub. We are aware of the possibility of using &quot;conda_env&quot; in the MLflow project file but wish to avoid this.<\/p>\n<p>Our question is,<\/p>\n<p>Do we need to set some sort of &quot;docker in docker&quot; solution to achieve our goal?<\/p>\n<p>Is it possible to set up the docker container in which MLflow is running so that it can access the &quot;host machine&quot; docker daemon?<\/p>\n<p>I have been all over Google and MLflow's documentation but I can seem to find anything that can guide us. Thanks a lot in advance for any help or pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_date":"2021-12-22 08:13:08.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-22 14:51:26.953 UTC",
        "Question_score":1,
        "Question_tags":"docker|mlflow|docker-in-docker",
        "Question_view_count":779,
        "Owner_creation_date":"2019-01-02 12:14:24.35 UTC",
        "Owner_last_access_date":"2022-09-22 12:14:35.057 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>I managed to create my pipeline using docker and docker_env in MLflow. It is not necessary to run d-in-d, the &quot;sibling approach&quot; is sufficient. This approach is described here:<\/p>\n<p><a href=\"https:\/\/jpetazzo.github.io\/2015\/09\/03\/do-not-use-docker-in-docker-for-ci\/\" rel=\"nofollow noreferrer\">https:\/\/jpetazzo.github.io\/2015\/09\/03\/do-not-use-docker-in-docker-for-ci\/<\/a><\/p>\n<p>and it is the preferred method to avoid d-in-d.<\/p>\n<p>One needs to be very careful when mounting volumes within the primary and secondary docker environments: all volume mounts happen in the host machine.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-12-24 22:41:29.187 UTC",
        "Answer_score":2.0,
        "Owner_location":"Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70445997",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70111193,
        "Question_title":"How can I load the latest model version from MLflow model registry?",
        "Question_body":"<p>I can load a specific version of a model using the mlflow client:<\/p>\n<pre><code>import mlflow\n\nmodel_version = 1\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f&quot;models:\/c3760a15e6ac48f88ad7e5af940047d4\/{model_version}&quot;\n)\n<\/code><\/pre>\n<p>But is there a way to load the latest model version?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-25 12:32:21.287 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-25 14:31:27.89 UTC",
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":1873,
        "Owner_creation_date":"2012-10-24 12:12:59.277 UTC",
        "Owner_last_access_date":"2022-09-25 05:49:23.95 UTC",
        "Owner_reputation":3126,
        "Owner_up_votes":1817,
        "Owner_down_votes":2,
        "Owner_views":262,
        "Answer_body":"<p>There is no such thing, like load <code>latest<\/code>, but:<\/p>\n<ul>\n<li>You can specify the stage (<code>staging<\/code>, <code>production<\/code>) - see <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/concepts.html#referencing-artifacts\" rel=\"nofollow noreferrer\">docs<\/a><\/li>\n<li>You can find latest version using the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_latest_versions\" rel=\"nofollow noreferrer\">get_latest_versions<\/a> function - but it will also return latest per stage<\/li>\n<\/ul>\n<p>So you need to define what <code>latest<\/code> means for you.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-25 15:13:20.393 UTC",
        "Answer_score":2.0,
        "Owner_location":"Leuven, Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70111193",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65992776,
        "Question_title":"MLflow change experiment id",
        "Question_body":"<p>I am unable to change the experiment id of a MLflow experiment.<\/p>\n<p>Currently, I am running the following code to create an experiment before logging:<\/p>\n<pre><code>mlflow.set_experiment(experiment_name=&quot;my_model&quot;)\n\nwith mlflow.start_run():\n   #train model\n<\/code><\/pre>\n<p>Doing so allows me to create a new experiment, but the experiment id will always be 1.<\/p>\n<p>The yaml file created looks like this:<\/p>\n<pre><code>artifact_location: file:\/\/\/project\/src\/mlruns\/1\nexperiment_id: '1'\nlifecycle_stage: active\nname: my_model\n<\/code><\/pre>\n<p>I have tried to look at the MLflow documentation, but I cannot find examples or functions where the experiment id is altered.<\/p>\n<p>I would greatly appreciate any help or tips with this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-02-01 12:30:22.783 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"python|machine-learning|mlflow",
        "Question_view_count":2003,
        "Owner_creation_date":"2018-11-12 08:31:58.403 UTC",
        "Owner_last_access_date":"2022-06-18 20:28:19.107 UTC",
        "Owner_reputation":267,
        "Owner_up_votes":69,
        "Owner_down_votes":5,
        "Owner_views":13,
        "Answer_body":"<p>You should call you <code>experiment_id<\/code> in the <code>start_run()<\/code>:<\/p>\n<pre><code>mlflow.set_experiment(&quot;experiment name&quot;)\nexperiment = mlflow.get_experiment_by_name(&quot;experiment name&quot;)\n\nwith mlflow.start_run(experiment_id=experiment.experiment_id):\n     # train model\n<\/code><\/pre>\n<p><strong>Note<\/strong>: If you use <code>set_tracking_uri()<\/code>, you should <code>set_experiment()<\/code> after that.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-07-05 09:05:11.003 UTC",
        "Answer_score":6.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65992776",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60088889,
        "Question_title":"How Do You \"Permanently\" Delete An Experiment In Mlflow?",
        "Question_body":"<p>Permanent deletion of an experiment isn't documented anywhere. I'm using Mlflow w\/ backend postgres db<\/p>\n\n<p>Here's what I've run: <\/p>\n\n<pre><code>client = MlflowClient(tracking_uri=server)\nclient.delete_experiment(1)\n<\/code><\/pre>\n\n<p>This deletes the the experiment, but when I run a new experiment with the same name as the one I just deleted, it will return this error:<\/p>\n\n<pre><code>mlflow.exceptions.MlflowException: Cannot set a deleted experiment 'cross-sell' as the active experiment. You can restore the experiment, or permanently delete the  experiment to create a new one.\n<\/code><\/pre>\n\n<p>I cannot find anywhere in the documentation that shows how to permanently delete everything.<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-06 06:26:41.043 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":null,
        "Question_score":20,
        "Question_tags":"python|mlflow",
        "Question_view_count":13984,
        "Owner_creation_date":"2015-09-26 00:03:29.767 UTC",
        "Owner_last_access_date":"2022-09-23 01:58:54.27 UTC",
        "Owner_reputation":2332,
        "Owner_up_votes":133,
        "Owner_down_votes":3,
        "Owner_views":560,
        "Answer_body":"<p>Unfortunately it seems there is no way to do this via the UI or CLI at the moment :-\/<\/p>\n\n<p>The way to do it depends on the type of backend file store that you are using.<\/p>\n\n<p><strong>Filestore<\/strong>:<\/p>\n\n<p>If you are using the filesystem as a storage mechanism (the default) then it is easy. The 'deleted' experiments are moved to a <code>.trash<\/code> folder. You just need to clear that out:<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>rm -rf mlruns\/.trash\/*\n<\/code><\/pre>\n\n<p>As of the current version of the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/cli.html#mlflow-experiments-delete\" rel=\"noreferrer\">documentation<\/a> (1.7.2), they remark:<\/p>\n\n<blockquote>\n  <p>It is recommended to use a cron job or an alternate workflow mechanism to clear <code>.trash<\/code> folder.<\/p>\n<\/blockquote>\n\n<p><strong>SQL Database:<\/strong><\/p>\n\n<p>This is more tricky, as there are dependencies that need to be deleted. I am using MySQL, and these commands work for me:<\/p>\n\n<pre class=\"lang-sql prettyprint-override\"><code>USE mlflow_db;  # the name of your database\nDELETE FROM experiment_tags WHERE experiment_id=ANY(\n    SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n);\nDELETE FROM latest_metrics WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM metrics WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM tags WHERE run_uuid=ANY(\n    SELECT run_uuid FROM runs WHERE experiment_id=ANY(\n        SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n    )\n);\nDELETE FROM runs WHERE experiment_id=ANY(\n    SELECT experiment_id FROM experiments where lifecycle_stage=\"deleted\"\n);\nDELETE FROM experiments where lifecycle_stage=\"deleted\";\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-03-26 14:05:13.453 UTC",
        "Answer_score":22.0,
        "Owner_location":"Vancouver, BC, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60088889",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72431938,
        "Question_title":"TypeError: 'numpy.float32' object is not iterable when logging in mlflow",
        "Question_body":"<p>I am trying a machine learning model and logging metrics using mlflow. But I am getting <code>TypeError: 'numpy.float32' object is not iterable<\/code>. I have tried using <code>.tolist()<\/code> and <code>dict()<\/code> but nothing seems to work.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def train(max_epochs, model, optimizer, scheduler, train_loader, valid_loader, project_name):\n    best_val_loss = 100\n    for epoch in range(max_epochs):\n        model.train()\n        running_loss = []\n        tq_loader = tqdm(train_loader)\n        o = {}\n        for samples in tq_loader:\n            optimizer.zero_grad()\n            outputs, interaction_map = model(\n                [samples[0].to(device), samples[1].to(device), torch.tensor(samples[2]).to(device),\n                 torch.tensor(samples[3]).to(device)])\n            l1_norm = torch.norm(interaction_map, p=2) * 1e-4\n            loss = loss_fn(outputs, torch.tensor(samples[4]).to(device).float()) + l1_norm\n            loss.backward()\n            optimizer.step()\n            loss = loss - l1_norm\n            running_loss.append(loss.cpu().detach())\n            tq_loader.set_description(\n                &quot;Epoch: &quot; + str(epoch + 1) + &quot;  Training loss: &quot; + str(np.mean(np.array(running_loss))))\n        model.eval()\n        val_loss, mae_loss = get_metrics(model, valid_loader)\n        scheduler.step(val_loss)\n        \n        #metrics mlflow\n        mlflow.log_metrics('train_loss',(np.mean(np.array(running_loss))).tolist())\n        mlflow.log_metrics('validation_loss',(val_loss).tolist())\n        mlflow.log_metrics('MAE Val_loss', (mae_loss).tolist())\n\n        print(&quot;Epoch: &quot; + str(epoch + 1) + &quot;  train_loss &quot; + str(np.mean(np.array(running_loss))) + &quot; Val_loss &quot; + str(\n            val_loss) + &quot; MAE Val_loss &quot; + str(mae_loss))\n        if val_loss &lt; best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), &quot;.\/runs\/run-&quot; + str(project_name) + &quot;\/models\/best_model.tar&quot;)\n\nmlflow.set_experiment('CIGIN_V2')\nmlflow.start_run(nested=True)\ntrain(max_epochs, model, optimizer, scheduler, train_loader, valid_loader, project_name)\nmlflow.end_run()\n<\/code><\/pre>\n<p>Error<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>Epoch: 1  Training loss: 6770.575: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1\/1 [00:04&lt;00:00,  4.35s\/it]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1\/1 [00:03&lt;00:00,  3.86s\/it]\n\n---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\n&lt;ipython-input-96-8c3a6eb822c3&gt; in &lt;module&gt;()\n      1 mlflow.set_experiment('CIGIN_V2')\n      2 mlflow.start_run(nested=True)\n----&gt; 3 train(max_epochs, model, optimizer, scheduler, train_loader, valid_loader, project_name)\n      4 mlflow.end_run()\n\n&lt;ipython-input-95-ab0a6c80b65b&gt; in train(max_epochs, model, optimizer, scheduler, train_loader, valid_loader, project_name)\n     55 \n     56         #metrics mlflow\n---&gt; 57         mlflow.log_metrics('train_loss',dict(np.mean(np.array(running_loss))).tolist())\n     58         mlflow.log_metrics('validation_loss',dict(val_loss).tolist())\n     59         mlflow.log_metrics('MAE Val_loss', dict(mae_loss).tolist())\n\nTypeError: 'numpy.float32' object is not iterable\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-05-30 09:18:30.097 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-30 09:21:18.313 UTC",
        "Question_score":0,
        "Question_tags":"python|pytorch|mlflow",
        "Question_view_count":51,
        "Owner_creation_date":"2022-05-07 04:46:02.637 UTC",
        "Owner_last_access_date":"2022-09-15 16:20:15.517 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>Youre logging a single value into log_metrics and i dont think thats correct based on the implementation of log_metric and log_metrics in the documentation:<\/p>\n<p><a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_metric\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_metric<\/a> and\n<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_metrics\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_metrics<\/a><\/p>\n<p>So i would suggest to maybe change the &quot;log_metrics&quot; to &quot;log_metric&quot; and leave the tolist out<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-05-30 09:38:56.587 UTC",
        "Answer_score":0.0,
        "Owner_location":"India",
        "Answer_last_edit_date":"2022-05-30 09:44:54.553 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72431938",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68718719,
        "Question_title":"How can I retrive the model.pkl in the experiment in Databricks",
        "Question_body":"<p>I want to retrieve the pickle off my trained model, which I know is in the run file inside my experiments in Databricks.<\/p>\n<p>It seems that the <code>mlflow.pyfunc.load_model<\/code> can only do the <code>predict<\/code> method.<\/p>\n<p>There is an option to directly access the pickle?<\/p>\n<p>I also tried to use the path in the run using the <code>pickle.load(path)<\/code> (example of path: dbfs:\/databricks\/mlflow-tracking\/20526156406\/92f3ec23bf614c9d934dd0195\/artifacts\/model\/model.pkl).<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-09 21:26:51.17 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|databricks|datastore|mlflow",
        "Question_view_count":3081,
        "Owner_creation_date":"2018-03-26 15:02:34.45 UTC",
        "Owner_last_access_date":"2022-09-23 02:49:37.96 UTC",
        "Owner_reputation":96,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":"<p>I recently found the solution which can be done by the following two approaches:<\/p>\n<ol>\n<li>Use the customized predict function at the moment of saving the model (check <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">databricks<\/a> documentation for more details).<\/li>\n<\/ol>\n<p>example give by Databricks<\/p>\n<pre><code>class AddN(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, n):\n        self.n = n\n\n    def predict(self, context, model_input):\n        return model_input.apply(lambda column: column + self.n)\n# Construct and save the model\nmodel_path = &quot;add_n_model&quot;\nadd5_model = AddN(n=5)\nmlflow.pyfunc.save_model(path=model_path, python_model=add5_model)\n\n# Load the model in `python_function` format\nloaded_model = mlflow.pyfunc.load_model(model_path)\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Load the model artefacts as we are downloading the artefact:<\/li>\n<\/ol>\n<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\ntmp_path = client.download_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path='model\/model.pkl')\n\nf = open(tmp_path,'rb')\n\nmodel = pickle.load(f)\n\nf.close()\n\n \n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;&quot;)\n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;model&quot;)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-08-23 19:53:41.287 UTC",
        "Answer_score":1.0,
        "Owner_location":"S\u00e3o Paulo, State of S\u00e3o Paulo, Brazil",
        "Answer_last_edit_date":"2022-01-24 20:08:25.513 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68718719",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58541794,
        "Question_title":"MLflow saving weights after each epoch",
        "Question_body":"<p>I have been testing some small examples with MLflow tracking but for my usecase I would like to have the weights saved after each epoch. \nSometimes I kill the runs before they are completely finished (I cannot use earlystopping), but what I experience now is that the weights do not get saved to the tracking ui server.\nIs there a way to do this after each epoch?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-10-24 12:50:01.1 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"keras|mlflow",
        "Question_view_count":1121,
        "Owner_creation_date":"2018-08-15 21:09:08.473 UTC",
        "Owner_last_access_date":"2022-09-23 10:17:25.177 UTC",
        "Owner_reputation":344,
        "Owner_up_votes":74,
        "Owner_down_votes":2,
        "Owner_views":35,
        "Answer_body":"<p>Save the weights to disk and then log them as an artifact.  As long as the checkpoints\/weights are saved to disk, you can log them with <code>mlflow_log_artifact()<\/code> or <code>mlflow_log_artifacts()<\/code>.  From the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#logging-functions\" rel=\"nofollow noreferrer\">docs<\/a>,<\/p>\n\n<blockquote>\n  <p><strong>mlflow.log_artifact()<\/strong> logs a local file or directory as an artifact,\n  optionally taking an artifact_path to place it in within the run\u2019s\n  artifact URI. Run artifacts can be organized into directories, so you\n  can place the artifact in a directory this way.<\/p>\n  \n  <p><strong>mlflow.log_artifacts()<\/strong> logs all the files in a given directory as\n  artifacts, again taking an optional artifact_path.<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-31 12:38:13.02 UTC",
        "Answer_score":1.0,
        "Owner_location":"Leuven, Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58541794",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60616430,
        "Question_title":"MLflow: how to read metrics or params from an existing run?",
        "Question_body":"<p>I try to read metrics in this way:<\/p>\n\n<pre><code> data, info = mlflow.get_run(run_id)\n print(data[1].metrics)\n # example of output: {'loss': 0.01}\n<\/code><\/pre>\n\n<p>But it get only last value. It is possible to read manually all steps of a particular metric?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":2,
        "Question_creation_date":"2020-03-10 11:10:49.443 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-03-14 11:44:28.603 UTC",
        "Question_score":3,
        "Question_tags":"python|metrics|mlflow",
        "Question_view_count":2995,
        "Owner_creation_date":"2019-01-14 12:03:19.037 UTC",
        "Owner_last_access_date":"2022-09-22 14:18:16.19 UTC",
        "Owner_reputation":171,
        "Owner_up_votes":31,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":"<p>I ran into this same problem and was able to do get all of the values for the metric by using using <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_metric_history\" rel=\"noreferrer\"><code>mlflow.tracking.MlflowClient().get_metric_history<\/code><\/a>. This will return every value you logged using <code>mlflow.log_metric(key, value)<\/code>.<\/p>\n<p>Quick example (untested)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\ntrackingDir = 'file:\/\/\/....'\nregistryDir = 'file:\/\/\/...'\nrunID = 'my run id'\nmetricKey = 'loss'\n\nclient = mlflow.tracking.MlflowClient(\n            tracking_uri=trackingDir,\n            registry_uri=registryDir,\n        )\n\nmetrics = client.get_metric_history(runID, metricKey)\n<\/code><\/pre>\n<p><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_metric_history\" rel=\"noreferrer\">From the docs<\/a><\/p>\n<blockquote>\n<p>get_metric_history(run_id, key)[source] Return a list of metric\nobjects corresponding to all values logged for a given metric.<\/p>\n<p>Parameters run_id \u2013 Unique identifier for run<\/p>\n<p>key \u2013 Metric name within the run<\/p>\n<p>Returns A list of mlflow.entities.Metric entities if logged, else\nempty list<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from mlflow.tracking import MlflowClient\n\ndef print_metric_info(history):\n    for m in history:\n        print(&quot;name: {}&quot;.format(m.key))\n        print(&quot;value: {}&quot;.format(m.value))\n        print(&quot;step: {}&quot;.format(m.step))\n        print(&quot;timestamp: {}&quot;.format(m.timestamp))\n        print(&quot;--&quot;)\n\n# Create a run under the default experiment (whose id is &quot;0&quot;). Since this is low-level\n# CRUD operation, the method will create a run. To end the run, you'll have\n# to explicitly end it. \nclient = MlflowClient() \nexperiment_id = &quot;0&quot; \nrun = client.create_run(experiment_id) \nprint(&quot;run_id:{}&quot;.format(run.info.run_id))\nprint(&quot;--&quot;)\n\n# Log couple of metrics, update their initial value, and fetch each\n# logged metrics' history. \nfor k, v in [(&quot;m1&quot;, 1.5), (&quot;m2&quot;, 2.5)]:\n    client.log_metric(run.info.run_id, k, v, step=0)\n    client.log_metric(run.info.run_id, k, v + 1, step=1)\n    print_metric_info(client.get_metric_history(run.info.run_id, k))\nclient.set_terminated(run.info.run_id) \n<\/code><\/pre>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-12-02 04:51:47.693 UTC",
        "Answer_score":5.0,
        "Owner_location":"Busto Arsizio, VA, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60616430",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72780610,
        "Question_title":"MLFlow in container is not mapped to host port",
        "Question_body":"<p>I am learning about MLFlow and Docker Containers.\nI created an ubuntu container and mapped port 5001 of the host to 5000 of the container.<\/p>\n<pre><code>docker run -it -p 5001:5000 -v D:\\Docker\\mlflow:\/home --name mlflow ubuntu:18.04 bash\n<\/code><\/pre>\n<p>Inside the container, I installed the mlflow using pip<\/p>\n<pre><code>pip install mlflow\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mmQVx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mmQVx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I run the mlflow UI it's running but I can't access it from my host PC (localhost:5001) is not working.<\/p>\n<p>Did I do any mistakes anywhere?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-28 04:01:39.483 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"docker|mlflow",
        "Question_view_count":51,
        "Owner_creation_date":"2018-10-17 13:06:23.973 UTC",
        "Owner_last_access_date":"2022-09-23 08:56:16.093 UTC",
        "Owner_reputation":434,
        "Owner_up_votes":141,
        "Owner_down_votes":3,
        "Owner_views":77,
        "Answer_body":"<p>The problem is that you are starting the server on <code>127.0.0.1<\/code> and the port mapping was not pointing to this interface (socket hang up). Starting it on all interfaces <code>0.0.0.0<\/code> works.<\/p>\n<p>You should just run this command in the container.<\/p>\n<pre><code>mlflow ui -h 0.0.0.0\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-05 21:40:54.01 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bangkok, Thailand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72780610",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65494496,
        "Question_title":"How to load a model using the object \"mlflow.tracking.client.MlflowClient\"?",
        "Question_body":"<p>I'm stuck with the MLFlow model registry. Does anyone know how to load a model using the object &quot;mlflow.tracking.client.MlflowClient&quot;?<\/p>\n<p>I would like to do a predict after with that. I'm sure I'm wrong somewhere because I've already done that in the past. I'm not able to find it in the doc, in the web.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-29 15:24:28.723 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-20 10:46:15.95 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":608,
        "Owner_creation_date":"2015-02-11 07:34:40.283 UTC",
        "Owner_last_access_date":"2022-09-23 14:32:37.963 UTC",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Answer_body":"<p>You'll have to make use of <code>mlflow.&lt;model_flavor&gt;.load_model()<\/code> to load a given model from the Model Registry. For example:<\/p>\n<pre><code>import mlflow.pyfunc\n\nmodel = mlflow.pyfunc.load_model(\n          model_uri=&quot;models:\/&lt;model_name&gt;\/&lt;model_version&gt;&quot;\n          )\n\nmodel.predict(...)\n<\/code><\/pre>\n<p>With <code>mlflow.tracking.client.MlflowClient<\/code> you can retrieve metadata about a model from the model registry, but for retrieving the actual model you will need to use <code>mlflow.&lt;model_flavor&gt;.load_model<\/code>. For example, you could use the MlflowClient to get the download URI for a given model, and then use <code>mlflow.&lt;flavor&gt;.load_model<\/code> to retrieve that model.<\/p>\n<pre><code>model_uri = client.get_model_version_download_uri(&quot;&lt;model_name&gt;&quot;, &lt;version&gt;)\nmodel = mlflow.pyfunc.load_model(model_uri)\n\nmodel.predict(...)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-01-04 20:25:59.68 UTC",
        "Answer_score":2.0,
        "Owner_location":"Lyon, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65494496",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72411618,
        "Question_title":"MLFLOW and Postgres getting Bad Request error",
        "Question_body":"<p>I have been pulling my hair trying to figure out what's wrong with mlflow. Iam deploying mlflow v1.26 in google cloudRun . back end artitfactory is google storage and backend database is google cloudsql postgres v13 instance.<\/p>\n<p>here is my entrypoint using pg8000 v1.21.3 (I tried latest version as well) and psycopg2-binary v2.9.3<\/p>\n<pre><code>\nset -e\nexport ARTIFACT_URL=&quot;gs:\/\/ei-cs-dev01-ein-sb-teambucket-chaai-01\/mlflow\/&quot;\nexport DATABASE_URL=&quot;postgresql+pg8000:\/\/mlflow:change2022@10.238.139.37:5432\/mlflowps&quot; #&quot;$(python3 \/app\/get_secret.py --project=&quot;${GCP_PROJECT}&quot; --secret=mlflow_database_url)&quot;\n\nif [[ -z &quot;${PORT}&quot; ]]; then\n    export PORT=8080\nfi\n\nexec mlflow server -h 0.0.0.0 -w 4 -p ${PORT} --default-artifact-root ${ARTIFACT_URL} --backend-store-uri ${DATABASE_URL}\n<\/code><\/pre>\n<p>now when I open mlflow ui page I see this error happening:\n(<\/p>\n<blockquote>\n<p>BAD_REQUEST: (pg8000.dbapi.ProgrammingError) {'S': 'ERROR', 'V':\n'ERROR', 'C': '42883', 'M': 'operator does not exist: integer =\ncharacter varying', 'H': 'No operator matches the given name and\nargument types. You might need to add explicit type casts.', 'P':\n'382', 'F': 'parse_oper.c', 'L': '731', 'R': 'op_error'} [SQL: SELECT\nDISTINCT runs.run_uuid..<\/p>\n<\/blockquote>\n<p>)\n<a href=\"https:\/\/i.stack.imgur.com\/gjbLj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gjbLj.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-27 22:30:11.447 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"postgresql|google-cloud-platform|mlflow|pg8000",
        "Question_view_count":185,
        "Owner_creation_date":"2022-02-11 00:55:25.377 UTC",
        "Owner_last_access_date":"2022-09-02 21:42:33.8 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>You should use psycopg2 instead, e.g.:<\/p>\n<p><code>postgresql+psycopg2:\/\/&lt;username&gt;:&lt;password&gt;@\/&lt;dbname&gt;?host=\/cloudsql\/&lt;my-project&gt;:&lt;us-central1&gt;:&lt;dbinstance&gt;<\/code><\/p>\n<p>It works for me, with versions:<\/p>\n<p>mlflow==1.26.1<\/p>\n<p>psycopg2-binary==2.9.3<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-17 10:05:21.537 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72411618",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70036318,
        "Question_title":"Databricks multi-task jobs - pass MLflow run_id from one task to next task",
        "Question_body":"<p>I would like to create a databricks multi-task with following sequence:<\/p>\n<ul>\n<li>notebook task 1: train model with results logged to MLflow tracking server<\/li>\n<li>notebook task 2: use mlflow run_id from task 1 to register model in model registry<\/li>\n<\/ul>\n<p>Is it possible to pass run_id from task 1 to task 2 and if so is there any documentation on how this could be done?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-19 14:21:58.763 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-09 07:45:09.85 UTC",
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":198,
        "Owner_creation_date":"2015-07-09 13:14:04.057 UTC",
        "Owner_last_access_date":"2022-09-22 06:56:24.25 UTC",
        "Owner_reputation":818,
        "Owner_up_votes":76,
        "Owner_down_votes":2,
        "Owner_views":94,
        "Answer_body":"<p>As of <em>right now<\/em> (it may change), it's impossible to pass results between jobs if you use multi-task job.<\/p>\n<p>But you can call another notebook as a child job if you use <a href=\"https:\/\/docs.databricks.com\/notebooks\/notebook-workflows.html\" rel=\"nofollow noreferrer\">notebook workflows<\/a>  and function <code>dbutils.notebooks.run<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># notebook 1\n... training code ...\ndbutils.notebooks.run(&quot;notebook2&quot;, 300, {&quot;run_id&quot;: run_id})\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-19 17:00:39.877 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70036318",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70820661,
        "Question_title":"Track to database, artifacts to specific destination",
        "Question_body":"<p>I am running <code>mlflow ui<\/code> and PostgreSQL db in docker compose.<\/p>\n<p>Mlflow UI container runs like this: <code>mlflow ui --backend-store-uri &quot;postgresql+psycopg2:\/\/postgres:passw0rd@database:5432\/postgres&quot; --host 0.0.0.0<\/code><\/p>\n<p>Then I run my models locally from jupyter, e.g.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>remote_server_uri = &quot;postgresql+psycopg2:\/\/postgres:passw0rd@localhost:5432\/postgres&quot;\nmlflow.set_tracking_uri(remote_server_uri)\nmlflow.set_experiment(&quot;exp2&quot;)\n\nX = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\ny = np.array([0, 0, 1, 1, 1, 0])\nlr = LogisticRegression()\nlr.fit(X, y)\nscore = lr.score(X, y)\nprint(&quot;Score: %s&quot; % score)\nwith mlflow.start_run():\n    mlflow.log_metric(&quot;score&quot;, score)\n<\/code><\/pre>\n<p>Everything works fine - experiments get logged into PostgreSQL and mlflow UI can read it from PostgreSQL .<\/p>\n<p>One thing that bothers me is that artifacts are stored locally into .\/mlruns folder. How to change it to save it somewhere else?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-23 09:18:47.63 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-23 09:23:27.49 UTC",
        "Question_score":0,
        "Question_tags":"python|postgresql|mlflow",
        "Question_view_count":361,
        "Owner_creation_date":"2016-04-04 13:56:35.087 UTC",
        "Owner_last_access_date":"2022-09-24 15:49:58.61 UTC",
        "Owner_reputation":622,
        "Owner_up_votes":296,
        "Owner_down_votes":11,
        "Owner_views":59,
        "Answer_body":"<p>So apparently <code>--default-artifact-root<\/code> argument has to be used when launching server\/ui. The only downside is that that default artifact root is relative to development environment, so if you are running mlflow server in docker and specify default-artifact-root to e.g. <code>some\/path<\/code> then the artifacts are going to be saved to your <strong>local machine<\/strong> to that path (<strong>not inside docker container<\/strong>). Probably the best solution is to use remote storage such as S3\/Blob.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-01-23 18:03:46.12 UTC",
        "Answer_score":0.0,
        "Owner_location":"Czech Republic",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70820661",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66320435,
        "Question_title":"mlflow.exceptions.MlflowException: Changing param values is not allowed. Param with key='input_rows' was already logged with value='32205'",
        "Question_body":"<p>I am using Mlflow as a work orchestration tool. I have a Machine Learning pipeline. In this pipeline, I have real-time data. I'm listening this data with Apache Kafka. Also, I'm doing this: Whenever 250 message comes to this topic, I'm gathering them, and I'm appending this message my previous data. After that, my training function is triggered. Thus, I am able to making new training in every 250 new data. With Mlflow, I can show the results, metrics and any other parameters of trained models. But After training occurred one time, the second one doesn't occurs, and It throws me this error which I have shown in title. Here it is my consumer:<\/p>\n<pre><code>topic_name = 'twitterdata'\ntrain_every = 250\n\n\ndef consume_tweets():\n    consumer = KafkaConsumer(\n        topic_name,\n        bootstrap_servers=['localhost:9093'],\n        auto_offset_reset='latest',\n        enable_auto_commit=True,\n        auto_commit_interval_ms=5000,\n        fetch_max_bytes=128,\n        max_poll_records=100,\n        value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n\n    tweet_counter = 0\n    for message in consumer:\n        tweets = json.loads(json.dumps(message.value))\n        # print(tweets['text'])\n        tweet_sentiment = make_prediction(tweets['text'])\n\n        if tweet_counter == train_every:\n            update_df()\n            data_path = 'data\/updated_tweets.csv'\n            train(data_path)\n            print(&quot;\\nTraining with new data is completed!\\n&quot;)\n            tweet_counter = 0\n\n        else:\n            tweet_counter += 1\n\n        publish_prediction(tweet_sentiment, tweets['text'])\n\n<\/code><\/pre>\n<p>And here it is my train.py:<\/p>\n<pre><code>train_tweets = pd.read_csv(DATA_PATH)\n    # train_tweets = train_tweets[:20000]\n\n    tweets = train_tweets.tweet.values\n    labels = train_tweets.label.values\n\n    # Log data params\n    mlflow.log_param('input_rows', train_tweets.shape[0])\n\n    # Do preprocessing and return vectorizer with it\n    vectorizer, processed_features = embedding(tweets)\n\n    # Saving vectorizer\n    save_vectorizer(vectorizer)\n\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)\n\n    # Handle imbalanced data by using 'Smote' and log to Mlflow\n    smote = SMOTE('minority')\n    mlflow.log_param(&quot;over-sampling&quot;, smote)\n\n    X_train, y_train = smote.fit_sample(X_train, y_train)\n\n    # text_classifier = MultinomialNB()\n    text_classifier = LogisticRegression(max_iter=10000)\n    text_classifier.fit(X_train, y_train)\n    predictions = text_classifier.predict(X_test)\n\n    # Model metrics\n    (rmse, mae, r2) = eval_metrics(y_test, predictions)\n\n    mlflow.log_param('os-row-Xtrain', X_train.shape[0])\n    mlflow.log_param('os-row-ytrain', y_train.shape[0])\n    mlflow.log_param(&quot;model_name&quot;, text_classifier)\n    mlflow.log_metric(&quot;rmse&quot;, rmse)\n    mlflow.log_metric(&quot;r2&quot;, r2)\n    mlflow.log_metric(&quot;mae&quot;, mae)\n    mlflow.log_metric('acc_score', accuracy_score(y_test, predictions))\n\n    mlflow.sklearn.log_model(text_classifier, &quot;model&quot;)\n<\/code><\/pre>\n<p>I couldn't solve the problem. MLflow is one of the newest tool, so issues and examples of Mlflow are very few.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-22 17:23:12.93 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-02-22 17:31:38.323 UTC",
        "Question_score":1,
        "Question_tags":"python|machine-learning|apache-kafka|mlflow|real-time-data",
        "Question_view_count":2716,
        "Owner_creation_date":"2021-02-12 11:44:23.95 UTC",
        "Owner_last_access_date":"2022-09-22 11:40:37.707 UTC",
        "Owner_reputation":44,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>I think you need an MLflow &quot;run&quot; for every new batch of data, so that your parameters are logged independently for each new training.<\/p>\n<p>So, try the following in your consumer:<\/p>\n<pre><code>if tweet_counter == train_every:\n            update_df()\n            data_path = 'data\/updated_tweets.csv'\n            with mlflow.start_run() as mlrun:\n               train(data_path)\n            print(&quot;\\nTraining with new data is completed!\\n&quot;)\n            tweet_counter = 0\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-02-26 14:45:10.747 UTC",
        "Answer_score":3.0,
        "Owner_location":"Turkey",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66320435",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72886409,
        "Question_title":"MLflow proxied artifact access: Unable to locate credentials",
        "Question_body":"<p>I am using MLflow to track my experiments. I am using an S3 bucket as an artifact store. For acessing it, I want to use <em>proxied artifact access<\/em>, as described in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>, however this does not work for me, since it locally looks for credentials (but the server should handle this).<\/p>\n<h2>Expected Behaviour<\/h2>\n<p>As described in the docs, I would expect that locally, I do not need to specify my AWS credentials, since the server handles this for me. From <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>:<\/p>\n<blockquote>\n<p>This eliminates the need to allow end users to have direct path access to a remote object store (e.g., s3, adls, gcs, hdfs) for artifact handling and eliminates the need for an end-user to provide access credentials to interact with an underlying object store.<\/p>\n<\/blockquote>\n<h2>Actual Behaviour \/ Error<\/h2>\n<p>Whenever I run an experiment on my machine, I am running into the following error:<\/p>\n<p><code>botocore.exceptions.NoCredentialsError: Unable to locate credentials<\/code><\/p>\n<p>So the error is local. However, this should not happen since the server should handle the auth instead of me needing to store my credentials locally. Also, I would expect that I would not even need library <code>boto3<\/code> locally.<\/p>\n<h2>Solutions Tried<\/h2>\n<p>I am aware that I need to create a new experiment, because existing experiments might still use a different artifact location which is proposed in <a href=\"https:\/\/stackoverflow.com\/a\/71417933\/10465165\">this SO answer<\/a> as well as in the note in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>. Creating a new experiment did not solve the error for me. Whenever I run the experiment, I get an explicit log in the console validating this:<\/p>\n<p><code>INFO mlflow.tracking.fluent: Experiment with name 'test' does not exist. Creating a new experiment.<\/code><\/p>\n<p>Related Questions (<a href=\"https:\/\/stackoverflow.com\/questions\/72206086\/cant-log-mlflow-artifacts-to-s3-with-docker-based-tracking-server\">#1<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/72236258\/mlflow-unable-to-store-artifacts-to-s3\/72261826#comment128726676_72261826\">#2<\/a>) refer to a different scenario, which is also <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\" rel=\"nofollow noreferrer\">described in the docs<\/a><\/p>\n<h2>Server Config<\/h2>\n<p>The server runs on a kubernetes pod with the following config:<\/p>\n<pre><code>mlflow server \\\n    --host 0.0.0.0 \\\n    --port 5000 \\\n    --backend-store-uri postgresql:\/\/user:pw@endpoint \\\n    --artifacts-destination s3:\/\/my_bucket\/artifacts \\\n    --serve-artifacts \\\n    --default-artifact-root s3:\/\/my_bucket\/artifacts \\\n<\/code><\/pre>\n<p>I would expect my config to be correct, looking at doc <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">page 1<\/a> and <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#using-the-tracking-server-for-proxied-artifact-access\" rel=\"nofollow noreferrer\">page 2<\/a><\/p>\n<p>I am able to see the mlflow UI if I forward the port to my local machine. I also see the experiment runs as failed, because of the error I sent above.<\/p>\n<h2>My Code<\/h2>\n<p>The relevant part of my code which fails is the logging of the model:<\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.set_experiment(&quot;test2)\n\n...\n\n# this works\nmlflow.log_params(hyperparameters)\n                        \nmodel = self._train(model_name, hyperparameters, X_train, y_train)\ny_pred = model.predict(X_test)\nself._evaluate(y_test, y_pred)\n\n# this fails with the error from above\nmlflow.sklearn.log_model(model, &quot;artifacts&quot;)\n\n<\/code><\/pre>\n<h2>Question<\/h2>\n<p>I am probably overlooking something. Is there a need to locally indicate that I want to use proxied artified access? If yes, how do I do this? Is there something I have missed?<\/p>\n<h2>Full Traceback<\/h2>\n<pre><code>  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/models\/model.py&quot;, line 295, in log\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 726, in log_artifacts\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py&quot;, line 1001, in log_artifacts\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 346, in log_artifacts\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/store\/artifact\/s3_artifact_repo.py&quot;, line 141, in log_artifacts\n    self._upload_file(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/store\/artifact\/s3_artifact_repo.py&quot;, line 117, in _upload_file\n    s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/boto3\/s3\/inject.py&quot;, line 143, in upload_file\n    return transfer.upload_file(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/boto3\/s3\/transfer.py&quot;, line 288, in upload_file\n    future.result()\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/futures.py&quot;, line 103, in result\n    return self._coordinator.result()\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/futures.py&quot;, line 266, in result\n    raise self._exception\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/tasks.py&quot;, line 139, in __call__\n    return self._execute_main(kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/tasks.py&quot;, line 162, in _execute_main\n    return_value = self._main(**kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/upload.py&quot;, line 758, in _main\n    client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 508, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 898, in _make_api_call\n    http, parsed_response = self._make_request(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 921, in _make_request\n    return self._endpoint.make_request(operation_model, request_dict)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 119, in make_request\n    return self._send_request(request_dict, operation_model)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 198, in _send_request\n    request = self.create_request(request_dict, operation_model)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 134, in create_request\n    self._event_emitter.emit(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 412, in emit\n    return self._emitter.emit(aliased_event_name, **kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 256, in emit\n    return self._emit(event_name, kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 239, in _emit\n    response = handler(**kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/signers.py&quot;, line 103, in handler\n    return self.sign(operation_name, request)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/signers.py&quot;, line 187, in sign\n    auth.add_auth(request)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/auth.py&quot;, line 407, in add_auth\n    raise NoCredentialsError()\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-06 15:40:30.593 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-06 15:52:51.947 UTC",
        "Question_score":0,
        "Question_tags":"amazon-web-services|machine-learning|amazon-s3|boto3|mlflow",
        "Question_view_count":237,
        "Owner_creation_date":"2018-10-06 09:06:11.613 UTC",
        "Owner_last_access_date":"2022-09-22 14:26:03.733 UTC",
        "Owner_reputation":647,
        "Owner_up_votes":971,
        "Owner_down_votes":39,
        "Owner_views":61,
        "Answer_body":"<p>The problem is that the server is running on wrong run parameters, the <code>--default-artifact-root<\/code> needs to either be removed or set to <code>mlflow-artifacts:\/<\/code>.<\/p>\n<p>From <code>mlflow server --help<\/code>:<\/p>\n<pre><code>  --default-artifact-root URI  Directory in which to store artifacts for any\n                               new experiments created. For tracking server\n                               backends that rely on SQL, this option is\n                               required in order to store artifacts. Note that\n                               this flag does not impact already-created\n                               experiments with any previous configuration of\n                               an MLflow server instance. By default, data\n                               will be logged to the mlflow-artifacts:\/ uri\n                               proxy if the --serve-artifacts option is\n                               enabled. Otherwise, the default location will\n                               be .\/mlruns.\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-07 09:40:14.37 UTC",
        "Answer_score":0.0,
        "Owner_location":"Berlin",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72886409",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72250896,
        "Question_title":"PowerShell Get request with body",
        "Question_body":"<p>I am trying <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#search-modelversions\" rel=\"nofollow noreferrer\">this api endpoint<\/a>.\nI can call this in python, no problem, like the below<\/p>\n<pre><code>get_model_versions={\n    &quot;filter&quot;:&quot;name='model_name'&quot;,\n    &quot;order_by&quot;:[&quot;version DESC&quot;],\n    &quot;max_results&quot;:1\n}\n\ninit_get = requests.get(&quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search&quot;,headers=header_read,json=get_model_versions)\n<\/code><\/pre>\n<p>However, I just can't seem to find a way to make it work in Powershell.<\/p>\n<p>First the powershell &quot;get&quot; Invoke-RestMethod does not accept a body<\/p>\n<p>and then I can't seem to find a way to append it in Powershell as a query string.<\/p>\n<p>I have tried (among other failed attempts), the following<\/p>\n<pre><code>$get_model_versions=([PSCustomObject]@{\n  filter = &quot;name=`'model_name`'&quot;\n  order_by = @(&quot;version desc&quot;)\n} | ConvertTo-Json)\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get -Body $get_model_versions\n<\/code><\/pre>\n<p>But that gives me an error that body can't be used with a get method<\/p>\n<p>trying to append it as a query string (like if I even just keep the name filter and remove the others), also fails<\/p>\n<pre><code>$searchuri= &quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search?filter=&quot;&quot;name==model_name&quot;&quot;&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get\n<\/code><\/pre>\n<p>fails with<\/p>\n<pre><code>{&quot;error_code&quot;:&quot;INVALID_PARAMETER_VALUE&quot;,&quot;message&quot;:&quot;Unsupported filter query : `\\&quot;name==model_name\\&quot;`. Unsupported operator.&quot;}\n<\/code><\/pre>\n<p>How can I mimic the same behaviour in Powershell, as I do in Python?<\/p>\n<p>EDIT 1: I did try to encode the query param (maybe I did it wrong), but here's how my failed attempt looked like<\/p>\n<pre><code>$encodedvalue = [System.Web.HttpUtility]::UrlEncode(&quot;`&quot;name='model_name'`&quot;&quot;)\n$searchuri= &quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search?filter=$encodedvalue&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get\n<\/code><\/pre>\n<p>But that too gives me<\/p>\n<pre><code>&quot;Unsupported filter query : `\\&quot;name='model_name'\\&quot;`. Unsupported operator.&quot;\n<\/code><\/pre>\n<p>I have also tried it successfully in Postman by passing a raw json body (the same as python) and when I look at the generated PowerShell code in Postman I see this<\/p>\n<pre><code>$headers = New-Object &quot;System.Collections.Generic.Dictionary[[String],[String]]&quot;\n$headers.Add(&quot;Authorization&quot;, &quot;Bearer token&quot;)\n$headers.Add(&quot;Content-Type&quot;, &quot;application\/json&quot;)\n\n$body = &quot;{\n`n    `&quot;filter`&quot;:`&quot;name='model_name'`&quot;,\n`n    `&quot;order_by`&quot;:[`&quot;version DESC`&quot;],\n`n    `&quot;max_results`&quot;:1\n`n}\n`n&quot;\n\n$response = Invoke-RestMethod 'baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search' -Method 'GET' -Headers $headers -Body $body\n$response | ConvertTo-Json\n<\/code><\/pre>\n<p>But of course that fails (if you copy that in an powershell editor and run it<\/p>\n<pre><code>Invoke-RestMethod : Cannot send a content-body with this verb-type\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2022-05-15 17:59:33.657 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-15 18:55:35.86 UTC",
        "Question_score":1,
        "Question_tags":"powershell|rest|python-requests|mlflow",
        "Question_view_count":281,
        "Owner_creation_date":"2015-04-10 08:31:54.763 UTC",
        "Owner_last_access_date":"2022-09-24 09:37:37.383 UTC",
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Answer_body":"<p>Finally, after struggling for a long time, I found the answer !<\/p>\n<p>The crux is in the documentation <a href=\"https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.utility\/invoke-restmethod?view=powershell-7.2\" rel=\"nofollow noreferrer\">here<\/a>.\nEspecially this section<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/h0gwk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/h0gwk.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>So, if you want to pass on a body for your &quot;get&quot; method in powershell, pass it as a hashtable.<\/p>\n<p>So, finally the answer is<\/p>\n<pre><code>$query=@{&quot;filter&quot;=&quot;name='model_name'&quot;;&quot;order_by&quot;=@(&quot;version DESC&quot;); &quot;max_results&quot;=1};\n$searchuri=&quot;baseurl\/api\/2.0\/preview\/mlflow\/model-versions\/search&quot;\n\n$resp=Invoke-RestMethod -Uri $searchuri -Headers $auth -Method Get -Body $query\n<\/code><\/pre>\n<p>Hope this helps someone looking for something similar.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-05-15 21:19:52.32 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72250896",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68812238,
        "Question_title":"How to export a MLFlow Model from Azure Databricks as an Azure DevOps Artifacts for CD phase?",
        "Question_body":"<p>I am trying to create an MLOps Pipeline using Azure DevOps and Azure Databricks. From Azure DevOps, I am submitting a Databricks job to a cluster, which trains a Machine Learning Model and saves it into MLFlow Model Registry with a custom flavour (using PyFunc Custom Model).<\/p>\n<p>Now after the job gets over, I want to export this MLFlow Object (with all dependencies - Conda dependencies, two model files - one <code>.pkl<\/code> and one <code>.h5<\/code>, the Python Class with <code>load_context()<\/code> and <code>predict()<\/code> functions defined so that after exporting I can import it and call predict as we do with MLFlow Models).<\/p>\n<p>How do I export this entire MLFlow Model and save it as an AzureDevOps Artifact to be used in the CD phase (where I will deploy it to an AKS cluster with a custom base image)?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-17 05:44:23.687 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-devops|azure-databricks|mlflow",
        "Question_view_count":575,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>There is no official way to export a Databricks MLflow run from one workspace to another. However, there is an &quot;unofficial&quot; tool that does most of the job with the main limitation being that notebook revisions linked to a run cannot be exported due to lack of a REST API endpoint for this.<\/p>\n<p><a href=\"https:\/\/github.com\/amesar\/mlflow-export-import\" rel=\"nofollow noreferrer\">https:\/\/github.com\/amesar\/mlflow-export-import<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-08-24 06:44:14.223 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68812238",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68356746,
        "Question_title":"Changing subdirectory of MLflow artifact store",
        "Question_body":"<p>Is there anything in the Python API that lets you alter the artifact subdirectories? For example, I have a .json file stored here:<\/p>\n<p><code>s3:\/\/mlflow\/3\/1353808bf7324824b7343658882b1e45\/artifacts\/feature_importance_split.json<\/code><\/p>\n<p>MlFlow creates a <code>3\/<\/code> key in s3. Is there a way to change to modify this key to something else (a date or the name of the experiment)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-07-13 05:02:26.053 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":1493,
        "Owner_creation_date":"2014-03-06 03:54:30.85 UTC",
        "Owner_last_access_date":"2022-09-20 20:56:03.467 UTC",
        "Owner_reputation":913,
        "Owner_up_votes":156,
        "Owner_down_votes":5,
        "Owner_views":88,
        "Answer_body":"<p>As I commented above, yes, <code>mlflow.create_experiment()<\/code> does allow you set the artifact location using the <code>artifact_location<\/code> parameter.<\/p>\n<p>However, sort of related, the problem with setting the <code>artifact_location<\/code> using the <code>create_experiment()<\/code> function is that once you create a experiment, MLflow will throw an error if you run the <code>create_experiment()<\/code> function again.<\/p>\n<p>I didn't see this in the docs but it's confirmed that if an experiment already exists in the backend-store, MlFlow will not allow you to run the same <code>create_experiment()<\/code> function again. And as of this post, MLfLow does not have <code>check_if_exists<\/code> flag or a <code>create_experiments_if_not_exists()<\/code> function.<\/p>\n<p>To make things more frustrating, you cannot set the <code>artifcact_location<\/code> in the <code>set_experiment()<\/code> function either.<\/p>\n<p>So here is a pretty easy work around, it also avoids the &quot;ERROR mlflow.utils.rest_utils...&quot; stdout logging as well.\n:<\/p>\n<pre><code>import os\nfrom random import random, randint\n\nfrom mlflow import mlflow,log_metric, log_param, log_artifacts\nfrom mlflow.exceptions import MlflowException\n\ntry:\n    experiment = mlflow.get_experiment_by_name('oof')\n    experiment_id = experiment.experiment_id\nexcept AttributeError:\n    experiment_id = mlflow.create_experiment('oof', artifact_location='s3:\/\/mlflow-minio\/sample\/')\n\nwith mlflow.start_run(experiment_id=experiment_id) as run:\n    mlflow.set_tracking_uri('http:\/\/localhost:5000')\n    print(&quot;Running mlflow_tracking.py&quot;)\n\n    log_param(&quot;param1&quot;, randint(0, 100))\n    \n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>If it is the user's first time creating the experiment, the code will run into an AttributeError since <code>experiment_id<\/code> does not exist and the <code>except<\/code> code block gets executed creating the experiment.<\/p>\n<p>If it is the second, third, etc the code is run, it will only execute the code under the <code>try<\/code> statement since the experiment now exists. Mlflow will now create a 'sample' key in your s3 bucket. Not fully tested but it works for me at least.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-07-13 22:05:27.413 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-07-14 04:26:34.42 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68356746",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56351452,
        "Question_title":"Connect on-prem jypyter notebook to mlflow tracking server in Azure",
        "Question_body":"<p>Is it possible to connect a notebook running in premises to an mlflow Tracking server that is part of an Azure Databricks workspace? Have all the local logging and tracking saved in Azure?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-29 00:00:53.237 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-databricks|mlflow",
        "Question_view_count":291,
        "Owner_creation_date":"2012-08-02 23:01:34.333 UTC",
        "Owner_last_access_date":"2022-09-02 23:21:30.913 UTC",
        "Owner_reputation":1390,
        "Owner_up_votes":122,
        "Owner_down_votes":2,
        "Owner_views":121,
        "Answer_body":"<p>I had a similar problem, used python and solved it with the following steps:<\/p>\n<ol>\n<li>Install mlflow and datbricks-cli libraries.<\/li>\n<li>Define the following env variables : DATABRICKS_HOST (databricks workspace url: <a href=\"https:\/\/region.azuredatabricks.net\" rel=\"nofollow noreferrer\">https:\/\/region.azuredatabricks.net<\/a>) and DATABRICKS_TOKEN<\/li>\n<li>Define mlflow client:<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow_client = mlflow.tracking.MlflowClient(tracking_uri='databricks')\n<\/code><\/pre>\n<ol start=\"5\">\n<li>Use mlflow_client client for logging, saving and etc..<\/li>\n<\/ol>\n<p>for more reference you can look at the &quot;Log to a tracking server from a notebook&quot; section <a href=\"https:\/\/docs.azuredatabricks.net\/applications\/mlflow\/tracking.html#log-to-a-tracking-server-from-a-notebook\" rel=\"nofollow noreferrer\">here<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-05-29 08:23:47.527 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56351452",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69944447,
        "Question_title":"How to change the directory of mlflow logs?",
        "Question_body":"<p>I am using MLflow to log the metrics but I want to change the default saving logs directory. So, instead of writing log files besides my main file, I want to store them to <code>\/path\/outputs\/lg <\/code>. I don't know how to change it. I use it without in the <code>Model<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nfrom time import time\n\nimport mlflow\nimport numpy as np\nimport torch\nimport tqdm\n\n# from segmentation_models_pytorch.utils import metrics\nfrom AICore.emergency_landing.metrics import IoU, F1\nfrom AICore.emergency_landing.utils import AverageMeter\nfrom AICore.emergency_landing.utils import TBLogger\n\n\nclass Model:\n    def __init__(self, model, num_classes=5, ignore_index=0, optimizer=None, scheduler=None, criterion=None,\n                 device=None, epochs=30, train_loader=None, val_loader=None, tb_logger: TBLogger = None,\n                 logger=None,\n                 best_model_path=None,\n                 model_check_point_path=None,\n                 load_from_best_model=None,\n                 load_from_model_checkpoint=None,\n                 early_stopping=None,\n                 debug=False):\n\n        self.debug = debug\n\n        self.early_stopping = {\n            'init': early_stopping,\n            'changed': 0\n        }\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.criterion = criterion\n        self.device = device\n        self.epochs = epochs\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.model = model.to(device)\n\n        self.tb_logger = tb_logger\n        self.logger = logger\n\n        self.best_loss = np.Inf\n\n        if not os.path.exists(best_model_path):\n            os.makedirs(best_model_path)\n        self.best_model_path = best_model_path\n\n        if not os.path.exists(model_check_point_path):\n            os.makedirs(model_check_point_path)\n        self.model_check_point_path = model_check_point_path\n\n        self.load_from_best_model = load_from_best_model\n        self.load_from_model_checkpoint = load_from_model_checkpoint\n\n        if self.load_from_best_model is not None:\n            self.load_model(path=self.load_from_best_model)\n        if self.load_from_model_checkpoint is not None:\n            self.load_model_checkpoint(path=self.load_from_model_checkpoint)\n\n        self.train_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.val_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.test_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n\n        self.train_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.val_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.test_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n\n    def metrics(self, is_train=True):\n        if is_train:\n            train_losses = AverageMeter('Training Loss', ':.4e')\n            train_iou = AverageMeter('Training iou', ':6.2f')\n            train_f_score = AverageMeter('Training F_score', ':6.2f')\n\n            return train_losses, train_iou, train_f_score\n        else:\n            val_losses = AverageMeter('Validation Loss', ':.4e')\n            val_iou = AverageMeter('Validation mean iou', ':6.2f')\n            val_f_score = AverageMeter('Validation F_score', ':6.2f')\n\n            return val_losses, val_iou, val_f_score\n\n    def fit(self):\n\n        self.logger.info(&quot;\\nStart training\\n\\n&quot;)\n        start_training_time = time()\n\n        with mlflow.start_run():\n            for e in range(self.epochs):\n                start_training_epoch_time = time()\n                self.model.train()\n                train_losses_avg, train_iou_avg, train_f_score_avg = self.metrics(is_train=True)\n                with tqdm.tqdm(self.train_loader, unit=&quot;batch&quot;) as tepoch:\n                    tepoch.set_description(f&quot;Epoch {e}&quot;)\n                    for image, target in tepoch:\n                        # Transfer Data to GPU if available\n                        image = image.to(self.device)\n                        target = target.to(self.device)\n                        # Clear the gradients\n                        self.optimizer.zero_grad()\n                        # Forward Pass\n                        # out = self.model(image)['out']\n                        # if unet == true =&gt; remove ['out']\n                        out = self.model(image)\n                        # Find the Loss\n                        loss = self.criterion(out, target)\n                        # Calculate Loss\n                        train_losses_avg.update(loss.item(), image.size(0))\n                        # Calculate gradients\n                        loss.backward()\n                        # Update Weights\n                        self.optimizer.step()\n\n                        iou = self.train_iou(out.cpu(), target.cpu()).item()\n                        train_iou_avg.update(iou)\n\n                        f1_score = self.train_f1(out.cpu(), target.cpu()).item()\n                        train_f_score_avg.update(f1_score)\n\n                        tepoch.set_postfix(loss=train_losses_avg.avg,\n                                           iou=train_iou_avg.avg,\n                                           f_score=train_f_score_avg.avg)\n                        if self.debug:\n                            break\n\n                self.tb_logger.log(log_type='criterion\/training', value=train_losses_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='iou\/training', value=train_iou_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='f_score\/training', value=train_f_score_avg.avg, epoch=e)\n\n                mlflow.log_metric('criterion\/training', train_losses_avg.avg, step=e)\n                mlflow.log_metric('iou\/training', train_iou_avg.avg, step=e)\n                mlflow.log_metric('f_score\/training', train_f_score_avg.avg, step=e)\n\n                end_training_epoch_time = time() - start_training_epoch_time\n                print('\\n')\n                self.logger.info(\n                    f'Training Results - [{end_training_epoch_time:.3f}s] Epoch: {e}:'\n                    f' f_score: {train_f_score_avg.avg:.3f},'\n                    f' IoU: {train_iou_avg.avg:.3f},'\n                    f' Loss: {train_losses_avg.avg:.3f}')\n\n                # validation step\n                val_loss = self.evaluation(e)\n                # apply scheduler\n                if self.scheduler:\n                    self.scheduler.step()\n                # early stopping\n                if self.early_stopping['init'] &gt;= self.early_stopping['changed']:\n                    self._early_stopping_model(val_loss=val_loss)\n                else:\n                    print(f'The model can not learn more, Early Stopping at epoch[{e}]')\n                    break\n\n                # save best model\n                if self.best_model_path is not None:\n                    self._best_model(val_loss=val_loss, path=self.best_model_path)\n\n                # model check points\n                if self.model_check_point_path is not None:\n                    self.save_model_check_points(path=self.model_check_point_path, epoch=e, net=self.model,\n                                                 optimizer=self.optimizer, loss=self.criterion,\n                                                 avg_loss=train_losses_avg.avg)\n\n                # log mlflow\n                if self.scheduler:\n                    mlflow.log_param(&quot;get_last_lr&quot;, self.scheduler.get_last_lr())\n                    mlflow.log_param(&quot;scheduler&quot;, self.scheduler.state_dict())\n\n                self.tb_logger.flush()\n                if self.debug:\n                    break\n\n            end_training_time = time() - start_training_time\n            print(f'Finished Training after {end_training_time:.3f}s')\n            self.tb_logger.close()\n\n    def evaluation(self, epoch):\n        print('Validating...')\n        start_validation_epoch_time = time()\n        self.model.eval()  # Optional when not using Model Specific layer\n        with torch.no_grad():\n            val_losses_avg, val_iou_avg, val_f_score_avg = self.metrics(is_train=False)\n            with tqdm.tqdm(self.val_loader, unit=&quot;batch&quot;) as tepoch:\n                for image, target in tepoch:\n                    # Transfer Data to GPU if available\n                    image = image.to(self.device)\n                    target = target.to(self.device)\n                    # out = self.model(image)['out']\n                    # if unet == true =&gt; remove ['out']\n                    out = self.model(image)\n                    # Find the Loss\n                    loss = self.criterion(out, target)\n                    # Calculate Loss\n                    val_losses_avg.update(loss.item(), image.size(0))\n\n                    iou = self.val_iou(out.cpu(), target.cpu()).item()\n                    val_iou_avg.update(iou)\n\n                    f1_score = self.val_f1(out.cpu(), target.cpu()).item()\n                    val_f_score_avg.update(f1_score)\n\n                    tepoch.set_postfix(loss=val_losses_avg.avg,\n                                       iou=val_iou_avg.avg,\n                                       f_score=val_f_score_avg.avg)\n                    if self.debug:\n                        break\n            print('\\n')\n            self.tb_logger.log(log_type='criterion\/validation', value=val_losses_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='iou\/validation', value=val_iou_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='f_score\/validation', value=val_f_score_avg.avg, epoch=epoch)\n\n            mlflow.log_metric('criterion\/validation', val_losses_avg.avg, step=epoch)\n            mlflow.log_metric('iou\/validation', val_iou_avg.avg, step=epoch)\n            mlflow.log_metric('f_score\/validation', val_f_score_avg.avg, step=epoch)\n\n            end_validation_epoch_time = time() - start_validation_epoch_time\n            self.logger.info(\n                f'validation Results - [{end_validation_epoch_time:.3f}s] Epoch: {epoch}:'\n                f' f_score: {val_f_score_avg.avg:.3f},'\n                f' IoU: {val_iou_avg.avg:.3f},'\n                f' Loss: {val_losses_avg.avg:.3f}')\n            print('\\n')\n            return val_losses_avg.avg\n\n    def _save_model(self, name, path, params):\n        torch.save(params, path)\n\n    def _early_stopping_model(self, val_loss):\n        if self.best_loss &lt; val_loss:\n            self.early_stopping['changed'] += 1\n        else:\n            self.early_stopping['changed'] = 0\n\n    def _best_model(self, val_loss, path):\n        if self.best_loss &gt; val_loss:\n            self.best_loss = val_loss\n            name = f'\/best_model_loss_{self.best_loss:.2f}'.replace('.', '_')\n            self._save_model(name, path=f'{path}\/{name}.pt', params={\n                'model_state_dict': self.model.state_dict(),\n            })\n\n            print(f'The best model is saved with criterion: {self.best_loss:.2f}')\n\n    def save_model_check_points(self, path, epoch, net, optimizer, loss, avg_loss):\n        name = f'\/model_epoch_{epoch}_loss_{avg_loss:.2f}'.replace('.', '_')\n        self._save_model(name, path=f'{path}\/{name}.pt', params={\n            'epoch': epoch,\n            'model_state_dict': net.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'criterion': loss,\n        })\n        print(f'model checkpoint is saved at model_epoch_{epoch}_loss_{avg_loss:.2f}')\n\n    def load_model_checkpoint(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        epoch = checkpoint['epoch']\n        self.criterion = checkpoint['criterion']\n\n        return epoch\n\n    def load_model(self, path):\n        best_model = torch.load(path)\n        self.model.load_state_dict(best_model['model_state_dict'])\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-12 14:25:19.83 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-12 22:16:19.243 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|deep-learning|pytorch|mlflow",
        "Question_view_count":436,
        "Owner_creation_date":"2014-09-10 07:11:45.327 UTC",
        "Owner_last_access_date":"2022-09-06 18:46:08.593 UTC",
        "Owner_reputation":477,
        "Owner_up_votes":133,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Answer_body":"<p>The solution is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(uri=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nexp = mlflow.get_experiment_by_name(name='Emegency_landing')\nif not exp:\n    experiment_id = mlflow.create_experiment(name='Emegency_landing',\n                                                 artifact_location=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nelse:\n    experiment_id = exp.experiment_id\n<\/code><\/pre>\n<p>And then you should pass the experiment Id to:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with mlflow.start_run(experiment_id=experiment_id):\n     pass \n<\/code><\/pre>\n<p>If you don't mention the <code>\/path\/mlruns<\/code>, when you run the command of <code>mlflow ui<\/code>, it will create another folder automatically named <code>mlruns<\/code>. so, pay attention to this point to have the same name as <code>mlruns<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-12 15:50:35.59 UTC",
        "Answer_score":0.0,
        "Owner_location":"Turin, Metropolitan City of Turin, Italy",
        "Answer_last_edit_date":"2021-11-12 22:19:00.677 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69944447",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61351024,
        "Question_title":"Kubernetes MLflow Service Pod Connection",
        "Question_body":"<p>I have deployed a build of mlflow to a pod in my kubernetes cluster. I'm able to port forward to the mlflow ui, and now I'm attempting to test it. To do this, I am running the following test on a jupyter notebook that is running on another pod in the same cluster.<\/p>\n<pre><code>import mlflow\n\nprint(&quot;Setting Tracking Server&quot;)\ntracking_uri = &quot;http:\/\/mlflow-tracking-server.default.svc.cluster.local:5000&quot;\n\nmlflow.set_tracking_uri(tracking_uri)\n\nprint(&quot;Logging Artifact&quot;)\nmlflow.log_artifact('\/home\/test\/mlflow-example-artifact.png')\n\nprint(&quot;DONE&quot;)\n<\/code><\/pre>\n<p>When I run this though, I get<\/p>\n<pre><code>ConnectionError: HTTPConnectionPool(host='mlflow-tracking-server.default.svc.cluster.local', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get? (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n<\/code><\/pre>\n<p>The way I have deployed the mlflow pod is shown below in the yaml and docker:<\/p>\n<p>Yaml:<\/p>\n<pre><code>---\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\n  name: mlflow-tracking-server\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: mlflow-tracking-server\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: mlflow-tracking-server\n    spec:\n      containers:\n      - name: mlflow-tracking-server\n        image: &lt;ECR_IMAGE&gt;\n        ports:\n        - containerPort: 5000\n        env:\n        - name: AWS_MLFLOW_BUCKET\n          value: &lt;S3_BUCKET&gt;\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: AWS_SECRET_ACCESS_KEY\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mlflow-tracking-server\n  namespace: default\n  labels:\n    app: mlflow-tracking-server\n  annotations:\n    service.beta.kubernetes.io\/aws-load-balancer-type: nlb\nspec:\n  externalTrafficPolicy: Local\n  type: LoadBalancer\n  selector:\n    app: mlflow-tracking-server\n  ports:\n    - name: http\n      port: 5000\n      targetPort: http\n<\/code><\/pre>\n<p>While the dockerfile calls a script that executes the mlflow server command: <code>mlflow server --default-artifact-root ${AWS_MLFLOW_BUCKET} --host 0.0.0.0 --port 5000<\/code>, I cannot connect to the service I have created using that mlflow pod.<\/p>\n<p>I have tried using the tracking uri <code>http:\/\/mlflow-tracking-server.default.svc.cluster.local:5000<\/code>, I've tried using the service EXTERNAL-IP:5000, but everything I tried cannot connect and log using the service. Is there anything that I have missed in deploying my mlflow server pod to my kubernetes cluster?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_creation_date":"2020-04-21 18:54:46.493 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-09-07 11:16:43.817 UTC",
        "Question_score":2,
        "Question_tags":"kubernetes|kubernetes-service|mlflow",
        "Question_view_count":855,
        "Owner_creation_date":"2014-11-26 14:40:35.813 UTC",
        "Owner_last_access_date":"2021-08-12 15:37:44.573 UTC",
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Answer_body":"<p>Your <strong>mlflow-tracking-server<\/strong> service should have <em>ClusterIP<\/em> type, not <em>LoadBalancer<\/em>. <\/p>\n\n<p>Both pods are inside the same Kubernetes cluster, therefore, there is no reason to use <em>LoadBalancer<\/em> Service type.<\/p>\n\n<blockquote>\n  <p>For some parts of your application (for example, frontends) you may want to expose a Service onto an external IP address, that\u2019s outside of your cluster.\n  Kubernetes ServiceTypes allow you to specify what kind of Service you want. The default is ClusterIP.<\/p>\n  \n  <p>Type values and their behaviors are:<\/p>\n  \n  <ul>\n  <li><p><strong>ClusterIP<\/strong>: Exposes the Service on a cluster-internal IP. Choosing this\n  value makes the Service only reachable from within the cluster. This\n  is the default ServiceType. <\/p><\/li>\n  <li><p><strong>NodePort<\/strong>: Exposes the Service on each Node\u2019s IP at a static port (the NodePort). A > ClusterIP Service, to which the NodePort Service routes, is automatically created. You\u2019ll > be able to contact the NodePort Service, from outside the cluster, by\n  requesting :. <\/p><\/li>\n  <li><strong>LoadBalancer<\/strong>: Exposes the Service\n  externally using a cloud provider\u2019s load balancer. NodePort and\n  ClusterIP Services, to which the external load balancer routes, are\n  automatically created. <\/li>\n  <li><strong>ExternalName<\/strong>: Maps the Service to the contents\n  of the externalName field (e.g. foo.bar.example.com), by returning a\n  CNAME record with its value. No proxying of any kind is set up.<\/li>\n  <\/ul>\n  \n  <p><a href=\"https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/#publishing-services-service-types\" rel=\"nofollow noreferrer\">kubernetes.io<\/a><\/p>\n<\/blockquote>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2020-04-21 19:52:17.657 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-04-21 20:02:33.943 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61351024",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63973530,
        "Question_title":"Convert an instance of xgboost.Booster into a model that implements the scikit-learn API",
        "Question_body":"<p>I am trying to use <code>mlflow<\/code> to save a model and then load it later to make predictions.<\/p>\n<p>I'm using a <code>xgboost.XGBRegressor<\/code> model and its sklearn functions <code>.predict()<\/code> and <code>.predict_proba()<\/code> to make predictions but it turns out that <code>mlflow<\/code> doesn't support models that implements the sklearn API, so when loading the model later from mlflow, mlflow returns an instance of <code>xgboost.Booster<\/code>, and it doesn't implements the <code>.predict()<\/code> or <code>.predict_proba()<\/code> functions.<\/p>\n<p>Is there a way to convert a <code>xgboost.Booster<\/code> back into a <code>xgboost.sklearn.XGBRegressor<\/code> object that implements the sklearn API functions?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-19 21:27:38.547 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"scikit-learn|save|xgboost|mlflow|xgbclassifier",
        "Question_view_count":1317,
        "Owner_creation_date":"2020-06-15 23:34:46.427 UTC",
        "Owner_last_access_date":"2022-09-23 19:41:30.79 UTC",
        "Owner_reputation":35,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>Have you tried wrapping up your model in custom class, logging and loading it using <code>mlflow.pyfunc.PythonModel<\/code>?\nI put up a simple example and upon loading back the model it correctly shows <code>&lt;class 'xgboost.sklearn.XGBRegressor'&gt;<\/code> as a type.<\/p>\n<p>Example:<\/p>\n<pre><code>import xgboost as xgb\nxg_reg = xgb.XGBRegressor(...)\n\nclass CustomModel(mlflow.pyfunc.PythonModel):\n    def __init__(self, xgbRegressor):\n        self.xgbRegressor = xgbRegressor\n\n    def predict(self, context, input_data):\n        print(type(self.xgbRegressor))\n        \n        return self.xgbRegressor.predict(input_data)\n\n# Log model to local directory\nwith mlflow.start_run():\n     custom_model = CustomModel(xg_reg)\n     mlflow.pyfunc.log_model(&quot;custome_model&quot;, python_model=custom_model)\n\n\n# Load model back\nfrom mlflow.pyfunc import load_model\nmodel = load_model(&quot;\/mlruns\/0\/..\/artifacts\/custome_model&quot;)\nmodel.predict(X_test)\n<\/code><\/pre>\n<p>Output:<\/p>\n<pre><code>&lt;class 'xgboost.sklearn.XGBRegressor'&gt;\n[ 9.107417 ]\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-09-20 13:06:22.583 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63973530",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56701139,
        "Question_title":"Model-logging for \"hybrid models\" (e.g. SKlearn Pipeline including KerasWrapper) possible?",
        "Question_body":"<p>I have wrapped my keras-tf-model into a Sklearn Pipeline, which also does some pre- and postprocessing. I want to serialize this model and capture its dependencies via MLflow.<\/p>\n\n<p>I have tried <code>mlflow.keras.save_model()<\/code>, which seems not appropriate. (it's not a \"pure\" keras model and as no <code>save()<\/code> attribute)<\/p>\n\n<p>I also tried <code>mlflow.sklearn.save_model()<\/code> and <code>mlflow.pyfunc.save_model()<\/code>, which both lead my to the same error: <\/p>\n\n<p><code>NotImplementedError: numpy() is only available when eager execution is enabled.<\/code><\/p>\n\n<p>(This error seems to stem from a clash between python and tensorflow, maybe?)<\/p>\n\n<p>I wonder, should it already\/ generally be possible to serialize these kind of \"hybrid\" models with mlflow?<\/p>\n\n<h3>Please finde a minimal example below<\/h3>\n\n<pre><code># In[1]:\n\n\nfrom mlflow.sklearn import save_model\nimport mlflow.sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\n\nfrom tensorflow.keras.models import Sequential\n\nimport numpy as np\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n\n# ### Save Keras Model\n\n# In[2]:\n\n\niris_data = load_iris() \n\nx = iris_data.data\ny_ = iris_data.target.reshape(-1, 1)\n\n# One Hot encode the class labels\nencoder = OneHotEncoder(sparse=False)\ny = encoder.fit_transform(y_)\n\n# Split the data for training and testing\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n\n# Build the model\nmodel = Sequential()\n\nmodel.add(Dense(10, input_shape=(4,), activation='relu', name='fc1'))\nmodel.add(Dense(10, activation='relu', name='fc2'))\nmodel.add(Dense(3, activation='softmax', name='output'))\n\noptimizer = Adam(lr=0.001)\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_x, train_y, verbose=2, batch_size=5, epochs=20)\n\n\n# In[3]:\n\n\nimport mlflow.keras\n\nmlflow.keras.save_model(model, \"modelstorage\/model40\")\n\n\n# ### Save Minimal SKlearn-Pipeline (with Keras)\n\n# In[4]:\n\n\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\n# In[5]:\n\n\ndef define_model():\n    \"\"\"\n    Create fully connected network with given parameters.\n    \"\"\"\n    keras_model = Sequential()\n\n    keras_model.add(Dense(10, input_shape=(4,), activation='relu', name='fc1'))\n    keras_model.add(Dense(10, activation='relu', name='fc2'))\n    keras_model.add(Dense(3, activation='softmax', name='output'))\n\n    optimizer = Adam(lr=0.001)\n    keras_model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# In[6]:\n\n\n# target_encoder = TargetEncoder() \nscaler = StandardScaler()\nkeras_model = KerasClassifier(define_model, batch_size=5, epochs=20)\n\n\n# In[7]:\n\n\npipeline = Pipeline([\n#     ('encoding', target_encoder),\n    ('scaling', scaler),\n    ('modeling', keras_model)\n])\n\n\n# In[8]:\n\n\npipeline.fit(train_x, train_y)\n\n\n# In[9]:\n\n\nmlflow.keras.save_model(pipeline, \"modelstorage\/model42\")   #not working\n\n\n# In[10]:\n\n\nimport mlflow.sklearn\n\nmlflow.sklearn.save_model(pipeline, \"modelstorage\/model43\")\n\nOutput from modelstorage\/model43\/conda.yaml:\n\n======================\nchannels:\n- defaults\ndependencies:\n- python=3.6.7\n- scikit-learn=0.21.2\n- pip:\n  - mlflow\n  - cloudpickle==1.2.1\nname: mlflow-env\n======================\n\nDoesn't seem to capture Tensorflow.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-21 10:00:22.15 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-06-21 13:14:49.067 UTC",
        "Question_score":2,
        "Question_tags":"python|keras|scikit-learn|mlflow",
        "Question_view_count":1470,
        "Owner_creation_date":"2012-05-13 19:20:30.51 UTC",
        "Owner_last_access_date":"2022-09-13 14:34:11.823 UTC",
        "Owner_reputation":948,
        "Owner_up_votes":592,
        "Owner_down_votes":1,
        "Owner_views":132,
        "Answer_body":"<p>You can add extra dependencies when you save your model, for example if you have a keras step in your pipeline you can add keras &amp; tensorflow:<\/p>\n\n<pre><code>  conda_env = mlflow.sklearn.get_default_conda_env()\n  conda_env[\"dependencies\"] = ['keras==2.2.4', 'tensorflow==1.14.0'] + conda_env[\"dependencies\"]\n  mlflow.sklearn.log_model(pipeline, \"modelstorage\/model43\", conda_env = conda_env)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-11-01 17:18:24.763 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56701139",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62841756,
        "Question_title":"Can't use HDFS path to set_tracking_uri in mlflow within python",
        "Question_body":"<p>I'm new to mlflow so I may misunderstand how things are supposed to work on a fundamental level.<\/p>\n<p>However when I try to do the following:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TRACKING_URI = os.path.join(\n    &quot;hdfs:\/\/namenode\/user\/userid\/&quot;,\n    &quot;mlflow&quot;,\n    &quot;anomaly_detection&quot;,\n)\n        \nmlflow.set_tracking_uri(TRACKING_URI)\nclient = mlflow.tracking.MlflowClient(TRACKING_URI)\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>UnsupportedModelRegistryStoreURIException:  Model registry functionality is unavailable; got unsupported URI 'hdfs:\/\/nameservice1\/user\/rxb427\/mlflow\/anomaly_detection' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\n<\/code><\/pre>\n<p>Within the above link provided by the error it states that hdfs is supported. Bug or am I missing something?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-10 20:21:30.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-10 21:00:46.223 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":621,
        "Owner_creation_date":"2014-06-23 16:02:53.873 UTC",
        "Owner_last_access_date":"2022-09-23 14:18:04.92 UTC",
        "Owner_reputation":458,
        "Owner_up_votes":76,
        "Owner_down_votes":5,
        "Owner_views":119,
        "Answer_body":"<p>Ok. So it looks like while the ARTIFACTS STORE does support hdfs, you have to use either file or a sql like for the BACKEND STORE.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-13 17:24:30.47 UTC",
        "Answer_score":0.0,
        "Owner_location":"Atlanta, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62841756",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":51335594,
        "Question_title":"Error with \"mlflow ui\" when trying to run it on MS Windows",
        "Question_body":"<p>When I run <code>mlflow ui<\/code> the following error occurred:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\Scripts\\gunicorn.exe\\__main__.py\", line 5, in &lt;module&gt;\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\app\\wsgiapp.py\", line 9, in &lt;module&gt;\n    from gunicorn.app.base import Application\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\app\\base.py\", line 12, in &lt;module&gt;\n    from gunicorn import util\n  File \"c:\\anaconda3\\lib\\site-packages\\gunicorn\\util.py\", line 9, in &lt;module&gt;\n    import fcntl\nModuleNotFoundError: No module named 'fcntl'\nTraceback (most recent call last):\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\Scripts\\mlflow.exe\\__main__.py\", line 9, in &lt;module&gt;\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 722, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 697, in main\n    rv = self.invoke(ctx)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 895, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\anaconda3\\lib\\site-packages\\click\\core.py\", line 535, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\cli.py\", line 131, in ui\n    mlflow.server._run_server(file_store, file_store, host, port, 1)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\server\\__init__.py\", line 48, in _run_server\n    env=env_map, stream_output=True)\n  File \"c:\\anaconda3\\lib\\site-packages\\mlflow\\utils\\process.py\", line 38, in exec_cmd\n    raise ShellCommandException(\"Non-zero exitcode: %s\" % (exit_code))\nmlflow.utils.process.ShellCommandException: Non-zero exitcode: 1\n<\/code><\/pre>\n\n<p>I used anaconda + python 3.6.5 and I installed git and set path with <code>C:\\Program Files\\Git\\bin\\git.exe<\/code> and <code>C:\\Program Files\\Git\\cmd<\/code>.<\/p>\n\n<p>I installed <code>mlflow<\/code> whit <code>pip install mlflow<\/code> and its version is 0.2.1.<\/p>\n\n<p>I set a variable with name <code>GIT_PYTHON_GIT_EXECUTABLE<\/code> and value <code>C:\\Program Files\\Git\\bin\\git.exe<\/code> in Environment Variables. <\/p>\n\n<p>How can I solve this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2018-07-14 05:34:06.273 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-07-17 14:18:37.033 UTC",
        "Question_score":1,
        "Question_tags":"python|windows|fcntl|mlflow",
        "Question_view_count":4688,
        "Owner_creation_date":"2011-06-20 06:54:08.513 UTC",
        "Owner_last_access_date":"2022-09-24 14:46:49.627 UTC",
        "Owner_reputation":1177,
        "Owner_up_votes":24,
        "Owner_down_votes":0,
        "Owner_views":144,
        "Answer_body":"<p><a href=\"https:\/\/github.com\/databricks\/mlflow\" rel=\"nofollow noreferrer\">mlflow documentation<\/a> already says that <\/p>\n\n<blockquote>\n  <p>Note 2: We <strong>do not currently support running MLflow on Windows<\/strong>.\n  Despite this, we would appreciate any contributions to make MLflow\n  work better on Windows.<\/p>\n<\/blockquote>\n\n<p>You're hitting <code>fcntl<\/code> problem: it's not available on MS Windows platform because it's a \"wrapper\" around the <a href=\"http:\/\/man7.org\/linux\/man-pages\/man2\/fcntl.2.html\" rel=\"nofollow noreferrer\">fcntl function<\/a> that's available on POSIX-compatible systems. (See <a href=\"https:\/\/stackoverflow.com\/a\/1422436\/236007\">https:\/\/stackoverflow.com\/a\/1422436\/236007<\/a> for more details.)<\/p>\n\n<p>Solving this requires modifying the source code of mlflow accordingly. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-07-17 14:17:19.907 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51335594",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73127303,
        "Question_title":"Get Experiment that Created Model in MLflow",
        "Question_body":"<p>I want to get the name of the experiment that contains the run that created a registered MLflow model. How can I do this using MLflow, if I just have the name of the model and the version?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-26 17:10:29.667 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":44,
        "Owner_creation_date":"2018-03-24 01:53:05.82 UTC",
        "Owner_last_access_date":"2022-09-24 16:46:35.903 UTC",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Answer_body":"<p>As @Andre has said, I had to write my own function to achieve this,<\/p>\n<pre><code>def get_model_experiment(model_name, model_version):\n    # get run_id of the model version\n    run_id = mlflow_client.get_model_version(model_name, model_version).run_id\n\n    # get the experiment_id from the run_id\n    experiment_id = mlflow_client.get_run(run_id).info.experiment_id\n\n    # get the experiment name from the experiment_id\n    return mlflow_client.get_experiment(experiment_id).name\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-29 05:46:47.99 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73127303",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70169519,
        "Question_title":"How can I save more metadata on an MLFlow model",
        "Question_body":"<p>I am trying to save a model to MLFlow, but as I have a custom prediction pipeline to retrieve data, I need to save extra metadata into the model.<\/p>\n<p>I tried using my custom signature class, which It does the job correctly and saves the model with the extra metadata in the MLModel file (YAML format). But when want to load the model from the MLFlow registry, the signature is not easy accesible.<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, signature = signature)\n<\/code><\/pre>\n<p>I've also tried to save an extra dictionary at the log_model function, but it saves it in the conda.yaml file:<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, {&quot;metadata1&quot;:&quot;value1&quot;, &quot;metadata2&quot;:&quot;value2&quot;})\n<\/code><\/pre>\n<p>Should I make my own flavour? Or my own Model inheritance? I've seen <a href=\"https:\/\/github1s.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/pyfunc\/__init__.py\" rel=\"nofollow noreferrer\">here<\/a> that the PyFuncModel recieves some metadata class and an implementation to solve this, but I don't know where should I pass my own implementations to PyFuncModel on an experiment script. Here's a minimal example:<\/p>\n<pre><code>import mlflow\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nmetadata_dic = {&quot;metadata1&quot;: &quot;value1&quot;, \n                &quot;metadata2&quot;: &quot;value2&quot;}\n\nX = np.array([[-2, -1, 0, 1, 2, 1],[-2, -1, 0, 1, 2, 1]]).T\ny = np.array([0, 0, 1, 1, 1, 0])\n\nX = pd.DataFrame(X, columns=[&quot;X1&quot;, &quot;X2&quot;])\ny = pd.DataFrame(y, columns=[&quot;y&quot;])\n\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-30 12:40:45.39 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|scikit-learn|mlflow|mlops",
        "Question_view_count":323,
        "Owner_creation_date":"2019-02-15 12:18:22.177 UTC",
        "Owner_last_access_date":"2022-09-22 08:26:53.537 UTC",
        "Owner_reputation":621,
        "Owner_up_votes":87,
        "Owner_down_votes":26,
        "Owner_views":103,
        "Answer_body":"<p>Finally, I made a class that contains every metadata and saved it as an model argument:<\/p>\n<pre><code>model = LogisticRegression()\nmodel.fit(X, y)\nmodel.metadata = ModelMetadata(**metadata_dic)\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>\n<p>Here I lost the customizable <code>predict<\/code> process, but after reading the <code>MLFlow<\/code> documentation is not very clear how to proceed.<\/p>\n<p>If anyone finds a good approach It would be very appreciated.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-12-01 12:31:28.373 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70169519",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65316586,
        "Question_title":"get the run id for an mlflow experiment with the name?",
        "Question_body":"<p>I currently created an experiment in mlflow and created multiple runs in the experiment.<\/p>\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport mlflow\n\nexperiment_name=&quot;experiment-1&quot;\nmlflow.set_experiment(experiment_name)\n\nno_of_trees=[100,200,300]\ndepths=[2,3,4]\nfor trees in no_of_trees:\n    for depth in depths:\n        with mlflow.start_run() as run:\n            model=RandomForestRegressor(n_estimators=trees, criterion='mse',max_depth=depth)\n            model.fit(x_train, y_train)\n            predictions=model.predict(x_cv)\n            mlflow.log_metric('rmse',mean_squared_error(y_cv, predictions))\n<\/code><\/pre>\n<p>after creating the runs, I wanted to get the best run_id for this experiment. for now, I can get the best run by looking at the UI of mlflow but how can we do right the program?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-16 02:45:27.487 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":6,
        "Question_tags":"python|mlflow",
        "Question_view_count":6374,
        "Owner_creation_date":"2016-11-15 06:12:07.737 UTC",
        "Owner_last_access_date":"2022-08-15 17:25:10.4 UTC",
        "Owner_reputation":2470,
        "Owner_up_votes":265,
        "Owner_down_votes":22,
        "Owner_views":251,
        "Answer_body":"<p>we can get the experiment id from the experiment name and we can use python API to get the best runs.<\/p>\n<pre><code>experiment_name = &quot;experiment-1&quot;\ncurrent_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\nexperiment_id=current_experiment['experiment_id']\n<\/code><\/pre>\n<p>By using the experiment id, we can get all the runs and we can sort them based on metrics like below. In the below code, rmse is my metric name (so it may be different for you based on metric name)<\/p>\n<pre><code>df = mlflow.search_runs([experiment_id], order_by=[&quot;metrics.rmse DESC&quot;])\nbest_run_id = df.loc[0,'run_id']\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-12-16 02:45:27.487 UTC",
        "Answer_score":15.0,
        "Owner_location":"R G U K T , basar, Andhra Pradesh, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65316586",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67786052,
        "Question_title":"Log Pickle files as a part of Mlflow run",
        "Question_body":"<p>I am running an MLflow experiment as a part of it I would like to log a few artifacts as a python pickle.<\/p>\n<p>Ex: Trying out different categorical encoders, so wanted to log the encoder objects as a pickle file.<\/p>\n<p>Is there a way to achieve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-01 09:15:22.663 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|databricks|azure-databricks|mlflow",
        "Question_view_count":1843,
        "Owner_creation_date":"2014-09-22 04:46:57.027 UTC",
        "Owner_last_access_date":"2022-09-03 08:12:58.187 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":41,
        "Owner_down_votes":3,
        "Owner_views":123,
        "Answer_body":"<p>There are two functions for there:<\/p>\n<ol>\n<li><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"nofollow noreferrer\">log_artifact<\/a> - to log a local file or directory as an artifact<\/li>\n<li><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifacts\" rel=\"nofollow noreferrer\">log_artifacts<\/a> - to log a contents of a local directory<\/li>\n<\/ol>\n<p>so it would be as simple as:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with mlflow.start_run():\n    mlflow.log_artifact(&quot;encoder.pickle&quot;)\n<\/code><\/pre>\n<p>And you will need to use the <a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">custom MLflow model<\/a> to use that pickled file, something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow.pyfunc\n\nclass my_model(mlflow.pyfunc.PythonModel):\n    def __init__(self, encoders):\n        self.encoders = encoders\n\n    def predict(self, context, model_input):\n        _X = ...# do encoding using self.encoders.\n        return str(self.ctx.predict([_X])[0])\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-01 10:16:03.553 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67786052",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61481147,
        "Question_title":"MLFlow Registry high availability",
        "Question_body":"<p>I am running the mlflow registry using <code>mlflow server<\/code> (<a href=\"https:\/\/mlflow.org\/docs\/latest\/model-registry.html\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/model-registry.html<\/a>). The server runs fine. If the server crashes for any reason it restart automatically. But for the time of restart the server is not available.<\/p>\n\n<p>Is it possible to run multiple isntances in parallel behind a load balancer? Is this safe or could it be possible that there are any inconsistencies?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-28 13:18:31.073 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow|mlmodel",
        "Question_view_count":501,
        "Owner_creation_date":"2013-09-07 14:14:09.26 UTC",
        "Owner_last_access_date":"2022-07-27 10:56:50.33 UTC",
        "Owner_reputation":470,
        "Owner_up_votes":128,
        "Owner_down_votes":7,
        "Owner_views":45,
        "Answer_body":"<p>Yes, it's possible to have multiple instances of MLflow Tracker Service running behind a load balancer.<\/p>\n\n<p>Because the Tracking server is stateless, you could have multiple instances log to a replicated primary DB as a store. A second hot standby can take over if the primary fails.<\/p>\n\n<p>As for the documentation in how to set up replicated instances of your backend store will vary on which one you elect to use, we cannot definitely document all different scenarios and their configurations.<\/p>\n\n<p>I would check the respective documentation of your backend DB and load balancer for how to federate requests to multiple instances of an MLflow tracking server, how to failover to a hot standby or replicated DB, or how to configure a hot-standby replicated DB instance.<\/p>\n\n<p>The short of it: MLflow tracking server is stateless.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-05-02 01:27:08.087 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-05-02 04:42:51.917 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61481147",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":51064366,
        "Question_title":"Can't run MLflow web-based user interface",
        "Question_body":"<p>I've installed <a href=\"https:\/\/mlflow.org\/\" rel=\"nofollow noreferrer\">MLflow<\/a> on Ubuntu Server 18.04 LTS, in a virtual environment (Python 3), using its <a href=\"https:\/\/mlflow.org\/docs\/latest\/quickstart.html\" rel=\"nofollow noreferrer\">Quickstart documentation<\/a>:<\/p>\n\n<pre><code>$ python3 -m venv mlflow\n$ source \/home\/emre\/mlflow\/bin\/activate\n$ pip install mlflow\n<\/code><\/pre>\n\n<p>that gave the following output during install:<\/p>\n\n<pre><code>Collecting mlflow\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e8\/b3\/cf358e182be34a62fcd6843e5df793f278bd9d24f78f565509cb927c6a22\/mlflow-0.1.0.tar.gz (4.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 323kB\/s\nCollecting Flask (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/e7\/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b\/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 9.4MB\/s\nCollecting awscli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ba\/32\/d6d254f6ccc2ed21f02d81f38709ff06feca9cbdb2e68ea90635fa483a73\/awscli-1.15.46-py2.py3-none-any.whl (1.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3MB 1.0MB\/s\nCollecting boto3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/24\/e0\/a98898b94d8093bbd8fd4576fb2e89620adac1e24a2bfc28d11c4ce29a5b\/boto3-1.7.46-py2.py3-none-any.whl (128kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.8MB\/s\nCollecting click&gt;=6.7 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/34\/c1\/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77\/click-6.7-py2.py3-none-any.whl (71kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 9.3MB\/s\nCollecting databricks-cli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/58\/78\/4bda6f29a091ab7b0ad29efdba2491e5d0b56bd09d608857e6f0b799be48\/databricks-cli-0.7.2.tar.gz\nCollecting gitpython (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ac\/c9\/96d7c86c623cb065976e58c0f4898170507724d6b4be872891d763d686f4\/GitPython-2.1.10-py2.py3-none-any.whl (449kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 2.9MB\/s\nCollecting numpy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/68\/1e\/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2\/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2MB 110kB\/s\nCollecting pandas (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/eb\/6ab533ea8e35e7dd159af6922ac1123d4565d89f3926ad9a6aa46530978f\/pandas-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11.8MB 116kB\/s\nCollecting protobuf (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/fc\/f0\/db040681187496d10ac50ad167a8fd5f953d115b16a7085e19193a6abfd2\/protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7.1MB 177kB\/s\nCollecting pygal (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/5f\/b7\/201c9254ac0d2b8ffa3bb2d528d23a4130876d9ba90bc28e99633f323f17\/pygal-2.4.0-py2.py3-none-any.whl (127kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 9.7MB\/s\nCollecting python-dateutil (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/cf\/f5\/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825\/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 215kB 6.0MB\/s\nCollecting pyyaml (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/10\/7d\/6efe0bd69580fecd40adf47ebaf8d807238308ccb851f0549881fa7605aa\/PyYAML-4.1.tar.gz (153kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 7.8MB\/s\nCollecting querystring_parser (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/64\/3086a9a991ff3aca7b769f5b0b51ff8445a06337ae2c58f215bcee48f527\/querystring_parser-1.2.3.tar.gz\nCollecting requests&gt;=2.17.3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/65\/47\/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda\/requests-2.19.1-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 8.2MB\/s\nCollecting scikit-learn (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/3d\/2d\/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9\/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.4MB 108kB\/s\nCollecting scipy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a8\/0b\/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730\/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 31.2MB 42kB\/s\nCollecting six&gt;=1.10.0 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/67\/4b\/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a\/six-1.11.0-py2.py3-none-any.whl\nCollecting uuid (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ce\/63\/f42f5aa951ebf2c8dac81f77a8edcc1c218640a2a35a03b9ff2d4aa64c3d\/uuid-1.30.tar.gz\nCollecting zipstream (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/1a\/a4\/58f0709cef999db1539960aa2ae77100dc800ebb8abb7afc97a1398dfb2f\/zipstream-1.1.4.tar.gz\nCollecting itsdangerous&gt;=0.24 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/b4\/a60bcdba945c00f6d608d8975131ab3f25b22f2bcfe1dab221165194b2d4\/itsdangerous-0.24.tar.gz (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.4MB\/s\nCollecting Werkzeug&gt;=0.14 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/20\/c4\/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243\/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 4.0MB\/s\nCollecting Jinja2&gt;=2.10 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/ff\/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731\/Jinja2-2.10-py2.py3-none-any.whl (126kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.2MB\/s\nCollecting rsa&lt;=3.5.0,&gt;=3.1.2 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e1\/ae\/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e\/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.5MB\/s\nCollecting botocore==1.10.46 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b4\/04\/ddaad5574f70a539d106e8d53b4685e3de4387de7a16884a95459f8c7691\/botocore-1.10.46-py2.py3-none-any.whl (4.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4MB 314kB\/s\nCollecting s3transfer&lt;0.2.0,&gt;=0.1.12 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/d7\/14\/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d\/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.6MB\/s\nCollecting colorama&lt;=0.3.9,&gt;=0.2.5 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/db\/c8\/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf\/colorama-0.3.9-py2.py3-none-any.whl\nCollecting docutils&gt;=0.10 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/36\/fa\/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d\/docutils-0.14-py3-none-any.whl (543kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 552kB 2.5MB\/s\nCollecting jmespath&lt;1.0.0,&gt;=0.7.1 (from boto3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b7\/31\/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365\/jmespath-0.9.3-py2.py3-none-any.whl\nCollecting configparser&gt;=0.3.5 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/69\/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c\/configparser-3.5.0.tar.gz\nCollecting tabulate&gt;=0.7.7 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/12\/c2\/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc\/tabulate-0.8.2.tar.gz (45kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 7.9MB\/s\nCollecting gitdb2&gt;=2.0.0 (from gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e0\/95\/c772c13b7c5740ec1a0924250e6defbf5dfdaee76a50d1c47f9c51f1cabb\/gitdb2-2.0.3-py2.py3-none-any.whl (63kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 11.2MB\/s\nCollecting pytz&gt;=2011k (from pandas-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/83\/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2\/pytz-2018.4-py2.py3-none-any.whl (510kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 512kB 421kB\/s\nRequirement already satisfied: setuptools in .\/mlflow\/lib\/python3.6\/site-packages (from protobuf-&gt;mlflow)\nCollecting chardet&lt;3.1.0,&gt;=3.0.2 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bc\/a9\/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.7MB\/s\nCollecting idna&lt;2.8,&gt;=2.5 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4b\/2a\/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165\/idna-2.7-py2.py3-none-any.whl (58kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.3MB\/s\nCollecting urllib3&lt;1.24,&gt;=1.21.1 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bd\/c9\/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb\/urllib3-1.23-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.3MB\/s\nCollecting certifi&gt;=2017.4.17 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/e6\/92ad559b7192d846975fc916b65f667c7b8c3a32bea7372340bfe9a15fa5\/certifi-2018.4.16-py2.py3-none-any.whl (150kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 8.0MB\/s\nCollecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.10-&gt;Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4d\/de\/32d741db316d8fdb7680822dd37001ef7a448255de9699ab4bfcbdf4172b\/MarkupSafe-1.0.tar.gz\nCollecting pyasn1&gt;=0.1.3 (from rsa&lt;=3.5.0,&gt;=3.1.2-&gt;awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a0\/70\/2c27740f08e477499ce19eefe05dbcae6f19fdc49e9e82ce4768be0643b9\/pyasn1-0.4.3-py2.py3-none-any.whl (72kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 10.9MB\/s\nCollecting smmap2&gt;=2.0.0 (from gitdb2&gt;=2.0.0-&gt;gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e3\/59\/4e22f692e65f5f9271252a8e63f04ce4ad561d4e06192478ee48dfac9611\/smmap2-2.0.3-py2.py3-none-any.whl\nBuilding wheels for collected packages: mlflow, databricks-cli, pyyaml, querystring-parser, uuid, zipstream, itsdangerous, configparser, tabulate, MarkupSafe\n  Running setup.py bdist_wheel for mlflow ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/mlflow\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp10fdrz2ypip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for mlflow\n  Running setup.py clean for mlflow\n  Running setup.py bdist_wheel for databricks-cli ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/databricks-cli\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpy_2acqi3pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for databricks-cli\n  Running setup.py clean for databricks-cli\n  Running setup.py bdist_wheel for pyyaml ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/pyyaml\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp4bs2fwrtpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for pyyaml\n  Running setup.py clean for pyyaml\n  Running setup.py bdist_wheel for querystring-parser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/querystring-parser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp_cnm9w_tpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for querystring-parser\n  Running setup.py clean for querystring-parser\n  Running setup.py bdist_wheel for uuid ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/uuid\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpenr2igaxpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for uuid\n  Running setup.py clean for uuid\n  Running setup.py bdist_wheel for zipstream ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/zipstream\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpnzsjh5e2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for zipstream\n  Running setup.py clean for zipstream\n  Running setup.py bdist_wheel for itsdangerous ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/itsdangerous\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp7imi3zv2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for itsdangerous\n  Running setup.py clean for itsdangerous\n  Running setup.py bdist_wheel for configparser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/configparser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpyk9qtmi1pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for configparser\n  Running setup.py clean for configparser\n  Running setup.py bdist_wheel for tabulate ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/tabulate\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpjim2qr00pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for tabulate\n  Running setup.py clean for tabulate\n  Running setup.py bdist_wheel for MarkupSafe ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/MarkupSafe\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpsdpdd8ulpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for MarkupSafe\n  Running setup.py clean for MarkupSafe\nFailed to build mlflow databricks-cli pyyaml querystring-parser uuid zipstream itsdangerous configparser tabulate MarkupSafe\nInstalling collected packages: click, itsdangerous, Werkzeug, MarkupSafe, Jinja2, Flask, pyasn1, rsa, jmespath, six, python-dateutil, docutils, botocore, s3transfer, colorama, pyyaml, awscli, boto3, configparser, chardet, idna, urllib3, certifi, requests, tabulate, databricks-cli, smmap2, gitdb2, gitpython, numpy, pytz, pandas, protobuf, pygal, querystring-parser, scikit-learn, scipy, uuid, zipstream, mlflow\n  Running setup.py install for itsdangerous ... done\n  Running setup.py install for MarkupSafe ... done\n  Running setup.py install for pyyaml ... done\n  Running setup.py install for configparser ... done\n  Running setup.py install for tabulate ... done\n  Running setup.py install for databricks-cli ... done\n  Running setup.py install for querystring-parser ... done\n  Running setup.py install for uuid ... done\n  Running setup.py install for zipstream ... done\n  Running setup.py install for mlflow ... done\nSuccessfully installed Flask-1.0.2 Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 awscli-1.15.46 boto3-1.7.46 botocore-1.10.46 certifi-2018.4.16 chardet-3.0.4 click-6.7 colorama-0.3.9 configparser-3.5.0 databricks-cli-0.7.2 docutils-0.14 gitdb2-2.0.3 gitpython-2.1.10 idna-2.7 itsdangerous-0.24 jmespath-0.9.3 mlflow-0.1.0 numpy-1.14.5 pandas-0.23.1 protobuf-3.6.0 pyasn1-0.4.3 pygal-2.4.0 python-dateutil-2.7.3 pytz-2018.4 pyyaml-4.1 querystring-parser-1.2.3 requests-2.19.1 rsa-3.4.2 s3transfer-0.1.13 scikit-learn-0.19.1 scipy-1.1.0 six-1.11.0 smmap2-2.0.3 tabulate-0.8.2 urllib3-1.23 uuid-1.30 zipstream-1.1.4\n<\/code><\/pre>\n\n<p>After that I checked the following didn't give any errors:<\/p>\n\n<pre><code>import os\nfrom mlflow import log_metric, log_param, log_artifact\n<\/code><\/pre>\n\n<p>But when I try to run the web-based user interface, I get the following errors:<\/p>\n\n<pre><code>$ mlflow ui\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 574, in _build_master\n    ws.require(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 892, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/bin\/mlflow\", line 6, in &lt;module&gt;\n    from pkg_resources import load_entry_point\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3088, in &lt;module&gt;\n    @_call_aside\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3072, in _call_aside\n    f(*args, **kwargs)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3101, in _initialize_master_working_set\n    working_set = WorkingSet._build_master()\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 576, in _build_master\n    return cls._build_from_requirements(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 589, in _build_from_requirements\n    dists = ws.resolve(reqs, Environment())\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n<\/code><\/pre>\n\n<p>Any ideas how I can fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-06-27 13:42:34.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-06-27 15:08:51.487 UTC",
        "Question_score":0,
        "Question_tags":"python|python-3.x|pip|mlflow",
        "Question_view_count":791,
        "Owner_creation_date":"2009-12-21 12:58:40.737 UTC",
        "Owner_last_access_date":"2022-09-23 10:23:53.65 UTC",
        "Owner_reputation":7876,
        "Owner_up_votes":4051,
        "Owner_down_votes":47,
        "Owner_views":924,
        "Answer_body":"<p>Apparently I had to install the <code>wheel<\/code> module inside my virtual environment. I deleted the virtual environment, re-created it, and then installed the <code>wheel<\/code> module:<\/p>\n\n<pre><code>pip install wheel\n<\/code><\/pre>\n\n<p>after that <code>pip install mlflow<\/code>, as well as <code>mlflow ui<\/code> worked successfully.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-06-27 14:19:18.067 UTC",
        "Answer_score":1.0,
        "Owner_location":"Antwerp, Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51064366",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67062145,
        "Question_title":"Continue stopped run in MLflow",
        "Question_body":"<p>We run our experiment on AWS spot instances. Sometimes the experiments are stopped, and we would prefer to continue logging to the same run. How can you set the run-id of the active run?<\/p>\n<p>Something like this pseudocode (not working):<\/p>\n<pre><code>if new:\n    mlflow.start_run(experiment_id=1, run_name=x)\nelse:\n    mlflow.set_run(run_id)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-12 16:29:16.103 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":131,
        "Owner_creation_date":"2017-01-19 15:07:44.573 UTC",
        "Owner_last_access_date":"2022-09-22 14:55:11.743 UTC",
        "Owner_reputation":3937,
        "Owner_up_votes":672,
        "Owner_down_votes":27,
        "Owner_views":387,
        "Answer_body":"<p>You can pass the run_id directly to <code>start_run<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.start_run(experiment_id=1,\n                 run_name=x,\n                 run_id=&lt;run_id_of_interrupted_run&gt; # pass None to start a new run\n                 ) \n<\/code><\/pre>\n<p>Of course, you have to store the run_id for this. You can get it with <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.entities.html#mlflow.entities.RunInfo.run_id\" rel=\"nofollow noreferrer\"><code>run.info.run_id<\/code><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-17 13:21:05.5 UTC",
        "Answer_score":1.0,
        "Owner_location":"Amsterdam, Nederland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67062145",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65939058,
        "Question_title":"MLflow stores artifacts on GCP buckets but is not able to read them",
        "Question_body":"<p>I've found an almost identical question <a href=\"https:\/\/stackoverflow.com\/questions\/63727235\/mlflow-artifacts-storing-artifactsgoogle-cloud-storage-but-not-displaying-them?newreg=923da08a362547daab64c7d7e2275423\">here<\/a> but don't have enough reputation to add comments so will ask again hoping that someone has found a solution in the mean time.<\/p>\n<p>I am using MLflow (1.13.1) to track model performance and GCP Storage to store model artifacts.\nMLflow is running on a GCP VM instance and my python application uses a service account with Storage Object Creator and Storage Object Viewer roles (and then I've also added storage.buckets.get permissions) to store artifacts in GCP buckets and read from them.\nEverything is working as expected with parameters and metrics correctly displaying in MLflow UI and model artifacts correctly stored in buckets. The problem is that the model artifacts do not show up in MLflow UI because of this error:<\/p>\n<pre><code>Unable to list artifacts stored under gs:\/******\/artifacts for the current run. \nPlease contact your tracking server administrator to notify them of this error, \nwhich can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.\n<\/code><\/pre>\n<p>The quoted artifacts location exists and contains the correct model artifacts, and MLflow should be able to read the artifacts because of the Storage Object Viewer role and the storage.buckets.get permissions.<\/p>\n<p>Any suggestion on what could be wrong? Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-28 14:24:55.217 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"google-cloud-platform|mlflow",
        "Question_view_count":428,
        "Owner_creation_date":"2021-01-28 13:53:16.69 UTC",
        "Owner_last_access_date":"2021-11-25 23:39:43.27 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>I've found the problem just after posting the question.\nI had forgotten to install the <code>google-cloud-storage<\/code> library on the GCP VM. Everything works as expected now.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-28 14:48:14.603 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65939058",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72694707,
        "Question_title":"Multiple artifact paths when logging a model using mlflow and sklearn",
        "Question_body":"<p>I'm using mlflow to log parameters and artifacts of a Logistic Regression, but when I try to log the model so I can see all the files in the Mlflow UI, I see two folders: one named 'model' and the other one named 'logger' (the one I set).<\/p>\n<pre><code>model = LogisticRegression()\n\nmlflow.set_tracking_uri('file:\/\/\/artifacts')\nmlflow.set_experiment('test')\nmlflow.autolog()\n\nwith mlflow.start_run(run_name=run_name) as run:\n   model.train(X_train, y_train)\n   mlflow.sklearn.log_model(model, 'logreg')\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BtIHo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BtIHo.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Not sure if I'm missing something or if there's a configuration for that.<\/p>\n<p>I hope someone out there can help me!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-21 02:24:59.153 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|machine-learning|scikit-learn|mlflow|scikit-learn-pipeline",
        "Question_view_count":122,
        "Owner_creation_date":"2018-12-10 18:48:11.223 UTC",
        "Owner_last_access_date":"2022-08-01 19:20:26.413 UTC",
        "Owner_reputation":131,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":42,
        "Answer_body":"<p>You have set <code>autolog<\/code> and you are also logging the model explicitly. Remove one and then try.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-22 21:24:47.183 UTC",
        "Answer_score":2.0,
        "Owner_location":"Zacatecas, Mexico",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72694707",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71708147,
        "Question_title":"MLFlow tracking ui not showing experiments on local machine (laptop)",
        "Question_body":"<p>I am a beginner in mlflow and was trying to set it up locally using Anaconda 3.\nI have created a new environment in anaconda and install mlflow and sklearn in it. Now I am using jupyter notebook to run my sample code for mlflow.<\/p>\n<p>'''<\/p>\n<pre><code>import os\nimport warnings\nimport sys\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom urllib.parse import urlparse\nimport mlflow\nimport mlflow.sklearn\n\nimport logging\n\nlogging.basicConfig(level=logging.WARN)\nlogger = logging.getLogger(__name__)\n\nwarnings.filterwarnings(&quot;ignore&quot;)\nnp.random.seed(40)\n\n\nmlflow.set_tracking_uri(&quot;file:\/\/\/Users\/Swapnil\/Documents\/LocalPython\/MLFLowDemo\/mlrun&quot;)\n\nmlflow.get_tracking_uri()\n\nmlflow.get_experiment\n\n#experiment_id = mlflow.create_experiment(&quot;Mlflow_demo&quot;)\nexperiment_id = mlflow.create_experiment(&quot;Demo3&quot;)\nexperiment = mlflow.get_experiment(experiment_id)\nprint(&quot;Name: {}&quot;.format(experiment.name))\nprint(&quot;Experiment_id: {}&quot;.format(experiment.experiment_id))\nprint(&quot;Artifact Location: {}&quot;.format(experiment.artifact_location))\nprint(&quot;Tags: {}&quot;.format(experiment.tags))\nprint(&quot;Lifecycle_stage: {}&quot;.format(experiment.lifecycle_stage))\n\nmlflow.set_experiment(&quot;Demo3&quot;)\n\ndef eval_metrics(actual, pred):\n    rmse = np.sqrt(mean_squared_error(actual, pred))\n    mae = mean_absolute_error(actual, pred)\n    r2 = r2_score(actual, pred)\n    return rmse, mae, r2\n\n# Read the wine-quality csv file from the URL\ncsv_url =\\\n    'http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/wine-quality\/winequality-red.csv'\ntry:\n    data = pd.read_csv(csv_url, sep=';')\nexcept Exception as e:\n    logger.exception(\n        &quot;Unable to download training &amp; test CSV, check your internet connection. Error: %s&quot;, e)\n\ndata.head(2)\n\n\ndef train_model(data, alpha, l1_ratio):\n    \n    # Split the data into training and test sets. (0.75, 0.25) split.\n    train, test = train_test_split(data)\n\n    # The predicted column is &quot;quality&quot; which is a scalar from [3, 9]\n    train_x = train.drop([&quot;quality&quot;], axis=1)\n    test_x = test.drop([&quot;quality&quot;], axis=1)\n    train_y = train[[&quot;quality&quot;]]\n    test_y = test[[&quot;quality&quot;]]\n\n    # Set default values if no alpha is provided\n    alpha = alpha\n    l1_ratio = l1_ratio\n\n\n    # Execute ElasticNet\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n    lr.fit(train_x, train_y)\n\n    # Evaluate Metrics\n    predicted_qualities = lr.predict(test_x)\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n    # Print out metrics\n    print(&quot;Elasticnet model (alpha=%f, l1_ratio=%f):&quot; % (alpha, l1_ratio))\n    print(&quot;  RMSE: %s&quot; % rmse)\n    print(&quot;  MAE: %s&quot; % mae)\n    print(&quot;  R2: %s&quot; % r2)\n    \n    # Log parameter, metrics, and model to MLflow\n    with mlflow.start_run(experiment_id = experiment_id):\n        mlflow.log_param(&quot;alpha&quot;, alpha)\n        mlflow.log_param(&quot;l1_ratio&quot;, l1_ratio)\n        mlflow.log_metric(&quot;rmse&quot;, rmse)\n        mlflow.log_metric(&quot;r2&quot;, r2)\n        mlflow.log_metric(&quot;mae&quot;, mae)\n        mlflow.sklearn.log_model(lr, &quot;model&quot;)\n        \n\ntrain_model(data, 0.5, 0.5)\n\ntrain_model(data, 0.5, 0.3)\n\ntrain_model(data, 0.4, 0.3)\n<\/code><\/pre>\n<p>'''<\/p>\n<p>using above code, I am successfully able to create 3 different experiment as I can see the folders created in my local directory as shown below:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jKqgX.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p>Now, I am trying to run the mlflow ui using the jupyter terminal in my chrome browser and I am able to open the mlflow ui but cannot see and experiments as shown below:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6KaQK.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p>Could you help me in finding where I am going wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-04-01 14:01:52.31 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|windows|mlflow|mlops",
        "Question_view_count":936,
        "Owner_creation_date":"2022-04-01 13:44:18.173 UTC",
        "Owner_last_access_date":"2022-09-23 11:29:25.81 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":"<p>Where do you run <code>mlflow ui<\/code> command?<\/p>\n<p>I think if you pass tracking ui path in the arguments, it would work:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>mlflow ui --backend-store-uri file:\/\/\/Users\/Swapnil\/Documents\/LocalPython\/MLFLowDemo\/mlrun\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-24 00:46:51.59 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-08-08 21:04:12.86 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71708147",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61377643,
        "Question_title":"Tracking SageMaker Estimator with MLFlow",
        "Question_body":"<p>I'm working on a version tracking system for a ML project and want to use MLflow to do so. My project uses AWS Sagemaker's DeepAR for forecast.<\/p>\n\n<p>What I want to do is very simple. I'm trying do log the Sagemaker DeepAR model (Sagemaker Estimator) with MLFlow. As it doesn't have a \"log_model\" funcion in it's \"mlflow.sagemaker\" module, I tried to use the \"mlflow.pyfunc\" module to do the log. Unfortunatelly it didn't worked. How can I log the Sagemaker model and get the cloudpickle and yaml files generated by MLFlow?<\/p>\n\n<p>My code for now:<\/p>\n\n<p><code>mlflow.pyfunc.log_model(model)<\/code><\/p>\n\n<p>Where model is a sagemaker.estimator.Estimator object and the error I get from the code is<\/p>\n\n<p><code>mlflow.exceptions.MlflowException: Either `loader_module` or `python_model` must be specified. A `loader_module` should be a python module. A `python_model` should be a subclass of PythonModel<\/code><\/p>\n\n<p>I know AWS Sagemaker logs my models, but it is really important to my project to do the log with MLFlow too.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-23 01:06:27.047 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-04-23 01:30:39.877 UTC",
        "Question_score":0,
        "Question_tags":"python|amazon-web-services|amazon-sagemaker|mlflow",
        "Question_view_count":437,
        "Owner_creation_date":"2019-01-20 22:33:06.667 UTC",
        "Owner_last_access_date":"2022-09-18 13:59:17.783 UTC",
        "Owner_reputation":111,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>You cannot use pyfunc to store Any type object.<\/p>\n\n<p>You should either specify one of loader_module as shown in the example below or you must write the wrapper that implements PythonModel interface and provides logic to deserialize your model from  previously-stored artifacts as described here \n <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#example-saving-an-xgboost-model-in-mlflow-format\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#example-saving-an-xgboost-model-in-mlflow-format<\/a><\/p>\n\n<p>example with loader:<\/p>\n\n<pre><code>    model_uri = 'model.pkl'\n\n    with open(model_uri, 'wb') as f:\n        pickle.dump(model, f)\n\n    mlflow.log_artifact(model_uri, 'model')\n\n    mlflow.pyfunc.log_model(\n        'model', loader_module='mlflow.sklearn', data_path='model.pkl', code_path=['src'], conda_env='environment.yml'\n    )\n<\/code><\/pre>\n\n<p>I think PythonModel is the better way for you because of mlflow doesn't have a built-in loader for SageMaker DeepAR model.<\/p>\n\n<p>Nonetheless, You must have the knowledge how to restore SageMaker model from artifacts, because I am not sure that is possible at all, cuz of some built-in SageMaker algorithms are blackboxes.<\/p>\n\n<p>You can also may be interested in container that allow you to run any MLFlow projects inside Sagemaker: <a href=\"https:\/\/github.com\/odahu\/sagemaker-mlflow-container\" rel=\"nofollow noreferrer\">https:\/\/github.com\/odahu\/sagemaker-mlflow-container<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-04-24 09:24:49.803 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61377643",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70538098,
        "Question_title":"Databricks MLFlow AutoML XGBoost can't predict_proba()",
        "Question_body":"<p>I used AutoML in Databricks Notebooks for a binary classification problem and the winning model flavor was XGBoost (big surprise).<\/p>\n<p>The outputted model is of this variety:<\/p>\n<pre><code>mlflow.pyfunc.loaded_model:\n      artifact_path: model\n      flavor: mlflow.sklearn\n      run_id: 123456789\n<\/code><\/pre>\n<p>Any idea why when I use <code>model.predict_proba(X)<\/code>, I get this response?<\/p>\n<p><code>AttributeError: 'PyFuncModel' object has no attribute 'predict_proba'<\/code><\/p>\n<p>I know it is possible to get the probabilities because ROC\/AUC is a metric used for tuning the model. Any help would be amazing!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 01:02:03.883 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pandas|scikit-learn|databricks|xgboost|mlflow",
        "Question_view_count":451,
        "Owner_creation_date":"2019-07-11 07:02:37.217 UTC",
        "Owner_last_access_date":"2022-09-21 21:43:57.89 UTC",
        "Owner_reputation":77,
        "Owner_up_votes":35,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>I had the same issue with catboost model.\nThe way I solved it was by saving the artifacts in a local dir<\/p>\n<pre><code>import os\nfrom mlflow.tracking import MlflowClient\nclient = MlflowClient()\nlocal_dir = &quot;\/dbfs\/FileStore\/user\/models&quot;\nlocal_path = client.download_artifacts('run_id', &quot;model&quot;, local_dir)```\n\n```model_path = '\/dbfs\/FileStore\/user\/models\/model\/model.cb'\nmodel = CatBoostClassifier()\nmodel = model.load_model(model_path)\nmodel.predict_proba(test_set)```\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-08 12:56:27.86 UTC",
        "Answer_score":2.0,
        "Owner_location":"San Francisco, CA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70538098",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71679081,
        "Question_title":"How can I connect mlflow server via nginx ssl authentication?",
        "Question_body":"<p>System information\nOS Platform and Distribution: Windows 10\nMLflow installed: using pip\nMLflow version: version 1.24.0\n**Python version: Python 3.9.7 **<\/p>\n<p>Describe the problem\nI have created a docker-compose system with a backend\/artifact storages, mlflow server and nginx to add an authentication layer.<\/p>\n<pre><code>...\nmlflow:\n        restart: always\n        build: .\n        environment:\n            - AWS_ACCESS_KEY_ID=${MINIO_USR}\n            - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n        expose:\n            - '5000'\n        networks:\n            - frontend\n            - backend\n        depends_on:\n            - storage                       \n        image: 'mlflow:Dockerfile'\n        container_name: mlflow_server_nginx\n\n    nginx:\n        restart: always\n        build: .\/nginx\n        container_name: mlflow_nginx\n        ports:\n            - 5043:443\n        links:\n            - mlflow:mlflow\n        volumes:\n            - 'path\/to\/nginx\/auth:\/etc\/nginx\/conf.d'\n            - 'path\/to\/nginx\/nginx.conf:\/etc\/nginx\/nginx.conf:ro'\n        networks:\n            - frontend\n        depends_on:\n            - mlflow\n<\/code><\/pre>\n<p>I have created an user\/password via htpasswd and a custom SSL CA (.pem\/.key) using openssl and my-mlflow.com server-name.<\/p>\n<p>When the docker-compose system is built i can access to mlflow UI via my browser. But when i try to create a new experiment using python trying diferent approaches, i get next errors:\nExecuted code 1:<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1108)')))\n<\/code><\/pre>\n<p>After read some notes in the documentation and realated issues I tryed next<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\nos.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4012)')))\n<\/code><\/pre>\n<p>Finally<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\nos.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(&quot;hostname 'localhost' doesn't match '*.my-mlflow.com'&quot;)))\n<\/code><\/pre>\n<p>Can you give me some hints about how to solve it?<\/p>\n<p>Thank you very much!\nFernando....<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-30 14:25:39.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python-3.x|docker|nginx|docker-compose|mlflow",
        "Question_view_count":625,
        "Owner_creation_date":"2020-02-04 18:43:25.373 UTC",
        "Owner_last_access_date":"2022-09-21 20:36:53.347 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>You can set:<\/p>\n<pre><code>os.environ['MLFLOW_TRACKING_INSECURE_TLS'] = 'true'\n<\/code><\/pre>\n<p>And then try to get your cert-chain straight from there for production use.<\/p>\n<p>Also see Documentation: <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-05-11 13:38:19.263 UTC",
        "Answer_score":0.0,
        "Owner_location":"Seville, Spain",
        "Answer_last_edit_date":"2022-05-13 13:35:43.407 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71679081",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59773167,
        "Question_title":"When will experiment be deleted with lifecycle_stage is set as deleted",
        "Question_body":"<p>I can see experiment 2 is in deleted, but when it will be deleted actually?<\/p>\n\n<pre><code>2   test    hdfs:\/\/\/1234\/mlflow deleted\n<\/code><\/pre>\n\n<p>If the experiment is not deleted automatically, how can I delete it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-16 15:41:36.547 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":412,
        "Owner_creation_date":"2014-08-18 14:07:01.673 UTC",
        "Owner_last_access_date":"2022-09-15 04:40:38.707 UTC",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Answer_body":"<p>I am assuming you use sql store?<\/p>\n\n<p>Currently there is no way to tell mlflow to hard-delete experiments. We are working with open source contributors to add a cli command that would perform garbage-collection of deleted experiments. This should be added soon in one of the upcoming mlflow releases. In the meantime, you can connect to your sql store and delete the experiments manually.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-01-22 23:47:09.917 UTC",
        "Answer_score":1.0,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59773167",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67499339,
        "Question_title":"Create mlflow experiment: Run with UUID is already active",
        "Question_body":"<p>I'm trying to create a new experiment on mlflow but I have this problem:<\/p>\n<pre><code>Exception: Run with UUID l142ae5a7cf04a40902ae9ed7326093c is already active.\n\n<\/code><\/pre>\n<p>This is my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\nimport mlflow.sklearn\nimport sys\n\nmlflow.set_experiment(&quot;New experiment 2&quot;)\n\nmlflow.set_tracking_uri('http:\/\/mlflow:5000')\nst= mlflow.start_run(run_name='Test2')\nid = st.info.run_id\nmlflow.log_metric(&quot;score&quot;, score)\nmlflow.sklearn.log_model(model, &quot;wineModel&quot;)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-12 07:49:03.553 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":675,
        "Owner_creation_date":"2021-05-11 15:53:08.617 UTC",
        "Owner_last_access_date":"2021-05-13 16:04:47.89 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>You have to run mlflow.end_run() to finish the first experiment. Then you can create another<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-12 07:51:54.963 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67499339",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58234777,
        "Question_title":"MLflow remote execution on databricks from windows creates an invalid dbfs path",
        "Question_body":"<p>I'm researching the use of MLflow as part of our data science initiatives and I wish to set up a minimum working example of remote execution on databricks from windows.<\/p>\n\n<p>However, when I perform the remote execution a path is created locally on windows in the MLflow package which is sent to databricks. This path specifies the upload location of the '.tar.gz' file corresponding to the Github repo containing the MLflow Project. In cmd this has a combination of '\\' and '\/', but on databricks there are no separators at all in this path, which raises the 'rsync: No such file or directory (2)' error.<\/p>\n\n<p>To be more general, I reproduced the error using an MLflow standard example and following this <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/projects.html\" rel=\"nofollow noreferrer\">guide<\/a> from databricks. The MLflow example is the <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine\" rel=\"nofollow noreferrer\">sklearn_elasticnet_wine<\/a>, but I had to add a default value to a parameter so I forked it and the MLproject which can be executed remotely can be found at (<a href=\"https:\/\/github.com\/aestene\/mlflow\/tree\/master\/examples\/sklearn_elasticnet_wine\" rel=\"nofollow noreferrer\">forked repo<\/a>).<\/p>\n\n<p>The Project can be executed remotely by the following command (assuming a databricks instance has been set up)<\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/aestene\/mlflow#examples\/sklearn_elasticnet_wine -b databricks -c db-clusterconfig.json --experiment-id &lt;insert-id-here&gt;\n<\/code><\/pre>\n\n<p>where \"db-clusterconfig.json\" correspond to the cluster to set up in databricks and is in this example set to<\/p>\n\n<pre><code>{\n    \"autoscale\": {\n        \"min_workers\": 1,\n        \"max_workers\": 2\n    },\n    \"spark_version\": \"5.5.x-scala2.11\",\n    \"node_type_id\": \"Standard_DS3_v2\",\n    \"driver_node_type_id\": \"Standard_DS3_v2\",\n    \"ssh_public_keys\": [],\n    \"custom_tags\": {},\n    \"spark_env_vars\": {\n        \"PYSPARK_PYTHON\": \"\/databricks\/python3\/bin\/python3\"\n    }\n}\n<\/code><\/pre>\n\n<p>When running the project remotely, this is the output in cmd:<\/p>\n\n<pre><code>2019\/10\/04 10:09:50 INFO mlflow.projects: === Fetching project from https:\/\/github.com\/aestene\/mlflow#examples\/sklearn_elasticnet_wine into C:\\Users\\ARNTS\\AppData\\Local\\Temp\\tmp2qzdyq9_ ===\n2019\/10\/04 10:10:04 INFO mlflow.projects.databricks: === Uploading project to DBFS path \/dbfs\\mlflow-experiments\\3947403843428882\\projects-code\\aa5fbb4769e27e1be5a983751eb1428fe998c3e65d0e66eb9b4c77355076f524.tar.gz ===\n2019\/10\/04 10:10:05 INFO mlflow.projects.databricks: === Finished uploading project to \/dbfs\\mlflow-experiments\\3947403843428882\\projects-code\\aa5fbb4769e27e1be5a983751eb1428fe998c3e65d0e66eb9b4c77355076f524.tar.gz ===\n2019\/10\/04 10:10:05 INFO mlflow.projects.databricks: === Running entry point main of project https:\/\/github.com\/aestene\/mlflow#examples\/sklearn_elasticnet_wine on Databricks ===\n2019\/10\/04 10:10:06 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 8. Getting run status page URL... ===\n2019\/10\/04 10:10:18 INFO mlflow.projects.databricks: === Check the run's status at https:\/\/&lt;region&gt;.azuredatabricks.net\/?o=&lt;databricks-id&gt;#job\/8\/run\/1 ===\n<\/code><\/pre>\n\n<p>Where the DBFS path has a leading '\/' before the remaining are '\\'. <\/p>\n\n<p>The command spins up a cluster in databricks and is ready to execute the job, but ends up with the following error message on the databricks side:<\/p>\n\n<pre><code>rsync: link_stat \"\/dbfsmlflow-experiments3947403843428882projects-codeaa5fbb4769e27e1be5a983751eb1428fe998c3e65d0e66eb9b4c77355076f524.tar.gz\" failed: No such file or directory (2)\nrsync error: some files\/attrs were not transferred (see previous errors) (code 23) at main.c(1183) [sender=3.1.1]\n<\/code><\/pre>\n\n<p>Where we can see the same path but without the '\\' inserted. I narrowed down the creation of this path to this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/databricks.py\" rel=\"nofollow noreferrer\">file<\/a> in the MLflow Github repo, where the following code creates the path (line 133):<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>dbfs_path = os.path.join(DBFS_EXPERIMENT_DIR_BASE, str(experiment_id),\n                                     \"projects-code\", \"%s.tar.gz\" % tarfile_hash)\ndbfs_fuse_uri = os.path.join(\"\/dbfs\", dbfs_path)\n<\/code><\/pre>\n\n<p>My current hypothesis is that <code>os.path.join()<\/code> in the first line joins the string together in a \"windows fashion\" such that they have backslashes. Then the following call to <code>os.path.join()<\/code> adds a '\/'. The databricks file system is then unable to handle this path and something causes the 'tar.gz' file to not be properly uploaded or to be accessed at the wrong path. <\/p>\n\n<p>It should also be mentioned that the project runs fine locally.<\/p>\n\n<p>I'm running the following versions:<\/p>\n\n<p>Windows 10<\/p>\n\n<p>Python 3.6.8<\/p>\n\n<p>MLflow 1.3.0 (also replicated the fault with 1.2.0)<\/p>\n\n<p>Any feedback or suggestions are greatly appreciated!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-04 10:39:52.42 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"databricks|mlflow",
        "Question_view_count":350,
        "Owner_creation_date":"2019-10-04 07:11:50.493 UTC",
        "Owner_last_access_date":"2022-09-23 07:12:04.557 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Thanks for the catch, you're right that using <code>os.path.join<\/code> when working with DBFS paths is incorrect, resulting in a malformed path that breaks project execution. I've filed to <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1926\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/1926<\/a> track this, if you're interested in making a bugfix PR (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst\" rel=\"nofollow noreferrer\">see the MLflow contributor guide for info on how to do this<\/a>) to replace <code>os.path.join<\/code> here with <code>os.posixpath.join<\/code> I'd be happy to review :)<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-10-11 00:00:25.483 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58234777",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64513552,
        "Question_title":"How to have multiple MLFlow runs in parallel?",
        "Question_body":"<p>I'm not very familiar with parallelization in Python and I'm getting an error when trying to train a model on multiple training folds in parallel. Here's a simplified version of my code:<\/p>\n<pre><code>def train_test_model(fold):\n    # here I train the model etc...\n    \n    # now I want to save the parameters and metrics\n    with mlflow.start_run():\n        mlflow.log_param(&quot;run_name&quot;, run_name)\n        mlflow.log_param(&quot;modeltype&quot;, modeltype)\n        # and so on...\n\nif __name__==&quot;__main__&quot;:\n    pool = ThreadPool(processes = num_trials)\n    # run folds in parallel\n    pool.map(lambda fold:train_test_model(fold), folds)\n<\/code><\/pre>\n<p>I'm getting the following error:<\/p>\n<pre><code>Exception: Run with UUID 23e9bb6d22674a518e48af9c51252860 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.start_run\" rel=\"nofollow noreferrer\">documentation<\/a> says that <code>mlflow.start_run()<\/code> starts a new run and makes it active which is the root of my problem. Every thread starts a MLFlow run for its corresponding fold and makes it active while I need the runs to run in parallel i.e. all be active(?) and save parameters\/metrics of the corresponding fold. How can I solve that issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-24 12:58:40.573 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|pyspark|parallel-processing|mlflow",
        "Question_view_count":2275,
        "Owner_creation_date":"2018-01-14 12:10:19.517 UTC",
        "Owner_last_access_date":"2022-09-24 19:20:31.11 UTC",
        "Owner_reputation":177,
        "Owner_up_votes":126,
        "Owner_down_votes":1,
        "Owner_views":7,
        "Answer_body":"<p>I found a solution, maybe it will be useful for someone else. You can see details with code examples here: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/3592\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/3592<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-28 09:26:02.673 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64513552",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62711259,
        "Question_title":"Customize metric visualization in MLFlow UI when using mlflow.tensorflow.autolog()",
        "Question_body":"<p>I'm trying to integrate MLFlow to my project. Because I'm using <code>tf.keras.fit_generator()<\/code> for my training so I take advantage of <code>mlflow.tensorflow.autolog()<\/code>(<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a> here) to enable automatic logging of metrics and parameters:<\/p>\n<pre><code>    model = Unet()\n    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n\n    metrics = [IOUScore(threshold=0.5), FScore(threshold=0.5)]\n    model.compile(optimizer, customized_loss, metrics)\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(&quot;model.h5&quot;, save_weights_only=True, save_best_only=True, mode='min'),\n        tf.keras.callbacks.TensorBoard(log_dir='.\/logs', profile_batch=0, update_freq='batch'),\n    ]\n\n\n    train_dataset = Dataset(src_dir=SOURCE_DIR)\n\n    train_data_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n\n   \n    with mlflow.start_run():\n        mlflow.tensorflow.autolog()\n        mlflow.log_param(&quot;batch_size&quot;, BATCH_SIZE)\n\n        model.fit_generator(\n            train_data_loader,\n            steps_per_epoch=len(train_data_loader),\n            epochs=EPOCHS,\n            callbacks=callbacks   \n            )\n<\/code><\/pre>\n<p>I expected something like this (just a demonstration taken from the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#visualizing-metrics\" rel=\"nofollow noreferrer\">docs<\/a>):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" alt=\"Visualization on the docs\" \/><\/a><\/p>\n<p>However, after the training finished, this is what I got:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" alt=\"f1_score visualization\" \/><\/a><\/p>\n<p>How can I configure so that the metric plot will update and display its value at each epoch instead of just showing the latest value?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-03 08:15:46.63 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-06 04:10:26.393 UTC",
        "Question_score":2,
        "Question_tags":"tf.keras|mlflow",
        "Question_view_count":1035,
        "Owner_creation_date":"2016-07-08 02:05:15.393 UTC",
        "Owner_last_access_date":"2022-09-25 05:18:34.54 UTC",
        "Owner_reputation":173,
        "Owner_up_votes":97,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":"<p>After searching around, I found <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2390\" rel=\"nofollow noreferrer\">this issue<\/a> related to my problem above. Actually, all my metrics just logged once each training (instead of each epoch as my intuitive thought). The reason is I didn't specify the <code>every_n_iter<\/code> parameter in <code>mlflow.tensorflow.autolog()<\/code>, which indicates how many 'iterations' must pass before MLflow logs metric executed (see the <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a>). So, changing my code to:<\/p>\n<p><code>mlflow.tensorflow.autolog(every_n_iter=1)<\/code><\/p>\n<p>fixed the problem.<\/p>\n<p>P\/s: Remember that in TF 2.x, an 'iteration' is an epoch (in TF 1.x it's a batch).<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-07-06 04:08:45.28 UTC",
        "Answer_score":1.0,
        "Owner_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62711259",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70051420,
        "Question_title":"MLFlow projects; bash: python: command not found",
        "Question_body":"<p>I'm running MLflow Project for a model using following command from my ubuntu 20.04 terminal<\/p>\n<pre><code>mlflow run . --no-conda -P alpha=0.5\n<\/code><\/pre>\n<p>My system doesn't have conda or python (It does however have python3). So, I added alias for python using terminal<\/p>\n<pre><code>alias python='python3'\n<\/code><\/pre>\n<p>After which I could open python in terminal using <code>python<\/code>. However, I still got the same error<\/p>\n<pre><code>2021\/11\/21 08:07:34 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpp4h595ql for downloading remote URIs passed to arguments of type 'path' ===\n2021\/11\/21 08:07:34 INFO mlflow.projects.backend.local: === Running command 'python tracking.py 0.5 0.1' in run with ID 'e50ca47b3f8848a083906be6220c26fc' === \nbash: python: command not found\n2021\/11\/21 08:07:34 ERROR mlflow.cli: === Run (ID 'e50ca47b3f8848a083906be6220c26fc') failed ===\n<\/code><\/pre>\n<p>How to get rid of this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-21 02:44:17.297 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|bash|ubuntu|terminal|mlflow",
        "Question_view_count":281,
        "Owner_creation_date":"2020-09-25 03:31:49.207 UTC",
        "Owner_last_access_date":"2022-09-24 07:17:02.153 UTC",
        "Owner_reputation":1074,
        "Owner_up_votes":239,
        "Owner_down_votes":21,
        "Owner_views":143,
        "Answer_body":"<p>Change <code>python<\/code> to <code>python3<\/code> in the <code>MLproject<\/code> file to the resolve error.<\/p>\n<pre><code>command: &quot;python3 tracking.py {alpha} {l1_ratio}&quot;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-21 03:02:34.447 UTC",
        "Answer_score":0.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":"2021-11-21 13:56:33.977 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70051420",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65937786,
        "Question_title":"Data and model drift monitoring with MLflow",
        "Question_body":"<p>The MLFlow Tracking is great for monitoring experiments, but I wonder if there is a solution on MLFlow or another open-source platform that can be integrated to monitor data and model drift.<\/p>\n<p>There is a <a href=\"https:\/\/databricks.com\/blog\/2019\/09\/18\/productionizing-machine-learning-from-deployment-to-drift-detection.html\" rel=\"noreferrer\">post<\/a> from Databricks showing how to achieve that with Delta Lake, however, as you can deploy and serve models with MLFlow, it looks to me that it would be easy to monitor the predictions made by the model, the same way we monitor the experiments run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-28 13:11:35.203 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"mlflow",
        "Question_view_count":2539,
        "Owner_creation_date":"2018-05-04 00:29:57.417 UTC",
        "Owner_last_access_date":"2022-09-23 19:26:48.707 UTC",
        "Owner_reputation":130,
        "Owner_up_votes":39,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>My team has recently added integration between MLflow and our open source data monitoring library called <a href=\"https:\/\/github.com\/whylabs\/whylogs-python\" rel=\"nofollow noreferrer\">whylogs<\/a>. This lets you log statistical profiles of the data passing through the model and\/or the output of the model. You can then collect these profiles from MLflow run artifacts and analyze them for drift.<\/p>\n<p>We have a <a href=\"https:\/\/github.com\/whylabs\/whylogs-examples\/blob\/mainline\/python\/MLFlow%20Integration%20Example.ipynb\" rel=\"nofollow noreferrer\">notebook<\/a> that walks you through the integration process and a <a href=\"https:\/\/whylabs.ai\/blog\/posts\/on-model-lifecycle-and-monitoring\" rel=\"nofollow noreferrer\">blog post<\/a> to go along with it. Lmk if you have any questions or additional feature requests!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-02-11 20:16:43.467 UTC",
        "Answer_score":4.0,
        "Owner_location":"Philadelphia, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65937786",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62664183,
        "Question_title":"MLflow: find model version with best metric using python code",
        "Question_body":"<p>I am trying to use API workflow (python code) to find a model version that has the best metric (for instance, \u201caccuracy\u201d) among several model versions. I understand we can use web UI to do so, but I would love to write python code to achieve this. Could someone help me?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-30 18:44:19.82 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|mlflow",
        "Question_view_count":445,
        "Owner_creation_date":"2014-12-26 18:42:31.727 UTC",
        "Owner_last_access_date":"2022-02-07 21:07:16.15 UTC",
        "Owner_reputation":125,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<pre><code>import mlflow \nclient = mlflow.tracking.MlflowClient()\nruns = client.search_runs(&quot;my_experiment_id&quot;, &quot;&quot;, order_by=[&quot;metrics.rmse DESC&quot;], max_results=1)\nbest_run = runs[0]\n<\/code><\/pre>\n<p><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.search_runs\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.search_runs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-07-23 05:03:25.94 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62664183",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61980244,
        "Question_title":"How to fix Artifacts not showing in MLflow UI",
        "Question_body":"<p>I'd used MLflow and logged parameters using the function below (from pydataberlin).<\/p>\n<pre><code>def train(alpha=0.5, l1_ratio=0.5):\n    # train a model with given parameters\n    warnings.filterwarnings(&quot;ignore&quot;)\n    np.random.seed(40)\n\n    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n    data_path = &quot;data\/wine-quality.csv&quot;\n    train_x, train_y, test_x, test_y = load_data(data_path)\n\n    # Useful for multiple runs (only doing one run in this sample notebook)    \n    with mlflow.start_run():\n        # Execute ElasticNet\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n\n        # Evaluate Metrics\n        predicted_qualities = lr.predict(test_x)\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n        # Print out metrics\n        print(&quot;Elasticnet model (alpha=%f, l1_ratio=%f):&quot; % (alpha, l1_ratio))\n        print(&quot;  RMSE: %s&quot; % rmse)\n        print(&quot;  MAE: %s&quot; % mae)\n        print(&quot;  R2: %s&quot; % r2)\n\n        # Log parameter, metrics, and model to MLflow\n        mlflow.log_param(key=&quot;alpha&quot;, value=alpha)\n        mlflow.log_param(key=&quot;l1_ratio&quot;, value=l1_ratio)\n        mlflow.log_metric(key=&quot;rmse&quot;, value=rmse)\n        mlflow.log_metrics({&quot;mae&quot;: mae, &quot;r2&quot;: r2})\n        mlflow.log_artifact(data_path)\n        print(&quot;Save to: {}&quot;.format(mlflow.get_artifact_uri()))\n        \n        mlflow.sklearn.log_model(lr, &quot;model&quot;)\n<\/code><\/pre>\n<p>Once I run <code>train()<\/code> with its parameters, in UI I cannot see Artifacts, but I can see models and its parameters and Metric.<\/p>\n<p>In artifact tab it's written <code>No Artifacts Recorded Use the log artifact APIs to store file outputs from MLflow runs.<\/code> But in finder in models folders all Artifacts existe with models Pickle.<\/p>\n<p>help<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-24 00:31:11.933 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2022-06-27 12:53:59.607 UTC",
        "Question_score":2,
        "Question_tags":"python|artifacts|mlflow",
        "Question_view_count":8044,
        "Owner_creation_date":"2017-07-19 18:57:23.013 UTC",
        "Owner_last_access_date":"2022-09-15 23:20:31.84 UTC",
        "Owner_reputation":722,
        "Owner_up_votes":703,
        "Owner_down_votes":8,
        "Owner_views":290,
        "Answer_body":"<p>Had a similar issue. In my case, I solved it by running <code>mlflow ui<\/code> inside the <code>mlruns<\/code> directory of your experiment.<\/p>\n<p>See the full discussion on Github <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/3030\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<p>Hope it helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-02 13:47:18.32 UTC",
        "Answer_score":4.0,
        "Owner_location":"France",
        "Answer_last_edit_date":"2020-07-05 20:47:50.673 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61980244",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57987999,
        "Question_title":"Delete a run in the experiment of mlflow from the UI so the run does not exist in backend store",
        "Question_body":"<p>I found deleting a <code>run<\/code> only change the state from <code>active<\/code> to <code>deleted<\/code>, because the run is still visible in the UI if searching by <code>deleted<\/code>. <\/p>\n\n<p>Is it possible to remove a <code>run<\/code> from the UI to save the space? \nWhen removing a run, does the artifact correspond to the run is also removed?<\/p>\n\n<p>If not, can the run be removed through rest call?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-18 08:10:47.973 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-18 08:47:48.593 UTC",
        "Question_score":6,
        "Question_tags":"mlflow",
        "Question_view_count":3582,
        "Owner_creation_date":"2014-08-18 14:07:01.673 UTC",
        "Owner_last_access_date":"2022-09-15 04:40:38.707 UTC",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Answer_body":"<p>You can't do it via the web UI but you can from a python terminal<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmlflow.delete_experiment(69)\n<\/code><\/pre>\n\n<p>Where 69 is the experiment ID<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-09-29 21:39:34.477 UTC",
        "Answer_score":2.0,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57987999",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72994988,
        "Question_title":"How to mlflow-autolog a sklearn ConfusionMatrixDisplay?",
        "Question_body":"<p>I'm trying to log the plot of a <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator\" rel=\"nofollow noreferrer\">confusion matrix generated with scikit-learn<\/a> for a <em>test<\/em> set using <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.sklearn.html\" rel=\"nofollow noreferrer\">mlflow's support for scikit-learn<\/a>.<\/p>\n<p>For this, I tried something that resemble the code below (I'm using mlflow hosted on Databricks, and <code>sklearn==1.0.1<\/code>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sklearn.datasets\nimport pandas as pd\nimport numpy as np\nimport mlflow\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nmlflow.set_tracking_uri(&quot;databricks&quot;)\nmlflow.set_experiment(&quot;\/Users\/name.surname\/plotcm&quot;)\n\ndata = sklearn.datasets.fetch_20newsgroups(categories=['alt.atheism', 'sci.space'])\n\ndf = pd.DataFrame(data = np.c_[data['data'], data['target']])\\\n       .rename({0:'text', 1:'class'}, axis = 'columns')\n\ntrain, test = train_test_split(df)\n\nmy_pipeline = Pipeline([\n    ('vectorizer', TfidfVectorizer()),\n    ('classifier', SGDClassifier(loss='modified_huber')),\n])\n\nmlflow.sklearn.autolog()\n\nfrom sklearn.metrics import ConfusionMatrixDisplay # should I import this after the call to `.autolog()`?\n\nmy_pipeline.fit(train['text'].values, train['class'].values)\n\ncm = ConfusionMatrixDisplay.from_predictions(\n      y_true=test[&quot;class&quot;], y_pred=my_pipeline.predict(test[&quot;text&quot;])\n  )\n<\/code><\/pre>\n<p>while the confusion matrix for the training set is saved in my mlflow run, no png file is created in the mlflow frontend for the <code>test<\/code> set.<\/p>\n<p>If I try to add<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>cm.figure_.savefig('test_confusion_matrix.png')\nmlflow.log_artifact('test_confusion_matrix.png')\n<\/code><\/pre>\n<p>that does the job, but requires explicitly logging the artifact.<\/p>\n<p>Is there an idiomatic\/proper way to autolog the confusion matrix computed using a test set after <code>my_pipeline.fit()<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-15 13:44:41.357 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-17 18:51:20.967 UTC",
        "Question_score":0,
        "Question_tags":"python|scikit-learn|confusion-matrix|mlflow",
        "Question_view_count":157,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":"<p>The proper way to do this is to use <code>mlflow.log_figure<\/code> as a fluent API announced in <code>MLflow 1.13.0<\/code>. You can read the documentation <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_figure\" rel=\"nofollow noreferrer\">here<\/a>. This code will do the job.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.log_figure(cm.figure_, 'test_confusion_matrix.png')\n<\/code><\/pre>\n<p>This function implicitly store the image, and then calls <code>log_artifact<\/code> against that path, something like you did.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-20 08:15:34.1 UTC",
        "Answer_score":1.0,
        "Owner_location":"Verona, VR, Italy",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72994988",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56851463,
        "Question_title":"How do I specify mlflow MLproject with zero parameters?",
        "Question_body":"<p>I tried to create MLproject with zero parameters as:<\/p>\n\n<pre><code>name: test\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    parameters:\n    command: \"python test.py\"\n<\/code><\/pre>\n\n<p>when I get an error:<\/p>\n\n<pre><code>  Traceback (most recent call last):\n File \"\/home\/ubuntu\/.local\/bin\/mlflow\", line 11, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/cli.py\", line 137, in run\n    run_id=run_id,\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\n    use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/__init__.py\", line 85, in _run\n    project = _project_spec.load_project(work_dir)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/_project_spec.py\", line 40, in load_project\n    entry_points[name] = EntryPoint(name, parameters, command)\n  File \"\/home\/ubuntu\/.local\/lib\/python2.7\/site-packages\/mlflow\/projects\/_project_spec.py\", line 87, in __init__\n    self.parameters = {k: Parameter(k, v) for (k, v) in parameters.items()}\nAttributeError: 'NoneType' object has no attribute 'items'\n<\/code><\/pre>\n\n<p>Am I missing something or mlflow does not allow project with  zero parameters?<\/p>\n\n<p>I have also posted this at my public repo of: <a href=\"https:\/\/github.com\/sameermahajan\/mlflow-try\" rel=\"nofollow noreferrer\">https:\/\/github.com\/sameermahajan\/mlflow-try<\/a> if someone would like to try out:<\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/sameermahajan\/mlflow-try.git\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-02 11:29:36.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":353,
        "Owner_creation_date":"2013-11-13 11:51:02.317 UTC",
        "Owner_last_access_date":"2022-09-23 07:08:32.33 UTC",
        "Owner_reputation":478,
        "Owner_up_votes":65,
        "Owner_down_votes":4,
        "Owner_views":118,
        "Answer_body":"<p>For this, you completely drop the 'parameters' section as below:<\/p>\n\n<pre><code>name: test\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    command: \"python test.py\"\n<\/code><\/pre>\n\n<p>(I thought I had tried it earlier but I was trying too many different ways to may be miss out on this one)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-07-04 11:42:23.613 UTC",
        "Answer_score":0.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56851463",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69126555,
        "Question_title":"how to log KerasClassifier model in a sklearn pipeline mlflow?",
        "Question_body":"<p>I have a set of pre-processing stages in sklearn <code>Pipeline<\/code> and an estimator which is a <code>KerasClassifier<\/code> (<code>from tensorflow.keras.wrappers.scikit_learn import KerasClassifier<\/code>).<\/p>\n<p>My overall goal is to tune and log the whole sklearn pipeline in <code>mlflow<\/code> (in databricks evn). I get a confusing type error which I can't figure out how to reslove:<\/p>\n<blockquote>\n<p>TypeError: can't pickle _thread.RLock objects<\/p>\n<\/blockquote>\n<p>I have the following code (without tuning stage) which returns the above error:<\/p>\n<pre><code>conda_env = _mlflow_conda_env(\n    additional_conda_deps=None,\n    additional_pip_deps=[\n        &quot;cloudpickle=={}&quot;.format(cloudpickle.__version__),\n        &quot;scikit-learn=={}&quot;.format(sklearn.__version__),\n        &quot;numpy=={}&quot;.format(np.__version__),\n        &quot;tensorflow=={}&quot;.format(tf.__version__),\n    ],\n    additional_conda_channels=None,\n)\n\nsearch_space = {\n    &quot;estimator__dense_l1&quot;: 20,\n    &quot;estimator__dense_l2&quot;: 20,\n    &quot;estimator__learning_rate&quot;: 0.1,\n    &quot;estimator__optimizer&quot;: &quot;Adam&quot;,\n}\n\n\ndef create_model(n):\n\n    model = Sequential()\n    model.add(Dense(int(n[&quot;estimator__dense_l1&quot;]), activation=&quot;relu&quot;))\n    model.add(Dense(int(n[&quot;estimator__dense_l2&quot;]), activation=&quot;relu&quot;))\n    model.add(Dense(1, activation=&quot;sigmoid&quot;))\n    model.compile(\n        loss=&quot;binary_crossentropy&quot;,\n        optimizer=n[&quot;estimator__optimizer&quot;],\n        metrics=[&quot;accuracy&quot;],\n    )\n\n    return model\n\n\nmlflow.sklearn.autolog()\nwith mlflow.start_run(nested=True) as run:\n\n    classfier = KerasClassifier(build_fn=create_model, n=search_space)\n    # fit the pipeline\n    clf = Pipeline(steps=[(&quot;preprocessor&quot;, preprocessor), \n                          (&quot;estimator&quot;, classfier)])\n    h = clf.fit(\n        X_train,\n        y_train.values,\n        estimator__validation_split=0.2,\n        estimator__epochs=10,\n        estimator__verbose=2,\n    )\n\n    # log scores\n    acc_score = clf.score(X=X_test, y=y_test)\n    mlflow.log_metric(&quot;accuracy&quot;, acc_score)\n\n    signature = infer_signature(X_test, clf.predict(X_test))\n    # Log the model with a signature that defines the schema of the model's inputs and outputs.\n    mlflow.sklearn.log_model(\n        sk_model=clf, artifact_path=&quot;model&quot;, \n        signature=signature, \n        conda_env=conda_env\n    )\n<\/code><\/pre>\n<p>I also get this warning before the error:<\/p>\n<pre><code>\n    WARNING mlflow.sklearn.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n                      transformer_weights=None,\n                      transformers=[('num',\n                                   Pipeline(memory=None,\n<\/code><\/pre>\n<p>note the the whole pipeline runs outside mlflow.\ncan someone help?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-10 02:30:04.103 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|tensorflow|scikit-learn|databricks|mlflow",
        "Question_view_count":435,
        "Owner_creation_date":"2016-02-17 00:01:25.907 UTC",
        "Owner_last_access_date":"2022-09-23 03:50:46.563 UTC",
        "Owner_reputation":283,
        "Owner_up_votes":35,
        "Owner_down_votes":7,
        "Owner_views":85,
        "Answer_body":"<p>I think I find sort of a workaround\/solution for this for now, but I think this issue needs to be addressed in MLFloow anyways.<\/p>\n<p>What I did is not the best way probably.\nI used a python package called <a href=\"https:\/\/scikeras.readthedocs.io\/en\/latest\/\" rel=\"nofollow noreferrer\">scikeras<\/a> that does this wrapping and then could log the model<\/p>\n<p>The code:<\/p>\n<pre><code>import scikeras \nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Flatten, Activation \n \nfrom scikeras.wrappers import KerasClassifier \n  \n \nclass ModelWrapper(mlflow.pyfunc.PythonModel): \n    def __init__(self, model): \n        self.model = model \n \n    def predict(self, context, model_input): \n        return self.model.predict(model_input) \n \nconda_env =  _mlflow_conda_env( \n      additional_conda_deps=None, \n      additional_pip_deps=[ \n        &quot;cloudpickle=={}&quot;.format(cloudpickle.__version__),  \n        &quot;scikit-learn=={}&quot;.format(sklearn.__version__), \n        &quot;numpy=={}&quot;.format(np.__version__), \n        &quot;tensorflow=={}&quot;.format(tf.__version__), \n        &quot;scikeras=={}&quot;.format(scikeras.__version__), \n      ], \n      additional_conda_channels=None, \n  ) \n \nparam = { \n   &quot;dense_l1&quot;: 20, \n   &quot;dense_l2&quot;: 20, \n   &quot;optimizer__learning_rate&quot;: 0.1, \n   &quot;optimizer&quot;: &quot;Adam&quot;, \n   &quot;loss&quot;:&quot;binary_crossentropy&quot;, \n} \n \n  \ndef create_model(dense_l1, dense_l2, meta): \n  \n  n_features_in_ = meta[&quot;n_features_in_&quot;] \n  X_shape_ = meta[&quot;X_shape_&quot;] \n  n_classes_ = meta[&quot;n_classes_&quot;] \n \n  model = Sequential() \n  model.add(Dense(n_features_in_, input_shape=X_shape_[1:], activation=&quot;relu&quot;)) \n  model.add(Dense(dense_l1, activation=&quot;relu&quot;)) \n  model.add(Dense(dense_l2, activation=&quot;relu&quot;)) \n  model.add(Dense(1, activation=&quot;sigmoid&quot;)) \n \n  return model   \n \nmlflow.sklearn.autolog() \nwith mlflow.start_run(run_name=&quot;sample_run&quot;): \n \n  classfier = KerasClassifier( \n    create_model, \n    loss=param[&quot;loss&quot;], \n    dense_l1=param[&quot;dense_l1&quot;], \n    dense_l2=param[&quot;dense_l2&quot;], \n    optimizer__learning_rate = param[&quot;optimizer__learning_rate&quot;], \n    optimizer= param[&quot;optimizer&quot;], \n) \n \n  # fit the pipeline \n  clf = Pipeline(steps=[('preprocessor', preprocessor), \n                      ('estimator', classfier)])   \n \n  h = clf.fit(X_train, y_train.values) \n  # log scores \n  acc_score = clf.score(X=X_test, y=y_test) \n  mlflow.log_metric(&quot;accuracy&quot;, acc_score) \n  signature = infer_signature(X_test, clf.predict(X_test)) \n  model_nn = ModelWrapper(clf,)  \n \n  mlflow.pyfunc.log_model( \n      python_model= model_nn, \n      artifact_path = &quot;model&quot;,  \n      signature = signature,  \n      conda_env = conda_env \n  ) \n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-14 04:21:08.677 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69126555",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65627039,
        "Question_title":"MLflow stores tags but does not return them",
        "Question_body":"<p>I am running the below code to store tags and then to retrieve them. As you can see below, Mlflow is storing one set of tags and returning another.<\/p>\n<pre><code>import mlflow\nwith mlflow.start_run() as active_run:\n    tw = { &quot;run_id&quot;: 1}\n    mlflow.set_tags(tw)            \n    print(&quot;Tags are &quot;, active_run.data.tags)\n    print(type(active_run.data.tags))\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>Tags are  {'mlflow.source.name': '\/media\/Space\/AI\/anaconda4\/lib\/python3.7\/site-packages\/ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'adeel'}\n<\/code><\/pre>\n<p>Looking at the stored tags through mlflow ui, I can see that the tag &quot;run_id&quot; set by the code is actually stored in the run. However, only the header information of the run seems to be getting returned by active_run.data.tags.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-08 10:09:35.263 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-20 10:45:29.42 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":173,
        "Owner_creation_date":"2015-10-28 00:01:57.173 UTC",
        "Owner_last_access_date":"2022-09-24 01:20:28.387 UTC",
        "Owner_reputation":689,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":87,
        "Answer_body":"<p>At the moment, you have to query your run again in MLflow to get the run with all the info that you logged. In the example below, I call <code>mlflow.get_run(&lt;run_id&gt;)<\/code> to achieve this.<\/p>\n<pre><code>import mlflow\n\n\nwith mlflow.start_run() as active_run:\n  tags = { &quot;my_tag&quot;: 1}\n  mlflow.set_tags(tags)            \n  # Keep track of the run ID of the active run\n  run_id = active_run.info.run_id\n\nrun = mlflow.get_run(run_id)\nprint(&quot;The tags are &quot;, run.data.tags)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-08 17:48:17.45 UTC",
        "Answer_score":2.0,
        "Owner_location":"Sydney, New South Wales, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65627039",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62778020,
        "Question_title":"Embarrassingly parallel hyperparameter search via Azure + DataBricks + MLFlow",
        "Question_body":"<p>Conceptual question.  My company is pushing Azure + DataBricks.  I am trying to understand where this can take us.<\/p>\n<p>I am porting some work I've done locally to the Azure + Databricks platform.  I want to run an experiment with a large number of hyperparameter combinations using Azure + Databricks + MLfLow.  I am using PyTorch to implement my models.<\/p>\n<p>I have a cluster with 8 nodes.  I want to kick off the parameter search across all of the nodes in an embarrassingly parallel manner (one run per node, running independently).  Is this as simple as creating a MLflow project and then using the mlflow.projects.run command for each hyperparameter combination and Databricks + MLflow will take care of the rest?<\/p>\n<p>Is this technology capable of this?  I'm looking for some references I could use to make this happen.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-07 14:52:06.057 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-07 15:12:05.2 UTC",
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":262,
        "Owner_creation_date":"2012-02-09 20:11:42.35 UTC",
        "Owner_last_access_date":"2022-09-16 14:37:11.437 UTC",
        "Owner_reputation":325,
        "Owner_up_votes":254,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>The short answer is yes, it's possible, but won't be exactly as easy as running a single mlflow command. You can paralelize single-node workflows using spark Python UDFs, a good example of this is this <a href=\"https:\/\/pages.databricks.com\/rs\/094-YMS-629\/images\/Fine-Grained-Time-Series-Forecasting.html?_ga=2.64430959.1760852900.1593769579-972789996.1561118598\" rel=\"nofollow noreferrer\">notebook<\/a><\/p>\n<p>I'm not sure if this will work with pytorch, but there is hyperopt library that lets you parallelize search across parameters using Spark - it's integrated with mlflow and available in databricks ML runtime. I've been using it only with scikit-learn, but it may be <a href=\"https:\/\/docs.databricks.com\/applications\/machine-learning\/automl\/hyperopt\/hyperopt-model-selection.html\" rel=\"nofollow noreferrer\">worth checking out<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-07-17 11:52:54.773 UTC",
        "Answer_score":1.0,
        "Owner_location":"Sioux City, IA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62778020",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67456172,
        "Question_title":"Unable to connect to MLFLOW_TRACKING_URI when running MLflow run in Docker container",
        "Question_body":"<p>I have setup a mlflow server locally at http:\/\/localhost:5000<\/p>\n<p>I followed the instructions at <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker<\/a> and tried to run the example docker with<\/p>\n<pre><code>\/mlflow\/examples\/docker$ mlflow run . -P alpha=0.5\n<\/code><\/pre>\n<p>but I encountered the following error.<\/p>\n<pre><code>2021\/05\/09 17:11:20 INFO mlflow.projects.docker: === Building docker image docker-example:7530274 ===\n2021\/05\/09 17:11:20 INFO mlflow.projects.utils: === Created directory \/tmp\/tmp9wpxyzd_ for downloading remote URIs passed to arguments of type 'path' ===\n2021\/05\/09 17:11:20 INFO mlflow.projects.backend.local: === Running command 'docker run --rm -v \/home\/mlf\/mlf\/0\/ae69145133bf49efac22b1d390c354f1\/artifacts:\/home\/mlf\/mlf\/0\/ae69145133bf49efac22b1d390c354f1\/artifacts -e MLFLOW_RUN_ID=ae69145133bf49efac22b1d390c354f1 -e MLFLOW_TRACKING_URI=http:\/\/localhost:5000 -e MLFLOW_EXPERIMENT_ID=0 docker-example:7530274 python train.py --alpha 0.5 --l1-ratio 0.1' in run with ID 'ae69145133bf49efac22b1d390c354f1' === \n\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/__init__.py:55: DeprecationWarning: MLflow support for Python 2 is deprecated and will be dropped in a future release. At that point, existing Python 2 workflows that use MLflow will continue to work without modification, but Python 2 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3 - see https:\/\/docs.python.org\/3\/howto\/pyporting.html for a migration guide.\n  &quot;for a migration guide.&quot;, DeprecationWarning)\nTraceback (most recent call last):\n  File &quot;train.py&quot;, line 56, in &lt;module&gt;\n    with mlflow.start_run():\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 122, in start_run\n    active_run_obj = MlflowClient().get_run(existing_run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/client.py&quot;, line 96, in get_run\n    return self._tracking_client.get_run(run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 49, in get_run\n    return self.store.get_run(run_id)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 92, in get_run\n    response_proto = self._call_endpoint(GetRun, req_body)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 32, in _call_endpoint\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 133, in call_endpoint\n    host_creds=host_creds, endpoint=endpoint, method=method, params=json_body)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 70, in http_request\n    url=url, headers=headers, verify=verify, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 51, in request_with_ratelimit_retries\n    response = requests.request(**kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/api.py&quot;, line 58, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py&quot;, line 508, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/sessions.py&quot;, line 618, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;\/opt\/conda\/lib\/python2.7\/site-packages\/requests\/adapters.py&quot;, line 508, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get?run_uuid=ae69145133bf49efac22b1d390c354f1&amp;run_id=ae69145133bf49efac22b1d390c354f1 (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f5cbd80d690&gt;: Failed to establish a new connection: [Errno 111] Connection refused',))\n2021\/05\/09 17:11:22 ERROR mlflow.cli: === Run (ID 'ae69145133bf49efac22b1d390c354f1') failed ===\n<\/code><\/pre>\n<p>Any ideas how to fix this? I tried adding the following in MLproject file but it doesn't help<\/p>\n<pre><code>environment: [[&quot;network&quot;, &quot;host&quot;], [&quot;add-host&quot;, &quot;host.docker.internal:host-gateway&quot;]]\n<\/code><\/pre>\n<p>Thanks for your help! =)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-09 09:28:50.28 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2021-05-09 09:54:30.857 UTC",
        "Question_score":0,
        "Question_tags":"docker|mlflow",
        "Question_view_count":1151,
        "Owner_creation_date":"2011-09-21 15:48:22.63 UTC",
        "Owner_last_access_date":"2022-02-01 05:15:47.643 UTC",
        "Owner_reputation":1308,
        "Owner_up_votes":177,
        "Owner_down_votes":1,
        "Owner_views":151,
        "Answer_body":"<p>Run MLflow server such was that it will use your machine IP instead of <code>localhost<\/code>.  Then point the <code>mlflow run<\/code> to that IP instead of <code>http:\/\/localhost:5000<\/code>.   The main reason is that <code>localhost<\/code> of Docker process is its own, not your machine.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-05-10 06:19:06.97 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67456172",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67677780,
        "Question_title":"MLFlow run: Pass parameters in a file instead of key\/value pairs",
        "Question_body":"<p>Usually when running an MLProject, I would use something similar to:<\/p>\n<pre><code>mlflow run . -P alpha=0.1 -P l1_ratio=0.9\n<\/code><\/pre>\n<p>Is it possible to pass a file containing the key\/value pairs instead ? so something like:<\/p>\n<pre><code>mlflow run . --file .\/parametrs\n<\/code><\/pre>\n<p>where .\/parameters contains the key\/value pairs (like an env file or something)<\/p>\n<p>One way I thought of is to make a seperate bash script that accept the file and extracts the key\/value pairs to be included in the run command, but I wonder if there's a way more native to mlflow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-24 19:18:08.327 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|machine-learning|mlflow|mlops",
        "Question_view_count":222,
        "Owner_creation_date":"2018-10-27 15:39:35.053 UTC",
        "Owner_last_access_date":"2022-09-22 15:17:20.653 UTC",
        "Owner_reputation":606,
        "Owner_up_votes":42,
        "Owner_down_votes":8,
        "Owner_views":69,
        "Answer_body":"<p>It's not supported functionality according to <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-run\" rel=\"nofollow noreferrer\">documentation<\/a>, and <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/cli.py#L124\" rel=\"nofollow noreferrer\">source code<\/a>, so you'll need to add your own wrapper to read parameters from file &amp; pass them explicitly.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-25 08:37:55.96 UTC",
        "Answer_score":1.0,
        "Owner_location":"Tunisia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67677780",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72604450,
        "Question_title":"MLflow load model fails Python",
        "Question_body":"<p>I am trying to build an API using an MLflow model.<\/p>\n<p>the funny thing is it works from one location on my PC and not from another. So, the reason for doing I wanted to change my repo etc.<\/p>\n<p>So, the simple code of<\/p>\n<pre><code>from mlflow.pyfunc import load_model\nMODEL_ARTIFACT_PATH = &quot;.\/model\/model_name\/&quot;\nMODEL = load_model(MODEL_ARTIFACT_PATH)\n<\/code><\/pre>\n<p>now fails with<\/p>\n<pre><code>ERROR:    Traceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 540, in lifespan\n    async for item in self.lifespan_context(app):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 481, in default_lifespan\n    await self.startup()\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 516, in startup\n    await handler()\n  File &quot;\/code\/.\/app\/main.py&quot;, line 32, in startup_load_model\n    MODEL = load_model(MODEL_ARTIFACT_PATH)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 733, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 737, in _load_pyfunc\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 656, in _load_model\n    return PipelineModel.load(model_uri)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 332, in load\n    return cls.read().load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/pipeline.py&quot;, line 258, in load\n    return JavaMLReader(self.cls).load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 282, in load\n    java_obj = self._jread.load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/py4j\/java_gateway.py&quot;, line 1321, in __call__\n    return_value = get_return_value(\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/sql\/utils.py&quot;, line 117, in deco\n    raise converted from None\npyspark.sql.utils.AnalysisException: Unable to infer schema for Parquet. It must be specified manually.\n<\/code><\/pre>\n<p>The model artifacts are already downloaded to the folder \/model folder which has the following structure.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>the load model call is in the main.py file\nAs I mentioned it works from another directory, but there is no reference to any absolute paths. Also, I have made sure that my package references are identical. e,g I have pinned them all down<\/p>\n<pre><code># Model\nmlflow==1.25.1\nprotobuf==3.20.1\npyspark==3.2.1\nscipy==1.6.2\nsix==1.15.0\n<\/code><\/pre>\n<p>also, the same docker file is used both places, which among other things, makes sure that the final resulting folder structure is the same<\/p>\n<pre><code>......other stuffs\n\nCOPY .\/app \/code\/app\nCOPY .\/model \/code\/model\n<\/code><\/pre>\n<p>what can explain it throwing this exception whereas in another location (on my PC), it works (same model artifacts) ?<\/p>\n<p>Since it uses load_model function, it should be able to read the parquet files ?<\/p>\n<p>Any question and I can explain.<\/p>\n<p>EDIT1: I have debugged this a little more in the docker container and it seems the parquet files in the itemFactors folder (listed in my screenshot above) are not getting copied over to my image , even though I have the copy command to copy all files under the model folder. It is copying the _started , _committed and _SUCCESS files, just not the parquet files. Anyone knows why would that be? I DO NOT have a .dockerignore file. Why are those files ignored while copying?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-13 14:21:39.67 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-13 15:37:50.387 UTC",
        "Question_score":2,
        "Question_tags":"python|docker|databricks|mlflow",
        "Question_view_count":109,
        "Owner_creation_date":"2015-04-10 08:31:54.763 UTC",
        "Owner_last_access_date":"2022-09-24 09:37:37.383 UTC",
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Answer_body":"<p>I found the problem. Like I wrote in the EDIT1 of my post, with further observations, the parquet files were missing in the docker container. That was strange because I was copying the entire folder in my Dockerfile.<\/p>\n<p>I then realized that I was hitting this problem <a href=\"https:\/\/github.com\/moby\/buildkit\/issues\/1366\" rel=\"nofollow noreferrer\">mentioned here<\/a>. File paths exceeding 260 characters, silently fail and do not get copied over to the docker container. This was really frustrating because nothing failed during build and then during run, it gave me that cryptic error of &quot;unable to infer schema for parquet&quot;, essentially because the parquet files were not copied over during docker build.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-14 07:29:05.993 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-06-14 10:34:01.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72604450",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65035488,
        "Question_title":"Running mlflow as a systemd service - gunicorn not found",
        "Question_body":"<p>I am trying to run a mlflow tracking server that is installed inside of a virtualenv as a systemd service on Ubuntu 20.04 but I am getting an error indicating that it is unable to find gunicorn. Here is my journal<\/p>\n<pre><code>nov 27 10:37:17 Atrium-Power mlflow[81375]: Traceback (most recent call last):\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/bin\/mlflow&quot;, line 8, in &lt;module&gt;\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     sys.exit(cli())\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/click\/core.py&quot;, line 829, in __call__\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     return self.main(*args, **kwargs)\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/click\/core.py&quot;, line 782, in main\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     rv = self.invoke(ctx)\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/click\/core.py&quot;, line 1259, in invoke\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     return _process_result(sub_ctx.command.invoke(sub_ctx))\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/click\/core.py&quot;, line 1066, in invoke\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     return ctx.invoke(self.callback, **ctx.params)\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/click\/core.py&quot;, line 610, in invoke\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     return callback(*args, **kwargs)\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/mlflow\/cli.py&quot;, line 392, in server\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     _run_server(\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/mlflow\/server\/__init__.py&quot;, line 138, in _run_server\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     exec_cmd(full_command, env=env_map, stream_output=True)\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/site-packages\/mlflow\/utils\/process.py&quot;, line 34, in exec_cmd\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     child = subprocess.Popen(\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/subprocess.py&quot;, line 947, in __init__\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     self._execute_child(args, executable, preexec_fn, close_fds,\nnov 27 10:37:17 Atrium-Power mlflow[81375]:   File &quot;\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/lib\/python3.9\/subprocess.py&quot;, line 1819, in _execute_child\nnov 27 10:37:17 Atrium-Power mlflow[81375]:     raise child_exception_type(errno_num, err_msg, err_filename)\nnov 27 10:37:17 Atrium-Power mlflow[81375]: FileNotFoundError: [Errno 2] No such file or directory: 'gunicorn'\n<\/code><\/pre>\n<p>and my systemd is this:<\/p>\n<pre><code>[Unit]\nStartLimitBurst=5\nStartLimitIntervalSec=33\n\n[Service]\nUser=praxasense\nWorkingDirectory=\/home\/praxasense\nRestart=always\nRestartSec=5\nExecStart=\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/bin\/mlflow server --port 3569 --backend-store-uri .mlruns\n\n[Install]\nWantedBy=multi-user.target\n<\/code><\/pre>\n<p>The strange thing is that if I run the command from <code>ExecStart<\/code> in my terminal it works fine in fish shell, but not in bash, <em>but<\/em> if I do <code>conda activate mlflow-server<\/code> and then do <code>mlflow ...<\/code> it <em>does<\/em> work. As far as I understood the Python interpreter should be aware of it's virtual environment and so it should work as I tried it, but apparently I am missing something that makes it not able to find the gunicon package, which is obviously there.<\/p>\n<p>Any ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-27 10:10:59.393 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|systemd|ubuntu-20.04|mlflow",
        "Question_view_count":1018,
        "Owner_creation_date":"2011-08-28 11:59:19.333 UTC",
        "Owner_last_access_date":"2022-09-07 16:14:20.447 UTC",
        "Owner_reputation":2732,
        "Owner_up_votes":414,
        "Owner_down_votes":15,
        "Owner_views":609,
        "Answer_body":"<p>Try adding the venv's bin path to the environment that systemd runs in:<\/p>\n<pre><code>[Service]\n...\nEnvironment=&quot;PATH=\/home\/praxasense\/.miniconda3\/envs\/mlflow-server\/bin&quot;\n...\n<\/code><\/pre>\n<p>I also recommend setting <code>KillMode=mixed<\/code>, since MLFlow will spawn gunicorn instances that won't be terminated if you terminate the service otherwise. <code>mixed<\/code> means that child processes will also be terminated.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-12-08 15:40:42.567 UTC",
        "Answer_score":3.0,
        "Owner_location":"Rotterdam, Netherlands",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65035488",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65789715,
        "Question_title":"MLFlow sklearn autologging prints too many info messages in colab",
        "Question_body":"<p>I am trying mlflow sklearn auto logging, in colab, mlflow prints a lot of info messages and at times it crashes the browser. Attaching the pic of info logs<a href=\"https:\/\/i.stack.imgur.com\/RqvNM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RqvNM.png\" alt=\"mlflow info logs\" \/><\/a><\/p>\n<p>codes are in <a href=\"https:\/\/colab.research.google.com\/drive\/1wvHSgYk6boKW0AMPqIt-AByyFHSO26wm?usp=sharing\" rel=\"nofollow noreferrer\">this colab file<\/a><\/p>\n<p>Am not sure what am missing here, but the same code works fine without producing these info logs on my local computer.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-19 10:31:50.507 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":194,
        "Owner_creation_date":"2020-12-22 10:45:25.527 UTC",
        "Owner_last_access_date":"2022-07-10 06:14:47.843 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>This is a known issue with MLFlow package, in which a hotfix has been raised.<\/p>\n<p>See here: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/3978\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/pull\/3978<\/a><\/p>\n<p><strong>Description of fault<\/strong><\/p>\n<p>In MLflow 1.13.0 and 1.13.1, the following Python event logging message is emitted when a patched ML training function begins execution within a preexisting MLflow run.<\/p>\n<p>Unfortunately, for patched ML training routines that make child calls to other patched ML training routines (e.g. sklearn random forests that call fit() on a collection of sklearn DecisionTree instances), this event log is printed to stdout every time a child is called.<\/p>\n<p>This can produce hundreds of redundant event logging calls that don't provide value to the user.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-01-19 10:55:13.91 UTC",
        "Answer_score":1.0,
        "Owner_location":"Dubai - United Arab Emirates",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65789715",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71752458,
        "Question_title":"MLflow Experiments Tracking : local (dev tools - vscode) to databricks workspace",
        "Question_body":"<p>I had configured my databricks workspace in local using,<\/p>\n<p><code>databricks configure --profile &lt;profile_name&gt; --token<\/code><\/p>\n<p>by which I am able to list the clusters and create secret scope.<\/p>\n<p>But I am unable to create mlflow experiments. I had set the tracking uri to &quot;databricks&quot; and also tested with &quot;databricks\/&lt;profile_name&quot; and tested but i am unable to create or track any experiments on my databricks workspace.<\/p>\n<p>I get this following error;<\/p>\n<p><code>from mlflow.tracking import MlflowClient client = MlflowClient() mlflow.set_tracking_uri(&quot;databricks&quot;) experiment =  client.get_experiment_by_name('\/Shared\/test')<\/code><\/p>\n<p>MlflowException: API request to endpoint was successful but the response body was not in a valid JSON format. Response body: '&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;\/&gt;&lt;meta http-equiv=&quot;Content-Language&quot; content=&quot;en&quot;\/&gt;&lt;title&gt;Databricks - Sign In&lt;\/title&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=960&quot;\/&gt;&lt;link rel=&quot;icon&quot; type=&quot;image\/png&quot; href=&quot;\/favicon.ico&quot;\/&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text\/html; charset=UTF8&quot;\/&gt;&lt;link rel=&quot;icon&quot; href=&quot;\/favicon.ico&quot;&gt;&lt;script defer=&quot;defer&quot; src=&quot;\/login\/login.0ceb14c0.js&quot;&gt;&lt;\/script&gt;&lt;\/head&gt;&lt;body class=&quot;light-mode&quot;&gt;&lt;uses-legacy-bootstrap&gt;&lt;div id=&quot;login-page&quot;&gt;&lt;\/div&gt;&lt;\/uses-legacy-bootstrap&gt;&lt;\/body&gt;&lt;\/html&gt;'<\/p>\n<p>Could someone help me on what I am missing here?<\/p>\n<p>I am expecting to create\/track mlflow experiements in databricks workspace via dev-tools(vscode).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-05 13:14:45.623 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":220,
        "Owner_creation_date":"2018-01-10 07:23:49.903 UTC",
        "Owner_last_access_date":"2022-06-20 10:34:36.247 UTC",
        "Owner_reputation":5,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>I had the same problem while trying to load a model from model registry with mismatching versions (client 1.22.0).<\/p>\n<p>I had to downgrade the client version to make it work.<\/p>\n<p>Downgraded first the client to 1.21 and then server to 1.20<\/p>\n<p>Refer - <a href=\"https:\/\/docs.databricks.com\/dev-tools\/api\/latest\/mlflow.html#operation\/transition-model-version-stage\" rel=\"nofollow noreferrer\">https:\/\/docs.databricks.com\/dev-tools\/api\/latest\/mlflow.html#operation\/transition-model-version-stage<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-06 06:17:24.71 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71752458",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72518344,
        "Question_title":"Logging and Fetching Run Parameters in AzureML",
        "Question_body":"<p>I am able to log and fetch metrics to AzureML using Run.log, however, I need a way to also log run parameters, like Learning Rate, or Momentum. I can't seem to find anything in the AzureML Python SDK documentation to achieve this. However, if I use MLflow's mlflow.log_param, I am able to log parameters, and they even nicely show up on the AzureML Studio Dashboard (bottom right of the image):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Again, I am able to fetch this using MLflow's get_params() function, but I can't find a way to do this using just AzureML's Python SDK. Is there a way to do this directly using <code>azureml<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-06 13:22:27.343 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|mlflow|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":73,
        "Owner_creation_date":"2019-04-05 20:51:24.963 UTC",
        "Owner_last_access_date":"2022-09-24 07:41:48.093 UTC",
        "Owner_reputation":438,
        "Owner_up_votes":15,
        "Owner_down_votes":2,
        "Owner_views":120,
        "Answer_body":"<p>The retrieving of log run parameters like <strong>Learning Rate, or Momentum<\/strong> is not possible with <strong>AzureML<\/strong> alone. Because it was tied with <strong>MLFlow<\/strong> and <strong>azureml-core<\/strong>. without those two involvements, we cannot retrieve the log run parameters.<\/p>\n<pre><code>pip install azureml-core mlflow azureml-mlflow\n<\/code><\/pre>\n<p>Need to install these three for getting run parameters. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Link<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-05 05:29:14.31 UTC",
        "Answer_score":1.0,
        "Owner_location":"Hyderabad, Telangana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72518344",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63920599,
        "Question_title":"PowerBI and MLflow integration (through AzureML)",
        "Question_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-16 12:59:50.477 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-09-23 10:11:20.503 UTC",
        "Question_score":0,
        "Question_tags":"azure|powerbi|mlflow|azure-machine-learning-service",
        "Question_view_count":405,
        "Owner_creation_date":"2020-09-16 12:42:46.047 UTC",
        "Owner_last_access_date":"2021-03-12 15:06:56.23 UTC",
        "Owner_reputation":15,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-20 12:28:40.243 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-09-23 10:12:37.377 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69466354,
        "Question_title":"MLflow S3UploadFailedError: Failed to upload",
        "Question_body":"<p>I've created with docker a MinioS3 artifact storage and a mysql bakend storage using the next docker-compose:<\/p>\n<pre><code>    version: '3.8'\n    services:\n        db:\n           environment:\n              - MYSQL_DATABASE=${MYSQL_DATABASE}\n              - MYSQL_USER=${MYSQL_USER}\n              - MYSQL_PASSWORD=${MYSQL_PASSWORD}\n              - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\n           expose:\n              - '3306'        \n           volumes:\n              - '(path)\/server_backend:\/var\/lib\/mysql '\n           image: 'mysql'\n           container_name: db\n\n        storage:\n            environment:\n                - MINIO_ACCESS_KEY=${MINIO_USR}\n                - MINIO_SECRET_KEY=${MINIO_PASS}\n            expose:\n                - '9000'\n            ports:\n                - '9000:9000'        \n            depends_on:\n                - db\n            command: server \/data\n            volumes:\n                - '(path)\/server_artifact:\/data'\n            image: minio\/minio:RELEASE.2021-02-14T04-01-33Z\n            container_name: MinIO\n\n        mlflow:\n            build: .\/mlflow\n            environment:\n                - AWS_ACCESS_KEY_ID=${MINIO_USR}\n                - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n            expose:\n                - '5000'\n            ports:\n                - '5000:5000'\n            depends_on:\n                - storage                       \n            image: 'mlflow:Dockerfile'\n            container_name: server\n<\/code><\/pre>\n<p>The Mlflow server docker was created using the next Dockerfile:<\/p>\n<pre><code>    FROM python:3.8-slim-buster\n    WORKDIR \/usr\/src\/app\n    RUN pip install cryptography mlflow psycopg2-binary boto3 pymysql\n    ENV MLFLOW_S3_ENDPOINT_URL=http:\/\/storage:9000\n    CMD mlflow server \\\n        --backend-store-uri mysql+pymysql:\/\/MLFLOW:temporal@db:3306\/DBMLFLOW \\\n        --default-artifact-root s3:\/\/artifacts \\\n        --host 0.0.0.0\n<\/code><\/pre>\n<p>The credantials are defined in a <code>.env<\/code> file.<\/p>\n<p>The results of the <code>docker-compose<\/code> up command :<\/p>\n<pre><code>\n    [+] Running 21\/22\n     - mlflow Error                                                                                                                              5.6s\n     - storage Pulled                                                                                                                           36.9s\n       - a6b97b4963f5 Pull complete                                                                                                             24.6s\n       - 13948a011eec Pull complete                                                                                                             24.7s\n       - 40cdef9976a6 Pull complete                                                                                                             24.7s\n       - f47162848743 Pull complete                                                                                                             24.8s\n       - 5f2758d8e94c Pull complete                                                                                                             24.9s\n       - c2950439edb8 Pull complete                                                                                                             25.0s\n       - 1b08f8a15998 Pull complete                                                                                                             30.7s\n     - db Pulled                                                                                                                                45.8s\n       - 07aded7c29c6 Already exists                                                                                                             0.0s\n       - f68b8cbd22de Pull complete                                                                                                              0.7s\n       - 30c1754a28c4 Pull complete                                                                                                              2.1s\n       - 1b7cb4d6fe05 Pull complete                                                                                                              2.2s\n       - 79a41dc56b9a Pull complete                                                                                                              2.3s\n       - 00a75e3842fb Pull complete                                                                                                              6.7s\n       - b36a6919c217 Pull complete                                                                                                              6.8s\n       - 635b0b84d686 Pull complete                                                                                                              6.8s\n       - 6d24c7242d02 Pull complete                                                                                                             39.4s\n       - 5be6c5edf16f Pull complete                                                                                                             39.5s\n       - cb35eac1242c Pull complete                                                                                                             39.5s\n       - a573d4e1c407 Pull complete                                                                                                             39.6s\n    [+] Building 1.4s (7\/7) FINISHED\n     =&gt; [internal] load build definition from Dockerfile                                                                                         0.0s\n     =&gt; =&gt; transferring dockerfile: 32B                                                                                                          0.0s\n     =&gt; [internal] load .dockerignore                                                                                                            0.0s\n     =&gt; =&gt; transferring context: 2B                                                                                                              0.0s\n     =&gt; [internal] load metadata for docker.io\/library\/python:3.8-slim-buster                                                                    1.3s\n     =&gt; [1\/3] FROM docker.io\/library\/python:3.8-slim-buster@sha256:13a3f2bffb4b18ff7eda2763a3b0ba316dd82e548f52ea8b4fd11c94b97afa7d              0.0s\n     =&gt; CACHED [2\/3] WORKDIR \/usr\/src\/app                                                                                                        0.0s\n     =&gt; CACHED [3\/3] RUN pip install cryptography mlflow psycopg2-binary boto3 pymysql                                                           0.0s\n     =&gt; exporting to image                                                                                                                       0.0s\n     =&gt; =&gt; exporting layers                                                                                                                      0.0s\n     =&gt; =&gt; writing image sha256:76d4e4462b5c7c1826734e59a54488b56660de0dd5ecc188c308202608a8f20b                                                 0.0s\n     =&gt; =&gt; naming to docker.io\/library\/mlflow:Dockerfile                                                                                         0.0s\n    \n    Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n    [+] Running 3\/3\n     - Container db  Created                                                                                                       0.5s\n     - Container MinIO      Created                                                                                                       0.1s\n     - Container server     Created                                                                                                       0.1s\n    Attaching to server, MinIO, db\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.26-1debian10 started.\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.26-1debian10 started.\n    db  | 2021-10-06 12:12:57+00:00 [Note] [Entrypoint]: Initializing database files\n    db  | 2021-10-06T12:12:57.679527Z 0 [System] [MY-013169] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) initializing of server in progress as process 44\n    db  | 2021-10-06T12:12:57.687748Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:12:58.230036Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:12:59.888820Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:12:59.889102Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:12:59.997461Z 6 [Warning] [MY-010453] [Server] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.\n    MinIO      | Attempting encryption of all config, IAM users and policies on MinIO backend\n    MinIO      | Endpoint: http:\/\/172.18.0.3:9000  http:\/\/127.0.0.1:9000\n    MinIO      |\n    MinIO      | Browser Access:\n    MinIO      |    http:\/\/172.18.0.3:9000  http:\/\/127.0.0.1:9000\n    MinIO      |\n    MinIO      | Object API (Amazon S3 compatible):\n    MinIO      |    Go:         https:\/\/docs.min.io\/docs\/golang-client-quickstart-guide\n    MinIO      |    Java:       https:\/\/docs.min.io\/docs\/java-client-quickstart-guide\n    MinIO      |    Python:     https:\/\/docs.min.io\/docs\/python-client-quickstart-guide\n    MinIO      |    JavaScript: https:\/\/docs.min.io\/docs\/javascript-client-quickstart-guide\n    MinIO      |    .NET:       https:\/\/docs.min.io\/docs\/dotnet-client-quickstart-guide\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.1 seconds\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.3 seconds\n    server     | 2021\/10\/06 12:13:02 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 0.7 seconds\n    server     | 2021\/10\/06 12:13:03 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 1.5 seconds\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Database files initialized\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Starting temporary server\n    db  | 2021-10-06T12:13:04.422603Z 0 [System] [MY-010116] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) starting as process 93\n    db  | 2021-10-06T12:13:04.439806Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:13:04.575773Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:13:04.827307Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:04.827865Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:04.832827Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.\n    db  | 2021-10-06T12:13:04.834132Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.\n    db  | 2021-10-06T12:13:04.841629Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '\/var\/run\/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.\n    db  | 2021-10-06T12:13:04.855748Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Socket: \/var\/run\/mysqld\/mysqlx.sock\n    db  | 2021-10-06T12:13:04.855801Z 0 [System] [MY-010931] [Server] \/usr\/sbin\/mysqld: ready for connections. Version: '8.0.26'  socket: '\/var\/run\/mysqld\/mysqld.sock'  port: 0  MySQL Community Server - GPL.\n    db  | 2021-10-06 12:13:04+00:00 [Note] [Entrypoint]: Temporary server started.\n    server     | 2021\/10\/06 12:13:05 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 3.1 seconds\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/iso3166.tab' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/leap-seconds.list' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/zone.tab' as time zone. Skipping it.\n    db  | Warning: Unable to load '\/usr\/share\/zoneinfo\/zone1970.tab' as time zone. Skipping it.\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Creating database DBMLFLOW\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Creating user MLFLOW\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Giving user MLFLOW access to schema DBMLFLOW\n    db  |\n    db  | 2021-10-06 12:13:06+00:00 [Note] [Entrypoint]: Stopping temporary server\n    db  | 2021-10-06T12:13:06.948482Z 13 [System] [MY-013172] [Server] Received SHUTDOWN from user root. Shutting down mysqld (Version: 8.0.26).\n    server     | 2021\/10\/06 12:13:08 WARNING mlflow.store.db.utils: SQLAlchemy engine could not be created. The following exception is caught.\n    server     | (pymysql.err.OperationalError) (2003, &quot;Can't connect to MySQL server on 'db' ([Errno 111] Connection refused)&quot;)\n    server     | (Background on this error at: https:\/\/sqlalche.me\/e\/14\/e3q8)\n    server     | Operation will be retried in 6.3 seconds\n    db  | 2021-10-06T12:13:08.716131Z 0 [System] [MY-010910] [Server] \/usr\/sbin\/mysqld: Shutdown complete (mysqld 8.0.26)  MySQL Community Server - GPL.\n    db  | 2021-10-06 12:13:08+00:00 [Note] [Entrypoint]: Temporary server stopped\n    db  |\n    db  | 2021-10-06 12:13:08+00:00 [Note] [Entrypoint]: MySQL init process done. Ready for start up.\n    db  |\n    db  | 2021-10-06T12:13:09.159115Z 0 [System] [MY-010116] [Server] \/usr\/sbin\/mysqld (mysqld 8.0.26) starting as process 1\n    db  | 2021-10-06T12:13:09.167405Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n    db  | 2021-10-06T12:13:09.298925Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n    db  | 2021-10-06T12:13:09.488958Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:09.489087Z 0 [Warning] [MY-013746] [Server] A deprecated TLS version TLSv1.1 is enabled for channel mysql_main\n    db  | 2021-10-06T12:13:09.489934Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.\n    db  | 2021-10-06T12:13:09.490169Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.\n    db  | 2021-10-06T12:13:09.494728Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '\/var\/run\/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.\n    db  | 2021-10-06T12:13:09.509856Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '::' port: 33060, socket: \/var\/run\/mysqld\/mysqlx.sock\n    db  | 2021-10-06T12:13:09.509982Z 0 [System] [MY-010931] [Server] \/usr\/sbin\/mysqld: ready for connections. Version: '8.0.26'  socket: '\/var\/run\/mysqld\/mysqld.sock'  port: 3306  MySQL Community Server - GPL.\n    db  | mbind: Operation not permitted\n    server     | 2021\/10\/06 12:13:14 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n    server     | 2021\/10\/06 12:13:14 INFO mlflow.store.db.utils: Updating database tables\n    server     | INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n    server     | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n    server     | INFO  [alembic.runtime.migration] Running upgrade  -&gt; 451aebb31d03, add metric step\n    server     | INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -&gt; 90e64c465722, migrate user column to tags\n    server     | INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -&gt; 181f10493468, allow nulls for metric values\n    server     | INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -&gt; df50e92ffc5e, Add Experiment Tags Table\n    server     | INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -&gt; 7ac759974ad8, Update run tags with larger limit\n    server     | INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -&gt; 89d4b8295536, create latest metrics table\n    server     | INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n    server     | INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -&gt; 2b4d017a5e9b, add model registry tables to db\n    server     | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n    server     | INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n    server     | INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -&gt; cfd24bdc0731, Update run status constraint with killed\n    server     | INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -&gt; 0a8213491aaa, drop_duplicate_killed_constraint\n    server     | INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -&gt; 728d730b5ebd, add registered model tags table\n    server     | INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -&gt; 27a6a02d2cf1, add model version tags table\n    server     | INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -&gt; 84291f40a231, add run_link to model_version\n    server     | INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -&gt; a8c4a736bde6, allow nulls for run_id\n    server     | INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -&gt; 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n    server     | INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -&gt; c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n    server     | INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n    server     | INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n    db  | mbind: Operation not permitted\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Starting gunicorn 20.1.0\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Listening at: http:\/\/0.0.0.0:5000 (17)\n    server     | [2021-10-06 12:13:16 +0000] [17] [INFO] Using worker: sync\n    server     | [2021-10-06 12:13:16 +0000] [19] [INFO] Booting worker with pid: 19\n    server     | [2021-10-06 12:13:16 +0000] [20] [INFO] Booting worker with pid: 20\n    server     | [2021-10-06 12:13:16 +0000] [21] [INFO] Booting worker with pid: 21\n    server     | [2021-10-06 12:13:16 +0000] [22] [INFO] Booting worker with pid: 22\n\n<\/code><\/pre>\n<p>It makes me suspect because on the second line appears <code>- mlflow Error<\/code> but i think that this is why the other builds haven't finished.<\/p>\n<p>Then I've set my environment variables on the client to create the information flow between my script and the storages:<\/p>\n<pre><code>\n    os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/localhost:9000\/'\n    os.environ['AWS_ACCESS_KEY_ID'] = 'key'\n    os.environ['AWS_SECRET_ACCESS_KEY'] = 'pw'\n    \n    remote_server_uri = &quot;http:\/\/localhost:5000\/&quot; # server URI\n    mlflow.set_tracking_uri(remote_server_uri)\n    \n    mlflow.set_experiment(&quot;mnist_mLflow_demo&quot;)\n\n<\/code><\/pre>\n<p>finally i trained a tensorflow network and i didn't have problems storing parameters and metrics but gave me some warnings (refering to next error). But the model haven't been auto log, so i tryed to do it manually:<\/p>\n<pre><code>    with mlflow.start_run(run_name = &quot;test0&quot;) as run:\n    \n        mlflow.keras.log_model(model2, 'model2')\n\n    mlflow.end_run()\n<\/code><\/pre>\n<p>It dosen't work and it gives me the next INFO (but essencialy an error):<\/p>\n<pre><code>    INFO:tensorflow:Assets written to: (path)\\Temp\\tmpgr5eaha2\\model\\data\\model\\assets\n    INFO:tensorflow:Assets written to: (path)\\Temp\\tmpgr5eaha2\\model\\data\\model\\assets\n    2021\/10\/06 14:16:00 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: (path)\\AppData\\Local\\Temp\\tmpgr5eaha2\\model, flavor: keras)\n    Traceback (most recent call last):\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\environment.py&quot;, line 212, in infer_pip_requirements\n        return _infer_requirements(model_uri, flavor)\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 263, in _infer_requirements\n        modules = _capture_imported_modules(model_uri, flavor)\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 221, in _capture_imported_modules\n        _run_command(\n      File &quot;(path)\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py&quot;, line 163, in _run_command\n        stderr = stderr.decode(&quot;utf-8&quot;)\n    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf1 in position 349: invalid continuation byte\n\n<\/code><\/pre>\n<p>And the next error:<\/p>\n<pre><code>\n    ClientError                               Traceback (most recent call last)\n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py in upload_file(self, filename, bucket, key, callback, extra_args)\n        278         try:\n    --&gt; 279             future.result()\n        280         # If a client error was raised, add the backwards compatibility layer\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py in result(self)\n        105             # out of this and propogate the exception.\n    --&gt; 106             return self._coordinator.result()\n        107         except KeyboardInterrupt as e:\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\futures.py in result(self)\n        264         if self._exception:\n    --&gt; 265             raise self._exception\n        266         return self._result\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py in __call__(self)\n        125             if not self._transfer_coordinator.done():\n    --&gt; 126                 return self._execute_main(kwargs)\n        127         except Exception as e:\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\tasks.py in _execute_main(self, kwargs)\n        149 \n    --&gt; 150         return_value = self._main(**kwargs)\n        151         # If the task is the final task, then set the TransferFuture's\n    \n    ~\\Python\\Python39\\lib\\site-packages\\s3transfer\\upload.py in _main(self, client, fileobj, bucket, key, extra_args)\n        693         with fileobj as body:\n    --&gt; 694             client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)\n        695 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\botocore\\client.py in _api_call(self, *args, **kwargs)\n        385             # The &quot;self&quot; in this scope is referring to the BaseClient.\n    --&gt; 386             return self._make_api_call(operation_name, kwargs)\n        387 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\botocore\\client.py in _make_api_call(self, operation_name, api_params)\n        704             error_class = self.exceptions.from_code(error_code)\n    --&gt; 705             raise error_class(parsed_response, operation_name)\n        706         else:\n    \n    ClientError: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The Access Key Id you provided does not exist in our records.\n    \n    During handling of the above exception, another exception occurred:\n    \n    S3UploadFailedError                       Traceback (most recent call last)\n    C:\\Users\\FCAIZA~1\\AppData\\Local\\Temp\/ipykernel_7164\/2476247499.py in &lt;module&gt;\n          1 with mlflow.start_run(run_name = &quot;test0&quot;) as run:\n          2 \n    ----&gt; 3     mlflow.keras.log_model(model2, 'model2')\n          4 \n          5 mlflow.end_run()\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\keras.py in log_model(keras_model, artifact_path, conda_env, custom_objects, keras_module, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, **kwargs)\n        402             mlflow.keras.log_model(keras_model, &quot;models&quot;)\n        403     &quot;&quot;&quot;\n    --&gt; 404     Model.log(\n        405         artifact_path=artifact_path,\n        406         flavor=mlflow.keras,\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\models\\model.py in log(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\n        186             mlflow_model = cls(artifact_path=artifact_path, run_id=run_id)\n        187             flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n    --&gt; 188             mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\n        189             try:\n        190                 mlflow.tracking.fluent._record_logged_model(mlflow_model)\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\fluent.py in log_artifacts(local_dir, artifact_path)\n        582     &quot;&quot;&quot;\n        583     run_id = _get_or_start_run().info.run_id\n    --&gt; 584     MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\n        585 \n        586 \n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\client.py in log_artifacts(self, run_id, local_dir, artifact_path)\n        975             is_dir: True\n        976         &quot;&quot;&quot;\n    --&gt; 977         self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\n        978 \n        979     @contextlib.contextmanager\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py in log_artifacts(self, run_id, local_dir, artifact_path)\n        332         :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n        333         &quot;&quot;&quot;\n    --&gt; 334         self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\n        335 \n        336     def list_artifacts(self, run_id, path=None):\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\n        102                 upload_path = posixpath.join(dest_path, rel_path)\n        103             for f in filenames:\n    --&gt; 104                 self._upload_file(\n        105                     s3_client=s3_client,\n        106                     local_file=os.path.join(root, f),\n    \n    ~\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py in _upload_file(self, s3_client, local_file, bucket, key)\n         78         if environ_extra_args is not None:\n         79             extra_args.update(environ_extra_args)\n    ---&gt; 80         s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)\n         81 \n         82     def log_artifact(self, local_file, artifact_path=None):\n    \n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\inject.py in upload_file(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\n        128     &quot;&quot;&quot;\n        129     with S3Transfer(self, Config) as transfer:\n    --&gt; 130         return transfer.upload_file(\n        131             filename=Filename, bucket=Bucket, key=Key,\n        132             extra_args=ExtraArgs, callback=Callback)\n    \n    ~\\Python\\Python39\\lib\\site-packages\\boto3\\s3\\transfer.py in upload_file(self, filename, bucket, key, callback, extra_args)\n        283         # client error.\n        284         except ClientError as e:\n    --&gt; 285             raise S3UploadFailedError(\n        286                 &quot;Failed to upload %s to %s: %s&quot; % (\n        287                     filename, '\/'.join([bucket, key]), e))\n    \n    S3UploadFailedError: Failed to upload (path)\\AppData\\Local\\Temp\\tmpgr5eaha2\\model\\conda.yaml to artifacts\/1\/5ae5fcef2d07432d811c3d7eb534382c\/artifacts\/model2\/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The Access Key Id you provided does not exist in our records.\n\n<\/code><\/pre>\n<p>Do you know how to help me with it? I have been looking all this morning but i did not find a solution. Thank you!!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-06 13:09:44.987 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mysql|docker|minio|mlflow",
        "Question_view_count":969,
        "Owner_creation_date":"2020-02-04 18:43:25.373 UTC",
        "Owner_last_access_date":"2022-09-21 20:36:53.347 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>I found the solution of this issue. It is a tricky problem due to spanish characters, my system's user profile in &quot;C:\/&quot; is &quot;fca\u00f1izares&quot; (Ca\u00f1izares is my first last name). I have created another user named &quot;fcanizares&quot; and all is working fine. Hope you find this solution helpfull.<\/p>\n<p>PS: Moral of the issue, get rid of the extrange characters!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-08 08:04:08.313 UTC",
        "Answer_score":0.0,
        "Owner_location":"Seville, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69466354",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66152375,
        "Question_title":"MLFlow active run does not match environment run id",
        "Question_body":"<p>I am trying to perform an MLFlow run but stuck with the following error after trying a lot of things.<\/p>\n<pre><code>\nrun = mlflow.active_run()\nif run:\n    print(&quot;Active run_id: {}&quot;.format(run.info.run_id))\n    mlflow.end_run()\n\nmlflow.set_experiment('TNF_EXP') \nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000\/&quot;) # Actual Server URI instead of localhost\nexperiment = mlflow.get_experiment_by_name(&quot;TNF_EXP&quot;)\n\nwith mlflow.start_run(experiment_id=experiment.experiment_id) as run:\n...\n...\n\nmlflow.end_run()\n<\/code><\/pre>\n<p>Error -<\/p>\n<pre><code>File &quot;\/...\/ModelTrainer.py&quot;, line 108, in train\n    with mlflow.start_run(experiment_id=experiment.experiment_id) as run:\n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 207, in start_run\n    &quot;arguments&quot;.format(existing_run_id)\nmlflow.exceptions.MlflowException: Cannot start run with ID e9953eb5918845bb9be1xxxxxx because active run ID does not match environment run ID. Make sure --experiment-name or --experiment-id matches experiment set with set_experiment(), or just use command-line arguments\n2021\/02\/11 09:41:36 ERROR mlflow.cli: === Run (ID 'e9953eb5918845bb9be1xxxxxx') failed ===\n<\/code><\/pre>\n<p>I noticed I had an <code>active run<\/code> earlier so I included the first <code>if block<\/code> to end that run. The code ran successfully and I was able to log the data on MLFlow UI but now when I run it I start getting the same issue. There are no active runs found before starting a new run currently.<\/p>\n<blockquote>\n<p>FYI, I am running the code on Azure server with the respective tracking URI mentioned in the code.<\/p>\n<\/blockquote>\n<p>However the code runs fine if I include an argument <code>--experiment-name=&quot;TNF_EXP&quot;<\/code> in the <code>mlflow run<\/code> command on the CLI<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-11 09:55:19.843 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":4094,
        "Owner_creation_date":"2019-06-06 12:06:56.093 UTC",
        "Owner_last_access_date":"2022-09-19 19:12:46.643 UTC",
        "Owner_reputation":861,
        "Owner_up_votes":117,
        "Owner_down_votes":6,
        "Owner_views":149,
        "Answer_body":"<p>That is primarily because you have started a run with <code>default experiment name<\/code> and then you are trying to set the <code>experiment_name<\/code> as &quot;TNF_EXP&quot;.<\/p>\n<p>Will suggest you to make use of <code>mlflow.run(..., experiment_name=&quot;TNF_EXP&quot;)<\/code> python method then running it from the <code>CLI<\/code>.<\/p>\n<p>You can find more information <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.run\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-03-25 07:27:52.013 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66152375",
        "Question_exclusive_tag":"MLFlow"
    }
]