[
    {
        "Question_id":66888622,
        "Question_title":"How to effectively use azureml.exceptions.WebserviceException for efficient REST API Error Management?",
        "Question_body":"<p>In Azure Machine Learning Service, when we deploy a Model as an AKS Webservice Endpoint, how can we raise exceptions to let the end-user get proper feedback if their API call is unsuccessful? Azure mentions using <code>azureml.exceptions.WebserviceException<\/code> in their <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.webserviceexception?view=azure-ml-py\" rel=\"nofollow noreferrer\">documentation<\/a>. However, how do we use this class to raise exceptions in case the API call cannot be processed properly and the end-user is responsible for it?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-31 13:14:00.647 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"rest|azure-web-app-service|azure-machine-learning-service",
        "Question_view_count":250,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>To raise exceptions to let the end-user get proper feedback if their API call is unsuccessful, we use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-services\/azureml.contrib.services.aml_response.amlresponse?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>azureml.contrib.services.aml_response.AMLResponse<\/code> Class<\/a>.<\/p>\n<p>Example of use in <code>score.py<\/code>:<\/p>\n<pre><code>if [some-condition]:    \n    return AMLResponse(&quot;bad request&quot;, 500)\n<\/code><\/pre>\n<p>Documentation Link can be found <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-02 06:19:10.897 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66888622",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59386244,
        "Question_title":"Azure machine learning could not import package azureml-dataprep",
        "Question_body":"<p>I am trying to go through the following tutorial published <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-train-tensorflow\" rel=\"nofollow noreferrer\">here<\/a> but get the error below when I run these lines fo code:<\/p>\n\n<pre><code>run = exp.submit(est)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n\n<p>ERROR:<\/p>\n\n<pre><code>\"message\": \"Could not import package \\\"azureml-dataprep\\\". Please ensure it is installed by running: pip install \\\"azureml-dataprep[fuse,pandas]\\\"\"\n<\/code><\/pre>\n\n<p>However, I have already installed the required packages:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PZBAt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PZBAt.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am running this through Jupyter Notebooks in an Anacoda Python 3.7 environment.<\/p>\n\n<p><strong>UPDATE<\/strong><\/p>\n\n<p>Tried creating a new conda environment as specified <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/resource-known-issues\" rel=\"nofollow noreferrer\">here<\/a> but still get the same error.<\/p>\n\n<pre><code>conda create -n aml python=3.7.3\n<\/code><\/pre>\n\n<p>After installing all the required packages, I am able to reproduce the exeception by executing the following:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3Jysg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3Jysg.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-18 05:58:04.5 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-12-18 07:27:42.773 UTC",
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":2558,
        "Owner_creation_date":"2011-07-10 04:05:42.513 UTC",
        "Owner_last_access_date":"2022-09-24 21:34:08.517 UTC",
        "Owner_reputation":2297,
        "Owner_up_votes":157,
        "Owner_down_votes":3,
        "Owner_views":244,
        "Answer_body":"<p>Sorry for this. Take a look at the Jupyter Notebook version of the same tutorial:\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/deployment\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/deployment\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb<\/a><\/p>\n\n<p>When configuring estimator, you need to specify the pip packages u wanna install on the remote compute. In this case, azureml-dataprep[fuse, blob]. Installing the package to your local computer is not useful since the training script is executed on the remote compute target, which doesn't have the required package installed yet. <\/p>\n\n<pre><code>est = TensorFlow(source_directory=script_folder,\n             script_params=script_params,\n             compute_target=compute_target,\n             entry_script='tf_mnist.py',\n             use_gpu=True,\n             pip_packages=['azureml-dataprep[pandas,fuse]'])\n<\/code><\/pre>\n\n<p>Can you pls try the fix and let us know whether it solves your issue :) In the mean time, I will update the public documentation to include pip_packages in estimator config.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-12-26 09:42:08.88 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59386244",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38632533,
        "Question_title":"Recommendations without ratings (Azure ML)",
        "Question_body":"<p>I'm trying to build an experiment to create recommendations (using the Movie Ratings sample database), but without using the ratings. I simply consider that if a user has rated certain movies, then he would be interested by other movies that have been rated by users that have also rated his movies.<\/p>\n\n<p>I can consider, for instance, that ratings are 1 (exists in the database) or 0 (does not exist), but in that case, how do I transform the initial data to reflect this?<\/p>\n\n<p>I couldn't find any kind of examples or tutorials about this kind of scenario, and I don't really know how to proceed. Should I transform the data before injecting it into an algorithm? And\/or is there any kind of specific algorithm that I should use?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2016-07-28 09:36:11.557 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-07-28 10:18:09.49 UTC",
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":910,
        "Owner_creation_date":"2016-04-28 15:29:39.437 UTC",
        "Owner_last_access_date":"2018-11-30 14:23:33.087 UTC",
        "Owner_reputation":133,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>If you're hoping to use the Matchbox Recommender in AML, you're correct that you need to identify some user-movie pairs that <em>are<\/em> not present in the raw dataset, and add these in with a rating of zero. (I'll assume that you have already set all of the real user-movie pairs to have a rating of one, as you described above.)<\/p>\n\n<p>I would recommend generating some random candidate pairs and confirming their absence from the training data in an Execute R (or Python) Script module. I don't know the names of your dataset's features, but here is some pseudocode in R to do that:<\/p>\n\n<pre><code>library(dplyr)\ndf &lt;- maml.mapInputPort(1)  # input dataset of observed user-movie pairs\nall_movies &lt;- unique(df[['movie']])\nall_users &lt;- unique(df[['user']])\nn &lt;- 30  # number of random pairs to start with\n\nnegative_observations &lt;- data.frame(movie = sample(all_movies, n, replace=TRUE),\n                                    user = sample(all_users, n, replace=TRUE),\n                                    rating = rep(0, n))          \nacceptable_negative_observations &lt;- anti_join(unique(negative_observations), df, by=c('movie', 'user'))\ndf &lt;- rbind(df, acceptable_negative_observations)\nmaml.mapOutputPort(\"df\");\n<\/code><\/pre>\n\n<p>Alternatively, you could try a method like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Association_rule_learning\" rel=\"nofollow\">association rule learning<\/a> which would not require you to add in the fake zero ratings. Martin Machac has posted a <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Frequently-bought-together-market-basket-analyses-using-ARULES-1\" rel=\"nofollow\">nice example<\/a> of how to do this in R\/AML in the Cortana Intelligence Gallery.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-08-16 13:34:13.81 UTC",
        "Answer_score":1.0,
        "Owner_location":"Lille, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38632533",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55837639,
        "Question_title":"How to enable authentication for an ACI webservice in Azure Machine Learning service?",
        "Question_body":"<p>I am able to deploy a Azure Machine learning prediction service in my workspace <code>ws<\/code> using the syntax<\/p>\n\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=8, \n                                               tags={\"method\" : \"some method\"}, \n                                               description='Predict something')\n<\/code><\/pre>\n\n<p>and then<\/p>\n\n<pre><code>service = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                       image = image,\n                                       name = service_name,\n                                       workspace = ws)\n<\/code><\/pre>\n\n<p>as described in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">documentation<\/a>.<br>\nHowever, this exposes a service publicly and this is not really optimal.<\/p>\n\n<p>What's the easiest way to shield the ACI service? I understand that passing an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aciwebservice?view=azure-ml-py#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none-\" rel=\"nofollow noreferrer\"><code>auth_enabled=True<\/code><\/a> parameter may do the job, but then how can I instruct a client (say, using <code>curl<\/code> or Postman) to use the service afterwards? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-24 19:55:31.34 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-04-25 10:02:27.293 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":676,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":"<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#call-the-service-c\" rel=\"nofollow noreferrer\">here<\/a> for an example (in C#). When you enable auth, you will need to send the API key in the \"Authorization\" header in the HTTP request:<\/p>\n\n<pre><code>client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", authKey);\n<\/code><\/pre>\n\n<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#authentication-key\" rel=\"nofollow noreferrer\">here<\/a> how to retrieve the key.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2019-04-25 08:49:30.523 UTC",
        "Answer_score":2.0,
        "Owner_location":"Verona, VR, Italy",
        "Answer_last_edit_date":"2019-04-25 09:06:44.093 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55837639",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37140987,
        "Question_title":"power by dashboard with machine learning azure data",
        "Question_body":"<p>Hi I have a web service which is the result of my machine learning azure training. I would like to set a new datasource in power bi, which calls the web service with the current datetime as a parameter in order to create a report with the result predictions. I cannot find a way to call the api. Is this any? I am thinking another solution of creating a service and execute the api, and insert the result in a table in order to connect to this table. But, I would like to avoid doing this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-10 14:09:39.01 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|powerbi|azure-machine-learning-studio",
        "Question_view_count":444,
        "Owner_creation_date":"2016-01-05 14:27:32.637 UTC",
        "Owner_last_access_date":"2018-11-22 19:35:34.697 UTC",
        "Owner_reputation":606,
        "Owner_up_votes":64,
        "Owner_down_votes":1,
        "Owner_views":168,
        "Answer_body":"<p>I used something called Azure Data Factory (ADF). It allows you to schedule a job by defining a pipeline with activities. There are activities for training your model or scoring your predictive ML. The scoring result, I am storing it in Azure DB (it could be another storage) and connected it to Power BI.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-05-13 14:43:12.243 UTC",
        "Answer_score":3.0,
        "Owner_location":"Buenos Aires, Argentina",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37140987",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56848293,
        "Question_title":"What is Random seed in Azure Machine Learning?",
        "Question_body":"<p>I am learning Azure Machine Learning. I am frequently encountering the <strong>Random Seed<\/strong> in some of the steps like,<\/p>\n\n<ol>\n<li>Split Data<\/li>\n<li>Untrained algorithm models as Two Class Regression, Multi-class regression, Tree, Forest,..<\/li>\n<\/ol>\n\n<p>In the tutorial, they choose Random Seed as '123'; trained model has high accuracy but when I try to choose other random integers like 245, 256, 12, 321,.. it did not do well.<\/p>\n\n<hr>\n\n<p><strong>Questions<\/strong><\/p>\n\n<ul>\n<li>What is a Random Seed Integer?<\/li>\n<li>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/li>\n<li>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/li>\n<\/ul>\n\n<hr>\n\n<p><strong>Pretext<\/strong><\/p>\n\n<ol>\n<li>I have <a href=\"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\" rel=\"nofollow noreferrer\">Iris-Sepal-Petal-Dataset<\/a> with Sepal (<em>Length &amp; Width<\/em>) and Petal (<em>Length &amp; Width<\/em>)<\/li>\n<li>Last column in data-set is 'Binomial ClassName'<\/li>\n<li>I am training the data-set with Multiclass Decision Forest Algorithm and splitting the data with different random seeds 321, 123 and 12345 in order<\/li>\n<li>It affects the final quality of trained model. Random seed#123 being best of Prediction probability score: 1.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/12OyD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/12OyD.png\" alt=\"ML Studio Snap\"><\/a><\/p>\n\n<hr>\n\n<p><strong>Observations<\/strong><\/p>\n\n<p><strong>1. Random seed: 321<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" alt=\"Random-seed-321\"><\/a><\/p>\n\n<p><strong>2. Random seed: 123<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" alt=\"Random-seed-123\"><\/a><\/p>\n\n<p><strong>3. Random seed: 12345<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" alt=\"Random-seed-12345\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":9,
        "Question_creation_date":"2019-07-02 08:27:18.867 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-07-02 11:29:03.383 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio|random-seed|iris-dataset",
        "Question_view_count":2046,
        "Owner_creation_date":"2016-10-05 18:11:48.437 UTC",
        "Owner_last_access_date":"2022-07-24 08:26:07.79 UTC",
        "Owner_reputation":1849,
        "Owner_up_votes":366,
        "Owner_down_votes":21,
        "Owner_views":253,
        "Answer_body":"<blockquote>\n  <p>What is a Random Seed Integer?<\/p>\n<\/blockquote>\n\n<p>Will not go into any details regarding what a random seed is in general; there is plenty of material available by a simple web search (see for example <a href=\"https:\/\/stackoverflow.com\/questions\/22639587\/random-seed-what-does-it-do\">this SO thread<\/a>).<\/p>\n\n<p>Random seed serves just to initialize the (pseudo)random number generator, mainly in order to make ML examples reproducible.<\/p>\n\n<blockquote>\n  <p>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/p>\n<\/blockquote>\n\n<p>Arguably this is already answered implicitly above: you are simply not supposed to choose any particular random seed, and your results should be roughly the same across different random seeds.<\/p>\n\n<blockquote>\n  <p>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/p>\n<\/blockquote>\n\n<p>Now, to the heart of your question. The answer <em>here<\/em> (i.e. with the iris dataset) is the <strong>small-sample effects<\/strong>...<\/p>\n\n<p>To start with, your reported results across different random seeds are not <em>that<\/em> different. Nevertheless, I agree that, at first sight, a difference in macro-average precision of 0.9 and 0.94 might <em>seem<\/em> large; but looking more closely it is revealed that the difference is really not an issue. Why?<\/p>\n\n<p>Using the 20% of your (only) 150-samples dataset leaves you with only 30 samples in your test set (where the evaluation is performed); this is stratified, i.e. about 10 samples from each class. Now, for datasets of <em>that<\/em> small size, it is not difficult to imagine that a difference in the correct classification of <strong>only 1-2<\/strong> samples can have this apparent difference in the performance metrics reported.<\/p>\n\n<p>Let's try to verify this in scikit-learn using a decision tree classifier (the essence of the issue does not depend on the specific framework or the ML algorithm used):<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_iris(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321, stratify=y)\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n<\/code><\/pre>\n\n<p>Result:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  9  1]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.90      0.95        10\n           2       0.91      1.00      0.95        10\n\n   micro avg       0.97      0.97      0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n<\/code><\/pre>\n\n<p>Let's repeat the code above, changing only the <code>random_state<\/code> argument in <code>train_test_split<\/code>; for <code>random_state=123<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  7  3]\n [ 0  2  8]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.78      0.70      0.74        10\n           2       0.73      0.80      0.76        10\n\n   micro avg       0.83      0.83      0.83        30\n   macro avg       0.84      0.83      0.83        30\nweighted avg       0.84      0.83      0.83        30\n<\/code><\/pre>\n\n<p>while for <code>random_state=12345<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  8  2]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.80      0.89        10\n           2       0.83      1.00      0.91        10\n\n   micro avg       0.93      0.93      0.93        30\n   macro avg       0.94      0.93      0.93        30\nweighted avg       0.94      0.93      0.93        30\n<\/code><\/pre>\n\n<p>Looking at the <em>absolute numbers<\/em> of the 3 confusion matrices (in <em>small samples<\/em>, percentages can be <strong>misleading<\/strong>), you should be able to convince yourself that the differences are not that big, and they can be arguably justified by the random element inherent in the whole procedure (here the exact split of the dataset into training and test).<\/p>\n\n<p>Should your test set be significantly bigger, these discrepancies would be practically negligible... <\/p>\n\n<p>A last notice; I have used the exact same seed numbers as you, but this does not actually mean anything, as in general the random number generators <em>across<\/em> platforms &amp; languages are not the same, hence the corresponding seeds are not actually compatible. See own answer in <a href=\"https:\/\/stackoverflow.com\/questions\/52293899\/are-random-seeds-compatible-between-systems\">Are random seeds compatible between systems?<\/a> for a demonstration.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-07-02 12:17:30.057 UTC",
        "Answer_score":2.0,
        "Owner_location":"India",
        "Answer_last_edit_date":"2019-07-02 12:22:31.17 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56848293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35237226,
        "Question_title":"Cannot run huge Python program",
        "Question_body":"<p>I am trying to run a python program using Pycharm IDE but unable to do so without stumbling into \"Your system has run out of application memory\". After some research I came across a suggestion of using Microsoft Azure ML. Can anyone point me to some helpful links that can get me started or any other suggestions at all?<\/p>\n\n<p>Edit: I am working with a data that has 400,000 samples and ~5000 samples and I want to use chi2 feature selection but I am unable to run the program.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-02-06 04:10:09.19 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-01-04 09:42:15.08 UTC",
        "Question_score":1,
        "Question_tags":"python|pycharm|azure-machine-learning-studio",
        "Question_view_count":118,
        "Owner_creation_date":"2016-01-31 00:41:27.397 UTC",
        "Owner_last_access_date":"2016-12-03 00:21:09.023 UTC",
        "Owner_reputation":115,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>You can use: PyPy to run your program with less memory usage and more speed. see this <a href=\"http:\/\/pypy.org\/\" rel=\"nofollow\">pypy site<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-06 04:23:52.4 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35237226",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65556574,
        "Question_title":"How to make prediction after model registration in azure?",
        "Question_body":"<p>I created a simply model and then registered in azure. How can I make a prediction?<\/p>\n<pre><code>from sklearn import svm\nimport joblib\nimport numpy as np\n\n# customer ages\nX_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nX_train = X_train.reshape(-1, 1)\n# churn y\/n\ny_train = [&quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;]\n\nclf = svm.SVC(gamma=0.001, C=100.)\nclf.fit(X_train, y_train)\n\njoblib.dump(value=clf, filename=&quot;churn-model.pkl&quot;)\n<\/code><\/pre>\n<p>Registration:<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.get(name=&quot;myworkspace&quot;, subscription_id='My_subscription_id', resource_group='ML_Lingaro')\n\nfrom azureml.core.model import Model\nmodel = Model.register(workspace=ws, model_path=&quot;churn-model.pkl&quot;, model_name=&quot;churn-model-test&quot;)\n<\/code><\/pre>\n<p>Prediction:<\/p>\n<pre><code>from azureml.core.model import Model\nimport os\n\nmodel = Model(workspace=ws, name=&quot;churn-model-test&quot;)\nX_test = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nmodel.predict(X_test) ???? \n<\/code><\/pre>\n<p>Error: <code>AttributeError: 'Model' object has no attribute 'predict'<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-04 01:09:35.69 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-04 01:24:17.017 UTC",
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":540,
        "Owner_creation_date":"2020-11-20 01:00:01.337 UTC",
        "Owner_last_access_date":"2021-04-10 20:06:50.227 UTC",
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":"<p>great question -- I also had the same misconception starting out. The missing piece is that there's a difference between model 'registration' and model 'deployment'. Registration is simply for tracking and for easy downloading at a later place and time. Deployment is what you're after, making a model available to be scored against.<\/p>\n<p>There's a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">whole section in the docs about deployment<\/a>. My suggestion would be to deploy it locally first for testing.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-04 05:20:26.627 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65556574",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40028165,
        "Question_title":"Azure ML's web service asking for label?",
        "Question_body":"<p>I built a linear regression algorithm in Azure ML. On the &quot;Score Model&quot; module I can actually see the predictions and the rest of the features. However, when I deploy this project as a web service, the service is expecting the actual label of the data (e.g. I'm trying to predict a house's price and it asks me for the price of the house to make the prediction), which doesn't make any sense to me... What am I doing wrong? On the &quot;Train Model&quot; module I set that the label column is the HousePrice, which is what I'm trying to predict...<\/p>\n<p>This is my model:\n<a href=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I tried leaving that field blank but the prediction returns null...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-10-13 18:16:02.787 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1012,
        "Owner_creation_date":"2014-06-02 17:25:36.86 UTC",
        "Owner_last_access_date":"2022-09-12 15:39:08.48 UTC",
        "Owner_reputation":1102,
        "Owner_up_votes":390,
        "Owner_down_votes":25,
        "Owner_views":120,
        "Answer_body":"<p>The input schema (names\/types of required input) based on the location in the graph where you attach the \"Web Service Input\" module. To get the schema you want, you will need to find -- or if necessary, create -- a place in the experiment where the data has the column names\/types you desire.<\/p>\n\n<p>Consider this simple example experiment that predicts whether a field called \"income\" will be above or below $50k\/year:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When we click \"Set up web service\", the following graph is automatically generated:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Since the input dataset and \"Web service input\" modules are connected to the same port, the web service schema will perfectly match the schema of the input dataset. This is unfortunate because the input dataset contains a column called \"income\", which is what our web service is supposed to predict -- this is equivalent to the problem that you are having.<\/p>\n\n<p>To get around it, we need to create a place in our experiment graph where we've dropped the unneeded \"income\" field from the input dataset, and attach the \"Web service input\" module there:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>With this arrangement, the web service only requests the features actually needed to score the model. I'm sure you can use a similar method to create a predictive experiment with whatever input schema you need for your own work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-17 18:55:27.013 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40028165",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36127510,
        "Question_title":"How to use Azure Data Lake Store as an input data set for Azure ML?",
        "Question_body":"<p>I am moving data into Azure Data Lake Store and processing it using Azure Data Lake Analytics. Data is in form of XML and I am reading it through <a href=\"https:\/\/github.com\/Azure\/usql\/tree\/master\/Examples\/DataFormats\/Microsoft.Analytics.Samples.Formats\" rel=\"nofollow\">XML Extractor<\/a>. Now I want to access this data from Azure ML and it looks like Azure Data Lake store is not directly supported at the moment. <\/p>\n\n<p>What are the possible ways to use Azure Data Lake Store with Azure ML?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-21 09:42:18.21 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-data-lake",
        "Question_view_count":963,
        "Owner_creation_date":"2010-05-23 18:06:11.227 UTC",
        "Owner_last_access_date":"2022-09-23 09:27:27.487 UTC",
        "Owner_reputation":838,
        "Owner_up_votes":32,
        "Owner_down_votes":1,
        "Owner_views":101,
        "Answer_body":"<p>Right now, Azure Data Lake Store is not a supported source, as you note.  That said, Azure Data Lake Analytics can also be used to write data out to Azure Blob Store, and so you can use that as an approach to process the data in U-SQL and then stage it for Azure Machine Learning to process it from Blob store.  When Azure ML supports Data Lake store, then you can switch that over. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-03-23 16:22:08.12 UTC",
        "Answer_score":4.0,
        "Owner_location":"Pakistan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36127510",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58906453,
        "Question_title":"H2O Download CSV in Azure Machine Learning",
        "Question_body":"<p>I am trying to build a ML model in Azure Machine Learning using H2o AutoML and could successfully create the model and do prediction.\nWhat I am struggling with is to download the result as csv (ideally to my local PC).<\/p>\n\n<p>The code I used is :<\/p>\n\n<pre><code>#Predict on the whole dataset\npred = best_model.predict(data)\ndata_pred = data.cbind(pred)\n\n# Download as csv\nh2o.download_csv(data_pred,'data_pred .csv')\n<\/code><\/pre>\n\n<p>The above code runs without any error &amp; shows <strong><em>'\/mnt\/azmnt\/code\/Users\/SA\/data_pred.csv'<\/em><\/strong> as the result message. I assume the csv has been created succesfully.<\/p>\n\n<p>But I don't know where to locate it.\nI searched in AzureML datasets but there is none. Appreciate if someone can help me with this. Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-18 00:09:32.023 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|download|h2o|automl|azure-machine-learning-service",
        "Question_view_count":60,
        "Owner_creation_date":"2015-10-09 15:15:37.137 UTC",
        "Owner_last_access_date":"2022-09-21 04:35:09.2 UTC",
        "Owner_reputation":167,
        "Owner_up_votes":264,
        "Owner_down_votes":0,
        "Owner_views":69,
        "Answer_body":"<p>H2O Documentation says that:<\/p>\n\n<p><code>h2o.h2o.download_csv(data, filename)<\/code><\/p>\n\n<p><code>data : H2OFrame<\/code> An H2OFrame object to be downloaded.<\/p>\n\n<p><code>filename : str<\/code> A string indicating the name that the CSV file should be should be saved to.<\/p>\n\n<p>Additionally, as you have written in your question <code>\/mnt\/azmnt\/code\/Users\/SA\/data_pred.csv'<\/code> should be the path.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-11-18 00:20:23.173 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58906453",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":27461432,
        "Question_title":"Cannot connect PlainText (JSON) to Dataset at Azure Machine Learning",
        "Question_body":"<p>I uploaded a PlainText file in a JSON format to the new Azure Machine Learning Studio (studio.azureml.net), but I cannot connect the PlainText object with any module. I get all the time the error message \"Cannot connect PlainText to Dataset...\". <\/p>\n\n<p>At the documentation (<a href=\"http:\/\/help.azureml.net\/Content\/html\/e8219c57-e8dd-4989-9559-bbd73ba5bcea.htm\" rel=\"nofollow\">here<\/a>) is written that \"Plain text can be read and then split up into columns with the help of downstream preprocessing modules.\", but I can't find any downstream preprocessing modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2014-12-13 17:07:45.2 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2015-10-30 08:07:34.607 UTC",
        "Question_score":5,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":2157,
        "Owner_creation_date":"2014-08-18 15:14:53.79 UTC",
        "Owner_last_access_date":"2022-02-02 05:52:18.31 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>Actually Azure ML can't process JSON data. It will probably be added in a future update, but the easiest way (in my opinion) to consume that data is to convert it into CSV format. This can be done quickly with Power Query. Then you upload the CSV file as a new dataset.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2014-12-18 16:18:15.8 UTC",
        "Answer_score":6.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/27461432",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62407943,
        "Question_title":"Restrict the number of nodes used by an Azure Machine Learning pipeine",
        "Question_body":"<p>I have written a pipeline that I want to run on a remote compute cluster within Azure Machine Learning. My aim is to process a large amount of historical data, and to do this I will need to run the pipeline on a large number of input parameter combinations.<\/p>\n\n<p>Is there a way to restrict the number of nodes that the pipeline uses on the cluster? By default it will use all the nodes available to the cluster, and I would like to restrict it so that it only uses a pre-defined maximum. This allows me to leave the rest of the cluster free for other users.<\/p>\n\n<p>My current code to start the pipeline looks like this:<\/p>\n\n<pre><code># Setup the pipeline\nsteps = [data_import_step] # Contains PythonScriptStep\npipeline = Pipeline(workspace=ws, steps=steps)\npipeline.validate()\n\n# Big long list of historical dates that I want to process data for\ndts = pd.date_range('2019-01-01', '2020-01-01', freq='6H', closed='left')\n# Submit the pipeline job\nfor dt in dts:\n    pipeline_run = Experiment(ws, 'my-pipeline-run').submit(\n        pipeline,\n        pipeline_parameters={\n            'import_datetime': dt.strftime('%Y-%m-%dT%H:00'),\n        }\n    )\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-06-16 12:00:24.897 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":274,
        "Owner_creation_date":"2014-06-25 12:11:55.16 UTC",
        "Owner_last_access_date":"2022-09-24 10:12:50.483 UTC",
        "Owner_reputation":1534,
        "Owner_up_votes":171,
        "Owner_down_votes":3,
        "Owner_views":56,
        "Answer_body":"<p>For me, the killer feature of Azure ML is not having to worry about load balancing like this. Our team has a compute target with <code>max_nodes=100<\/code> for every feature branch and we have <code>Hyperdrive<\/code> pipelines that result in 130 runs for each pipeline.<\/p>\n<p>We can submit multiple <code>PipelineRun<\/code>s back-to-back and the orchestrator does the heavy lifting of queuing, submitting, all the runs so that the <code>PipelineRun<\/code>s execute in the serial order I submitted them, and that the cluster is never overloaded. This works without issue for us 99% of the time.<\/p>\n<p>If what you're looking for is that you'd like the <code>PipelineRun<\/code>s to be executed in parallel, then you should check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-parallel-run-step#build-and-run-the-pipeline-containing-parallelrunstep\" rel=\"nofollow noreferrer\"><code>ParallelRunStep<\/code><\/a>.<\/p>\n<p>Another option is to isolate your computes. You can have up to 200 <code>ComputeTarget<\/code>s per workspace. Two 50-node <code>ComputeTarget<\/code>s cost the same as one 100-node <code>ComputeTarget<\/code>.<\/p>\n<p>On our team, we use <a href=\"https:\/\/www.pygit2.org\/\" rel=\"nofollow noreferrer\"><code>pygit2<\/code><\/a> to have a <code>ComputeTarget<\/code> created for each feature branch, so that, as data scientists, we can be confident that we're not stepping on our coworkers' toes.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-06-19 20:06:47.007 UTC",
        "Answer_score":2.0,
        "Owner_location":"London, UK",
        "Answer_last_edit_date":"2020-06-22 16:22:29.4 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62407943",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42145256,
        "Question_title":"Share dataset between two azureml environnement",
        "Question_body":"<p>a friend have sent me a python3 notebook with his dataset to validate his notebook.<\/p>\n\n<p>but when i try to use his dataset on my azureml workspace i have an error saying that the dataset does not exist<\/p>\n\n<p>he sent me his datset code :<\/p>\n\n<pre><code>from azureml import Workspace\n\nws = Workspace(\n    workspace_id='toto',\n    authorization_token='titi',\n    endpoint='https:\/\/studioapi.azureml.net'\n)\nds = ws.datasets['mini.csv00']\nframe = ds.to_dataframe()\n\nframe\n<\/code><\/pre>\n\n<p>when i try to use it i have a :<\/p>\n\n<pre><code>ndexError                                Traceback (most recent call last)\n&lt;ipython-input-7-5f41120e38e4&gt; in &lt;module&gt;()\n----&gt; 1 ds = ws.datasets['mini.csv00']\n      2 frame = ds.to_dataframe()\n      3 \n      4 frame\n\n\/home\/nbuser\/anaconda3_23\/lib\/python3.4\/site-packages\/azureml\/__init__.py in __getitem__(self, index)\n    461                     return self._create_dataset(dataset)\n    462 \n--&gt; 463         raise IndexError('A data set named \"{}\" does not exist'.format(index))\n    464 \n    465     def add_from_dataframe(self, dataframe, data_type_id, name, description):\n\nIndexError: A data set named \"mini.csv00\" does not exist\n<\/code><\/pre>\n\n<p>error ...<\/p>\n\n<p>But when i try it on my computer jupyter it works.\nAny ideas ?<\/p>\n\n<p>Thanks and regards<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-02-09 19:28:32.167 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|dataset|jupyter|azure-machine-learning-studio",
        "Question_view_count":108,
        "Owner_creation_date":"2010-08-05 09:07:28.53 UTC",
        "Owner_last_access_date":"2022-09-11 14:03:07.34 UTC",
        "Owner_reputation":1048,
        "Owner_up_votes":199,
        "Owner_down_votes":1,
        "Owner_views":602,
        "Answer_body":"<p>I guess you are using Jupyter notebook on AzureML to do the experiment. In that case the <code>'mini.csv00'<\/code> should be in your experiments with <code>workspace_id='toto'<\/code>. <\/p>\n\n<p>Create a new experiment in your workspace named toto and put the dataset into it first. Then open the dataset using 'open in a new Notebook'. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ztIw0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ztIw0.png\" alt=\"enter image description here\"><\/a> <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2017-02-12 04:53:12.387 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42145256",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30092360,
        "Question_title":"How do i schedule Azure Machine learning web service in Azure Scheduler?",
        "Question_body":"<p>I have published the web service from Azure Machine Learning experiment and now i want this web service to be scheduled using Azure Scheduler<\/p>\n\n<p>Can somebody please state the procedure?<\/p>\n\n<p>I got the API KEY, REQUEST\/RESPONSE and Batch Execution URI from the web service homepage.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-05-07 05:05:21.057 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2015-05-14 15:25:31.74 UTC",
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-scheduler|azure-machine-learning-studio",
        "Question_view_count":1301,
        "Owner_creation_date":"2014-06-23 16:37:06.413 UTC",
        "Owner_last_access_date":"2020-06-18 08:44:47.883 UTC",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":"<p>You will need to first create a new job in the Azure management portal (<a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn495651.aspx\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn495651.aspx<\/a>), where you can configure the URL and the HTTP method to POST, and specify the body. However, the initial configuration screens don't let you add any headers, so once you have created the job, go in and edit it to add the following headers:<\/p>\n\n<p>Content-Type: application\/json<br>\nAccept: application\/json<br>\nAuthorization: Bearer <\/p>\n\n<p>This will work, but am wondering if this actually serves your purpose. If you're calling the synchronous (request response) endpoint of the AzureML service, you need to specify the inputs in the request payload, which is statically configured with the Azure Scheduler job. So you will effectively be repeating the same call over and over again. You may also want to explore <a href=\"http:\/\/azure.microsoft.com\/en-us\/services\/data-factory\/\" rel=\"nofollow\">Azure Data Factory<\/a> if your needs are served by calling the asynchronous (batch) endpoint of the AzureML service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-05-07 16:29:00.103 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30092360",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41603082,
        "Question_title":"401 Errors Calling the Microsoft Luis.ai Programmatic API",
        "Question_body":"<h2><strong>ASKING THIS HERE AT THE EXPLICIT REQUEST OF THE MICROSOFT AZURE SUPPORT TEAM.<\/strong><\/h2>\n\n<p>I've been attempting to call the MS Luis.ai <em>programmatic<\/em> API (bit.ly\/2iev01n) and have been receiving a 401 unauthorized response to every request. Here's a simple GET example: <code>https:\/\/api.projectoxford.ai\/luis\/v1.0\/prog\/apps\/{appId}\/entities?subscription-key={subscription_key}<\/code>.  <\/p>\n\n<p>I am providing my appId from the Luis.ai GUI (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/Cg2Fw.png\" alt=\"Luis.ai App Settings App Id\"><\/p>\n\n<p>I am providing my subscription key from Azure (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/GS2Fe.png\" alt=\"Azure Console\"><\/p>\n\n<p>The app ID and subscription key, sourced from above, are the exact same as what I'm using to hit the query API successfully (see note at bottom). My account is pay-as-you-go (not free).<\/p>\n\n<p><strong><em>Am I doing something wrong here? Is this API deprecated, moved, down, or out-of-sync with the docs?<\/em><\/strong><\/p>\n\n<p><strong>NOTE:<\/strong> I can manipulate my model through the online GUI but that approach will be far too manual for our business needs where our model will need to be programmatically updated as new business entities come into existence.  <\/p>\n\n<p><strong>NOTE:<\/strong> The programmatic API is different from the query API which has this request URL, which is working fine for me:<br>\n<code>https:\/\/api.projectoxford.ai\/luis\/v2.0\/apps\/{appId}?subscription-key={subscription_key}&amp;verbose=true&amp;q={utterance}<\/code>  <\/p>\n\n<p><strong>NOTE:<\/strong> There doesn't seem to be a Luis.ai programmatic API for v2.0--which is why the URLs from the query and programmatic APIs have different versions.  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2017-01-12 00:14:45.28 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2017-01-12 03:50:11.887 UTC",
        "Question_score":4,
        "Question_tags":"azure|botframework|chatbot|azure-machine-learning-studio|azure-language-understanding",
        "Question_view_count":1280,
        "Owner_creation_date":"2012-07-24 22:13:17.557 UTC",
        "Owner_last_access_date":"2022-09-24 00:34:08.103 UTC",
        "Owner_reputation":191,
        "Owner_up_votes":11,
        "Owner_down_votes":2,
        "Owner_views":27,
        "Answer_body":"<p>Answering my own question here:<\/p>\n\n<p>I have found my LUIS.ai programmatic API key. It is found by:\nLUIS.ai dashboard -> username (upper-right) -> settings in dropdown -> Subscription Keys tab -> Programmatic API Key<\/p>\n\n<p>It was not immediately obvious since it's found nowhere else: not alongside any of the other key listings in cognitive services or the LUIS.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-01-17 16:17:25.333 UTC",
        "Answer_score":7.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41603082",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46132850,
        "Question_title":"How to see the column that influences the prediction result the most?",
        "Question_body":"<p>I'm using Azure Machine Learning Studio in order to predict a column using Two-Class Boosted Decision Tree and split data. <\/p>\n\n<p>The diagram that I have assembled can be found here: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/U3Ns8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U3Ns8.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What I need is that I'd like to see the column in the dataset that affects and influences the prediction the most. In other words, the column that changes the prediction result more than the other columns in the dataset.<\/p>\n\n<p>Sorry if this has been asked before, but I couldn't find a proper answer to this simple question.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-09-09 16:39:31.127 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2017-09-09 17:25:37.157 UTC",
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":951,
        "Owner_creation_date":"2015-03-31 20:08:15.217 UTC",
        "Owner_last_access_date":"2022-09-23 08:12:53.993 UTC",
        "Owner_reputation":65,
        "Owner_up_votes":209,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>As said before, Permutation Feature Importance do the trick. Attach the Permutation Feature Importance block do the train block, click on the output port, and select visualize to get results of the module. The figure above shows the list of features sorted in descending order of their permutation importance scores. \n<a href=\"https:\/\/i.stack.imgur.com\/NQRsK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NQRsK.png\" alt=\"Importance Score output\"><\/a><\/p>\n\n<p>An advice: be careful when interpreting results of permutation score when you have high correlated features.<\/p>\n\n<p>For more info, see: \n<a href=\"https:\/\/standupdata.com\/category\/permutation-feature-importance\/\" rel=\"nofollow noreferrer\">https:\/\/standupdata.com\/category\/permutation-feature-importance\/<\/a> <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Permutation-Feature-Importance-5\" rel=\"nofollow noreferrer\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Permutation-Feature-Importance-5<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-09-09 17:53:27.98 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46132850",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66020144,
        "Question_title":"How can one download the outputs of historical Azure ML experiment Runs via the python API",
        "Question_body":"<p>I'm trying to write a script which can download the outputs from an Azure ML experiment Run after the fact.<\/p>\n<p>Essentially, I want to know how I can get a Run by its <code>runId<\/code> property (or some other identifier).<\/p>\n<p>I am aware that I have access to the Run object when I create it for the purposes of training. What I want is a way to recreate this Run object later in a separate script, possibly from a completely different environment.<\/p>\n<p>What I've found so far is a way to get a list of ScriptRun objects from an experiment via the <code>get_runs()<\/code> function. But I don't see a way to use one of these ScriptRun objects to create a Run object representing the original Run and allowing me to download the outputs.<\/p>\n<p>Any help appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-02-03 01:48:46.667 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1402,
        "Owner_creation_date":"2021-02-03 01:39:44.927 UTC",
        "Owner_last_access_date":"2021-05-19 00:46:14.763 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>I agree that this could probably be better documented, but fortunately, it's a simple implementation.<\/p>\n<p>this is how you get a run object for an already submitted run for <code>azureml-sdk&gt;=1.16.0<\/code> (for the older approach <a href=\"https:\/\/stackoverflow.com\/questions\/62949488\/amls-experiment-run-stuck-in-status-running\/62958369#62958369\">see my answer here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\nws = Workspace.from_config()\nrun = ws.get_run('YOUR_RUN_ID')\n<\/code><\/pre>\n<p>once you have the <code>run<\/code> object, you can call methods like<\/p>\n<ul>\n<li><code>.get_file_names()<\/code> to see what files are available (the logs in <code>azureml-logs\/<\/code> and <code>logs\/azureml\/<\/code> will also be listed)<\/li>\n<li><code>.download_file()<\/code> to download an individual file<\/li>\n<li><code>.download_files()<\/code> to download all files that match a given prefix (or all the files)<\/li>\n<\/ul>\n<p>See the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py&amp;WT.mc_id=AI-MVP-5003930\" rel=\"noreferrer\">Run object docs<\/a> for more details.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-02-03 20:43:11.07 UTC",
        "Answer_score":7.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66020144",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44881303,
        "Question_title":"Best way to import MongoDB data in Azure Machine Learning",
        "Question_body":"<p>I have a MongoDB database (the Bitnami one) hosted on Azure. I want to import the data there to use it in my Azure Machine Learning experiment.<\/p>\n\n<p>Currently, I am exporting the data to <strong>.csv<\/strong> using <strong>mongoexport<\/strong> and then copy\/pasting it to the <strong>\"Enter Manually Data\"<\/strong> module. This is fine for small amounts of data but I would prefer to have a more robust technique for larger databases.<\/p>\n\n<p>I also thought about using the <strong>\"Import Data\"<\/strong> module from http url along with the <strong>http port (28017) of my mongodb<\/strong> instance but read this was not the recommended use of the http mongodb feature.<\/p>\n\n<p>Finally, I have installed <strong>cosmosDB<\/strong> instead of my bitnami MongoDB and it worked fine but this thing <strong>costs an arm<\/strong> when used with sitecore (it reaches around 100\u20ac per day) and we can't afford it so I switched back to by Mongo.<\/p>\n\n<p>So is there a better way to export data from Mongo to Azure ML ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-03 08:49:40.183 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mongodb|azure|azure-machine-learning-studio",
        "Question_view_count":724,
        "Owner_creation_date":"2015-09-03 08:08:18.017 UTC",
        "Owner_last_access_date":"2022-09-21 12:03:24.133 UTC",
        "Owner_reputation":781,
        "Owner_up_votes":516,
        "Owner_down_votes":0,
        "Owner_views":97,
        "Answer_body":"<p>one way is to use a Python code block in AzureML, something like this:<\/p>\n\n<pre><code>import pandas as p\nimport pymongo as m\n\ndef azureml_main():\n    c = m.MongoClient(host='host_IP')\n    a = p.DataFrame(c.database_names())\n    return a\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-09-06 08:28:58.047 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44881303",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57600154,
        "Question_title":"How to correctly specify a private ACR Docker image in an Azure ML Pipeline?",
        "Question_body":"<p>I created a private Azure Container Registry, and pushed a docker image to that registry. I was trying to understand the correct way to access that registry in my pipeline, and my understanding was that I needed to set the following info in the run configuration:<\/p>\n\n<pre><code>        run_config.environment.docker.base_image = \"myprivateacr.azurecr.io\/mydockerimage:0.0.1\"\n        run_config.environment.docker.base_image_registry.username = \"MyPrivateACR\"\n        run_config.environment.docker.base_image_registry.password = \"&lt;the password for the registry&gt;\"\n<\/code><\/pre>\n\n<p>Let's assume that I correctly provided the username and password. Any idea why this didn't work? Or: is there an example of a pipeline notebook that uses a docker image that's in a private docker registry, and thus deals with this type of authentication issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-21 23:02:53.66 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"docker|azure-machine-learning-service",
        "Question_view_count":278,
        "Owner_creation_date":"2017-04-11 16:38:45.063 UTC",
        "Owner_last_access_date":"2020-03-06 06:36:54.733 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>There's a separate address property for a custom image registry. Try specifying it this way:<\/p>\n\n<pre><code>run_config.environment.docker.base_image = \"mydockerimage:0.0.1\"\nrun_config.environment.docker.base_image_registry.address = \"myprivateacr.azurecr.io\"\nrun_config.environment.docker.base_image_registry.username = \"MyPrivateACR\"\nrun_config.environment.docker.base_image_registry.password = \"&lt;the password for the registry&gt;\"\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-08-22 13:40:55.417 UTC",
        "Answer_score":2.0,
        "Owner_location":"Redmond, WA, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57600154",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70873347,
        "Question_title":"Recommended options for Feature store in Azure ML",
        "Question_body":"<p>This is regard to ML Feature Stores, is Feast the recommended option today for Feature Store with Azure ML or is there any other options?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-27 04:24:37.277 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":327,
        "Owner_creation_date":"2021-09-24 05:28:30.82 UTC",
        "Owner_last_access_date":"2022-04-25 04:15:48.037 UTC",
        "Owner_reputation":107,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>We have roadmap to support that is something more native and also tightly integrates into Azure ML.<\/p>\n<p>Here is <a href=\"https:\/\/techcommunity.microsoft.com\/t5\/ai-customer-engineering-team\/bringing-feature-store-to-azure-from-microsoft-azure-redis-and\/ba-p\/2918917\" rel=\"nofollow noreferrer\">doc<\/a> to integration with OSS tool such as Hopsworks\/Feast and leveraging existing functionalities (designer\/pipelines, dataset) for an end-to-end &quot;feature store&quot; solution.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-01-27 07:17:35.687 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70873347",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73282180,
        "Question_title":"In AzureML, start_logging will start asynchronous execution or synchronous execution?",
        "Question_body":"<p>It was written in the Microsoft AzureML documentation, &quot;A run represents a single trial of an experiment. Runs are used to monitor the asynchronous execution of a trial&quot; and A Run object is also created when you submit or start_logging with the Experiment class.&quot;<\/p>\n<p>Related to <code>start_logging<\/code>, as far as I know, when we have simply started the run by executing this <code>start logging<\/code> method. We have to stop, or complete by <code>complete<\/code> method when the run is completed. This is because  <code>start_logging<\/code> is a synchronized way of creating an experiment. However, Run object created from <code>start_logging<\/code> is to monitor the asynchronous execution of a trial.<\/p>\n<p>Can anyone clarify whether <code>start_logging<\/code> will start asynchronous execution or synchronous execution?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-08 17:55:30.19 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-12 01:22:46.787 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":61,
        "Owner_creation_date":"2018-05-02 19:00:43 UTC",
        "Owner_last_access_date":"2022-09-16 13:48:06.8 UTC",
        "Owner_reputation":27,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p><strong>start_logging<\/strong> will be considered as <strong>asynchronous<\/strong> execution as this generates the multiple interactive run sessions. In a specific experiment, there is a chance of multiple interactive sessions, that work parallelly and there will be no scenario to be followed in sequential.<\/p>\n<p>The individual operation can be performed and recognized based on the parameters like <strong>args<\/strong>  and <strong>kwargs<\/strong>.<\/p>\n<p>When the start_logging is called, then an interactive run like <strong>jupyter notebook<\/strong> was created. The complete metrics and components which are created when the start_logging was called will be utilized. When the output directory was mentioned for each interactive run, based on the args value, the output folder will be called seamlessly.<\/p>\n<p>The following code block will help to define the operation of start_logging<\/p>\n<pre><code>experiment = Experiment(your_workspace, &quot;your_experiment_name&quot;)\n   run = experiment.start_logging(outputs=None, snapshot_directory=&quot;.&quot;, display_name=&quot;test&quot;)\n   ...\n   run.log_metric(&quot;Accuracy_Value&quot;, accuracy)\n   run.complete()\n<\/code><\/pre>\n<p>the below code block will be defining the basic syntax of start_logging<\/p>\n<pre><code>start_logging(*args, **kwargs)\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-08-09 12:29:07.607 UTC",
        "Answer_score":1.0,
        "Owner_location":"Ottawa, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73282180",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37519858,
        "Question_title":"What type should the returned scores from an R scoring script?",
        "Question_body":"<p>I am attempting to develop an Azure ML experiment that uses R to perform predictions of a continuous response variable. The initial experiment is relatively simple, incorporating only a few experiment items, including \"Create R Model\", \"Train Model\" and \"Score Model\", along with some data input.<\/p>\n\n<p>I have written a training script and a scoring script, both of which appear to execute without errors when I run the experiment within ML Studio. However, when I examine the scored dataset, the score values are all missing values. So I am concerned that my scoring script could be returning scores incorrectly. Can anyone advise what type I should be returning? Is it meant to be a single column data.frame, or something else?<\/p>\n\n<p>It is also possible that my scores are not being properly calculated within the scoring script, although I have run the training and scoring scripts within R Studio, which shows the expected results. It would also be helpful if someone could suggest how to perform debugging of my scoring script in some way, so that I could determine whereabouts the code is failing to behave as expected.<\/p>\n\n<p>Thanks, Paul<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-30 07:23:50.317 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":238,
        "Owner_creation_date":"2016-05-30 01:28:09.107 UTC",
        "Owner_last_access_date":"2016-08-02 23:54:21.49 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Try using this sample and compare with yours - <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Compare-Sample-5-in-R-vs-Azure-ML-1\" rel=\"nofollow\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Compare-Sample-5-in-R-vs-Azure-ML-1<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-05-31 06:15:35.14 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37519858",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65517560,
        "Question_title":"Failure reading parquet files",
        "Question_body":"<p>Azure ML fails to read tabular data set from parquet files, many parquet files.<\/p>\n<p>Creating datasets<\/p>\n<pre><code>from azureml.data.datapath import DataPath\ndatastore_path = [DataPath(datastore, 'churn')]\ntabular_dataset = Dataset.Tabular.from_parquet_files(path=datastore_path)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2020-12-31 06:47:36.717 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1008,
        "Owner_creation_date":"2020-04-14 14:36:43.487 UTC",
        "Owner_last_access_date":"2022-01-04 01:54:47.8 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>Add extensions: *.parquet:<\/p>\n<pre><code>from azureml.data.datapath import DataPath\ndatastore_path = [DataPath(datastore, 'churn\/*.parquet')]\ntabular_dataset = Dataset.Tabular.from_parquet_files(path=datastore_path)\n<\/code><\/pre>\n<p>Other ways to not read all data into memory at once would be to use <code>skip()<\/code> and <code>take()<\/code> on the TabularDataset to only request portions of source data at a time.\nOr to mount the Parquet files as a FileDataset and then construct separate TabularDataset for subsets of the files in your training script.<\/p>\n<p>Here\u2019s a sample notebook for your reference: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-12-31 09:26:04.367 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65517560",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55525445,
        "Question_title":"How to overcome TrainingException when training a large model with Azure Machine Learning service?",
        "Question_body":"<p>I'm training a large-ish model, trying to use for the purpose <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml#create-an-estimator\" rel=\"nofollow noreferrer\">Azure Machine Learning service<\/a> in Azure notebooks.<\/p>\n\n<p>I thus create an <code>Estimator<\/code> to train locally:<\/p>\n\n<pre><code>from azureml.train.estimator import Estimator\n\nestimator = Estimator(source_directory='.\/source_dir',\n                      compute_target='local',\n                      entry_script='train.py')\n<\/code><\/pre>\n\n<p>(my <code>train.py<\/code> should load and train starting from a large word vector file).<\/p>\n\n<p>When running with <\/p>\n\n<pre><code>run = experiment.submit(config=estimator)\n<\/code><\/pre>\n\n<p>I get <\/p>\n\n<blockquote>\n  <p>TrainingException: <\/p>\n  \n  <p>====================================================================<\/p>\n  \n  <p>While attempting to take snapshot of\n  \/data\/home\/username\/notebooks\/source_dir Your total\n  snapshot size exceeds the limit of 300.0 MB. Please see\n  <a href=\"http:\/\/aka.ms\/aml-largefiles\" rel=\"nofollow noreferrer\">http:\/\/aka.ms\/aml-largefiles<\/a> on how to work with large files.<\/p>\n  \n  <p>====================================================================<\/p>\n<\/blockquote>\n\n<p>The link provided in the error is likely <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/26076\" rel=\"nofollow noreferrer\">broken<\/a>. \nContents in my <code>.\/source_dir<\/code> indeed exceed 300 MB.<br>\nHow can I solve this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-04 21:50:42.303 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-04-07 13:10:37.94 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":1127,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":"<p>You can place the training files outside <code>source_dir<\/code> so that they don't get uploaded as part of submitting the experiment, and then upload them separately to the data store (which is basically using the Azure storage associated with your workspace). All you need to do then is reference the training files from <code>train.py<\/code>. <\/p>\n\n<p>See the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml\" rel=\"nofollow noreferrer\">Train model tutorial<\/a> for an example of how to upload data to the data store and then access it from the training file.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-04-05 06:29:53.38 UTC",
        "Answer_score":3.0,
        "Owner_location":"Verona, VR, Italy",
        "Answer_last_edit_date":"2019-04-05 07:25:03.93 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55525445",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67988138,
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_body":"<p>I'm doing following tutorial. I failed to run &quot;Create a control script&quot;.<\/p>\n<p>What could be wrong?<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a><\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0 \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).\nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5? \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff- \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49- \n866b- \n06c297c116cc\nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-15 14:22:54.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1241,
        "Owner_creation_date":"2016-11-04 09:17:30.693 UTC",
        "Owner_last_access_date":"2022-09-22 08:39:28.943 UTC",
        "Owner_reputation":1519,
        "Owner_up_votes":116,
        "Owner_down_votes":0,
        "Owner_views":375,
        "Answer_body":"<p>I think the error indicates that your environment is using pyarrow package which is of version 4.0.0 whereas azureml-dataset-runtime requires the package to be &gt;=0.17.0 but &lt;4.0.0<\/p>\n<p>It would be easier for you to uninstall the package and install a specific version. The list of releases of pyarrow are available here.<\/p>\n<p>Since you are using a notebook create new cells and run these commands.<\/p>\n<pre><code> !pip uninstall pyarrow\n !pip install -y pyarrow==3.0.0\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-16 16:35:31.177 UTC",
        "Answer_score":1.0,
        "Owner_location":"Finland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67988138",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58377444,
        "Question_title":"swagger.json example json for forecast model doesn't seem to return predictions",
        "Question_body":"<p>When trying to make predictions for forecasting models using Azure ML Service, the swagger.json includes the following schema for input:<\/p>\n\n<pre><code>\"example\": {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1.0}]}\n<\/code><\/pre>\n\n<p>However, when I feed this as an input to generate predictions, I receive the following error:<\/p>\n\n<pre><code>data= {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1 }]}\n# Convert to JSON string\ninput_data = json.dumps(data)\n\n# Set the content type\nheaders = {'Content-Type': 'application\/json'}\n# If authentication is enabled, set the authorization header\n#headers['Authorization'] = f'Bearer {key}'\n\n# Make the request and display the response\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)\n\n<\/code><\/pre>\n\n<pre><code>\"{\\\"error\\\": \\\"DataException:\\\\n\\\\tMessage: y values are present for each date. Nothing to forecast.\\\\n\\\\tInnerException None\\\\n\\\\tErrorResponse \\\\n{\\\\n    \\\\\\\"error\\\\\\\": {\\\\n        \\\\\\\"code\\\\\\\": \\\\\\\"UserError\\\\\\\",\\\\n        \\\\\\\"inner_error\\\\\\\": {\\\\n            \\\\\\\"code\\\\\\\": \\\\\\\"InvalidData\\\\\\\"\\\\n        },\\\\n        \\\\\\\"message\\\\\\\": \\\\\\\"y values are present for each date. Nothing to forecast.\\\\\\\"\\\\n    }\\\\n}\\\"}\"\n<\/code><\/pre>\n\n<p>I have tried not passing a y value, which causes an 'expected two axis got one' and passing 0 as the y_query. Any guidance on how to make predictions using this approach would be greatly appreciated. <\/p>\n\n<p>The documentation for web services is here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_creation_date":"2019-10-14 13:01:11.523 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":530,
        "Owner_creation_date":"2016-06-03 10:19:29.833 UTC",
        "Owner_last_access_date":"2022-07-13 18:55:59.383 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":"<p>Try using nan as the value for y_query. and make sure the date is the next time unit after the one that was used in the training set.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-18 16:52:16.483 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58377444",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37375506,
        "Question_title":"AzureML: \"Train Matchbox Recommender\" is not working and does not descibe the error",
        "Question_body":"<p>I tried to create my own experiment using the module, but failed to make it work.\nhere is the exception i got:  <\/p>\n\n<blockquote>\n  <p>Error 0018: Training dataset of user-item-rating triples contains invalid data.\n  [Critical]     {\"InputParameters\":{\"DataTable\":[{\"Rows\":14,\"Columns\":3,\"estimatedSize\":12668928,\"ColumnTypes\":{\"System.String\":1,\"System.Int32\":1,\"System.Double\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[10,0],\"1\":[5422.0,5999.0,873.0,6616.0,1758.0582820478173,7.0,0.0],\"2\":[1.0,1.0,1.0,1.0,0.0,1.0,0.0]}},{\"Rows\":2338,\"Columns\":3,\"estimatedSize\":1404928,\"ColumnTypes\":{\"System.String\":1,\"System.Int32\":1,\"System.Double\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[2338,0],\"1\":[7.5367835757057318,3.0,0.0,704.0,17.738259318519511,64.0,0.0],\"2\":[3.3737234816082085,1.5,0.0,352.0,8.3956874404883841,122.0,0.0]}},{\"Rows\":2532,\"Columns\":22,\"estimatedSize\":4648960,\"ColumnTypes\":{\"System.Int32\":10,\"System.String\":5,\"System.Double\":6,\"System.Boolean\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"1\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"2\":[613.0,613.0,613.0,613.0,0.0,1.0,0.0],\"3\":[0,2532],\"4\":[0,2532],\"5\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"6\":[23.647231437598673,19.99,1.99,149.99,17.237723488320938,90.0,0.0],\"7\":[0.043827014218009476,0.0,0.0,45.99,1.3460680431173562,3.0,0.0],\"8\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"9\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"10\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"11\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"12\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"13\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"14\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"15\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"16\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"17\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"18\":[2524,0],\"19\":[242,18],\"20\":[1,0],\"21\":[2524,0]}}],\"Generic\":{\"traitCount\":10,\"iterationCount\":5,\"batchCount\":4}},\"OutputParameters\":[],\"ModuleType\":\"Microsoft.Analytics.Modules.MatchboxRecommender.Dll\",\"ModuleVersion\":\" Version=6.0.0.0\",\"AdditionalModuleInfo\":\"Microsoft.Analytics.Modules.MatchboxRecommender.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.MatchboxRecommender.Dll.MatchboxRecommender;Train\",\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0018: Training dataset of user-item-rating triples contains invalid data.\\r\\n   at Microsoft.Analytics.Modules.MatchboxRecommender.Dll.Utilities.UpdateRatingMetadata(DataTable dataset, String datasetName) in d:\\_Bld\\8833\\7669\\Sources\\Product\\Source\\Modules\\MatchboxRecommender.Dll\\Utilities.cs:line 179\\r\\n   at Microsoft.Analytics.Modules.MatchboxRecommender.Dll.MatchboxRecommender.TrainImpl(DataTable userItemRatingTriples, DataTable userFeatures, DataTable itemFeatures, Int32 traitCount, Int32 iterationCount, Int32 batchCount) in d:\\_Bld\\8833\\7669\\Sources\\Product\\Source\\Modules\\MatchboxRecommender.Dll\\MatchboxRecommender.cs:line 62\",\"Warnings\":[],\"Duration\":\"00:00:00.6722068\"}\n  Module finished after a runtime of 00:00:01.1250071 with exit code -2\n  Module failed due to negative exit code of -2<\/p>\n<\/blockquote>\n\n<p>i've check the input data i'm setting as input user-place-rating table, record by record (no worries it's only 14 records) here it is: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LjyD6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LjyD6.png\" alt=\"the input data\"><\/a><\/p>\n\n<p>Here is a screenshot of the experiment:\n<a href=\"https:\/\/i.stack.imgur.com\/I43tG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/I43tG.png\" alt=\"the experiment\"><\/a><\/p>\n\n<p>since the error message is not very informative, I don't know where to start, so, if anybody has an idea, I would be happy to hear about it.<\/p>\n\n<p>Update:\nA friend of mine suggested to add \"Edit Metadata\" module to change the \"rating\" feature into \"int\" or \"float\" types, and the two other(placeID and userID) into string features. that didn't help as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-22 14:18:46.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-05-22 16:48:18.457 UTC",
        "Question_score":3,
        "Question_tags":"azure|machine-learning|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1187,
        "Owner_creation_date":"2011-10-31 11:53:18.253 UTC",
        "Owner_last_access_date":"2022-06-28 13:56:00.827 UTC",
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Answer_body":"<p>The matchbox recommender requires that ratings be numerical or categorical. Also when training, your ratings cannot all be the same.<\/p>\n\n<p>You need to use a metadata editor <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn905986.aspx\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn905986.aspx<\/a> to convert the ratings into numerical features and you need to make sure you are using a range of ratings.<\/p>\n\n<p>Then this should work!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-05-24 09:46:39.417 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37375506",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73192053,
        "Question_title":"azure cli not recognizing the following command az ml data create -f <file-name>.yml",
        "Question_body":"<p>got a folder called data-asset which contains a yaml file with the following<\/p>\n<pre><code>type: uri_folder\nname: &lt;name_of_data&gt;\ndescription: &lt;description goes here&gt;\npath: &lt;path&gt;\n<\/code><\/pre>\n<p>In a pipeline am referencing this using azure cli inline script using the following command az ml data create -f .yml but getting error<\/p>\n<p>full error-D:\\a\\1\\s\\ETL\\data-asset&gt;az ml data create -f data-asset.yml\nERROR: 'ml' is misspelled or not recognized by the system.<\/p>\n<p>Examples from AI knowledge base:\naz extension add --name anextension\nAdd extension by name<\/p>\n<p>trying to implement this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI<\/a><\/p>\n<p>how can a resolve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-01 10:02:24.177 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|yaml|azure-cli|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":112,
        "Owner_creation_date":"2020-11-30 17:06:44.663 UTC",
        "Owner_last_access_date":"2022-08-31 08:48:49.383 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":"<p>One of the workaround you can follow to resolve the above issue;<\/p>\n<p>Based on this <a href=\"https:\/\/github.com\/Azure\/azure-cli\/issues\/21390#issuecomment-1161782243\" rel=\"nofollow noreferrer\"><em><strong>GitHub issue<\/strong><\/em><\/a> as suggested by @<em>adba-msft<\/em> .<\/p>\n<blockquote>\n<p><strong>Please make sure that you have upgraded your azure cli to latest and<\/strong>\n<strong>Azure CLI ML extension v2 is being used.<\/strong><\/p>\n<\/blockquote>\n<p>To check and upgrade the cli we can use the below <code>cmdlts<\/code>:<\/p>\n<pre><code>az version\n\naz upgrade\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Uopde.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Uopde.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more information please refer this similar <a href=\"https:\/\/stackoverflow.com\/questions\/73110661\/create-is-misspelled-or-not-recognized-by-the-system-on-az-ml-dataset-create\"><em><strong>SO THREAD|'create' is misspelled or not recognized by the system on az ml dataset create<\/strong><\/em><\/a> .<\/p>\n<p>I did observe the same issue after trying the aforementioned suggestion by @<em>Dor Lugasi-Gal<\/em> it works for me with (in my case <code>az ml -h<\/code>) after installed the extension with  <code>az extension add -n ml -y<\/code> can able to get the result of <code>az ml -h<\/code> without any error.<\/p>\n<p><em><strong>SCREENSHOT FOR REFERENCE:-<\/strong><\/em><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/39LHa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/39LHa.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-01 13:39:44.08 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-08-01 14:09:07.923 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73192053",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69827748,
        "Question_title":"get metrics out of AutoMLRun based on test_data",
        "Question_body":"<p>I\u2019m using the following script to execute an AutoML run, also passing the test dataset<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>automl_settings = {\n    &quot;n_cross_validations&quot;: 10,\n    &quot;primary_metric&quot;: 'spearman_correlation',\n    &quot;enable_early_stopping&quot;: True,\n    &quot;max_concurrent_iterations&quot;: 10, \n    &quot;max_cores_per_iteration&quot;: -1,   \n    &quot;experiment_timeout_hours&quot;: 1,\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO}\nautoml_config = AutoMLConfig(task = 'regression',\n                             debug_log = 'automl_errors.log',\n                             compute_target = compute_target,\n                             training_data = training_data,\n                             test_data = test_data,\n                             label_column_name = label_column_name,\n                             model_explainability = True,\n                             **automl_settings                            )\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-03 15:42:35.38 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":85,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>Note that the TEST DATASET SUPPORT is a feature still in PRIVATE PREVIEW. It'll probably be released as PUBLIC PREVIEW later in NOVEMBER, but until then, you need to be enrolled in the PRIVATE PREVIEW in order to see the &quot;Test runs and metrics&quot; in the UI. You can send me an email to cesardl at microsoft dot com and send me your AZURE SUBSCRIPTION ID to be enabled so you see it in the UI.<\/p>\n<p>You can see further info on how to get started here:\n<a href=\"https:\/\/github.com\/Azure\/automl-testdataset-preview\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/automl-testdataset-preview<\/a><\/p>\n<p>About how to use it, you need to either provide the test_Data (specific Test AML Tabular Dataset that for instance you loaded from a file os split manually previously)\nor you can provide a test_size which is the % (i.e. 0.2 is 20%) to be split from the single\/original dataset.<\/p>\n<p>About the TEST metrics, since you can make multiple TEST runs against a single model, you need to go to the specific TEST run available under the link &quot;Test results&quot;<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3pPPS.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-03 18:28:47.853 UTC",
        "Answer_score":3.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69827748",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61392212,
        "Question_title":"Authentication Error: Compute instance for Azure Machine Learning",
        "Question_body":"<p>I created Compute instance in Azure Machine Learning in the Edge browser right after logging in. When it was started, I clicked on the Jupyter link. <\/p>\n\n<p>I got the following authentication error: \"User live.com#myname@outlook.com does not have access to compute instance vm-aml-lab4.\nOnly the creator can access a compute instance.\"<\/p>\n\n<p>Is there a way to avoid this error?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-23 16:28:33.437 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-06-11 14:17:10.16 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":953,
        "Owner_creation_date":"2012-02-27 20:09:22.2 UTC",
        "Owner_last_access_date":"2022-09-23 04:33:42.027 UTC",
        "Owner_reputation":445,
        "Owner_up_votes":377,
        "Owner_down_votes":0,
        "Owner_views":104,
        "Answer_body":"<p>Currently the AML compute instance only allows the creator to access the CI.It's known bug, once it's fixed we will update you. We think it is related to MSA accounts.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-04-24 07:23:49.463 UTC",
        "Answer_score":2.0,
        "Owner_location":"Kennett Square, PA",
        "Answer_last_edit_date":"2020-08-25 05:59:01.843 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61392212",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61803031,
        "Question_title":"Azure ML: Include additional files during model deployment",
        "Question_body":"<p>In my AML pipeline, I've got a model built and deployed to the AciWebservice. I now have a need to include some additional data that would be used by score.py. This data is in json format (~1mb) and is specific to the model that's built. To accomplish this, I was thinking of sticking this file in blob store and updating some \"placholder\" vars in the score.py during deployment, but it seems hacky. <\/p>\n\n<p>Here are some options I was contemplating but wasn't sure on the practicality<\/p>\n\n<p><strong>Option 1:<\/strong>\nIs it possible to include this file, during the model deployment itself so that it's part of the docker image? <\/p>\n\n<p><strong>Option 2:<\/strong>\nAnother possibility I was contemplating, would it be possible to include this json data part of the Model artifacts?<\/p>\n\n<p><strong>Option 3:<\/strong>\nHow about registering it as a dataset and pull that in the score file?<\/p>\n\n<p>What is the recommended way to deploy dependent files in a model deployment scenario?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-14 16:56:48.817 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-05-14 18:07:01.85 UTC",
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":866,
        "Owner_creation_date":"2012-02-23 16:54:25.41 UTC",
        "Owner_last_access_date":"2022-09-02 23:23:03.83 UTC",
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Answer_body":"<p>There are few ways to accomplish this:<\/p>\n\n<ol>\n<li><p>Put the additional file in the same folder as your model file, and <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-\" rel=\"nofollow noreferrer\">register<\/a> the whole folder as the model. In this approach the file is stored alongside the model.<\/p><\/li>\n<li><p>Put the file in a local folder, and specify that folder as source_directory in <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">InferenceConfig<\/a>. In this approach the file is re-uploaded every time you deploy a new endpoint.<\/p><\/li>\n<li><p>Use custom base image in InferenceConfig to bake the file into Docker image itself.<\/p><\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-05-14 19:28:31.663 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61803031",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71023918,
        "Question_title":"ModuleNotFound Error - Azure ML with prebuilt docker image",
        "Question_body":"<p>I have developed a module which works perfectly when executed locally.<\/p>\n<p>I have created an environment on azure using a prebuilt docker image found here:\n<strong>&quot;azureml\/minimal-ubuntu18.04-py37-cpu-inference&quot;<\/strong> <a href=\"https:\/\/mcr.microsoft.com\/v2\/_catalog\" rel=\"nofollow noreferrer\">https:\/\/mcr.microsoft.com\/v2\/_catalog<\/a>\n. Also, Using pythonScriptStep, to run a pipeline. Here is how the step looks<\/p>\n<pre><code>StepPreprocessing = PythonScriptStep(\n    name=&quot;Preprocessing&quot;,\n    script_name=e.preprocess_script_path,\n    arguments=[\n        &quot;--config_path&quot;, e.preprocess_config_path,\n        &quot;--task&quot;, e.preprocess_task,\n    ],\n    inputs=None,\n    compute_target=aml_compute,\n    runconfig=run_config,\n    source_directory=e.sources_directory,\n    allow_reuse=False\n)\nprint(&quot;Step Preprocessing created&quot;)\n<\/code><\/pre>\n<p>This results in error:<\/p>\n<pre><code>Traceback (most recent call last):\n[stderr]  File &quot;Pipeline\/custom_pipeline.py&quot;, line 4, in &lt;module&gt;\n[stderr]    from Preprocess.logger import logger\n[stderr]ModuleNotFoundError: No module named 'Preprocess'\n<\/code><\/pre>\n<p>in the 1st line of entry script (<strong>custom_pipeline.py<\/strong>):<\/p>\n<pre><code>import sys\nsys.path.append(&quot;.&quot;) \nfrom Preprocess.logger import logger\n<\/code><\/pre>\n<p>The folder structure is as:<\/p>\n<pre><code>-Preprocess\n  -__init__.py\n  - Module1\n    -__init__.py\n    -somefile.py\n  - Module2\n    -__init__.py\n    -someOtherfile.py\n  - Pipeline\n    -__init__.py\n    -custom_pipeline.py\n  - logger\n    -__init__.py\n    -logger.py\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-07 18:55:00.2 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|docker|azure-machine-learning-service",
        "Question_view_count":109,
        "Owner_creation_date":"2015-09-23 14:11:04.707 UTC",
        "Owner_last_access_date":"2022-09-23 08:54:35.743 UTC",
        "Owner_reputation":644,
        "Owner_up_votes":33,
        "Owner_down_votes":1,
        "Owner_views":126,
        "Answer_body":"<p>I found out that the python script step copies everything inside the source_dir and therefore in my case it was copying the modules and not the root folder. So I had to put the dir Preprocess inside another dir and mention the new dir as source_dir.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-11 18:41:46.183 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71023918",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67277764,
        "Question_title":"How to install OpenJDK library?",
        "Question_body":"<p>I created the following <code>environment.yml<\/code> file from my local Anaconda that contains an openjdk package.<\/p>\n<pre><code>name: venv\nchannels:\n  - defaults\ndependencies:\n  - openjdk=11.0.6\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6AlVr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6AlVr.png\" alt=\"Anaconda openjdk\" \/><\/a><\/p>\n<p>However, Azure Machine Learning couldn't install the openjdk package from the <code>environment.yml<\/code> file as module is not found.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/gxuS6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gxuS6.png\" alt=\"ResolvePackageNotFound\" \/><\/a><\/p>\n<p>Backstory:<\/p>\n<p>I'm building a machine learning model using H2O.ai Python library. Unfortunately, H2O.ai is written in Java so it requires Java to run. I've installed openjdk to my local Anaconda venv for running H2O.ai locally - it runs perfectly. However, I couldn't deploy this model to Azure Machine Learning because it couldn't install openjdk from requirements.txt or environment.yml as module not found.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-04-27 06:07:21.653 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-04-30 17:10:30.133 UTC",
        "Question_score":0,
        "Question_tags":"java|python|anaconda|h2o|azure-machine-learning-service",
        "Question_view_count":1389,
        "Owner_creation_date":"2019-06-07 06:29:38.77 UTC",
        "Owner_last_access_date":"2022-09-22 21:28:04.37 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":448,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":"<p>Solution:<\/p>\n<p>Install openjdk through conda but specify conda-forge as the channel to install the package from.<\/p>\n<pre><code>name: venv\nchannels:\n  - defaults\n  - conda-forge\ndependencies:\n  - conda-forge::openjdk=11.0.9.1\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AHCye.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AHCye.png\" alt=\"Conda Forge\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-01 14:44:33.88 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67277764",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57660058,
        "Question_title":"Azure ML SDK DataReference - File Pattern - MANY files",
        "Question_body":"<p>I\u2019m building out a pipeline that should execute and train fairly frequently.  I\u2019m following this: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline<\/a> <\/p>\n\n<p>Anyways, I\u2019ve got a stream analytics job dumping telemetry into .json files on blob storage (soon to be adls gen2).  Anyways, I want to find all .json files and use all of those files to train with.  I could possibly use just new .json files as well (interesting option honestly).<\/p>\n\n<p>Currently I just have the store mounted to a data lake and available; and it just iterates the mount for the data files and loads them up.<\/p>\n\n<ol>\n<li>How can I use data references for this instead?<\/li>\n<li>What does data references do for me that mounting time stamped data does not?\na.  From an audit perspective, I have version control, execution time and time stamped read only data.  Albeit, doing a replay on this would require additional coding, but is do-able.<\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-26 14:37:54.697 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":296,
        "Owner_creation_date":"2013-11-18 19:13:55.143 UTC",
        "Owner_last_access_date":"2022-09-13 18:41:22 UTC",
        "Owner_reputation":2682,
        "Owner_up_votes":75,
        "Owner_down_votes":4,
        "Owner_views":1006,
        "Answer_body":"<p>You could pass pointer to folder as an input parameter for the pipeline, and then your step can mount the folder to iterate over the json files.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-08-26 21:23:08.78 UTC",
        "Answer_score":1.0,
        "Owner_location":"Miami Beach, FL",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57660058",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41080045,
        "Question_title":"How can I use ML function in Azure Stream Analytics?",
        "Question_body":"<p>I try to use a trained model from Microsoft Azure Machine Learning Studio in Azure Stream Analytics.\nBefore I start work with my IoT-Stream sensor data, I try this sample: \n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/stream-analytics\/stream-analytics-machine-learning-integration-tutorial\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/stream-analytics\/stream-analytics-machine-learning-integration-tutorial<\/a><\/p>\n\n<p>I can deploy the web service and it works fine with a console application.\nThe result from web service:<\/p>\n\n<pre><code>{\n    \"Results\": {\n        \"output1\": {\n            \"type\": \"table\",\n            \"value\": {\n                \"ColumnNames\": [\"Sentiment\", \"Score\"],\n                \"ColumnTypes\": [\"String\", \"Double\"],\n                \"Values\": [\n                    [\"neutral\", \"0.564501523971558\"]\n                ]\n            }\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>The T-SQL in Stream Analytics from tutorial looks like:<\/p>\n\n<pre><code>WITH subquery AS (  \n    SELECT text, sentiment(text) as result from input  \n)  \n\nSelect text, result.[Scored Labels]  \nInto output  \nFrom subquery\n<\/code><\/pre>\n\n<p>Unfortunately it does not work. Can someone explain <code>result.[Scored Labels]<\/code><\/p>\n\n<p>Is it possible to debug my Stream Analytic job?\nI get no output. No result-file, no warning, no exception...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-12-10 20:33:54.54 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|stream-analytics",
        "Question_view_count":752,
        "Owner_creation_date":"2014-05-22 20:37:18.563 UTC",
        "Owner_last_access_date":"2022-09-22 21:26:19.833 UTC",
        "Owner_reputation":2437,
        "Owner_up_votes":791,
        "Owner_down_votes":261,
        "Owner_views":234,
        "Answer_body":"<p>It is not currently possible to test your query when you use a function to call out to Azure ML. The test query functionality runs in the web browser window so I guess they haven't implemented that feature yet. <\/p>\n\n<p>I expect if you start the job it will actually work. However you may need to change <code>result.[Scored Labels]<\/code> to match the columns in the Azure ML API output by saying <code>result.Sentiment<\/code> and <code>result.Score<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-12-11 09:40:33.937 UTC",
        "Answer_score":1.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41080045",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71407308,
        "Question_title":"Azure ML model to a container instance, call to the model fails when using the code provided in the \"Consume\" section of the endpoint (Python and C#)",
        "Question_body":"<p>After deploying an Azure ML model to a container instance, call to the model fails when using the code provided in the &quot;Consume&quot; section of the endpoint (Python and C#).<\/p>\n<p>I have trained a model in Azure Auto-ML and deployed the model to a container instance.<\/p>\n<p><strong>Now when I am try to use the Python code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: 502\nContent-Length: 55\nContent-Type: text\/html; charset=utf-8\nDate: Mon, 07 Mar 2022 12:32:07 GMT\nServer: nginx\/1.14.0 (Ubuntu)\nX-Ms-Request-Id: 768c2eb5-10f3-4e8a-9412-3fcfc0f6d648\nX-Ms-Run-Function-Failed: True\nConnection: close\n\n---------------------------------------------------------------------------\nJSONDecodeError Traceback (most recent call last)\n&lt;ipython-input-1-6eeff158e915&gt; in &lt;module&gt;\n48 # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n49 print(error.info())\n---&gt; 50 print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/init.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n352 parse_int is None and parse_float is None and\n353 parse_constant is None and object_pairs_hook is None and not kw):\n--&gt; 354 return _default_decoder.decode(s)\n355 if cls is None:\n356 cls = JSONDecoder\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in decode(self, s, _w)\n337\n338 &quot;&quot;&quot;\n--&gt; 339 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n340 end = _w(s, end).end()\n341 if end != len(s):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in raw_decode(self, s, idx)\n355 obj, end = self.scan_once(s, idx)\n356 except StopIteration as err:\n--&gt; 357 raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None\n358 return obj, end\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n<p><strong>If I use C# code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: BadGateway\nConnection: keep-alive\nX-Ms-Request-Id: 5c3543cf-29ac-46a3-a9fb-dcb6a0041b08\nX-Ms-Run-Function-Failed: True\nDate: Mon, 07 Mar 2022 12:38:32 GMT\nServer: nginx\/1.14.0 (Ubuntu)\n\n'&lt;=' not supported between instances of 'str' and 'int'\n<\/code><\/pre>\n<p><strong>The Python code I am using:<\/strong><\/p>\n<pre><code> import urllib.request\n import json\n import os\n import ssl\n    \n def allowSelfSignedHttps(allowed):\n     # bypass the server certificate verification on client side\n     if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n         ssl._create_default_https_context = ssl._create_unverified_context\n    \n allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n    \n data = {\n     &quot;Inputs&quot;: {\n         &quot;data&quot;:\n         [\n             {\n                 &quot;SaleDate&quot;: &quot;2022-02-08T00:00:00.000Z&quot;,\n                 &quot;OfferingGroupId&quot;: &quot;0&quot;,\n                 &quot;week_of_year&quot;: &quot;7&quot;,\n                 &quot;month_of_year&quot;: &quot;2&quot;,\n                 &quot;day_of_week&quot;: &quot;1&quot;\n             },\n         ]\n     },\n     &quot;GlobalParameters&quot;: {\n         &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n     }\n }\n    \n body = str.encode(json.dumps(data))\n    \n url = 'http:\/\/4a0427c2-30d4-477e-85f5-dfdfdfdfdsfdff623f.uksouth.azurecontainer.io\/score'\n api_key = '' # Replace this with the API key for the web service\n headers = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n    \n req = urllib.request.Request(url, body, headers)\n    \n try:\n     response = urllib.request.urlopen(req)\n    \n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(&quot;The request failed with status code: &quot; + str(error.code))\n    \n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n<\/code><\/pre>\n<p><strong>The C# code I have tried<\/strong>:<\/p>\n<pre><code> using System;\n using System.Collections.Generic;\n using System.IO;\n using System.Net.Http;\n using System.Net.Http.Headers;\n using System.Text;\n using System.Threading.Tasks;\n using Newtonsoft.Json;\n    \n namespace MLModelAPICall\n {\n     class Program\n     {\n         static void Main(string[] args)\n         {\n             InvokeRequestResponseService().Wait();\n         }\n    \n         static async Task InvokeRequestResponseService()\n         {\n             var handler = new HttpClientHandler()\n             {\n                 ClientCertificateOptions = ClientCertificateOption.Manual,\n                 ServerCertificateCustomValidationCallback =\n                         (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n             };\n             using (var client = new HttpClient(handler))\n             {\n                 \/\/ Request data goes here\n                 var scoreRequest = new\n                 {\n                     Inputs = new Dictionary&lt;string, List&lt;Dictionary&lt;string, string&gt;&gt;&gt;()\n                     {\n                         {\n                             &quot;data&quot;,\n                             new List&lt;Dictionary&lt;string, string&gt;&gt;()\n                             {\n                                 new Dictionary&lt;string, string&gt;()\n                                 {\n                                     {\n                                         &quot;SaleDate&quot;, &quot;2022-02-08T00:00:00.000Z&quot;\n                                     },\n                                     {\n                                         &quot;OfferingGroupId&quot;, &quot;0&quot;\n                                     },\n                                     {\n                                         &quot;week_of_year&quot;, &quot;7&quot;\n                                     },\n                                     {\n                                         &quot;month_of_year&quot;, &quot;2&quot;\n                                     },\n                                     {\n                                         &quot;day_of_week&quot;, &quot;1&quot;\n                                     }\n                                 }\n                             }\n                         }\n                     },\n                     GlobalParameters = new Dictionary&lt;string, string&gt;()\n                     {\n                         {\n                             &quot;quantiles&quot;, &quot;0.025,0.975&quot;\n                         }\n                     }\n                 };\n    \n    \n                 const string apiKey = &quot;&quot;; \/\/ Replace this with the API key for the web service\n                 client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(&quot;Bearer&quot;, apiKey);\n                 client.BaseAddress = new Uri(&quot;http:\/\/4a0427c2-30d4-477e-85f5-xxxxxxxxxxxxx.uksouth.azurecontainer.io\/score&quot;);\n    \n                 \/\/ WARNING: The 'await' statement below can result in a deadlock\n                 \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                 \/\/ One way to address this would be to call ConfigureAwait(false)\n                 \/\/ so that the execution does not attempt to resume on the original context.\n                 \/\/ For instance, replace code such as:\n                 \/\/      result = await DoSomeTask()\n                 \/\/ with the following:\n                 \/\/      result = await DoSomeTask().ConfigureAwait(false)\n    \n                 var requestString = JsonConvert.SerializeObject(scoreRequest);\n                 var content = new StringContent(requestString);\n    \n                 content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application\/json&quot;);\n    \n                 HttpResponseMessage response = await client.PostAsync(&quot;&quot;, content);\n    \n                 if (response.IsSuccessStatusCode)\n                 {\n                     string result = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(&quot;Result: {0}&quot;, result);\n                 }\n                 else\n                 {\n                     Console.WriteLine(string.Format(&quot;The request failed with status code: {0}&quot;, response.StatusCode));\n    \n                     \/\/ Print the headers - they include the requert ID and the timestamp,\n                     \/\/ which are useful for debugging the failure\n                     Console.WriteLine(response.Headers.ToString());\n    \n                     string responseContent = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(responseContent);\n                     Console.ReadLine();\n                 }\n             }\n         }\n     }\n }\n<\/code><\/pre>\n<p>Could you please help me with this issue? I am not sure what do to if Microsoft's provided code is erroring out, don't know what else to do.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-09 09:47:27.667 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":89,
        "Owner_creation_date":"2013-02-04 21:33:28.22 UTC",
        "Owner_last_access_date":"2022-09-23 11:51:21.363 UTC",
        "Owner_reputation":65842,
        "Owner_up_votes":1661,
        "Owner_down_votes":333,
        "Owner_views":4569,
        "Answer_body":"<p>After much more digging I found out that the &quot;Consume&quot; scripts provided with the endpoint are wrong (Python and C#) .<\/p>\n<p>When making a call to the endpoint the GlobalParameters expects an integer value, but the provided scripts have wrapped the values in double quotes hence making it a string:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n }\n<\/code><\/pre>\n<p>If you are using Python to consume the model, when making call to the endpoint your GlobalParameters should be define as this:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: [0.025,0.975]\n }\n<\/code><\/pre>\n<p>wrapped in square brackets<\/p>\n<blockquote>\n<p>[0.025,0.975]<\/p>\n<\/blockquote>\n<p>and not in double quotes &quot;<\/p>\n<blockquote>\n<p><em>I have also opened a ticket with microsoft so hopefully they will fix the code provided in the &quot;consume&quot; section of every endpoint<\/em><\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-09 14:14:58.18 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bolton, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71407308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30115812,
        "Question_title":"Error while running Azure Machine Learning web service but the experiment works fine",
        "Question_body":"<p>I have created the Azure ML experiment with R script module \nit works fine while we run the experiment but\n when we publish the web service it throws error http 500 \n ( I believe the error is causing in the R script module because other modules are running fine in web service but i can't debug the problem<\/p>\n\n<blockquote>\n  <p>Http status code: 500, Timestamp: Fri, 08 May 2015 04:23:14 GMT<\/p>\n<\/blockquote>\n\n<p>Also is there any limitation in r e.g. some function which wont work in web service<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-05-08 04:33:28.047 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2015-10-30 08:16:05.57 UTC",
        "Question_score":1,
        "Question_tags":"r|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":415,
        "Owner_creation_date":"2014-06-23 16:37:06.413 UTC",
        "Owner_last_access_date":"2020-06-18 08:44:47.883 UTC",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":"<p>I found the problem. I was facing this error because the R module in the Azure ML was was taking variable as the other data type and not producing any outputs results which i was checking through for loop which is why i was getting this error.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-08-14 08:09:05.913 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bengaluru, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30115812",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71292240,
        "Question_title":"How to replace missing datapoints with prior in MS Azure?",
        "Question_body":"<p>When using the ML-pipeline designer in MS Azure it is possible to clean missing data, namely by replacing them by means or constant values.<\/p>\n<p>In my dataset I have gaps, when the measured value did not change enough, thus I should want to replace the missing data with the last existing entry.\nSo from<\/p>\n<pre><code>VALUE A\n2\nNONE\nNONE\nNONE\n3\nNONE\nNONE\n<\/code><\/pre>\n<p>I would like to get<\/p>\n<pre><code>VALUE A\n2\n2\n2\n2\n3\n3\n3\n<\/code><\/pre>\n<p>This option is not available in the pipeline designer as far as I know. Can I manipulate the dataset somehow else within Azure, before training?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-28 08:23:08.14 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":13,
        "Owner_creation_date":"2020-11-26 11:40:24.85 UTC",
        "Owner_last_access_date":"2022-09-23 09:09:31.537 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>I figured it out, by using the Notebooks (do not work in Firefox for me, only on Chrome).\nThere it is possible to handle the dataset in python, transform it to pandas, manipulate it and save it to the datastore.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-14 08:58:23.807 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71292240",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70252478,
        "Question_title":"Azure Machine Learning Designer Error: JobConfigurationMaxSizeExceeded",
        "Question_body":"<p>I have an Azure Machine Learning Designer pipeline that I've run successfully many dozens of times.  Suddenly, today, The pipeline is getting down to the 'Train Model' node and failing with the following error:<\/p>\n<p><code>JobConfigurationMaxSizeExceeded: The specified job configuration exceeds the max allowed size of 32768 characters. Please reduce the size of the job's command line arguments and environment settings<\/code><\/p>\n<p>How do I address this error in designer-built pipelines?<\/p>\n<p>I have even gone back to previously successful runs of this pipeline and resubmitted one of these runs which also failed with the exact same error.  A resubmitted run should have the exact same pipeline architecture and input data (afaik), so it seems like a problem outside my control.<\/p>\n<p>Pipeline with error:\n<a href=\"https:\/\/i.stack.imgur.com\/uLoIe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uLoIe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Pipeline run overview:\n<a href=\"https:\/\/i.stack.imgur.com\/eTzTA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eTzTA.png\" alt=\"enter image description here\" \/><\/a>\nAny ideas?<\/p>\n<p>EDIT:  I'm able to repro this with a really simple pipeline.  Simply trying to exclude columns in a <code>Select Columns<\/code> node from a dataset gives me this error:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qZKj1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qZKj1.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-06 21:58:03.783 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-07 00:32:53.277 UTC",
        "Question_score":3,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":358,
        "Owner_creation_date":"2012-06-27 21:51:16.13 UTC",
        "Owner_last_access_date":"2022-09-21 21:19:20.11 UTC",
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Answer_body":"<p>This appears to be a bug introduced by Microsoft's rollout of their new Compute Common Runtime.<\/p>\n<p>If I go into any nodes failing with the <code>JobConfigurationMaxSizeExceeded<\/code> exception and manually set <code>AZUREML_COMPUTE_USE_COMMON_RUNTIME:false<\/code> in their  <code>Environment JSON<\/code> field, then they work correctly.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-12-07 04:44:33.883 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70252478",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60151965,
        "Question_title":"How can I access files (images) in an azureml FileDataSet?",
        "Question_body":"<p>I have uploaded a big (10+gb) dataset into Azure Blob Storage, containing thousands of images (jpg) format.<br>\nI registered the blob container in Azure Machine Learning Service as a data store and I also registered a File Dataset, pointing to the actual blob container, containing the images. (showing there are 44440 images).<\/p>\n\n<p>Now, I want to run a notebook (in AzureML) that needs to read a specific image and load it into an image (using <code>cv2.imread()<\/code>).  However, I don't seem to find the right documentation for this...  The only option I see is to download the entire dataset onto the local temp storage, which I prefer not to do (multiple giga bytes).<\/p>\n\n<p>Is there an option I can use to access the actual file reference and pass it to my 3rd party method?<\/p>\n\n<p>Below you can find some code that is relevant:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code># get workspace and datastore\nws = Workspace.from_config()\ndstore = ws.datastores[datastore_name]\nimage_dataset = ws.datasets[image_dataset_name]\n\nmounted_images = image_dataset.mount() \n\nimg = cv2.imread(mounted_images['my_file_name.jpg']) # this will not work\n<\/code><\/pre>\n\n<p>Any idea on how to get this to work?<\/p>\n\n<p>Thank you<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-10 13:56:49.563 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":3000,
        "Owner_creation_date":"2013-02-12 07:50:30.743 UTC",
        "Owner_last_access_date":"2022-09-21 18:28:12.907 UTC",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Answer_body":"<p>dataset.mount() actually returns a MountContext which has a mount_point attribute. <\/p>\n\n<p>So:<\/p>\n\n<p>img = cv2.imread(mounted_images.mount_point +\u2019\/my_file_name.jpg')<\/p>\n\n<p>Should hopefully work.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-02-10 16:15:54.33 UTC",
        "Answer_score":4.0,
        "Owner_location":"Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60151965",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34990561,
        "Question_title":"Azure Machine Learning Request Response latency",
        "Question_body":"<p>I have made an Azure Machine Learning Experiment which takes a small dataset (12x3 array) and some parameters and does some calculations using a few Python modules (a linear regression calculation and some more). This all works fine.<\/p>\n\n<p>I have deployed the experiment and now want to throw data at it from the front-end of my application. The API-call goes in and comes back with correct results, but it takes up to 30 seconds to calculate a simple linear regression. Sometimes it is 20 seconds, sometimes only 1 second. I even got it down to 100 ms one time (which is what I'd like), but 90% of the time the request takes more than 20 seconds to complete, which is unacceptable.<\/p>\n\n<p>I guess it has something to do with it still being an experiment, or it is still in a development slot, but I can't find the settings to get it to run on a faster machine.<\/p>\n\n<p>Is there a way to speed up my execution?<\/p>\n\n<p>Edit: To clarify: The varying timings are obtained with the same test data, simply by sending the same request multiple times. This made me conclude it must have something to do with my request being put in a queue, there is some start-up latency or I'm throttled in some other way.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-01-25 10:40:39.993 UTC",
        "Question_favorite_count":5.0,
        "Question_last_edit_date":"2016-01-27 16:15:36.527 UTC",
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1128,
        "Owner_creation_date":"2015-10-29 11:07:20.793 UTC",
        "Owner_last_access_date":"2020-05-19 23:12:48.357 UTC",
        "Owner_reputation":311,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Answer_body":"<p>First, I am assuming you are doing your timing test on the published AML endpoint.<\/p>\n\n<p>When a call is made to the AML the first call must warm up the container. By default a web service has 20 containers. Each container is cold, and a cold container can cause a large(30 sec) delay. In the string returned by the AML endpoint, only count requests that have the <code>isWarm<\/code> flag set to true. By smashing the service with MANY requests(relative to how many containers you have running) can get all your containers warmed.<\/p>\n\n<p>If you are sending out dozens of requests a instance, the endpoint might be getting throttled. You can adjust the number of calls your endpoint can accept by going to manage.windowsazure.com\/<\/p>\n\n<ol>\n<li>manage.windowsazure.com\/<\/li>\n<li>Azure ML Section from left bar<\/li>\n<li>select your workspace<\/li>\n<li>go to web services tab<\/li>\n<li>Select your web service from list<\/li>\n<li>adjust the number of calls with slider<\/li>\n<\/ol>\n\n<p>By enabling debugging onto your endpoint you can get logs about the execution time for each of your modules to complete. You can use this to determine if a module is not running as you intended which may add to the time.<\/p>\n\n<p>Overall, there is an overhead when using the Execute python module, but I'd expect this request to complete in under 3 secs. <\/p>",
        "Answer_comment_count":11.0,
        "Answer_creation_date":"2016-01-26 18:20:06.127 UTC",
        "Answer_score":8.0,
        "Owner_location":"Antwerp, Belgium",
        "Answer_last_edit_date":"2016-01-27 16:10:48.927 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34990561",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71127858,
        "Question_title":"Cant install imbalanced-learn on an Azure ML Environment",
        "Question_body":"<p>I have an Azure ML Workspace which comes by default with some pre-installed packages.<\/p>\n<p>I tried to install<\/p>\n<pre><code>!pip install -U imbalanced-learn\n<\/code><\/pre>\n<p>But I got this error<\/p>\n<pre><code>Requirement already up-to-date: scikit-learn in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (0.24.2)\nRequirement already satisfied, skipping upgrade: scipy&gt;=0.19.1 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: numpy&gt;=1.13.3 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.18.5)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (2.1.0)\nCollecting imbalanced-learn\n  Using cached imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (2.1.0)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: scipy&gt;=1.1.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (1.4.1)\nERROR: Could not find a version that satisfies the requirement scikit-learn&gt;=1.0.1 (from imbalanced-learn) (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22rc2.post1, 0.22rc3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0rc1, 0.23.0, 0.23.1, 0.23.2, 0.24.dev0, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2)\nERROR: No matching distribution found for scikit-learn&gt;=1.0.1 (from imbalanced-\n<\/code><\/pre>\n<p>learn)<\/p>\n<p>Not sure how to solve this, I have read in other posts to use conda, but that didnt work either.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-02-15 14:06:37.077 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-15 21:26:00.047 UTC",
        "Question_score":1,
        "Question_tags":"python|scikit-learn|pip|azure-machine-learning-service",
        "Question_view_count":219,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p><a href=\"https:\/\/pypi.org\/project\/scikit-learn\/1.0.1\/\" rel=\"nofollow noreferrer\"><code>scikit-learn<\/code> 1.0.1<\/a> and up require Python &gt;= 3.7; you use Python 3.6. You need to upgrade Python or downgrade <code>imbalanced-learn<\/code>. <a href=\"https:\/\/pypi.org\/project\/imbalanced-learn\/0.8.1\/\" rel=\"nofollow noreferrer\"><code>imbalanced-learn<\/code> 0.8.1<\/a> allows Python 3.6 so<\/p>\n<pre><code>!pip install -U &quot;imbalanced-learn &lt; 0.9&quot;\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-02-15 14:23:56.627 UTC",
        "Answer_score":2.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71127858",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60506398,
        "Question_title":"How do I use an environment in an ML Azure Pipeline",
        "Question_body":"<p><strong>Background<\/strong><\/p>\n\n<p>I have created an ML Workspace environment from a conda <code>environment.yml<\/code> plus some docker config and environment variables. I can access it from within a Python notebook:<\/p>\n\n<pre><code>env = Environment.get(workspace=ws, name='my-environment', version='1')\n<\/code><\/pre>\n\n<p>I can use this successfully to run a Python script as an experiment, i.e.<\/p>\n\n<pre><code>runconfig = ScriptRunConfig(source_directory='script\/', script='my-script.py', arguments=script_params)\nrunconfig.run_config.target = compute_target\nrunconfig.run_config.environment = env\nrun = exp.submit(runconfig)\n<\/code><\/pre>\n\n<p><strong>Problem<\/strong><\/p>\n\n<p>I would now like to run this same script as a Pipeline, so that I can trigger multiple runs with different parameters. I have created the Pipeline as follows:<\/p>\n\n<pre><code>pipeline_step = PythonScriptStep(\n    source_directory='script', script_name='my-script.py',\n    arguments=['-a', param1, '-b', param2],\n    compute_target=compute_target,\n    runconfig=runconfig\n)\nsteps = [pipeline_step]\npipeline = Pipeline(workspace=ws, steps=steps)\npipeline.validate()\n<\/code><\/pre>\n\n<p>When I then try to run the Pipeline:<\/p>\n\n<pre><code>pipeline_run = Experiment(ws, 'my_pipeline_run').submit(\n    pipeline, pipeline_parameters={...}\n)\n<\/code><\/pre>\n\n<p>I get the following error: <code>Response status code does not indicate success: 400 (Conda dependencies were not specified. Please make sure that all conda dependencies were specified i).<\/code><\/p>\n\n<p>When I view the pipeline run in the Azure Portal it seems that the environment has not been picked up: none of my conda dependencies are configured, hence the code does not run. What am I doing wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-03 11:37:15.267 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-03 23:14:33.84 UTC",
        "Question_score":3,
        "Question_tags":"python|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1972,
        "Owner_creation_date":"2014-06-25 12:11:55.16 UTC",
        "Owner_last_access_date":"2022-09-24 10:12:50.483 UTC",
        "Owner_reputation":1534,
        "Owner_up_votes":171,
        "Owner_down_votes":3,
        "Owner_views":56,
        "Answer_body":"<p>You're almost there, but you need to use <code>RunConfiguration<\/code> instead of <code>ScriptRunConfig<\/code>. More info <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-getting-started.ipynb\" rel=\"noreferrer\">here<\/a><\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.runconfig import RunConfiguration\n\nenv = Environment.get(workspace=ws, name='my-environment', version='1')\n# create a new runconfig object\nrunconfig = RunConfiguration()\nrunconfig.environment = env\n\npipeline_step = PythonScriptStep(\n    source_directory='script', script_name='my-script.py',\n    arguments=['-a', param1, '-b', param2],\n    compute_target=compute_target,\n    runconfig=runconfig\n)\n\npipeline = Pipeline(workspace=ws, steps=[pipeline_step])\n\npipeline_run = Experiment(ws, 'my_pipeline_run').submit(pipeline)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-03 17:07:50.993 UTC",
        "Answer_score":8.0,
        "Owner_location":"London, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60506398",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52370381,
        "Question_title":"Azure ML ModelManagement web service update",
        "Question_body":"<p><strong>NOTICE: Azure Machine Learning Workbench (Preview) is deprecated. The workflow for deploying models, images and services has been updated since this question was posted.<\/strong><\/p>\n\n<p>I have been developing a Machine Learning model for Azure Machine Learning Services using Azure Machine Learning Workbench (Preview). I successfully managed to deploy the model as a web service, as instructed in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/desktop-workbench\/model-management-service-deploy\" rel=\"nofollow noreferrer\">Azure Machine Learning Documentation (Preview)<\/a>. I have managed to get the service up and running, and the model, manifest and images are all configured correctly. So far so good.<\/p>\n\n<p>But now I have come to the phase where I want to be able to update the service with new configurations. And this is where I find myself with more questions than answers. <\/p>\n\n<p>I have figured out that I can<\/p>\n\n<ol>\n<li>configure a new model<\/li>\n<li>configure a new manifest pointing to that model<\/li>\n<li>configure a new image pointing to that manifest<\/li>\n<li>update an existing (or create a new) service to point to the new image<\/li>\n<\/ol>\n\n<p>This seems reasonable enough. But what If I just need to update the manifest, would it be possible to skip the configuration of a new model (1), and just begin the update from (2) above, and let it point to an existing model instead of a new one?<\/p>\n\n<p>I have of course tried this by calling the following from the CLI, and I get stuck with the following output:<\/p>\n\n<pre><code>&gt;&gt; az ml manifest create --manifest-name manifestname -f score.py -r python -c aml_config\/conda_dependencies.yml -s outputs\/schema.json -i [existing-model-id]\nCreating new driver at \/var\/folders\/tmp\/tmp.py\nSuccessfully created manifest\nId: [manifest-id]\n&gt;&gt; az ml image create -n imagename --manifest-id [manifest-id-from-above]\nCreating image............................................Done.\nImage ID: [image-id]\n&gt;&gt; az ml service update realtime -i [existing-service-id] --image-id [image-id-from-above] -v\nUpdating service..................................Failed\nFound default kubeconfig in \/Users\/username\/.kube\/config using it\nUsing kubeconfig file: \/Users\/username\/.kube\/config\nKubectl exists in default location, adding it to PATH\nloading kubeconfig file\nGetting Replica sets from default namespace\nGot hash ####\n{\n    \"Azure-cli-ml Version\": null,\n    \"Error\": \"Error occurred\",\n    \"Response Content\": {\n        \"CreatedTime\": \"2018-09-17T13:31:22.4230543Z\",\n        \"EndTime\": \"2018-09-17T13:34:18.0774994Z\",\n        \"Error\": {\n            \"Code\": \"KubernetesDeploymentFailed\",\n            \"Details\": [\n                {\n                    \"Code\": \"CrashLoopBackOff\",\n                    \"Message\": \"Back-off 40s restarting failed container=### pod=###\"\n                }\n            ],\n            \"Message\": \"Kubernetes Deployment failed\",\n            \"StatusCode\": 400\n        },\n        \"Id\": \"###\",\n        \"OperationType\": \"Service\",\n        \"ResourceLocation\": \"###\",\n        \"State\": \"Failed\"\n    },\n    \"Response Headers\": {\n        \"Connection\": \"keep-alive\",\n        \"Content-Encoding\": \"gzip\",\n        \"Content-Type\": \"application\/json; charset=utf-8\",\n        \"Date\": \"Mon, 17 Sep 2018 13:34:22 GMT\",\n        \"Strict-Transport-Security\": \"max-age=15724800; includeSubDomains; preload\",\n        \"Transfer-Encoding\": \"chunked\",\n        \"X-Content-Type-Options\": \"nosniff\",\n        \"X-Frame-Options\": \"SAMEORIGIN\",\n        \"api-supported-versions\": \"2017-09-01-preview, 2018-04-01-preview\",\n        \"x-ms-client-request-id\": \"###\",\n        \"x-ms-client-session-id\": \"\"\n    }\n}\n<\/code><\/pre>\n\n<p>If I try to rollback to the previous manifest, there is no error message, and everything works just fine. This makes me assume there is something wrong with my new manifest and\/or image. There is no warning or error when creating them, however.<\/p>\n\n<p>I have tried searching for the error messages but I find nothing.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-09-17 14:47:32.417 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-10-03 08:11:29.27 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":537,
        "Owner_creation_date":"2016-05-20 15:01:49.237 UTC",
        "Owner_last_access_date":"2022-09-05 14:52:13.07 UTC",
        "Owner_reputation":400,
        "Owner_up_votes":146,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>CrashLoopBackOff error normally means that the init() function of your score.py file has a problem, for example, finding or loading the model. It could also mean you are using a library that hasn't been imported.\nAzure ML just announced an update to the preview with an updated Python SDK (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/quickstart-get-started\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/quickstart-get-started<\/a>). \nThere are tutorials and notebooks that show the process in more details with examples. I would start there.<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-09-25 22:32:47.653 UTC",
        "Answer_score":0.0,
        "Owner_location":"Uppsala, Sverige",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52370381",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50414639,
        "Question_title":"How to Publish an Azure Bot",
        "Question_body":"<p>Just learning how to use <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">Azure Bot Service<\/a> and <code>Azure Bot Framework<\/code>. I created a Bot in Azure portal following <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">this<\/a> Official Azure tutorial. Does this bot need to be published somewhere? I read somewhere that you <code>Build--&gt;Test--&gt;Publish--&gt;Evaluate<\/code>. I've tested it in Azure portal itself as explained <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">here<\/a>. Not sure about the Publish part of it.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-18 15:25:22.62 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure|botframework|azure-machine-learning-studio|azure-bot-service",
        "Question_view_count":844,
        "Owner_creation_date":"2012-02-25 04:28:19.34 UTC",
        "Owner_last_access_date":"2022-09-24 17:06:32.277 UTC",
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Answer_body":"<p>How do you intend to use your bot? Azure Bots work by connecting them to existing channels like Skype, Facebook Messenger, SMS, etc or making REST calls from a custom application.<\/p>\n\n<p>However you can also reach your bot directly from: <code>https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE<\/code><\/p>\n\n<p>You can embed it on any web page with this HTML tag:<\/p>\n\n<pre><code>&lt;iframe src=\"https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE\"&gt;&lt;\/iframe&gt;\n<\/code><\/pre>\n\n<p>Please note that both of these methods expose your token and would allow other developers to add your bot to their pages as well.<\/p>\n\n<p>Bot ID is the name of your bot and you can get the token from the portal by going to your bot and choosing \"Channel\" blade and then clicking the \"Get bot embed codes\" link.<\/p>\n\n<p>Edit: I went ahead and wrote a blog post on this topic <a href=\"https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2018-05-18 16:11:16.24 UTC",
        "Answer_score":5.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2018-05-25 21:12:34.36 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50414639",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36132719,
        "Question_title":"Select columns dynamically in Azure ML model",
        "Question_body":"<p>I have deployed a model as a Webservice in Azure ML.Its a simple one and all it does is do a linear Regression .The underlying code is python . Now i need to pass which all columns have to selected as independent variables, dynamically, from the client side . How may i do this in Azure ML studio?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-21 13:45:55.05 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-03-22 02:09:37.147 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":238,
        "Owner_creation_date":"2015-02-01 20:05:09.973 UTC",
        "Owner_last_access_date":"2022-09-24 08:12:42.76 UTC",
        "Owner_reputation":1238,
        "Owner_up_votes":45,
        "Owner_down_votes":5,
        "Owner_views":172,
        "Answer_body":"<p>Based on my understanding, I think you want to dynamically get the selected columns data via request the Azure ML webservice with some parameters on the client.<\/p>\n\n<p>You can refer to the offical document <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-web-service-parameters\/\" rel=\"nofollow\">Use Azure Machine Learning Web Service Parameters<\/a> and the blog <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2014\/11\/25\/azureml-web-service-parameters\/\" rel=\"nofollow\">AzureML Web Service Parameters<\/a> to know how to set and use the web service parameters to implement your needs via add the selected column names as array into the json parameter <code>GlobalParameters<\/code>.<\/p>\n\n<p>Meanwhile, there is a client sample on GitHub <a href=\"https:\/\/github.com\/nk773\/AzureML_RRSApp\" rel=\"nofollow\">https:\/\/github.com\/nk773\/AzureML_RRSApp<\/a>. Althought it was writen in Java, I think it is easy to understand, then you can rewrite in Python with <code>requests<\/code> package.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-03-22 07:35:18.243 UTC",
        "Answer_score":0.0,
        "Owner_location":"India",
        "Answer_last_edit_date":"2016-03-23 02:14:37.763 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36132719",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54796762,
        "Question_title":"Cannot deploy a trained model to an existing AKS compute target",
        "Question_body":"<p>I have a model that was trained on a Machine Learning Compute on Azure Machine Learning Service. The registered model already lives my workspace and I would like to deploy it to a pre-existing AKS instance that I previously provisioned in my workspace. I am able to successfully configure and register the container image: <\/p>\n\n<pre><code># retrieve cloud representations of the models\nrf = Model(workspace=ws, name='pumps_rf')\nle = Model(workspace=ws, name='pumps_le')\nohc = Model(workspace=ws, name='pumps_ohc')\nprint(rf); print(le); print(ohc)\n\n&lt;azureml.core.model.Model object at 0x7f66ab3b1f98&gt;\n&lt;azureml.core.model.Model object at 0x7f66ab7e49b0&gt;\n&lt;azureml.core.model.Model object at 0x7f66ab85e710&gt;\n\npackage_list = [\n  'category-encoders==1.3.0',\n  'numpy==1.15.0',\n  'pandas==0.24.1',\n  'scikit-learn==0.20.2']\n\n# Conda environment configuration\nmyenv = CondaDependencies.create(pip_packages=package_list)\nconda_yml = 'file:'+os.getcwd()+'\/myenv.yml'\n\nwith open(conda_yml,\"w\") as f:\n    f.write(myenv.serialize_to_string())\n<\/code><\/pre>\n\n<p>Configuring and registering the image works:<\/p>\n\n<pre><code># Image configuration\nimage_config = ContainerImage.image_configuration(execution_script='score.py', \n                                                  runtime='python', \n                                                  conda_file='myenv.yml',\n                                                  description='Pumps Random Forest model')\n\n\n# Register the image from the image configuration\n# to Azure Container Registry\nimage = ContainerImage.create(name = Config.IMAGE_NAME, \n                              models = [rf, le, ohc],\n                              image_config = image_config,\n                              workspace = ws)\n\nCreating image\nRunning....................\nSucceededImage creation operation finished for image pumpsrfimage:2, operation \"Succeeded\"\n<\/code><\/pre>\n\n<p>Attaching to an existing cluster also works:<\/p>\n\n<pre><code># Attach the cluster to your workgroup\nattach_config = AksCompute.attach_configuration(resource_group = Config.RESOURCE_GROUP,\n                                                cluster_name = Config.DEPLOY_COMPUTE)\naks_target = ComputeTarget.attach(workspace=ws, \n                                  name=Config.DEPLOY_COMPUTE, \n                                  attach_configuration=attach_config)\n\n# Wait for the operation to complete\naks_target.wait_for_completion(True)\nSucceededProvisioning operation finished, operation \"Succeeded\"\n<\/code><\/pre>\n\n<p>However, when I try to deploy the image to the existing cluster, it fails with a <code>WebserviceException<\/code>. <\/p>\n\n<pre><code># Set configuration and service name\naks_config = AksWebservice.deploy_configuration()\n\n# Deploy from image\nservice = Webservice.deploy_from_image(workspace = ws,\n                                       name = 'pumps-aks-service-1' ,\n                                       image = image,\n                                       deployment_config = aks_config,\n                                       deployment_target = aks_target)\n# Wait for the deployment to complete\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n\nWebserviceException: Unable to create service with image pumpsrfimage:1 in non \"Succeeded\" creation state.\n---------------------------------------------------------------------------\nWebserviceException                       Traceback (most recent call last)\n&lt;command-201219424688503&gt; in &lt;module&gt;()\n      7                                        image = image,\n      8                                        deployment_config = aks_config,\n----&gt; 9                                        deployment_target = aks_target)\n     10 # Wait for the deployment to complete\n     11 service.wait_for_deployment(show_output = True)\n\n\/databricks\/python\/lib\/python3.5\/site-packages\/azureml\/core\/webservice\/webservice.py in deploy_from_image(workspace, name, image, deployment_config, deployment_target)\n    284                         return child._deploy(workspace, name, image, deployment_config, deployment_target)\n    285 \n--&gt; 286         return deployment_config._webservice_type._deploy(workspace, name, image, deployment_config, deployment_target)\n    287 \n    288     @staticmethod\n\n\/databricks\/python\/lib\/python3.5\/site-packages\/azureml\/core\/webservice\/aks.py in _deploy(workspace, name, image, deployment_config, deployment_target)\n<\/code><\/pre>\n\n<p>Any ideas on how to solve this issue? I am writing the code in a Databricks notebook. Also, I am able to create and deploy the cluster using Azure Portal no problem so this appears to be an issue with my code\/Python SDK or the way Databricks works with AMLS.<\/p>\n\n<p>UPDATE:\nI was able to deploy my image to AKS using Azure Portal and the webservice works as expected. This means the issue lies somewhere between Databricks, the Azureml Python SDK and Machine Learning Service.<\/p>\n\n<p>UPDATE 2:\nI'm working with Microsoft to fix this issue. Will report back once we have a solution.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2019-02-20 23:15:26.117 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-04-07 14:29:02.087 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-aks|azure-machine-learning-service",
        "Question_view_count":1051,
        "Owner_creation_date":"2014-08-20 22:42:51.227 UTC",
        "Owner_last_access_date":"2022-02-11 02:02:02.143 UTC",
        "Owner_reputation":2754,
        "Owner_up_votes":189,
        "Owner_down_votes":1,
        "Owner_views":124,
        "Answer_body":"<p>In my initial code, when creating the image, I was not using:<\/p>\n\n<pre><code>image.wait_for_creation(show_output=True)\n<\/code><\/pre>\n\n<p>As a consequence, I was calling <code>CreateImage<\/code> and <code>DeployImage<\/code> before the image was created which errored out. Can't believe it was that simple.. <\/p>\n\n<p>UPDATED IMAGE CREATION SNIPPET:<\/p>\n\n<pre><code># Register the image from the image configuration\n# to Azure Container Registry\nimage = ContainerImage.create(name = Config.IMAGE_NAME, \n                              models = [rf, le, ohc],\n                              image_config = image_config,\n                              workspace = ws)\n\nimage.wait_for_creation(show_output=True)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-03-07 20:22:05.42 UTC",
        "Answer_score":2.0,
        "Owner_location":"Toronto, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54796762",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68172002,
        "Question_title":"How to trigger Azure ML Pipeline from Power Automate",
        "Question_body":"<p>I have a published Azure ML Pipeline that I am trying to trigger from an Automate Flow I have that triggers when users edit a document. Since I have the REST Endpoint for the Published Pipeline, I figured I should be able to make a POST request using the HTTP module available in Power Automate to trigger the pipeline.<\/p>\n<p>However, when I actually try this, I get an authentication error. I assume this is because I need to include some access token with the REST Endpoint, but I can't find any documentation that will tell me where to get that token from. Please note that I do not need to pass any data to the Pipeline, it handles its own data collection, I literally just need a way to trigger it.<\/p>\n<p>Does anybody know how to trigger a Published Azure ML Pipeline using the REST Endpoint? Does it make sense to use the HTTP module, or is there a better way to achieve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-29 02:47:27.563 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-06-29 03:39:26.803 UTC",
        "Question_score":1,
        "Question_tags":"azure|rest|power-automate|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":305,
        "Owner_creation_date":"2021-01-20 22:28:36.003 UTC",
        "Owner_last_access_date":"2021-12-13 22:49:59.46 UTC",
        "Owner_reputation":119,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>So I figured out how to do it by following the directions contained within this piece of Microsoft Documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest<\/a><\/p>\n<p>Specifically, it required performing two of the calls in the documentation;<\/p>\n<ul>\n<li>The first to get an AAD token using an Azure Service Principle that is authorised to access the Machine Learning Instance.<\/li>\n<\/ul>\n<blockquote>\n<p>curl -X POST <a href=\"https:\/\/login.microsoftonline.com\/\" rel=\"nofollow noreferrer\">https:\/\/login.microsoftonline.com\/<\/a>\/oauth2\/token -d &quot;grant_type=client_credentials&amp;resource=https%3A%2F%2Fmanagement.azure.com%2F&amp;client_id=&amp;client_secret=&quot;<\/p>\n<\/blockquote>\n<ul>\n<li>The second to use this token to trigger your pipeline from its rest endpoint. This one I had to figure out myself a little, but below is the basic structure I used.<\/li>\n<\/ul>\n<blockquote>\n<p>curl -X POST {PIPELINE_REST_ENDPOINT} -H &quot;Authorisation:Bearer {AAD_TOKEN}&quot; -H &quot;Content-Type: application\/json&quot; -d &quot;{&quot;ExperimentName&quot;: &quot;{EXPERIMENT_NAME}&quot;,&quot;ParameterAssignments&quot;: {}}&quot;<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-06 01:43:49.443 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68172002",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71662401,
        "Question_title":"Synapse Analytics Auto ML Predict No module named 'azureml.automl'",
        "Question_body":"<p>I follow the official tutotial from microsoft: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a><\/p>\n<p>When I execute:<\/p>\n<pre><code>#Bind model within Spark session\n model = pcontext.bind_model(\n     return_types=RETURN_TYPES, \n     runtime=RUNTIME, \n     model_alias=&quot;Sales&quot;, #This alias will be used in PREDICT call to refer  this   model\n     model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI\n     aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed\n ).register()\n<\/code><\/pre>\n<p>I got : No module named 'azureml.automl'<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/g0UCX.png\" rel=\"nofollow noreferrer\">My Notebook<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-29 12:53:53.353 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-synapse|azure-machine-learning-studio|automl|azure-auto-ml",
        "Question_view_count":271,
        "Owner_creation_date":"2022-02-17 15:07:55.503 UTC",
        "Owner_last_access_date":"2022-09-24 22:14:48.837 UTC",
        "Owner_reputation":15,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>I solved it. In my case it works best like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/JKEmr.png\" rel=\"nofollow noreferrer\">Imports<\/a><\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#Import libraries\nfrom pyspark.sql.functions import col, pandas_udf,udf,lit\nfrom notebookutils.mssparkutils import azureML\nfrom azureml.core import Workspace, Model\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nfrom azureml.core.model import Model\nimport joblib\nimport pandas as pd\n\nws = azureML.getWorkspace(\"AzureMLService\")\nspark.conf.set(\"spark.synapse.ml.predict.enabled\",\"true\")<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ij760.png\" rel=\"nofollow noreferrer\">Predict function<\/a><\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>def forecastModel():\n    model_path = Model.get_model_path(model_name=\"modelName\", _workspace=ws)\n    modeljob = joblib.load(model_path + \"\/model.pkl\")\n\n    validation_data = spark.read.format(\"csv\") \\\n                            .option(\"header\", True) \\\n                            .option(\"inferSchema\",True) \\\n                            .option(\"sep\", \";\") \\\n                            .load(\"abfss:\/\/....csv\")\n\n    validation_data_pd = validation_data.toPandas()\n\n\n    predict = modeljob.forecast(validation_data_pd)\n\n    return predict<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-04-02 14:59:10.93 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-04-02 21:14:34.417 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71662401",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50439489,
        "Question_title":"Delete Project Azure ML Studio ( Web App)",
        "Question_body":"<p>How do I delete projects in my workspace ?when I click to delete a project the delete button is inactive. Tried clearing cache and whatnot but cannot delete the project from studio.azureml.net... how do I do this ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-20 21:21:27.06 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":576,
        "Owner_creation_date":"2017-09-26 14:24:54.64 UTC",
        "Owner_last_access_date":"2022-09-25 04:59:24.04 UTC",
        "Owner_reputation":1922,
        "Owner_up_votes":1232,
        "Owner_down_votes":72,
        "Owner_views":404,
        "Answer_body":"<p>I have reproduced your issue. Try to go to your project -> EDIT ->remove the <strong>ASSETS<\/strong> of your project. Then the delete button will be able.<\/p>\n\n<p>You could follow the screenshot.<\/p>\n\n<ol>\n<li>The <strong>DELETE<\/strong> button is disable.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/E850F.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E850F.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>2.Go to <strong>EDIT<\/strong> and remove the <strong>ASSETS<\/strong>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PbEZC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PbEZC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/2kBgO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2kBgO.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>3.Then the <strong>DELETE<\/strong> button will be able<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/08lOW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/08lOW.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-05-21 01:22:38.89 UTC",
        "Answer_score":1.0,
        "Owner_location":"Southeast Asia",
        "Answer_last_edit_date":"2018-05-21 01:33:21.04 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50439489",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63691515,
        "Question_title":"Azure Machine Learning Studio: cannot create Datastore from Azure SQL Database",
        "Question_body":"<p>I am trying to connect to an Azure SQL Database from inside Azure Machine Learning Studio. Based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py<\/a>, it seems that the recommended pattern is to create a Datastore using the Datastore.register_azure_sql_database method as follows:<\/p>\n<pre><code>import os\nfrom azureml.core import Workspace, Datastore\n\nws = Workspace.from_config() # asks for interactive authentication the first time\n\nsql_datastore_name  = &quot;datastore_test_01&quot; # any name should be fine\nserver_name         = os.getenv(&quot;SQL_SERVERNAME&quot;    , &quot;{SQL_SERVERNAME}&quot;) # Name of the Azure SQL server\ndatabase_name       = os.getenv(&quot;SQL_DATABASENAME&quot;  , &quot;{SQL_DATABASENAME}&quot;) # Name of the Azure SQL database\nusername            = os.getenv(&quot;SQL_USER_NAME&quot;     , &quot;{SQL_USER_NAME}&quot;) # The username of the database user.\npassword            = os.getenv(&quot;SQL_USER_PASSWORD&quot; , &quot;{SQL_USER_PASSWORD}&quot;) # The password of the database user.\n\nsql_datastore = Datastore.register_azure_sql_database(workspace      = ws,\n                                                      datastore_name = sql_datastore_name,\n                                                      server_name    = server_name,\n                                                      database_name  = database_name,\n                                                      username       = username,\n                                                      password       = password)\n<\/code><\/pre>\n<p>I am pretty sure I have set all parameters right, having copied them from the ADO.NET connection string at my SQL Database resource --&gt; Settings --&gt; Connection strings:<\/p>\n<pre><code>Server=tcp:{SQL_SERVERNAME}.database.windows.net,1433;Initial Catalog={SQL_DATABASENAME};Persist Security Info=False;User ID={SQL_USER_NAME};Password={SQL_USER_PASSWORD};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\n<\/code><\/pre>\n<p>However, I get the following error:<\/p>\n<pre><code>Registering datastore failed with a 400 error code and error message 'Azure SQL Database Error -2146232060: Please check the correctness of the datastore information.'\n<\/code><\/pre>\n<p>Am I missing something? E.g., a firewall rule? I have also tried adding the Azure ML compute resource's public IP address to the list of allowed IP addresses in my SQL Database resource, but still no success.<\/p>\n<hr \/>\n<p><strong>UPDATE<\/strong>: adding <code>skip_validation = True<\/code> to <code>Datastore.register_azure_sql_database<\/code> solves the issue. I can then query the data with<\/p>\n<pre><code>from azureml.core import Dataset\nfrom azureml.data.datapath import DataPath\n\nquery   = DataPath(sql_datastore, 'SELECT * FROM my_table')\ntabular = Dataset.Tabular.from_sql_query(query, query_timeout = 10)\ndf = tabular.to_pandas_dataframe()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-01 16:13:13.243 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-09-02 07:46:58.923 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":793,
        "Owner_creation_date":"2017-08-11 12:35:17.96 UTC",
        "Owner_last_access_date":"2021-01-27 09:52:25.2 UTC",
        "Owner_reputation":132,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>is the datastore behind vnet? where are you running the registration code above? On a compute instance behind the same vnet?\nhere is the doc that describe what you need to do to connect to data behind vnet:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-01 16:53:06.26 UTC",
        "Answer_score":2.0,
        "Owner_location":"Milano, MI, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63691515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72133111,
        "Question_title":"Azure ML: What means reconnecting terminal?",
        "Question_body":"<p>I am a newbie in this, and I am facing some problems with the Azure ML workspace. I ran a python code from the terminal, and then I opened another terminal to check the process. I got the following message in the terminal that checked the process:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<p>I appreciate any tips.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-05 20:12:30.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-python-sdk",
        "Question_view_count":48,
        "Owner_creation_date":"2019-11-30 18:16:16.887 UTC",
        "Owner_last_access_date":"2022-09-23 17:51:17.98 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":"<blockquote>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<\/blockquote>\n<ul>\n<li><code>Reconnecting terminal<\/code> message can appear for multiple reasons like intermittent connectivity issues, unused active terminal sessions, processing of different size\/format of data.<\/li>\n<li>Make sure you close any unused terminal sessions to preserve your compute instance's resources. Idle terminals may impact the performance of compute instances.<\/li>\n<\/ul>\n<p>You can refer to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#manage-terminal-sessions\" rel=\"nofollow noreferrer\">Access a compute instance terminal in your workspace<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-optimize-data-processing\" rel=\"nofollow noreferrer\">Optimize data processing with Azure Machine Learning<\/a> and <a href=\"https:\/\/www.youtube.com\/watch?v=kiScfw9i4FM\" rel=\"nofollow noreferrer\">Azure ML: Speed up processing time<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-05-06 08:27:02.423 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72133111",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68644137,
        "Question_title":"Azure Machine Learning Studio Designer Error: code_expired",
        "Question_body":"<p>I am trying to register a data set via the Azure Machine Learning Studio designer but keep getting an error. Here is my code, used in a &quot;Execute Python Script&quot; module:<\/p>\n<pre><code>import pandas as pd\nfrom azureml.core.dataset import Dataset\nfrom azureml.core import Workspace\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    ws = Workspace.get(name = &lt;my_workspace_name&gt;, subscription_id = &lt;my_id&gt;, resource_group = &lt;my_RG&gt;)\n    ds = Dataset.from_pandas_dataframe(dataframe1)\n    ds.register(workspace = ws,\n                name = &quot;data set name&quot;,\n                description = &quot;example description&quot;,\n                create_new_version = True)\n    return dataframe1, \n<\/code><\/pre>\n<p>But I get the following error in the Workspace.get line:<\/p>\n<pre><code>Authentication Exception: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired.\n<\/code><\/pre>\n<p>Since I am inside the workspace and in the designer, I do not usually need to do any kind of authentication (or even reference the workspace). Can anybody offer some direction? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-04 00:34:32.883 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-04 00:57:06.927 UTC",
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":321,
        "Owner_creation_date":"2013-06-17 20:00:29.817 UTC",
        "Owner_last_access_date":"2022-09-24 13:07:45.427 UTC",
        "Owner_reputation":1111,
        "Owner_up_votes":124,
        "Owner_down_votes":2,
        "Owner_views":191,
        "Answer_body":"<p>when you're inside a &quot;Execute Python Script&quot; module or <code>PythonScriptStep<\/code>, the authentication for fetching the workspace is already done for you (unless you're trying to authenticate to different Azure ML workspace.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Run\nrun = Run.get_context()\n\nws = run.experiment.workspace\n<\/code><\/pre>\n<p>You should be able to use that <code>ws<\/code> object to register a Dataset.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-08-04 00:53:58.487 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68644137",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64979752,
        "Question_title":"Unable to access python packages installed in Azure ML",
        "Question_body":"<p>I am trying to deploy a pre-trained ML model (saved as .h5 file) to Azure ML. I have created an AKS cluster and trying to deploy the model as shown below:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\n\nfrom azureml.core.environment import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\n\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\nenv = Environment.get(workspace, name='AzureML-TensorFlow-1.13-GPU')\n\n# Installing packages present in my requirements file\nwith open('requirements.txt') as f:\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\ndependencies.append(&quot;azureml-defaults&gt;=1.0.45&quot;)\n\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=dependencies)\n\n# Including the source folder so that all helper scripts are included in my deployment\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# Deployment with suitable config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=4, memory_gb=32)\nmodel = Model(workspace, 'sketch-inference')\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<p>My main entry script requires some additional helper scripts, which I include by mentioning the source folder in my inference config.<\/p>\n<p>I was expecting that the helper scripts I add should be able to access the packages installed while setting up the environment during deployment, but I get ModuleNotFoundError.<\/p>\n<p>Here is the error output, along with the a couple of environment variables I printed while executing entry script:<\/p>\n<pre><code>    AZUREML_MODEL_DIR ----  azureml-models\/sketch-inference\/1\n    PYTHONPATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages:\/var\/azureml-server:\n    PATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/opt\/intel\/compilers_and_libraries\/linux\/mpi\/bin64\n    Exception in worker process\n    Traceback (most recent call last):\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n        worker.init_process()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process\n        self.load_wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi\n        self.wsgi = self.app.wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n        self.callable = self.load()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load\n        return self.load_wsgiapp()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp\n        return util.import_app(self.app_uri)\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app\n        __import__(module)\n    File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n        import create_app\n    File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n        from app import main\n    File &quot;\/var\/azureml-server\/app.py&quot;, line 32, in &lt;module&gt;\n        from aml_blueprint import AMLBlueprint\n    File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 25, in &lt;module&gt;\n        import main\n    File &quot;\/var\/azureml-app\/main.py&quot;, line 12, in &lt;module&gt;\n        driver_module_spec.loader.exec_module(driver_module)\n    File &quot;\/structure\/azureml-app\/ProcessImage\/app.py&quot;, line 16, in &lt;module&gt;\n        from ProcessImage.samples.coco.inference import run as infer\n    File &quot;\/var\/azureml-app\/ProcessImage\/samples\/coco\/inference.py&quot;, line 1, in &lt;module&gt;\n        import skimage.io\n    ModuleNotFoundError: No module named 'skimage'\n<\/code><\/pre>\n<p>The existing answers related to this aren't of much help. I believe there must be a simpler way to fix this, since AzureML specifically provides the feature to setup environment with pip\/conda packages installed either by supplying requirements.txt file or individually.<\/p>\n<p>What am I missing here? Kindly help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-24 03:16:03.027 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1381,
        "Owner_creation_date":"2015-04-23 17:51:38.813 UTC",
        "Owner_last_access_date":"2022-09-23 21:23:01.117 UTC",
        "Owner_reputation":1910,
        "Owner_up_votes":85,
        "Owner_down_votes":6,
        "Owner_views":316,
        "Answer_body":"<p>So, after some trial and error, creating a fresh environment and then adding the packages solved the problem for me. I am still not clear on why this didn't work when I tried to use <a href=\"http:\/\/from%20azureml.core%20import%20Workspace%20from%20azureml.core.model%20import%20Model%20from%20azureml.core.environment%20import%20Environment,%20DEFAULT_GPU_IMAGE%20from%20azureml.core.conda_dependencies%20import%20CondaDependencies%20from%20azureml.core.model%20import%20InferenceConfig%20from%20azureml.core.webservice%20import%20AksWebservice,%20LocalWebservice%20from%20azureml.core.compute%20import%20ComputeTarget%20%20%20#%201.%20Instantiate%20the%20workspace%20workspace%20=%20Workspace.from_config(path=%22config.json%22)%20%20#%202.%20Setup%20the%20environment%20env%20=%20Environment(%27sketchenv%27)%20with%20open(%27requirements.txt%27)%20as%20f:%20#%20Fetch%20all%20dependencies%20as%20a%20list%20%20%20%20%20dependencies%20=%20f.readlines()%20dependencies%20=%20%5Bx.strip()%20for%20x%20in%20dependencies%20if%20%27#%20%27%20not%20in%20x%5D%20env.docker.base_image%20=%20DEFAULT_GPU_IMAGE%20env.python.conda_dependencies%20=%20CondaDependencies.create(conda_packages=%5B%27numpy==1.17.4%27,%20%27Cython%27%5D,%20pip_packages=dependencies)%20%20#%203.%20Inference%20Config%20inference_config%20=%20InferenceConfig(entry_script=%27app.py%27,%20environment=env,%20source_directory=%27.\/ProcessImage%27)%20%20#%204.%20Compute%20target%20(using%20existing%20cluster%20from%20the%20workspacke)%20aks_target%20=%20ComputeTarget(workspace=workspace,%20name=%27sketch-ppt-vm%27)%20%20#%205.%20Deployment%20config%20deployment_config%20=%20AksWebservice.deploy_configuration(cpu_cores=6,%20memory_gb=100)%20%20#%206.%20Model%20deployment%20model%20=%20Model(workspace,%20%27sketch-inference%27)%20#%20Registered%20model%20(which%20contains%20model%20files\/folders)%20service%20=%20Model.deploy(workspace,%20%22process-sketch-dev%22,%20%5Bmodel%5D,%20inference_config,%20deployment_config,%20deployment_target=aks_target,%20overwrite=True)%20service.wait_for_deployment(show_output%20=%20True)%20print(service.state)\" rel=\"nofollow noreferrer\">Environment.from_pip_requirements()<\/a>. A detailed answer in this regard would be interesting to read.<\/p>\n<p>My primary task was inference - object detection given an image, and we have our own model developed by our team. There are two types of imports I wanted to have:<\/p>\n<p><strong>1. Standard python packages (installed through pip)<\/strong><br \/>\nThis was solved by creating conda dependencies and add it to env object (Step 2)<\/p>\n<p><strong>2. Methods\/vars from helper scripts<\/strong> (if you have pre\/post processing to be done during model inference):<br \/>\nThis was done by mentioning <code>source_directory<\/code> in InferenceConfig (step 3)<\/p>\n<p>Here is my updated script which combines Environment creation, Inference and Deployment configs and using existing compute in the workspace (created through portal).<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.environment import Environment, DEFAULT_GPU_IMAGE\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\n\n# 1. Instantiate the workspace\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\n# 2. Setup the environment\nenv = Environment('sketchenv')\nwith open('requirements.txt') as f: # Fetch all dependencies as a list\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\nenv.docker.base_image = DEFAULT_GPU_IMAGE\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy==1.17.4', 'Cython'], pip_packages=dependencies)\n\n# 3. Inference Config\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\n# 4. Compute target (using existing cluster from the workspacke)\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# 5. Deployment config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=6, memory_gb=100)\n\n# 6. Model deployment\nmodel = Model(workspace, 'sketch-inference') # Registered model (which contains model files\/folders)\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<hr \/>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-24 20:27:00.653 UTC",
        "Answer_score":1.0,
        "Owner_location":"Boston, MA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64979752",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32993148,
        "Question_title":"Azure Machine Learning Decision Tree output",
        "Question_body":"<p>Is there any way to get the output of the Boosted Decision Tree module in ML Studio? To analyze the learned tree, like in Weka. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-10-07 13:11:29.47 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-02-01 04:24:14.71 UTC",
        "Question_score":0,
        "Question_tags":"azure|decision-tree|azure-machine-learning-studio",
        "Question_view_count":1425,
        "Owner_creation_date":"2013-02-26 16:24:29.993 UTC",
        "Owner_last_access_date":"2022-09-22 11:21:06.113 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":38,
        "Answer_body":"<p>Update: visualization of decision trees is available now!  Right-click on the output node of the \"Train Model\" module and select \"Visualize\".  <\/p>\n\n<p>My old answer:<\/p>\n\n<p><em>I'm sorry; visualization of decision trees isn't available yet.  (I really want it too!  You can upvote this feature request at <a href=\"http:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/7419469-show-variable-importance-after-experiment-runs\" rel=\"nofollow\">http:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/7419469-show-variable-importance-after-experiment-runs<\/a>, but they are currently working on it.)<br>\nJust FYI, you can currently see what the model builds for linear algorithms by right-clicking on the \"Train Model\" module output node and selecting \"Visualize\".  It will show the initial parameter values and the feature weights.  But for non-linear algorithms like decision trees, that visibility is still forthcoming.<\/em>  <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-10-08 04:35:40.207 UTC",
        "Answer_score":2.0,
        "Owner_location":"Szeged, Magyarorsz\u00e1g",
        "Answer_last_edit_date":"2015-11-17 03:48:57.527 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32993148",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45009184,
        "Question_title":"Powershell AzureML Get-AmlWorkspace",
        "Question_body":"<pre><code>Get-AmlWorkspace : One or more errors occurred.\nAt line:1 char:1\n+ Get-AmlWorkspace\n+ ~~~~~~~~~~~~~~~~\n+ CategoryInfo          : NotSpecified: (:) [Get-AmlWorkspace], \nAggregateException\n+ FullyQualifiedErrorId : \nSystem.AggregateException,AzureML.PowerShell.GetWorkspace\n<\/code><\/pre>\n\n<p>I am trying to use Powershell to connect to Azure ML studio as it looks like an easier way to manage a workspace. I've downloaded the dll file from <a href=\"https:\/\/github.com\/hning86\/azuremlps\" rel=\"nofollow noreferrer\">https:\/\/github.com\/hning86\/azuremlps<\/a> and changed my config.json file, but get the error above if I try to run any AzureML commands. I've unblocked the DLL file and imported the AzureMLPS module, and I can see the module and commands I am trying to use have been imported by doing <code>Get-Module<\/code> and <code>Get-Command<\/code><\/p>\n\n<p>For info I've not used Powershell before.<\/p>\n\n<p>Any suggestions much appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-10 10:03:54.153 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"powershell|azure-machine-learning-studio",
        "Question_view_count":428,
        "Owner_creation_date":"2014-04-14 20:35:27.1 UTC",
        "Owner_last_access_date":"2022-09-13 13:27:47.463 UTC",
        "Owner_reputation":340,
        "Owner_up_votes":60,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>Have you installed Azure PowerShell Installer on your local machine?\n<strong><a href=\"https:\/\/github.com\/Azure\/azure-powershell\/releases\" rel=\"nofollow noreferrer\">Click here<\/a><\/strong> for more info.<\/p>\n\n<p>Download the latest <strong>Azure PowerShell Installer (4.3.1)<\/strong>, then install on your local machine. Then retry using Azure PowerShell module and commands.<\/p>\n\n<p>I installed mine last May, using Azure PowerShell 4.0.1, and the command Get-AmlWorkspace is working.<\/p>\n\n<pre><code># Set local folder location\nSet-Location -Path \"C:\\Insert here the location of AzureMLPS.dll\"\n\n# Unblock and import Azure Powershell Module (leverages config.json file)\nUnblock-File .\\AzureMLPS.dll\nImport-Module .\\AzureMLPS.dll\n\n# Get Azure ML Workspace info\nGet-AmlWorkspace\n<\/code><\/pre>\n\n<p>The output on my side looks like this:\n<a href=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-08-22 08:14:14.69 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45009184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72831360,
        "Question_title":"Use dataset registed in on pipelines in AML",
        "Question_body":"<p>I was following the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\" rel=\"nofollow noreferrer\">SDK v2 Python tutorial<\/a> in order to create a pipeline job with my own assets. I notice that in this tutorial they let you use a csv file that can be downloaded but Im trying to use a registered dataset that I already registered by my own. The problem that I facing is that I dont know where I need to specify the dataset.<\/p>\n<p>The funny part is that at the beginning they create this dataset like this:<\/p>\n<pre><code>credit_data = ml_client.data.create_or_update(credit_data)\nprint(\n    f&quot;Dataset with name {credit_data.name} was registered to workspace, the dataset version is {credit_data.version}&quot;\n)\n<\/code><\/pre>\n<p>But the only part where they refer to this dataset is on the last part where they # the line:<\/p>\n<pre><code>registered_model_name = &quot;credit_defaults_model&quot;\n\n# Let's instantiate the pipeline with the parameters of our choice\npipeline = credit_defaults_pipeline(\n    # pipeline_job_data_input=credit_data,\n    pipeline_job_data_input=Input(type=&quot;uri_file&quot;, path=web_path),\n    pipeline_job_test_train_ratio=0.2,\n    pipeline_job_learning_rate=0.25,\n    pipeline_job_registered_model_name=registered_model_name,\n)\n<\/code><\/pre>\n<p>For me this means that I can use this data like this (a already registered dataset), the problem is that I don't know where I need to do the changes (I know that in the data_prep.py and in the code below but I don\u00b4t know where else) and I don't know how to set this:<\/p>\n<pre><code>%%writefile {data_prep_src_dir}\/data_prep.py\n...\n\ndef main():\n    &quot;&quot;&quot;Main function of the script.&quot;&quot;&quot;\n\n    # input and output arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;) # &lt;=== Here, but I don\u00b4t know how\n    parser.add_argument(&quot;--test_train_ratio&quot;, type=float, required=False, default=0.25)\n    parser.add_argument(&quot;--train_data&quot;, type=str, help=&quot;path to train data&quot;)\n    parser.add_argument(&quot;--test_data&quot;, type=str, help=&quot;path to test data&quot;)\n    args = parser.parse_args()\n\n...\n<\/code><\/pre>\n<p>Does anyone have experience working as registered datasets?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-01 15:16:58.547 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-10 19:49:51.39 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python|azureml-python-sdk",
        "Question_view_count":85,
        "Owner_creation_date":"2021-11-10 18:30:00.947 UTC",
        "Owner_last_access_date":"2022-08-30 22:20:17.243 UTC",
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<blockquote>\n<p>parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;) # &lt;=== Here, but I don\u00b4t know how<\/p>\n<\/blockquote>\n<p>To get the path to input data, according to <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/how-to-train-with-datasets.md\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<ul>\n<li><p>You can get <code>--input-data<\/code> by ID which you can access in your training script.<\/p>\n<\/li>\n<li><p>Use it as <code>argument<\/code> on <code>mounted_input_path<\/code><\/p>\n<\/li>\n<\/ul>\n<p>For example, try the following three code snippets taken from the <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/how-to-train-with-datasets.md\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<p><strong>Access dataset in training script:<\/strong><\/p>\n<pre><code>parser = argparse.ArgumentParser()\nparser.add_argument(&quot;--input-data&quot;, type=str)\nargs = parser.parse_args()\n\nrun = Run.get_context()\nws = run.experiment.workspace\n\n# get the input dataset by ID\ndataset = Dataset.get_by_id(ws, id=args.input_data)\n<\/code><\/pre>\n<p><strong>Configure the training run:<\/strong><\/p>\n<pre><code>src = ScriptRunConfig(source_directory=script_folder,\n                      script='train_titanic.py',\n                      # pass dataset as an input with friendly name 'titanic'\n                      arguments=['--input-data', titanic_ds.as_named_input('titanic')],\n                      compute_target=compute_target,\n                      environment=myenv)\n<\/code><\/pre>\n<p><strong>Pass <code>mounted_input_path<\/code> as argument:<\/strong><\/p>\n<pre><code>mounted_input_path = sys.argv[1]\nmounted_output_path = sys.argv[2]\n\nprint(&quot;Argument 1: %s&quot; % mounted_input_path)\nprint(&quot;Argument 2: %s&quot; % mounted_output_path)\n<\/code><\/pre>\n<p>References: <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/v1\/how-to-create-register-datasets.md\" rel=\"nofollow noreferrer\">How to create register dataset<\/a> and <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/scriptrun-with-data-input-output\/how-to-use-scriptrun.ipynb\" rel=\"nofollow noreferrer\">How to use configure a training run with data input and output<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-06 04:42:30.893 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72831360",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66978458,
        "Question_title":"In Azure ML timeseries forecasting, Model Explanations, how do I upload actual values?",
        "Question_body":"<p>Using Azure ML through the web UI. I'm doing a timeseries forecasting automl training job. In the explanations tab for a model, how can I upload the actual data for the forecast period to compare. See the red circled box in the image below.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/hBhzR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hBhzR.png\" alt=\"Example Explanation GUI\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-07 01:36:26.41 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":53,
        "Owner_creation_date":"2011-12-20 03:17:46.393 UTC",
        "Owner_last_access_date":"2022-09-15 01:17:57.817 UTC",
        "Owner_reputation":1306,
        "Owner_up_votes":49,
        "Owner_down_votes":5,
        "Owner_views":81,
        "Answer_body":"<p>We are currently developing test-set ingestion in the UI. However, currently there is no way to upload test data through the UI to populate these graphs. This experience can only be accessed by kicking off an explanation through the SDK with the test data. We refer to this as &quot;Interpretability at inference time&quot; and have some documentation on how to do this here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#interpretability-at-inference-time\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#interpretability-at-inference-time<\/a><\/p>\n<p>Test-set ingestion is scoped to land for private preview before end of June. Let's keep in touch to ensure you get early access here.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-07 22:54:26.05 UTC",
        "Answer_score":1.0,
        "Owner_location":"Christchurch, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66978458",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64546521,
        "Question_title":"Azure ML FileDataset registers, but cannot be accessed for Data Labeling project",
        "Question_body":"<p><strong>Objective<\/strong>: Generate a down-sampled FileDataset using random sampling from a larger FileDataset to be used in a Data Labeling project.<\/p>\n<hr \/>\n<p><strong>Details<\/strong>: I have a large FileDataset containing millions of images. Each filename contains details about the 'section' it was taken from. A section may contain thousands of images. I want to randomly select a specific number of <strong>sections<\/strong> and all the images associated with those sections. Then register the sample as a new dataset.<\/p>\n<p>Please note that the code below is not a direct copy and paste as there are elements such as filepaths and variables that have been renamed for confidentiality reasons.<\/p>\n<pre><code>import azureml.core\nfrom azureml.core import Dataset, Datastore, Workspace\n\n# Load in work space from saved config file\nws = Workspace.from_config()\n\n# Define full dataset of interest and retrieve it\ndataset_name = 'complete_2017'\ndata = Dataset.get_by_name(ws, dataset_name)\n\n# Extract file references from dataset as relative paths\nrel_filepaths = data.to_path()\n\n# Stitch back in base directory path to get a list of absolute paths\nsrc_folder = '\/raw-data\/2017'\nabs_filepaths = [src_folder + path for path in rel_filepaths]\n\n# Define regular expression pattern for extracting source section\nimport re\npattern = re.compile('\\\/(S.+)_image\\d+.jpg')\n\n# Create new list of all unique source sections\nsections = sorted(set([m.group(1) for m in map(pattern.match, rel_filepaths) if m]))\n\n# Randomly select sections\nnum_sections = 5\nset_seed = 221020\nrandom.seed(set_seed)   # for repeatibility\nsample_sections = random.choices(sections, k = num_sections)\n\n# Extract images related to the selected sections\nmatching_images = [filename for filename in abs_filepaths if any(section in filename for section in sample_sections)]\n\n# Define datastore of interest\ndatastore = Datastore.get(ws, 'ml-datastore')\n\n# Convert string paths to Azure Datapath objects and relate back to datastore\nfrom azureml.data.datapath import DataPath\ndatastore_path = [DataPath(datastore, filepath) for filepath in matching_images]\n\n# Generate new dataset using from_files() and filtered list of paths\nsample = Dataset.File.from_files(datastore_path)\n\nsample_name = 'random-section-sample'\nsample_dataset = sample.register(workspace = ws, name = sample_name, description = 'Sampled sections from full dataset using set seed.')\n<\/code><\/pre>\n<hr \/>\n<p><strong>Issue<\/strong>: The code I've written in Python SDK runs and the new FileDataset registers, but when I try to look at the dataset details or use it for a Data Labeling project I get the following error even as <em>Owner<\/em>.<\/p>\n<pre><code>Access denied: Failed to authenticate data access with Workspace system assigned identity. Make sure to add the identity as Reader of the data service.\n<\/code><\/pre>\n<p>Additionally, under the details tab <strong>Files in dataset<\/strong> is <em>Unknown<\/em> and <strong>Total size of files in dataset<\/strong> is <em>Unavailable<\/em>.<\/p>\n<p>I haven't come across this issue anywhere else. I'm able to generate datasets in other ways, so I suspect it's an issue with the code given that I'm working with the data in an unconventional way.<\/p>\n<hr \/>\n<p><strong>Additional Notes<\/strong>:<\/p>\n<ul>\n<li>Azure ML version is 1.15.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-10-26 23:50:26.34 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":801,
        "Owner_creation_date":"2020-10-26 22:17:36.893 UTC",
        "Owner_last_access_date":"2021-04-24 22:21:57.223 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>One of my colleagues discovered that the managed identities were preventing the preview functionality. Once this aspect of the identities was modified, we could examine the data and use it for a data labelling project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-28 20:31:26.963 UTC",
        "Answer_score":1.0,
        "Owner_location":"New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64546521",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60490195,
        "Question_title":"Unable to build local AMLS environment with private wheel",
        "Question_body":"<p>I am trying to write a small program using the AzureML Python SDK (v1.0.85) to register an Environment in AMLS and use that definition to construct a local Conda environment when experiments are being run (for a pre-trained model). The code works fine for simple scenarios where all dependencies are loaded from Conda\/ public PyPI, but when I introduce a private dependency (e.g. a utils library) I am getting a InternalServerError with the message \"Error getting recipe specifications\".<\/p>\n\n<p>The code I am using to register the environment is (after having authenticated to Azure and connected to our workspace):<\/p>\n\n<pre><code>environment_name = config['environment']['name']\npy_version = \"3.7\"\nconda_packages = [\"pip\"]\npip_packages = [\"azureml-defaults\"]\nprivate_packages = [\".\/env-wheels\/utils-0.0.3-py3-none-any.whl\"]\n\nprint(f\"Creating environment with name {environment_name}\")\nenvironment = Environment(name=environment_name)\nconda_deps = CondaDependencies()\n\nprint(f\"Adding Python version: {py_version}\")\nconda_deps.set_python_version(py_version)\n\nfor conda_pkg in conda_packages:\n    print(f\"Adding Conda denpendency: {conda_pkg}\")\n    conda_deps.add_conda_package(conda_pkg)\n\nfor pip_pkg in pip_packages:\n    print(f\"Adding Pip dependency: {pip_pkg}\")\n    conda_deps.add_pip_package(pip_pkg)\n\nfor private_pkg in private_packages:\n    print(f\"Uploading private wheel from {private_pkg}\")\n    private_pkg_url = Environment.add_private_pip_wheel(workspace=ws, file_path=Path(private_pkg).absolute(), exist_ok=True)\n    print(f\"Adding private Pip dependency: {private_pkg_url}\")\n    conda_deps.add_pip_package(private_pkg_url)\n\nenvironment.python.conda_dependencies = conda_deps\nenvironment.register(workspace=ws)\n<\/code><\/pre>\n\n<p>And the code I am using to create the local Conda environment is:<\/p>\n\n<pre><code>amls_environment = Environment.get(ws, name=environment_name, version=environment_version)\n\nprint(f\"Building environment...\")\namls_environment.build_local(workspace=ws)\n<\/code><\/pre>\n\n<p>The exact error message being returned when <code>build_local(...)<\/code> is called is:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\core\\environment.py\", line 814, in build_local\n    raise error\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\core\\environment.py\", line 807, in build_local\n    recipe = environment_client._get_recipe_for_build(name=self.name, version=self.version, **payload)\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\_restclient\\environment_client.py\", line 171, in _get_recipe_for_build\n    raise Exception(message)\nException: Error getting recipe specifications. Code: 500\n: {\n  \"error\": {\n    \"code\": \"ServiceError\",\n    \"message\": \"InternalServerError\",\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": null,\n    \"debugInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"15043e1469e85a4c96a3c18c45a2af67\",\n    \"request\": \"19231be75a2b8192\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2020-02-28T09:38:47.8900715+00:00\"\n}\n\nProcess finished with exit code 1\n<\/code><\/pre>\n\n<p>Has anyone seen this error before or able to provide some guidance around what the issue may be?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-02 13:47:16.04 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":239,
        "Owner_creation_date":"2018-05-21 07:58:33.9 UTC",
        "Owner_last_access_date":"2021-05-20 12:08:27.353 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>The issue was with out firewall blocking the required requests between AMLS and the storage container (I presume to get the environment definitions\/ private wheels).<\/p>\n\n<p>We resolved this by updating the firewall with appropriate ALLOW rules for the AMLS service to contact and read from the attached storage container.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-03-03 13:55:58.05 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60490195",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55941720,
        "Question_title":"R web scraping in Azure ML errors out",
        "Question_body":"<p>I have written a script in RStudio (running R 3.5.2) that scrapes data from a particular website. The script reaches out to a website, uses download.file to pull the underlying code, and uses tags to extract the desired data.<\/p>\n\n<p>The script runs without error in RStudio, but when I try to run the code in the \"Execute R Script\" node in Azure ML it throws a 0063 error saying that it \"cannot reach URL \". The code runs perfectly up until it tries to reach out to the URL. (see code below)<\/p>\n\n<p>I have tried switching the R version in Azure ML--neither of the 3 options work.<\/p>\n\n<pre class=\"lang-r prettyprint-override\"><code>for(a in 1:length(job_url)) {\n     download.file(url, destfile = filename, quiet=TRUE)\n      ...\n}\n<\/code><\/pre>\n\n<p>I expect the script to run the same in RStudio and Azure ML. Any ideas how to get this script to run in Azure ML the same way it runs in RStudio?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-01 19:37:28.177 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":84,
        "Owner_creation_date":"2019-05-01 19:06:54.63 UTC",
        "Owner_last_access_date":"2019-10-17 18:18:11.42 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<blockquote>\n  <p>For security reasons, all networking from or to R code in Execute R Script modules is blocked by Azure.<\/p>\n<\/blockquote>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#networking\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#networking<\/a><\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2019-05-01 21:28:02.267 UTC",
        "Answer_score":2.0,
        "Owner_location":"Columbus, OH, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55941720",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69561386,
        "Question_title":"How do I use Service Principal authentication with an Azure Machine Learning Pipeline Endpoint in C#?",
        "Question_body":"<p>I'm trying to call an Azure Machine Learning Pipeline Endpoint I've set up using C# &amp; the Machine Learning REST api.<\/p>\n<p>I am certain that I have the Service Principal configured correctly, as I can successfully authenticate &amp; hit the endpoint using the <code>azureml-core<\/code> python sdk:<\/p>\n<pre><code>sp = ServicePrincipalAuthentication(\n    tenant_id=tenant_id,\n    service_principal_id=service_principal_id,\n    service_principal_password=service_principal_password)\nws =Workspace.get(\n    name=workspace_name, \n    resource_group=resource_group, \n    subscription_id=subscription_id, \n    auth=sp)\n\nendpoint = PipelineEndpoint.get(ws, name='MyEndpoint')\nendpoint.submit('Test_Experiment')\n<\/code><\/pre>\n<p>I'm using the following example in C# to attempt to run my endpoint: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c<\/a><\/p>\n<p>I'm attempting to fill <code>auth_key<\/code> with the following code:<\/p>\n<pre><code>var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\nvar clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\nvar tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\nvar cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\nvar auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] {&quot;.default&quot; }));\n<\/code><\/pre>\n<p>I receive a 401 (unauthorized).<\/p>\n<p>What am I am doing wrong?<\/p>\n<ul>\n<li>UPDATE *<\/li>\n<\/ul>\n<p>I changed the 'scopes' param in the <code>TokenRequestContext<\/code> to look like:<\/p>\n<pre><code>var auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] { &quot;http:\/\/DataTriggerApp\/.default&quot; }));\n<\/code><\/pre>\n<p><code>http:\/\/DataTriggerApp<\/code> is one of the <code>servicePrincipalNames<\/code> that shows up when i query my Service Principal from the azure CLI.<\/p>\n<p>Now, when I attempt to use the returned token to call the Machine Learning Pipeline Endpoint, I receive a 403 instead of a 401.  Maybe some progress?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-13 19:37:07.71 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-10-13 20:21:13.113 UTC",
        "Question_score":1,
        "Question_tags":"c#|azure|asp.net-core-3.1|azure-machine-learning-service|azure-service-principal",
        "Question_view_count":752,
        "Owner_creation_date":"2012-06-27 21:51:16.13 UTC",
        "Owner_last_access_date":"2022-09-21 21:19:20.11 UTC",
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Answer_body":"<p>Ok, through a lot of trial-and-error I was able to come up with two ways of acquiring a token that allows me to hit my Azure Machine Learning Pipeline Endpoint through the REST api.  One uses Microsoft.Identity.Client &amp; one uses Azure.Identity.<\/p>\n<pre><code>using Microsoft.Identity.Client;\n\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n   \n      var app = ConfidentialClientApplicationBuilder.Create(clientId)\n                                                .WithClientSecret(clientSecret)                                                \n                                                .WithAuthority(AzureCloudInstance.AzurePublic, tenantId)\n                                                .Build();\n      var result = await app.AcquireTokenForClient(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }).ExecuteAsync();\n      return result.AccessToken;\n}\n<\/code><\/pre>\n<p>Or:<\/p>\n<pre><code>using Azure.Identity;\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n\n      var cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\n      var token =  await cred.GetTokenAsync(new Azure.Core.TokenRequestContext(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }));\n      return token.Token;\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-13 21:20:31.173 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-10-13 21:27:39.93 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69561386",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60637170,
        "Question_title":"How to pass arguments to scoring file when deploying a Model in AzureML",
        "Question_body":"<p>I am deploying a trained model to an ACI endpoint on Azure Machine Learning, using the Python SDK.\nI have created my score.py file, but I would like that file to be called with an argument being passed (just like with a training file) that I can interpret using <code>argparse<\/code>.\nHowever, I don't seem to find how I can pass arguments\nThis is the code I have to create the InferenceConfig environment and which obviously does not work.  Should I fall back on using the extra Docker file steps or so?<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.environment import Environment\nfrom azureml.core.model import InferenceConfig\n\nenv = Environment('my_hosted_environment')\nenv.python.conda_dependencies = CondaDependencies.create(\n    conda_packages=['scikit-learn'],\n    pip_packages=['azureml-defaults'])\nscoring_script = 'score.py --model_name ' + model_name\ninference_config = InferenceConfig(entry_script=scoring_script, environment=env)\n<\/code><\/pre>\n\n<p>Adding the score.py for reference on how I'd love to use the arguments in that script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>#removed imports\nimport argparse\n\ndef init():\n    global model\n\n    parser = argparse.ArgumentParser(description=\"Load sklearn model\")\n    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n    args, _ = parser.parse_known_args()\n\n    model_path = Model.get_model_path(model_name=args.model_name)\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    try:\n        data = json.loads(raw_data)['data']\n        data = np.array(data)\n        result = model.predict(data)\n        return result.tolist()\n\n    except Exception as e:\n        result = str(e)\n        return result\n<\/code><\/pre>\n\n<p>Interested to hear your thoughts<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2020-03-11 13:27:40.433 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-12 09:38:40.357 UTC",
        "Question_score":4,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1681,
        "Owner_creation_date":"2013-02-12 07:50:30.743 UTC",
        "Owner_last_access_date":"2022-09-21 18:28:12.907 UTC",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Answer_body":"<p>How to deploy using environments can be found here <a href=\"https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2FAzure%2FMachineLearningNotebooks%2Fblob%2Fmaster%2Fhow-to-use-azureml%2Fdeployment%2Fdeploy-to-cloud%2Fmodel-register-and-deploy.ipynb&amp;data=02%7C01%7CRamprasad.Mula%40microsoft.com%7Ce06d310b0447416ab46b08d7bc836a81%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637185146436156499&amp;sdata=uQo332dpjuiNqWFCguvs3Kgg7UUMN8MBEzLxTPyH4MM%3D&amp;reserved=0\" rel=\"nofollow noreferrer\">model-register-and-deploy.ipynb<\/a> .  InferenceConfig class accepts  source_directory and entry_script <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py#parameters\" rel=\"nofollow noreferrer\">parameters<\/a>, where source_directory  is a path to the folder that contains all files(score.py and any other additional files) to create the image. <\/p>\n\n<p>This <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\" rel=\"nofollow noreferrer\">multi-model-register-and-deploy.ipynb<\/a> has code snippets on how to create InferenceConfig with source_directory and entry_script.<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\n\nmyenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\ninference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n\nservice = Model.deploy(workspace=ws,\n                       name='sklearn-mnist-svc',\n                       models=[model], \n                       inference_config=inference_config,\n                       deployment_config=aciconfig)\n\nservice.wait_for_deployment(show_output=True)\n\nprint(service.scoring_uri)\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-03-12 09:36:25.48 UTC",
        "Answer_score":-2.0,
        "Owner_location":"Belgium",
        "Answer_last_edit_date":"2020-03-12 11:19:48.083 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60637170",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58307950,
        "Question_title":"Azure Machine Learning Compute quota?",
        "Question_body":"<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-manage-quotas#azure-machine-learning-compute\" rel=\"nofollow noreferrer\">Manage and request quotas for Azure resources<\/a> documentation page states that the default quota depends \"on your subscription offer type\". The quota doesn't show up in Azure web portal. Is there a way to find out current quota values using SDK, CLI, REST API?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-09 15:53:06.64 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":354,
        "Owner_creation_date":"2018-02-15 14:47:43.68 UTC",
        "Owner_last_access_date":"2022-08-24 16:53:36.967 UTC",
        "Owner_reputation":95,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>You probably want to try something like this command : <\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>az vm list-usage --location eastus --out table\n<\/code><\/pre>\n\n<p>It would get you the core usage for the region, which is what is important for deployment of resources.<\/p>\n\n<p>Other choices (az + Powershell) are available <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/networking\/check-usage-against-limits\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>Hope this helps!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-10-10 01:05:28.59 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58307950",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33741912,
        "Question_title":"How connect Azure Machine Learning and Spark Streaming or Apache Storm",
        "Question_body":"<p>Is there possibility to get stream from Spark Streaming or Apache Storm into Azure Machine Learning? In <strong><em>reader<\/em><\/strong> option there is an input to read data from Hive database\n<a href=\"https:\/\/i.stack.imgur.com\/8Em26.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8Em26.png\" alt=\"hive\"><\/a><\/p>\n\n<p>but how to achive real time stream of data from Spark or Storm, for example <strong><em>Real-time fraud detection<\/em><\/strong><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-11-16 18:12:20.763 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-01 16:32:46.663 UTC",
        "Question_score":0,
        "Question_tags":"azure|hadoop|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":549,
        "Owner_creation_date":"2012-01-25 08:53:59.093 UTC",
        "Owner_last_access_date":"2022-09-23 09:28:05.37 UTC",
        "Owner_reputation":2923,
        "Owner_up_votes":875,
        "Owner_down_votes":5,
        "Owner_views":838,
        "Answer_body":"<p>To do real time Fraud detection typically you will create a Model on Azure ML, then publish that model to oWeb service, then on you Spark or Storm system you will call that Web service, in  sequence ( like payment happened on commercial sites for example), then you will get an immediate answer about the actual parameters you had sent in you web service call.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-11-25 13:19:15.593 UTC",
        "Answer_score":1.0,
        "Owner_location":"Poznan, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33741912",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51086377,
        "Question_title":"Upload Microsoft Excel Workbook with Many Sheets into Azure ML Studio",
        "Question_body":"<p>I want to upload my <code>Excel<\/code> Workbook into Azure Machine Learning Studio. The reason is I have some data that I would like to join into my other <code>.csv<\/code> files to create a training data set. \nWhen I upload my <code>Excel<\/code>, I don't get <code>.xlsx<\/code>, or <code>.xls<\/code>, but other extensions such as <code>.csv<\/code>, <code>.txt<\/code> etc.. <\/p>\n\n<p>This is how it looks,\n<a href=\"https:\/\/i.stack.imgur.com\/SrSon.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/SrSon.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I uploaded anyways and now, I am getting weird characters. How can I get excel workbook uploaded and get my sheets, so, I can join data and do, data preparation. Any suggestions?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-06-28 15:15:36.39 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"excel|azure|azure-machine-learning-studio",
        "Question_view_count":577,
        "Owner_creation_date":"2018-03-01 20:34:46.96 UTC",
        "Owner_last_access_date":"2021-10-20 03:57:09.683 UTC",
        "Owner_reputation":1113,
        "Owner_up_votes":75,
        "Owner_down_votes":1,
        "Owner_views":122,
        "Answer_body":"<p>You could save the workbook as a (set of) CSV file(s) and upload them separately.<\/p>\n\n<p>A CSV file, a '<a href=\"https:\/\/en.wikipedia.org\/wiki\/Comma-separated_values\" rel=\"nofollow noreferrer\">Comma Separated Values<\/a>' file, is exactly that. A flat file with some values separated by a comma. If you load an Excel file it will mess up since there's way more information in an Excel file than just values separated by comma's. Have a look at <code>File<\/code> -> <code>Save as<\/code> -> <code>Save as type<\/code> where you can select 'CSV (comma delimited) (*.csv)'<\/p>\n\n<p><em>Disclaimer: no, it's not always a comma...<\/em>  <\/p>\n\n<blockquote>\n  <p>In addition, the term \"CSV\" also denotes some closely related delimiter-separated formats that use different field delimiters. These include tab-separated values and space-separated values. A delimiter that is not present in the field data (such as tab) keeps the format parsing simple. These alternate delimiter-separated files are often even given a .csv extension despite the use of a non-comma field separator.<\/p>\n<\/blockquote>\n\n<p><strong>Edit<\/strong><br>\nSo apparently Excel files <em>are<\/em> supported: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/desktop-workbench\/data-prep-appendix2-supported-data-sources\" rel=\"nofollow noreferrer\">Supported data sources for Azure Machine Learning data preparation<\/a>  <\/p>\n\n<p><em>Excel (.xls\/.xlsx)<\/em><br>\nRead an Excel file one sheet at a time by specifying sheet name or number.<\/p>\n\n<p>But also, only UTF-8 is supported: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/import-data#bkmk_Notes\" rel=\"nofollow noreferrer\">Import Data - Technical notes<\/a><\/p>\n\n<blockquote>\n  <p>Azure Machine Learning requires UTF-8 encoding. If the data you are importing uses a different encoding, or was exported from a data source that uses a different default encoding, various problems might appear in the text.<\/p>\n<\/blockquote>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2018-06-28 15:20:30.417 UTC",
        "Answer_score":1.0,
        "Owner_location":"Minneapolis, MN, USA",
        "Answer_last_edit_date":"2018-06-28 15:41:36.84 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51086377",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40234432,
        "Question_title":"Create a model that predicts an event based on other time series events and properties of an object",
        "Question_body":"<p>I have the following data:<\/p>\n\n<ul>\n<li>Identifier of a person<\/li>\n<li>Days in location (starts at 1 and runs until event)<\/li>\n<li>Age of person in months at that time (so this increases as the days in location increase too).<\/li>\n<li>Smoker (boolean), doesn't change over time in our case<\/li>\n<li>Sex, doesn't change over time<\/li>\n<li>Fall (boolean) this is an event that may never happen, or can happen multiple times during the complete period for a certain person<\/li>\n<li>Number of wounds: (this can go from 0 to 8), a wound mostly doesn't heal immediately so it mostly stays open for a certain period of time<\/li>\n<li>Event we want to predict (boolean), only the last row of a person will have value true for this<\/li>\n<\/ul>\n\n<p>I have this data for 1500 people (in total 1500000 records so on average about 1000 records per person). For some people the event I want to predict takes place after a couple of days, for some after 10 years.  For everybody in the dataset the event will take place, so the last record for a certain identifier will always have the event we want to predict as 1.<\/p>\n\n<p>I'm new to this and all the documentation I have found so far doesn't demonstrate time series for multiple persons or objects. When I for example split the data in the machine learning studio, I want to keep records of the same person over time together.<\/p>\n\n<p>Would it be possible to feed the system after the model is trained with new records and for each day that passes it would give the estimate of the event taking place in the next 5 days?<\/p>\n\n<p>Edit: sample data of 2 persons: <a href=\"http:\/\/pastebin.com\/KU4bjKwJ\" rel=\"nofollow\">http:\/\/pastebin.com\/KU4bjKwJ<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-10-25 07:58:48.947 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-10-25 12:58:24.01 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|prediction|azure-machine-learning-studio",
        "Question_view_count":596,
        "Owner_creation_date":"2012-08-19 21:59:16.18 UTC",
        "Owner_last_access_date":"2022-09-24 10:22:06.74 UTC",
        "Owner_reputation":1946,
        "Owner_up_votes":256,
        "Owner_down_votes":7,
        "Owner_views":211,
        "Answer_body":"<p>sounds like very similar to this sample:<\/p>\n\n<p><a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/df7c518dcba7407fb855377339d6589f\" rel=\"nofollow\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/df7c518dcba7407fb855377339d6589f<\/a><\/p>\n\n<p>Unfortunately there is going to be a bit of R code involved. Yes you should be able to retrain the model with new data.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-25 14:00:12.397 UTC",
        "Answer_score":0.0,
        "Owner_location":"Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40234432",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70156610,
        "Question_title":"Accessing an Azure ML Model Registry from another Azure ML Workspace",
        "Question_body":"<p>Suppose I have two Azure ML workspaces:<\/p>\n<ol>\n<li><p>Workspace1 - This is being used by one team (Team1) who only train the model and store the model in model registry of Workspace1<\/p>\n<\/li>\n<li><p>Workspace2 - This is used by another team  (Team2) who containerise the model, push it to ACR and then deploy the containerised model in Azure ML Compute.<\/p>\n<\/li>\n<\/ol>\n<p>Is it possible for Team2 to access the model registry of Workspace1 from their Workspace2 and retrieve the model for containerisation and subsequent deployment? Alternatively, is there any concept of a shared model registry in Azure ML where both the teams can store and access a common model registry? If none of these are possible, then what is the way for Team1 and Team2 to work together on a single model with the given responsibilities as described above?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-29 14:47:33.147 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":421,
        "Owner_creation_date":"2013-07-10 15:44:54.267 UTC",
        "Owner_last_access_date":"2022-09-23 14:36:38.093 UTC",
        "Owner_reputation":395,
        "Owner_up_votes":11,
        "Owner_down_votes":3,
        "Owner_views":66,
        "Answer_body":"<p>As described, I think the best solution is to use one Workspace, not two.  It sounds like you have Team 1 and Team 2 sharing contributions on a single project.  What may work better is to define user roles in the Azure ML workspace, such that Team 2 has permissions to deploy models, and Team 1 has permission to create models.<\/p>\n<p>Otherwise you can always write Python code using the ML SDK to connect to any workspace given you know the subscription, resource group, workspace name etc.<\/p>\n<pre><code>from azure.core import Workspace, Model\n\n# connect to an existing workspace\nname = 'WorkspaceName'\nsub = 'subscriptionName'\nresource_group = 'resourceGroupName'\nws = Workspace.get(name=name, subscription_id=sub, resource_group=resource_group) \n\n# retrieve existing model\nmodel = Model(ws, name='your model name')\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-11-29 18:28:09.53 UTC",
        "Answer_score":2.0,
        "Owner_location":"United Kingdom",
        "Answer_last_edit_date":"2021-11-29 21:06:55.58 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70156610",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63268849,
        "Question_title":"ERR_HTTP2_PROTOCOL_ERROR when opening Notebook in JUPYTERLAB Azure ML Studio",
        "Question_body":"<p>So our team created a new Azure <strong>Machine Learning<\/strong> resource, but whenever I try to add a new notebook and try to edit it using &quot;JUPYTERLAB&quot; i get <code>ERR_HTTP2_PROTOCOL_ERROR<\/code> error, but the same notebook, when edited using <code>EDIT IN JUPYTER<\/code> works perfectly.<\/p>\n<p>This is a blank and clean notebook, I also tried 2 different laptops and multiple browsers per laptop, same error. I also tried incognito and clearing cookies, but to no avail.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/IevSG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/IevSG.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>update: I seem to have accidentally replicated the issue and I now know what is causing it, the situation is that Im using my work laptop and constantly switching VPN connections, and some times, connecting to the AZURE PORTAl OUTSIDE the VPN. So, when you've worked on a notebook while inside a VPN, then you disconnected, and tried loading the notebook sometime later, you will encounter this<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-05 15:47:33.543 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-08-10 10:48:21.367 UTC",
        "Question_score":1,
        "Question_tags":"jupyter-notebook|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":246,
        "Owner_creation_date":"2012-06-18 23:56:44.277 UTC",
        "Owner_last_access_date":"2022-09-24 14:51:42.627 UTC",
        "Owner_reputation":298,
        "Owner_up_votes":10,
        "Owner_down_votes":1,
        "Owner_views":38,
        "Answer_body":"<p>This problem has stomped me for hours, but I was finally able to fix it. What I did was I opened a terminal and did a Jupyter lab rebuild &quot;jupyter lab build&quot;<\/p>\n<p><a href=\"https:\/\/imgur.com\/aRB8GWS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/imgur.com\/aRB8GWS.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/IceQO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/IceQO.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-08-05 16:08:25.983 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-08-05 23:10:31.917 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63268849",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59517355,
        "Question_title":"Permission denied: '.\\NTUSER.DAT' when trying to run an Azure ML Pipeline",
        "Question_body":"<p>The short story is, when I try to submit an azure ML pipeline run (an <em>azure ML pipeline<\/em>, not an <em>Azure pipeline<\/em>) from a jupyter notebook, I get PermissionError: [Errno 13] Permission denied: '.\\NTUSER.DAT'.  More details:<\/p>\n\n<p>Relevant code:<\/p>\n\n<pre><code>from azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.runtime import AutoMLStep\nautoml_settings = {\n    \"iteration_timeout_minutes\": 20,\n    \"experiment_timeout_minutes\": 30,\n    \"n_cross_validations\": 3,\n    \"primary_metric\": 'r2_score',\n    \"preprocess\": True,\n    \"max_concurrent_iterations\": 3,\n    \"max_cores_per_iteration\": -1,\n    \"verbosity\": logging.INFO,\n    \"enable_early_stopping\": True,\n    'time_column_name': \"DateTime\"\n}\n\nautoml_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             path = \".\",\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config,                               \n                             training_data = financeforecast_dataset,\n                             label_column_name = 'TotalUSD',\n                             **automl_settings\n                            )\n\nautoml_step = AutoMLStep(\n    name='automl_module',\n    automl_config=automl_config,\n    allow_reuse=False)\n\ntraining_pipeline = Pipeline(\n    description=\"training_pipeline\",\n    workspace=ws,    \n    steps=[automl_step])\n\ntraining_pipeline_run = Experiment(ws, 'test').submit(training_pipeline)\n<\/code><\/pre>\n\n<p>The training_pipeline step runs for apx 20 seconds, and then I get a long trace, ending in:<\/p>\n\n<pre><code>~\\AppData\\Local\\Continuum\\anaconda2\\envs\\forecasting\\lib\\site- \npackages\\azureml\\pipeline\\core\\_module_builder.py in _hash_from_file_paths(hash_src)\n    100             hasher = hashlib.md5()\n    101             for f in hash_src:\n--&gt; 102                 with open(str(f), 'rb') as afile:\n    103                     buf = afile.read()\n    104                     hasher.update(buf)\n\nPermissionError: [Errno 13] Permission denied: '.\\\\NTUSER.DAT'\n<\/code><\/pre>\n\n<p>According to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">Azure's docs on this topic<\/a>, submitting a pipeline uploads a \"snapshot\" of the \"source directory\" you specified.  Initially, I hadn't specified a source directory, so, to test that out, I added: <\/p>\n\n<pre><code>default_source_directory=\"testing\",\n<\/code><\/pre>\n\n<p>as a parameter for the training_pipeline object, but saw the same behavior when I then tried to run it.  Not sure if that is the same source directory the documentation is referring to.  The docs also say that if no source directory is specified, the \"current local directory\" is uploaded.  I used print (os.getcwd()) to get the working directory and gave \"Everyone\" full control permissions on the directory (working in a windows env).<\/p>\n\n<p>All the preceding code works fine, and I can submit an experiment if I use a ScriptRunConfig and run it on attached compute rather than using a pipeline\/training cluster.  <\/p>\n\n<p>Any ideas?  Thanks in advance to anyone who tries to help.  P.S. There is no \"azure-machine-learning-pipelines\" tag, and I can't add one because I don't have enough reputation points.  Someone else could though!  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines\" rel=\"nofollow noreferrer\">General<\/a> info on what they are.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-29 06:39:40.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio|automl",
        "Question_view_count":409,
        "Owner_creation_date":"2018-11-09 22:24:53.2 UTC",
        "Owner_last_access_date":"2022-09-21 15:21:46.45 UTC",
        "Owner_reputation":163,
        "Owner_up_votes":53,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>I resolved this answer by setting the path and the data_script variables in the AutoMLConfig task object, like this (relevant code indicated by -->):<\/p>\n\n<pre><code>automl_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config,\n                             --&gt;path = \"c:\\\\users\\\\me\",\n                             data_script =\"script.py\",&lt;--\n                             **automl_settings\n                            )\n<\/code><\/pre>\n\n<p>Setting the data_script variable to include the full path, as shown below, did not work.<\/p>\n\n<pre><code>automl_config = AutoMLConfig(task = 'forecasting',\n                             debug_log = 'automl_errors.log',\n                             path = \".\",\n                             --&gt;data_script = \"c:\\\\users\\\\me\\\\script.py\"&lt;--\n                             compute_target=compute_target,\n                             run_configuration=conda_run_config, \n                             **automl_settings\n                            )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-01-02 19:50:37.207 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59517355",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57403281,
        "Question_title":"Installing textshape package for Microsoft R Open 3.4.4 on Azure ML Studio",
        "Question_body":"<p>I'm trying to use the R <code>sentimentr<\/code> package on Azure ML Studio. As this package is not supported, I'm trying to install it and its dependencies as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#bkmk_AddingANewPackage\" rel=\"nofollow noreferrer\">in the documentation<\/a>.<\/p>\n\n<p>The steps that I have performed are:<\/p>\n\n<ul>\n<li><p>downloaded Windows binaries from the R Open 3.4.4 snapshot at <a href=\"https:\/\/mran.microsoft.com\/timemachine\" rel=\"nofollow noreferrer\">CRAN time machine<\/a><\/p>\n\n<ul>\n<li><code>sentimentr_2.2.3.zip<\/code><\/li>\n<li><code>syuzhet_1.0.4.zip<\/code><\/li>\n<li><code>textclean_0.6.3.zip<\/code><\/li>\n<li><code>lexicon_0.7.4.zip<\/code><\/li>\n<li><code>textshape_1.5.0.zip<\/code> <\/li>\n<\/ul><\/li>\n<li><p>zipped those zip files into a zipped folder <code>packages.zip<\/code><\/p><\/li>\n<li>uploaded <code>packages.zip<\/code> as a dataset to Microsoft Azure ML Studio<\/li>\n<\/ul>\n\n<p>In my ML experiment I connect the <code>packages.zip<\/code> dataset to the \"Script Bundle (Zip)\" input port on \"Execute R Script\" and include this code:<\/p>\n\n<pre><code># install R package contained in src  \ninstall.packages(\"src\/lexicon_0.7.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textclean_0.6.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textshape_1.5.0.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/syuzhet_1.0.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/sentimentr_2.2.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\n# load libraries\nlibrary(sentimentr, lib.loc = \".\", verbose = TRUE)\n<\/code><\/pre>\n\n<p>The experiment runs successfully, until I include a function from <code>sentimentr<\/code>:<\/p>\n\n<pre><code>mydata &lt;- mydata %&gt;%\n  get_sentences() %&gt;%\n  sentiment()\n<\/code><\/pre>\n\n<p>This gives the error:<\/p>\n\n<blockquote>\n  <p>there is no package called 'textshape'<\/p>\n<\/blockquote>\n\n<p>Which is difficult to understand given that the output log does not indicate an issue with the packages:<\/p>\n\n<pre><code>[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                           Name  Length                Date\n[Information]         1 sentimentr_2.2.3.zip 3366245 2019-08-07 14:57:00\n[Information]         2    syuzhet_1.0.4.zip 2918474 2019-08-07 15:05:00\n[Information]         3  textclean_0.6.3.zip 1154814 2019-08-07 15:13:00\n[Information]         4    lexicon_0.7.4.zip 4551995 2019-08-07 15:17:00\n[Information]         5  textshape_1.5.0.zip  463095 2019-08-07 15:42:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'lexicon' successfully unpacked and MD5 sums checked   \n[Information]         package 'textclean' successfully unpacked and MD5 sums checked\n[Information]         package 'textshape' successfully unpacked and MD5 sums checked\n[Information]         package 'syuzhet' successfully unpacked and MD5 sums checked\n[Information]         package 'sentimentr' successfully unpacked and MD5 sums checked\n<\/code><\/pre>\n\n<p>Has anyone seen this, or similar issues? Is it possible that \"successfully unpacked\" is not the same as successfully installed and usable?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-07 23:12:10.07 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|package|azure-machine-learning-studio",
        "Question_view_count":157,
        "Owner_creation_date":"2009-04-10 14:49:12.693 UTC",
        "Owner_last_access_date":"2022-09-23 09:38:34.63 UTC",
        "Owner_reputation":30129,
        "Owner_up_votes":685,
        "Owner_down_votes":51,
        "Owner_views":2937,
        "Answer_body":"<p>I can now answer my own question thanks to <a href=\"https:\/\/twitter.com\/bryan_hepworth\/status\/1159432174225055749\" rel=\"nofollow noreferrer\">a hint on Twitter<\/a> from @bryan_hepworth.<\/p>\n\n<p>The R packages were installed correctly, but not in the standard library location. So when a function from <code>sentimentr<\/code> runs, R tries to load the dependency package <code>textshape<\/code>:<\/p>\n\n<pre><code>library(textshape)\n<\/code><\/pre>\n\n<p>Which of course does not exist <em>in the standard location<\/em> as Azure ML does not support it.<\/p>\n\n<p>The solution is to load <code>textshape<\/code> explicitly from its installed location:<\/p>\n\n<pre><code>library(textshape, lib.loc = \".\")\n<\/code><\/pre>\n\n<p>So the solution is: explicitly load packages that you installed at the start of your R code, rather than letting R try to load them as dependencies, which will fail.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-08 22:14:34.167 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sydney, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57403281",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36563769,
        "Question_title":"How to download the entire scored dataset from Azure machine studio?",
        "Question_body":"<p>I have an experiment in azure machine learning studio, and I would like to the see entire scored dataset.<\/p>\n\n<p>Naturally I used the 'visualise' option on the scored dataset but these yields only 100 rows (the test dataset is around 500 rows)<\/p>\n\n<p>I also tired the 'save as dataset' option, but then file does not open well with excel or text editor (special character encoding)<\/p>\n\n<p>Basically, I want to see the entire test data with scored labels as table or download as .csv maybe<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-04-12 04:42:39.04 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":5296,
        "Owner_creation_date":"2014-07-25 05:27:39.94 UTC",
        "Owner_last_access_date":"2022-09-15 08:56:29.147 UTC",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Answer_body":"<p>Please try the Convert to CSV module: <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/faa6ba63-383c-4086-ba58-7abf26b85814\" rel=\"noreferrer\">https:\/\/msdn.microsoft.com\/library\/azure\/faa6ba63-383c-4086-ba58-7abf26b85814<\/a><\/p>\n\n<p>After you run the experiment, right click on the output of the module to download the CSV file.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-04-12 04:57:38.28 UTC",
        "Answer_score":14.0,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36563769",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63766714,
        "Question_title":"Run.get_context() gives the same run id",
        "Question_body":"<p>I am submitting the training through a script file. Following is the content of the <code>train.py<\/code> script. Azure ML is treating all these as one run (instead of run per alpha value as coded below) as <code>Run.get_context()<\/code> is returning the same Run id.<\/p>\n<p><strong>train.py<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.opendatasets import Diabetes\nfrom azureml.core import Run\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.externals import joblib\n\nimport math\nimport os\nimport logging\n\n# Load dataset\ndataset = Diabetes.get_tabular_dataset()\nprint(dataset.take(1))\n\ndf = dataset.to_pandas_dataframe()\ndf.describe()\n\n# Split X (independent variables) &amp; Y (target variable)\nx_df = df.dropna()      # Remove rows that have missing values\ny_df = x_df.pop(&quot;Y&quot;)    # Y is the label\/target variable\n\nx_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=66)\nprint('Original dataset size:', df.size)\nprint(&quot;Size after dropping 'na':&quot;, x_df.size)\nprint(&quot;Training split size: &quot;, x_train.size)\nprint(&quot;Test split size: &quot;, x_test.size)\n\n# Training\nalphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # Define hyperparameters\n\n# Create and log interactive runs\n\noutput_dir = os.path.join(os.getcwd(), 'outputs')\n\nfor hyperparam_alpha in alphas:\n    # Get the experiment run context\n    run = Run.get_context()\n    print(&quot;Started run: &quot;, run.id)\n    run.log(&quot;train_split_size&quot;, x_train.size)\n    run.log(&quot;test_split_size&quot;, x_train.size)\n    run.log(&quot;alpha_value&quot;, hyperparam_alpha)\n\n    # Train\n    print(&quot;Train ...&quot;)\n    model = Ridge(hyperparam_alpha)\n    model.fit(X = x_train, y = y_train)\n    \n    # Predict\n    print(&quot;Predict ...&quot;)\n    y_pred = model.predict(X = x_test)\n\n    # Calculate &amp; log error\n    rmse = math.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred))\n    run.log(&quot;rmse&quot;, rmse)\n    print(&quot;rmse&quot;, rmse)\n\n    # Serialize the model to local directory\n    if not os.path.isdir(output_dir):\n        os.makedirs(output_dir, exist_ok=True) \n\n    print(&quot;Save model ...&quot;)\n    model_name = &quot;model_alpha_&quot; + str(hyperparam_alpha) + &quot;.pkl&quot; # Pickle file\n    file_path = os.path.join(output_dir, model_name)\n    joblib.dump(value = model, filename = file_path)\n\n    # Upload the model\n    run.upload_file(name = model_name, path_or_stream = file_path)\n\n    # Complete the run\n    run.complete()\n<\/code><\/pre>\n<p><strong>Experiments view<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/E6xAG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E6xAG.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Authoring code (i.e. control plane)<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nfrom azureml.core import Workspace, Experiment, RunConfiguration, ScriptRunConfig, VERSION, Run\n\nws = Workspace.from_config()\nexp = Experiment(workspace = ws, name = &quot;diabetes-local-script-file&quot;)\n\n# Create new run config obj\nrun_local_config = RunConfiguration()\n\n# This means that when we run locally, all dependencies are already provided.\nrun_local_config.environment.python.user_managed_dependencies = True\n\n# Create new script config\nscript_run_cfg = ScriptRunConfig(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    script = 'train.py',\n    run_config = run_local_config) \n\nrun = exp.submit(script_run_cfg)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-06 17:01:50.61 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":"2020-09-07 00:23:12.36 UTC",
        "Question_score":3,
        "Question_tags":"azure|hyperparameters|azure-machine-learning-service",
        "Question_view_count":2523,
        "Owner_creation_date":"2009-06-23 03:11:55.29 UTC",
        "Owner_last_access_date":"2022-09-25 03:45:28.337 UTC",
        "Owner_reputation":77230,
        "Owner_up_votes":2724,
        "Owner_down_votes":43,
        "Owner_views":6359,
        "Answer_body":"<h2>Short Answer<\/h2>\n<h3>Option 1: create child runs within run<\/h3>\n<p><code>run = Run.get_context()<\/code> assigns the run object of the run that you're currently in to <code>run<\/code>. So in every iteration of the hyperparameter search, you're logging to the same run. To solve this, you need to create child (or sub-) runs for each hyperparameter value. You can do this with <code>run.child_run()<\/code>. Below is the template for making this happen.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>run = Run.get_context()\n\nfor hyperparam_alpha in alphas:\n    # Get the experiment run context\n    run_child = run.child_run()\n    print(&quot;Started run: &quot;, run_child.id)\n    run_child.log(&quot;train_split_size&quot;, x_train.size)\n<\/code><\/pre>\n<p>On the <code>diabetes-local-script-file<\/code> Experiment page, you can see that Run <code>9<\/code> was the parent run and Runs <code>10-19<\/code> were the child runs if you click &quot;Include child runs&quot; page. There is also a &quot;Child runs&quot; tab on Run 9 details page.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5IMcz.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5IMcz.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h2>Long answer<\/h2>\n<p>I highly recommend abstracting the hyperparameter search away from the data plane (i.e. <code>train.py<\/code>) and into the control plane (i.e. &quot;authoring code&quot;). This becomes especially valuable as training time increases and you can arbitrarily parallelize and also choose Hyperparameters more intelligently by using Azure ML's <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\" rel=\"noreferrer\"><code>Hyperdrive<\/code><\/a>.<\/p>\n<h3>Option 2 Create runs from control plane<\/h3>\n<p>Remove the loop from your code, add the code like below (<a href=\"https:\/\/gist.github.com\/swanderz\/f5c0dc1aefc796d37f6bc3600f2ae3cd\" rel=\"noreferrer\">full data and control here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import argparse\nfrom pprint import pprint\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--alpha', type=float, default=0.5)\nargs = parser.parse_args()\nprint(&quot;all args:&quot;)\npprint(vars(args))\n\n# use the variable like this\nmodel = Ridge(args.alpha)\n<\/code><\/pre>\n<p>below is how to submit a single run using a script argument. To submit multiple runs, just use a loop in the control plane.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # Define hyperparameters\n\nlist_rcs = [ScriptRunConfig(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    script = 'train.py',\n    arguments=['--alpha',a],\n    run_config = run_local_config) for a in alphas]\n\nlist_runs = [exp.submit(rc) for rc in list_rcs]\n\n<\/code><\/pre>\n<h3>Option 3 Hyperdrive (IMHO the recommended approach)<\/h3>\n<p>In this way you outsource the hyperparameter source to <code>Hyperdrive<\/code>. The UI will also report results exactly how you want them, and via the API you can easily download the best model.  Note you can't use this locally anymore and must use <code>AMLCompute<\/code>, but to me it is a worthwhile trade-off.<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters#configure-experiment\" rel=\"noreferrer\">This is a great overview<\/a>. Excerpt below (<a href=\"https:\/\/gist.github.com\/swanderz\/f5c0dc1aefc796d37f6bc3600f2ae3cd#file-hyperdrive-ipynb\" rel=\"noreferrer\">full code here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>param_sampling = GridParameterSampling( {\n        &quot;alpha&quot;: choice(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n    }\n)\n\nestimator = Estimator(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    entry_script = 'train.py',\n    compute_target=cpu_cluster,\n    environment_definition=Environment.get(workspace=ws, name=&quot;AzureML-Tutorial&quot;)\n)\n\nhyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n                          hyperparameter_sampling=param_sampling, \n                          policy=None,\n                          primary_metric_name=&quot;rmse&quot;, \n                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                          max_total_runs=10,\n                          max_concurrent_runs=4)\n\nrun = exp.submit(hyperdrive_run_config)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q1AhJ.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q1AhJ.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-06 23:48:42.23 UTC",
        "Answer_score":7.0,
        "Owner_location":"Cumming, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63766714",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62235365,
        "Question_title":"Models generate different results when moving to Azure Machine Learning Studio",
        "Question_body":"<p>We developed a Jupyter Notebook in a local machine to train models with the Python (V3) libraries <code>sklearn<\/code> and <code>gensim<\/code>.\nAs we set the <code>random_state<\/code> variable to a fixed integer, the results were always the same.<\/p>\n\n<p>After this, we tried moving the notebook to a workspace in Azure Machine Learning Studio (classic), but the results differ even if we leave the <code>random_state<\/code> the same.<\/p>\n\n<p>As suggested in the following links, we installed the same libraries versions and checked the <code>MKL<\/code> version was the same and the <code>MKL_CBWR<\/code> variable was set to <code>AUTO<\/code>.<\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/46766714\/t-sne-generates-different-results-on-different-machines\">t-SNE generates different results on different machines<\/a><\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/38228088\/same-python-code-same-data-different-results-on-different-machines\">Same Python code, same data, different results on different machines<\/a><\/p>\n\n<p>Still, we are not able to get the same results.<\/p>\n\n<p>What else should we check or why is this happening?<\/p>\n\n<p><strong>Update<\/strong><\/p>\n\n<p>If we generate a <code>pkl<\/code> file in the local machine and import it in AML, the results are the same (as the intention of the pkl file is).<\/p>\n\n<p>Still, we are looking to get the same results (if possible) without importing the pkl file.<\/p>\n\n<p><strong>Library versions<\/strong><\/p>\n\n<pre><code>gensim 3.8.3.\nsklearn 0.19.2.\nmatplotlib 2.2.3.\nnumpy 1.17.2.\nscipy 1.1.0.\n<\/code><\/pre>\n\n<p><strong>Code<\/strong><\/p>\n\n<p>Full code can be found <a href=\"https:\/\/t.ly\/YlCi\" rel=\"nofollow noreferrer\">here<\/a>, sample data link inside.<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nfrom gensim.models import KeyedVectors\n%matplotlib inline\n\nimport time\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\n\nwordvectors_file_vec = '..\/libraries\/embeddings-new_large-general_3B_fasttext.vec'\nwordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec)\n\nmath_quests = # some transformations using wordvectors\n\ndf_subset = pd.DataFrame()\n\npca = PCA(n_components=3, random_state = 42)\npca_result = pca.fit_transform(mat_quests)\ndf_subset['pca-one'] = pca_result[:,0]\ndf_subset['pca-two'] = pca_result[:,1] \n\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state = 42)\ntsne_results = tsne.fit_transform(mat_quests)\n\ndf_subset['tsne-2d-one'] = tsne_results[:,0]\ndf_subset['tsne-2d-two'] = tsne_results[:,1]\n\npca_50 = PCA(n_components=50, random_state = 42)\npca_result_50 = pca_50.fit_transform(mat_quests)\nprint('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300, random_state = 42)\ntsne_pca_results = tsne.fit_transform(pca_result_50)\nprint('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2020-06-06 17:23:19.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-07 00:25:15.657 UTC",
        "Question_score":1,
        "Question_tags":"python|scikit-learn|gensim|azure-machine-learning-studio",
        "Question_view_count":201,
        "Owner_creation_date":"2020-03-30 17:44:04.877 UTC",
        "Owner_last_access_date":"2020-06-28 18:13:06.573 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>Definitely empathize with the issue you're having. Every data scientist has struggled with this at some point.<\/p>\n\n<p>The hard truth I have for you is that Azure ML Studio (classic) isn't really capable of  solving this \"works on my machine\" problem. However, the good news is that Azure ML Service is incredible at it. Studio classic doesn't let you define custom environments deterministically, only add and remove packages (and not so well even at that) <\/p>\n\n<p>Because ML Service's execution is built on top of <code>Docker<\/code> containers and <code>conda<\/code> environments, you can feel more confident in repeated results. I highly recommend you take the time to learn it (and I'm also happy to debug any issues that come up). Azure's <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\" rel=\"nofollow noreferrer\">MachineLearningNotebooks repo<\/a> has a lot of great tutorials for getting started.<\/p>\n\n<p>I spent two hours making <a href=\"https:\/\/github.com\/swanderz\/MachineLearningNotebooks\/blob\/SO_CPR\/how-to-use-azureml\/training\/train-on-amlcompute\/train-on-amlcompute.ipynb\" rel=\"nofollow noreferrer\">a proof of concept<\/a> that demonstrate how ML Service solves the problem you're having by synthesizing:<\/p>\n\n<ul>\n<li>your code sample (before you shared your notebook),<\/li>\n<li><a href=\"https:\/\/scikit-learn.org\/stable\/auto_examples\/manifold\/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py\" rel=\"nofollow noreferrer\">Jake Vanderplas's sklearn example<\/a>, and<\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-amlcompute\/train-on-amlcompute.ipynb\" rel=\"nofollow noreferrer\">this Azure ML tutorial<\/a> on remote training.<\/li>\n<\/ul>\n\n<p>I'm no T-SNE expert, but from the screenshot below, you can see that the t-sne outputs are the same when I run the script locally and remotely. This might be possible with Studio classic, but it would be hard to guarantee that it will always work.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/mhlg6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mhlg6.png\" alt=\"Azure ML Experiment Results Page\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-06-07 01:37:03.77 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62235365",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73501103,
        "Question_title":"Getting Bad request while searching run in mlflow",
        "Question_body":"<p>Training a ml model with mlflow in azure environment.<\/p>\n<pre><code>import mlflow\nfrom mlflow import MlflowClient\nfrom azureml.core import Experiment, Workspace\n\nexperiment_name = 'housing-lin-mlflow'\n\nexperiment = Experiment(ws, experiment_name)\n\nruns = mlflow.search_runs(experiment_ids=[ experiment.id ])\n\n<\/code><\/pre>\n<p>While fetching runs from search_runs getting this error :<\/p>\n<pre><code>RestException: BAD_REQUEST: For input string: &quot;5b649b3c-3b8f-497a-bb4f&quot;\n<\/code><\/pre>\n<p>MLflow version : 1.28.0\nIn Azure studio jobs have been created and successfully run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-26 12:33:35.98 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-27 18:36:19.893 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|mlflow",
        "Question_view_count":56,
        "Owner_creation_date":"2020-02-19 08:37:57.803 UTC",
        "Owner_last_access_date":"2022-09-23 17:24:33.503 UTC",
        "Owner_reputation":171,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":"<p>The bad request in MLFlow after successful running the job is because of not giving proper API permissions for the application.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Search for <strong>MLFLOW<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Scroll down<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/s50AL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/s50AL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Click on View API Permissions<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Under API permissions, assign the permissions according to the application running region and requirements. Checkout the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models-mlflow\" rel=\"nofollow noreferrer\">document<\/a> for further information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-27 12:38:02.123 UTC",
        "Answer_score":1.0,
        "Owner_location":"Delhi, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73501103",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42228715,
        "Question_title":"Running h2o in R script in Azure machine learning",
        "Question_body":"<p>I know how to access packages in <code>R<\/code> scripts in <code>Azure machine<\/code> learning by either using the <code>Azure<\/code> supported ones or by zipping up the packages.<\/p>\n\n<p>My problem now is that <code>Azure<\/code> machine learning does not support the <code>h2o package<\/code> and when I tried using the zipped file - it gave an <code>error<\/code>. <\/p>\n\n<p>Has anyone figured out how to use <code>h2o<\/code> in <code>R<\/code> in <code>Azure machine<\/code> learning?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-14 14:29:19.403 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-02-14 14:35:46.53 UTC",
        "Question_score":0,
        "Question_tags":"r|azure|h2o|azure-machine-learning-studio",
        "Question_view_count":361,
        "Owner_creation_date":"2012-10-29 18:22:48.77 UTC",
        "Owner_last_access_date":"2022-09-21 14:01:44.35 UTC",
        "Owner_reputation":823,
        "Owner_up_votes":16,
        "Owner_down_votes":4,
        "Owner_views":114,
        "Answer_body":"<p>So since there was no reply to my question, I made some research and came up with the following:<\/p>\n\n<p>H2O cannot be ran in a straightforward manner in Azure machine learning embedded R scripts. A workaround the problem is to consider using an Azure created environment - specially for H2O. The options available are:<\/p>\n\n<ol>\n<li>Spinning up an H2O Artificial Intelligence Virtual Machine solution<\/li>\n<li>Using an H2O application for HDInsight<\/li>\n<\/ol>\n\n<p>For more reading, you can go to: <a href=\"http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/azure.html\" rel=\"nofollow noreferrer\">http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/azure.html<\/a> <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-02-16 09:36:45.673 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42228715",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45576092,
        "Question_title":"AzureML multiple models stored in dictionary",
        "Question_body":"<p><strong>Overview:<\/strong><\/p>\n\n<p>I have a unique Python model where we hold n trained random forest models in a dictionary. I tried to avoid this setup, but for the time being it's necessary. On my local, I can make predictions by passing a dataframe to a predict function and looping through the rows, calling the appropriate model for each row, like rf_models[model].predict().<\/p>\n\n<p>In AzureML I created a toy model that allows me to go:\nWeb Input -> Python Script -> Score Model -> Web output. <\/p>\n\n<p><strong>Challenge:<\/strong><\/p>\n\n<p>I need to be able to call the score_model, or specifically the predict method, from inside the \"Python Script\" function on AzureML so I can deal with the loops and n models stored in the dict. The results, either a JSON or dataframe, would be sent to AzureML's Web Output.<\/p>\n\n<p>I found a link online (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts<\/a>) that got me close, but the example shows a model being trained and used to predict at the same time inside the same Python script, thus calling the predict method as a local variable and not calling a previously trained model. I found only limited documentation online to solve this problem and I could not get the rest of the way there. I'm unsure if this type of customization is not yet available or if I'm completely overlooking some key functionality.<\/p>\n\n<p>Thank you for your assistance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-08-08 18:58:06.207 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio",
        "Question_view_count":200,
        "Owner_creation_date":"2017-05-02 19:38:19.063 UTC",
        "Owner_last_access_date":"2022-06-24 15:45:00.497 UTC",
        "Owner_reputation":159,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":"<p>Here are two links that might help:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/github.com\/Azure\/Machine-Learning-Operationalization\" rel=\"nofollow noreferrer\">AzureML Operationalization<\/a> <\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/Machine-Learning-Operationalization\/blob\/master\/samples\/python\/tutorials\/realtime\/digit_classification.ipynb\" rel=\"nofollow noreferrer\">Example notebook<\/a> that shows how to publish Python model as a web service. You would do a similar thing, only you would pickle the dictionary of your models instead. <\/li>\n<\/ol>\n\n<p>Note that this functionality is currently in preview mode.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-08-27 19:08:42.243 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45576092",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37812686,
        "Question_title":"Package usage in AzureML: ggplot2 and ggrepel",
        "Question_body":"<p>I have a code in Azure ML which uses the function <code>ggrepel<\/code>. That function requires the version 2.0.0 of the package <code>ggplot2<\/code>. When I try to use it I obtain the error:<\/p>\n\n<pre><code>Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\npackage 'ggplot2' 1.0.0 was found, but &gt;= 2.0.0 is required by 'ggrepel'\n<\/code><\/pre>\n\n<p>So, what I did was: <\/p>\n\n<ol>\n<li>updated the R package <code>ggplot2<\/code> of my local version (is there a command to use to check the version of a package?);<\/li>\n<li>taken the folder related to <code>ggplot2<\/code>, and put it in the zip file I pass to Azure. So the x.zip wil contain generic functions, then ggrepel.zip and ggplot2.zip.<\/li>\n<\/ol>\n\n<p>At the end I have written:<\/p>\n\n<pre><code>install.packages(\"src\/ggplot2.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\",lib = \".\", repos = NULL, verbose = TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>It seems working for ggrepel, but not for ggplot, because I obtain the same issue shown at the beginning. It's like the system does not see the updated package, but the default ggplot2 of Azure ML.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-14 12:55:44.767 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|ggplot2|zip|azure-machine-learning-studio",
        "Question_view_count":142,
        "Owner_creation_date":"2015-07-09 09:05:28.61 UTC",
        "Owner_last_access_date":"2022-09-19 17:14:25.487 UTC",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Answer_body":"<p>At the end I have solved adding an additional package. The problem is in the fact that you have to check the log of the error and not only the error output (that does not insert all you need). At the end I have solved in this way:<\/p>\n\n<pre><code>install.packages(\"src\/scales_0.4.0.zip\" ,lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2_2.1.0.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\"      ,lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(scales,  lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\n...\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-06-22 14:51:52.097 UTC",
        "Answer_score":0.0,
        "Owner_location":"Colleferro, Italy",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37812686",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35562896,
        "Question_title":"How to get the Prediction Score in a HttpResponseMessage provided by a Azure ML Web Service?",
        "Question_body":"<p>So I am currently working with an Azure Machine Learning experiment. I was able to create a model and post it as a web service. I was also able to get the response using the sample request\/response code in C# provided in the API documentation that was generated when I created the web service.<\/p>\n\n<p>My problem is, the response provided by the web service contains many information (a long string of info) including the Prediction Score which is the only thing I need for my C# application. The only thing that comes in mind is to use string manipulation methods in order to extract the info I want. But I think there's a better way than that. I am new to HTTP Request\/Response, so please elaborate answers and explanations about it.<\/p>\n\n<p>Here's my code:<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n\nif (response.IsSuccessStatusCode)\n{\n    string result = await response.Content.ReadAsStringAsync();\n    Console.WriteLine(\"Result: {0}\", result);\n}\n\nelse\n{\n    Console.WriteLine(string.Format(\"The request failed with status code: {0}\", response.StatusCode));\n\n    \/\/ Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    Console.WriteLine(response.Headers.ToString());\n\n    string responseContent = await response.Content.ReadAsStringAsync();\n    Console.WriteLine(responseContent);\n}\n<\/code><\/pre>\n\n<p>Here is the Response Message:<\/p>\n\n<pre><code>{\"Results\":{\"output1\":{\"type\":\"table\",\"value\":{\"ColumnNames\":[\"clump_thickness\",\"size_uniformity\",\"shape_uniformity\",\"marginal_adhesion\",\"epithelial_size\",\"bare_nucleoli\",\"bland_chromatin\",\"normal_nucleoli\",\"mitoses\",\"Scored Labels\",\"Scored Probabilities\"],\"ColumnTypes\":[\"Int32\",\"Int32\",\"Int32\",\"Int32\",\"Int32\",\"Nullable`1\",\"Int32\",\"Int32\",\"Int32\",\"Double\",\"Double\"],\"Values\":[[\"10\",\"10\",\"4\",\"8\",\"1\",\"8\",\"3\",\"10\",\"1\",\"1\",\"0.979712069034576\"],[\"10\",\"10\",\"4\",\"8\",\"1\",\"8\",\"3\",\"10\",\"1\",\"1\",\"0.979712069034576\"]]}}}}\n<\/code><\/pre>\n\n<p>I only want the value within \"Values\":[[...]], which in this case, the 9th index or \"1\".<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-02-22 20:11:57.173 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-01 16:33:20.163 UTC",
        "Question_score":2,
        "Question_tags":"c#|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":264,
        "Owner_creation_date":"2016-01-18 17:13:02.073 UTC",
        "Owner_last_access_date":"2017-08-04 13:01:27.537 UTC",
        "Owner_reputation":79,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>You need to use project columns in your AML experiment. Currently, you have a module connected to Web Service Output. Use a <code>project columns<\/code> module before your <code>web service output<\/code> to select just the columns you would like to send to our output instead. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-22 23:54:32.737 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35562896",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71872506,
        "Question_title":"Unable To Run AzureML Experiment with SDK - Failed to Build Wheel for pynacl \/ Exit status:1",
        "Question_body":"<p>I am trying to run a AzureML Experiment using sdk (following a Udemy course). When I try to use the Experiment.submit function the experiment prepares and then fails with the following error messages:<\/p>\n<pre><code>ERROR: Command errored out with exit status 1 \n\nERROR: Failed building wheel for pynacl\nERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly\n<\/code><\/pre>\n<p>The Azure env as created within my anaconda navigator for a short period of time and then gets removed.<\/p>\n<p>Does anyone know how I can get around this? Any help would be really appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-14 13:32:38.36 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-19 08:37:31.94 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|anaconda|azure-machine-learning-service|pynacl",
        "Question_view_count":73,
        "Owner_creation_date":"2020-10-24 10:49:09.85 UTC",
        "Owner_last_access_date":"2022-09-21 12:00:40.91 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":"<p>To resolve <code>ERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly<\/code> this error, try either of the following ways:<\/p>\n<ol>\n<li><p>Install missing dependencies:<\/p>\n<pre><code>sudo apt install libpython3-dev build-essential\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip:<\/p>\n<pre><code>pip3 install --upgrade pip\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip with setuptools wheel:<\/p>\n<pre><code>pip3 install --upgrade pip setuptools wheel\n<\/code><\/pre>\n<\/li>\n<li><p>Reinstall PEP517:<\/p>\n<pre><code>pip3 install p5py\npip3 install PEP517\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>You can refer to  <a href=\"https:\/\/stackoverflow.com\/questions\/61365790\/error-could-not-build-wheels-for-scipy-which-use-pep-517-and-cannot-be-installe\">ERROR: Could not build wheels for scipy which use PEP 517 and cannot be installed directly<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/64038673\/could-not-build-wheels-for-which-use-pep-517-and-cannot-be-installed-directly\">Could not build wheels for _ which use PEP 517 and cannot be installed directly - Easy Solution<\/a> and <a href=\"https:\/\/github.com\/martomi\/chiadog\/issues\/44\" rel=\"nofollow noreferrer\">failed building wheel for pynacl<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-18 04:47:54.673 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71872506",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64597526,
        "Question_title":"Provision AKS with internal load balancer from AMLS on Azure",
        "Question_body":"<p>I would like to provision an AKS cluster that is connected to a vnet and has an internal load balancer on Azure. I am using code from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=python\" rel=\"nofollow noreferrer\">here<\/a> that looks like this:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Verify that cluster does not exist already\ntry:\n    aks_target = AksCompute(workspace=ws, name=aks_cluster_name)\n    print(&quot;Found existing aks cluster&quot;)\n\nexcept:\n    print(&quot;Creating new aks cluster&quot;)\n\n    # Subnet to use for AKS\n    subnet_name = &quot;default&quot;\n    # Create AKS configuration\n    prov_config=AksCompute.provisioning_configuration(load_balancer_type=&quot;InternalLoadBalancer&quot;)\n    # Set info for existing virtual network to create the cluster in\n    prov_config.vnet_resourcegroup_name = &quot;myvnetresourcegroup&quot;\n    prov_config.vnet_name = &quot;myvnetname&quot;\n    prov_config.service_cidr = &quot;10.0.0.0\/16&quot;\n    prov_config.dns_service_ip = &quot;10.0.0.10&quot;\n    prov_config.subnet_name = subnet_name\n    prov_config.docker_bridge_cidr = &quot;172.17.0.1\/16&quot;\n\n    # Create compute target\n    aks_target = ComputeTarget.create(workspace = ws, name = &quot;myaks&quot;, provisioning_configuration = prov_config)\n    # Wait for the operation to complete\n    aks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>However, I get the following error<\/p>\n<pre><code>K8s failed to assign an IP for Load Balancer after waiting for an hour.\n<\/code><\/pre>\n<p>Is this because the AKS cluster does not yet have a 'network contributor' role for the vnet resource group? Is the only way to get this to work to first create AKS outside of AMLS, grant the network contributor role to the vnet resource group, then attach the AKS cluster to AMLS and configure the internal load balancer afterwards?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-29 18:55:35.143 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-29 20:12:02.987 UTC",
        "Question_score":1,
        "Question_tags":"azure-aks|azure-machine-learning-service|vnet|internal-load-balancer",
        "Question_view_count":352,
        "Owner_creation_date":"2020-05-17 18:00:51.347 UTC",
        "Owner_last_access_date":"2022-06-27 19:36:47.687 UTC",
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":"<p>I was able to get this to work by first creating an AKS resource without an internal load balancer, then separately updating the load balancer following this code:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute.aks import AksUpdateConfiguration\nfrom azureml.core.compute import AksCompute\n\n# ws = workspace object. Creation not shown in this snippet\naks_target = AksCompute(ws,&quot;myaks&quot;)\n\n# Change to the name of the subnet that contains AKS\nsubnet_name = &quot;default&quot;\n# Update AKS configuration to use an internal load balancer\nupdate_config = AksUpdateConfiguration(None, &quot;InternalLoadBalancer&quot;, subnet_name)\naks_target.update(update_config)\n# Wait for the operation to complete\naks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>No network contributor role was required.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-02 23:17:33.333 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64597526",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56240481,
        "Question_title":"Can I import data from On-Premises SQL Server Database to Azure Machine Learning virtual machine?",
        "Question_body":"<p>On the limited Azure Machine Learning Studio, one can import data from an On-Premises SQL Server Database.\nWhat about the ability to do the exact same thing on a python jupyter notebook on a virtual machine from the Azure Machine Learning Services workspace ?<\/p>\n\n<p>It does not seem possible from what I've found in the documentation.\nData sources would be limited in Azure ML Services : \"Currently, the list of supported Azure storage services that can be registered as datastores are Azure Blob Container, Azure File Share, Azure Data Lake, Azure Data Lake Gen2, Azure SQL Database, Azure PostgreSQL, and Databricks File System\"<\/p>\n\n<p>Thank you in advance for your assistance<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-21 14:26:44.447 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|sql|azure|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":1147,
        "Owner_creation_date":"2019-05-21 14:13:07.353 UTC",
        "Owner_last_access_date":"2022-04-20 09:16:53.527 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>As of today, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-load-data#load-sql-data\" rel=\"nofollow noreferrer\">you can load SQL data, but only a MS SQL Server source (also on-premise) is supported<\/a>.<\/p>\n\n<p>Using <code>azureml.dataprep<\/code>, code would read along the lines of<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nsecret = dprep.register_secret(value=\"[SECRET-PASSWORD]\", id=\"[SECRET-ID]\")\n\nds = dprep.MSSQLDataSource(server_name=\"[SERVER-NAME]\",\n                           database_name=\"[DATABASE-NAME]\",\n                           user_name=\"[DATABASE-USERNAME]\",\n                           password=secret)\n\ndflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [YourDB].[ATable]\")\n# print first records\ndflow.head(5)\n<\/code><\/pre>\n\n<p>As far as I understand the APIs are under heavy development and <code>azureml.dataprep<\/code> may be soon superseded by functionality provided by the <a href=\"https:\/\/aka.ms\/azureml\/concepts\/datasets\" rel=\"nofollow noreferrer\">Dataset class<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-05-21 22:53:14.14 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56240481",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72798225,
        "Question_title":"Remote Connection fails in setup of Python data-science client for SQL Server Machine Learning Services",
        "Question_body":"<p>I am trying to test the remote connection of a Python data-science client with SQL Server Machine Learning Services following this guide: <a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/python\/setup-python-client-tools-sql\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/python\/setup-python-client-tools-sql<\/a> (section 6).\nRunning the following script<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def send_this_func_to_sql():\n    from revoscalepy import RxSqlServerData, rx_import\n    from pandas.tools.plotting import scatter_matrix\n    import matplotlib.pyplot as plt\n    import io\n    \n    # remember the scope of the variables in this func are within our SQL Server Python Runtime\n    connection_string = &quot;Driver=SQL Server;Server=localhost\\instance02;Database=testmlsiris;Trusted_Connection=Yes;&quot;\n    \n    # specify a query and load into pandas dataframe df\n    sql_query = RxSqlServerData(connection_string=connection_string, sql_query = &quot;select * from iris_data&quot;)\n    df = rx_import(sql_query)\n    \n    scatter_matrix(df)\n    \n    # return bytestream of image created by scatter_matrix\n    buf = io.BytesIO()\n    plt.savefig(buf, format=&quot;png&quot;)\n    buf.seek(0)\n    \n    return buf.getvalue()\n\nnew_db_name = &quot;testmlsiris&quot;\nconnection_string = &quot;driver={sql server};server=sqlrzs\\instance02;database=%s;trusted_connection=yes;&quot; \n\nfrom revoscalepy import RxInSqlServer, rx_exec\n\n# create a remote compute context with connection to SQL Server\nsql_compute_context = RxInSqlServer(connection_string=connection_string%new_db_name)\n\n# use rx_exec to send the function execution to SQL Server\nimage = rx_exec(send_this_func_to_sql, compute_context=sql_compute_context)[0]\n<\/code><\/pre>\n<p>yields the following error message returned by rx_exec (stored in the <em>image<\/em> variable)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>connection_string: &quot;driver={sql server};server=sqlrzs\\instance02;database=testmlsiris;trusted_connection=yes;&quot;\nnum_tasks: 1\nexecution_timeout_seconds: 0\nwait: True\nconsole_output: False\nauto_cleanup: True\npackages_to_load: []\ndescription: &quot;sqlserver&quot;\nversion: &quot;1.0&quot;\nXXX lineno: 2, opcode: 0\nTraceback (most recent call last):\n  File &quot;&lt;string&gt;&quot;, line 3, in &lt;module&gt;\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 664, in rx_sql_satellite_pool_call\n    exec(inputfile.read())\n  File &quot;&lt;string&gt;&quot;, line 34, in &lt;module&gt;\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 886, in rx_remote_call\n    results = rx_resumeexecution(state_file = inputfile, patched_server_name=args[&quot;hostname&quot;])\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 135, in rx_resumeexecution\n    return _state[&quot;function&quot;](**_state[&quot;args&quot;])\n  File &quot;C:\\Users\\username\\sendtosql.py&quot;, line 2, in send_this_func_to_sql\nSystemError: unknown opcode\n====== sqlrzs ( process 0 ) has started run at 2022-06-29 13:47:04 W. Europe Daylight Time ======\n{'local_state': {}, 'args': {}, 'function': &lt;function send_this_func_to_sql at 0x0000020F5810F1E0&gt;}\n<\/code><\/pre>\n<p>What is going wrong here? Line 2 in the script is just an import (which works when testing Python scripts on SQL Server directly). Any help is appreciated - thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-06-29 08:32:20.923 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-29 11:56:46.377 UTC",
        "Question_score":0,
        "Question_tags":"python|sql-server|azure-machine-learning-studio|microsoft-machine-learning-server",
        "Question_view_count":54,
        "Owner_creation_date":"2022-06-28 14:49:02.04 UTC",
        "Owner_last_access_date":"2022-09-24 09:16:19.637 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>I just figured out the reason. As of today, the Python versions for the data clients in <a href=\"https:\/\/docs.microsoft.com\/de-de\/sql\/machine-learning\/python\/setup-python-client-tools-sql?view=sql-server-ver15\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/de-de\/sql\/machine-learning\/python\/setup-python-client-tools-sql?view=sql-server-ver15<\/a> are not the newest (revoscalepy Version 9.3), while the version of Machine Learning Services that we have running in our SQL Server is already 9.4.7.\nHowever, the revoscalepy libraries for the client and server must be the same, otherwise the deserialization fails server-sided.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-29 14:37:17.86 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72798225",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41855344,
        "Question_title":"Azure ML: How to save and process CSV files with semicolon as delimiter?",
        "Question_body":"<p>Azure ML support says to me that delimiter must be comma, this would cause too much hassle with data having semicolon as separator and with a lot of commas in the cell values. <\/p>\n\n<p>So how to process semicolon separated CSV files in Azure ML? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-01-25 15:26:11.913 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"csv|azure|azure-machine-learning-studio|escaping",
        "Question_view_count":2908,
        "Owner_creation_date":"2009-08-27 11:33:59.053 UTC",
        "Owner_last_access_date":"2022-05-27 10:56:29.307 UTC",
        "Owner_reputation":48616,
        "Owner_up_votes":1240,
        "Owner_down_votes":41,
        "Owner_views":3348,
        "Answer_body":"<p>Azure ML only accepts the comma <code>,<\/code> separated CSV. Do a little work around.\nOpen your data file using a text editor. (Notepad will do the trick). Find and replace all semicolons with 'tab' (Make it a TSV) and the commas in data values may not occur a problem then. Make sure to define that the input is a TSV; not a CSV. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-01-31 04:59:31.543 UTC",
        "Answer_score":7.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41855344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73050203,
        "Question_title":"azureml register datastore file share or blob storage",
        "Question_body":"<p>I have a folder called data with a bunch of csvs (about 80), file sizes are fairly small. This data is clean and has already been preprocessed. I want to upload this data folder and register as a datastore in azureml. Which would be best for this scenario data store created with file share or a data store created with blob storage?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-20 10:42:13.897 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-blob-storage|azure-machine-learning-service|azure-files|azureml-python-sdk",
        "Question_view_count":125,
        "Owner_creation_date":"2020-11-30 17:06:44.663 UTC",
        "Owner_last_access_date":"2022-08-31 08:48:49.383 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":"<p><strong>AFAIK<\/strong>, based on your scenario you can make use of <strong><code>Azure File Share<\/code><\/strong> to create data store.<\/p>\n<p>Please <strong>note<\/strong> that, Azure Blob storage is suitable for uploading large amount of unstructured data whereas <strong><code>Azure File Share<\/code><\/strong> is suitable for uploading and processing the structured files in chunks (more interaction with app to share files).<\/p>\n<blockquote>\n<p>I have a folder called data with a bunch of csvs (about 80), file sizes are fairly small. This data is clean and has already been preprocessed.<\/p>\n<\/blockquote>\n<p>As you mentioned <strong><code>CSV<\/code><\/strong> data is clean and preprocessed it comes under structured data. So, you can make you of <strong>Azure File Share<\/strong> to create data store.<\/p>\n<p>To register a data store with <strong>Azure File Share<\/strong> you can make use of this <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py#azureml-core-datastore-datastore-register-azure-file-share\" rel=\"nofollow noreferrer\"><strong>MsDoc<\/strong><\/a><\/p>\n<p>To know more about Azure File Share and Azure Blob storage, please find below <strong>links<\/strong>:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/67217164\/azure-blob-storage-or-azure-file-storage\">Azure Blob Storage or Azure File Storage by Mike<\/a><\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_storage_datastore.azurefiledatastore?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.data.azure_storage_datastore.AzureFileDatastore class - Azure Machine Learning Python | Microsoft Docs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-20 11:42:34.42 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73050203",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57759556,
        "Question_title":"How to access node from azure machine learning compute?",
        "Question_body":"<p>When submitting an aml compute job, I want to access the nodes where the compute happens for debugging purposes. The portal gives me the IP address, the port and the nodeID, but no password seems to exist within the portal. <\/p>\n\n<p>How am I supposed to connect to the machine?<\/p>\n\n<p>I am running on NC6 machines for a single node training. I have already tried to run the command given through the portal, but the node is (hopefully so) protected by a password.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-02 15:32:06.937 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":754,
        "Owner_creation_date":"2017-03-02 10:38:43.727 UTC",
        "Owner_last_access_date":"2021-07-27 15:20:42.48 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>In order to be able to log in to the nodes of an AML Compute cluster, you have to provide a username and password and ssh key (ssh key is optional), <strong>when you create the cluster<\/strong>. You can only do that at creation time.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ckh6j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ckh6j.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-09-04 12:15:01.197 UTC",
        "Answer_score":4.0,
        "Owner_location":"Paris",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57759556",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42651900,
        "Question_title":"How to connect Azure Data lake storage to Azure ML?",
        "Question_body":"<p>Hi i am started to learning the azure data lake and azure machine learning ,i need to use the azure data lake storage as a azure machine learning studio input data .There have a any options are there, i gone through the azure data lake and machine learning documentation but i can't reach that,finally i got one solution on this \n<a href=\"https:\/\/stackoverflow.com\/questions\/36127510\/how-to-use-azure-data-lake-store-as-an-input-data-set-for-azure-ml\">link<\/a> but they are mentioning there is no option for it,but this post is old one,so might be the Microsoft people added the future  on it if it's please let me know, let me know Thank you. <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-03-07 15:16:16.04 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2017-05-23 10:29:58.003 UTC",
        "Question_score":5,
        "Question_tags":"azure|azure-stream-analytics|azure-data-lake|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":4966,
        "Owner_creation_date":"2017-02-18 10:18:54.923 UTC",
        "Owner_last_access_date":"2020-12-03 12:57:12.34 UTC",
        "Owner_reputation":321,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":65,
        "Answer_body":"<p>I recommend the following:<\/p>\n\n<ul>\n<li>Get a tenant ID, client ID, and client secret for your ADLS using the tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-lake-store\/data-lake-store-authenticate-using-active-directory#step-2-get-client-id-client-secret-and-tenant-id\" rel=\"nofollow noreferrer\">here<\/a>.<\/li>\n<li>Install the <a href=\"https:\/\/github.com\/Azure\/azure-data-lake-store-python\" rel=\"nofollow noreferrer\"><code>azure-datalake-store<\/code><\/a> Python package on AML Studio by attaching it as a Script Bundle to an Execute Python Script module.<\/li>\n<li>In the Execute Python Script module, import the <code>azure-datalake-store<\/code> package and connect to the ADLS with your tenant ID, client ID, and client secret.<\/li>\n<li>Download the data you need from ADLS and convert it into a dataframe within the Python Script module; return that dataframe to make the data available in the rest of AML Studio.<\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-03-21 19:59:41.093 UTC",
        "Answer_score":4.0,
        "Owner_location":"Gurugram, Haryana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42651900",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58601697,
        "Question_title":"How to pass in the model name during init in Azure Machine Learning Service?",
        "Question_body":"<p>I am deploying 50 NLP models on Azure Container Instances via the Azure Machine Learning service. All 50 models are quite similar and have the same input\/output format with just the model implementation changing slightly. <\/p>\n\n<p>I want to write a generic score.py entry file and pass in the model name as a parameter. The interface method signature does not allow a parameter in the init() method of score.py, so I moved the model loading into the run method. I am assuming the init() method gets run once whereas Run(data) will get executed on every invocation, so this is possibly not ideal (the models are 1 gig in size)<\/p>\n\n<p>So how can I pass in some value to the init() method of my container to tell it what model to load? <\/p>\n\n<p>Here is my current, working code:<\/p>\n\n<pre><code>def init():\n\ndef loadModel(model_name):\n    model_path = Model.get_model_path(model_name)  \n    return fasttext.load_model(model_path)\n\ndef run(raw_data):\n    # extract model_name from raw_data omitted...\n    model = loadModel(model_name)\n\n    ...\n<\/code><\/pre>\n\n<p>but this is what I would like to do (which breaks the interface)<\/p>\n\n<pre><code>def init(model_name):\n    model = loadModel(model_name)\n\ndef loadModel(model_name):\n    model_path = Model.get_model_path(model_name)  \n    return fasttext.load_model(model_path)\n\ndef run(raw_data):\n    ...\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-29 05:06:48.637 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":851,
        "Owner_creation_date":"2009-10-21 01:51:25.5 UTC",
        "Owner_last_access_date":"2022-09-13 05:24:36.847 UTC",
        "Owner_reputation":4947,
        "Owner_up_votes":277,
        "Owner_down_votes":8,
        "Owner_views":531,
        "Answer_body":"<p>If you're looking to use the same deployed container and switch models between requests; it's not the preferred design choice for Azure machine learning service, we need to specify the model name to load during build\/deploy.<\/p>\n\n<p>Ideally, each deployed web-service endpoint should allow inference of one model only; with the model name defined before the container the image starts building\/deploying. <\/p>\n\n<p>It is mandatory that the entry script has both <code>init()<\/code> and <code>run(raw_data)<\/code> with those <strong>exact<\/strong> signatures. <\/p>\n\n<p>At the moment, we can't change the signature of <code>init()<\/code> method to take a parameter like in <code>init(model_name)<\/code>.  <\/p>\n\n<p>The only dynamic user input you'd ever get to pass into this web-service is via <code>run(raw_data)<\/code> method. As you have tried, given the size of your model passing it via run is not feasible. <\/p>\n\n<p><code>init()<\/code> is run first and only <strong>once<\/strong> after your web-service deploy. Even if <code>init()<\/code> took the <code>model_name<\/code> parameter, there isn't a straight forward way to call this method directly and pass your desired model name.<\/p>\n\n<hr>\n\n<p>But, one possible solution is: <\/p>\n\n<p>You can create params file like below and store the file in azure blob storage.<\/p>\n\n<p>Example runtime parameters generation script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pickle\n\nparams = {'model_name': 'YOUR_MODEL_NAME_TO_USE'}\n\nwith open('runtime_params.pkl', 'wb') as file:\n    pickle.dump(params, file)\n\n<\/code><\/pre>\n\n<p>You'll need to use <a href=\"https:\/\/github.com\/Azure\/azure-storage-python\" rel=\"nofollow noreferrer\">Azure Storage Python SDK<\/a> to write code that can read from your blob storage account. This also mentioned in the official docs <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#prepare-to-deploy\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>Then you can access this from <code>init()<\/code> function in your score script. <\/p>\n\n<p>Example <code>score.py<\/code> script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azure.storage.blob import BlockBlobService\nimport pickle\n\ndef init():\n\n  global model\n\n  block_blob_service = BlockBlobService(connection_string='your_connection_string')\n\n  blob_item = block_blob_service.get_blob_to_bytes('your-container-name','runtime_params.pkl')\n\n  params = pickle.load(blob_item.content)\n\n  model = loadModel(params['model_name'])\n<\/code><\/pre>\n\n<p>You can store connection strings in Azure KeyVault for secure access. Azure ML Workspaces comes with built-in KeyVault integration. More info <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.keyvault.keyvault?view=azure-ml-py#get-secret-name-\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>With this approach, you're abstracting runtime params config to another cloud location rather than the container itself. So you wouldn't need to re-build the image or deploy the web-service again. Simply restarting the container will work.<\/p>\n\n<hr>\n\n<p>If you're looking to simply re-use <code>score.py<\/code> (not changing code) for <strong>multiple model deployments in multiple containers<\/strong> then here's another possible solution.<\/p>\n\n<p>You can define your model name to use in web-service in a text file and read it in score.py. You'll need to pass this text file as a dependency when setting up the image config.<\/p>\n\n<p>This would, however, need multiple params files for each container deployment.<\/p>\n\n<p>Passing 'runtime_params.pkl' in <code>dependencies<\/code> to your image config (More detail example <a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\/blob\/master\/experiments\/notebooks\/Deploy%20Model%20-%20Azure.ipynb\" rel=\"nofollow noreferrer\">here<\/a>):<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\",\n                                                  dependencies=[\"runtime_params.pkl\"],\n                                                  docker_file=\"Dockerfile\")\n<\/code><\/pre>\n\n<p>Reading this in your score.py <code>init()<\/code> function:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def init():\n\n  global model\n\n  with open('runtime_params.pkl', 'rb') as file:\n    params = pickle.load(file)\n\n  model = loadModel(params['model_name'])\n\n<\/code><\/pre>\n\n<p>Since your creating a new image config with this approach, you'll need to build the image and re-deploy the service.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-10-29 20:44:54.847 UTC",
        "Answer_score":3.0,
        "Owner_location":"Sydney, Australia",
        "Answer_last_edit_date":"2019-10-29 22:59:51.297 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58601697",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72641789,
        "Question_title":"Azure Machine Learning workspace's storage account permission issue",
        "Question_body":"<p>Was working on az ml cli v2 to deploy real-time endpoint with command <code>az ml online-deployment<\/code> through Azure pipeline. had double confirmed that the service connection used in this pipeline task had added the permissions below in Azure Portal but still showing the same error.<\/p>\n<pre><code>ERROR: Error with code: You don't have permission to alter this storage account. Ensure that you have been assigned both Storage Blob Data Reader and Storage Blob Data Contributor roles.\n<\/code><\/pre>\n<p>Using the same service connection, we are able to perform the creation of online endpoint with <code>az ml online-endpoint create<\/code> in the same and other workspaces.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-16 07:10:03.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-devops|azure-storage|azure-machine-learning-service",
        "Question_view_count":129,
        "Owner_creation_date":"2019-09-11 07:07:53.007 UTC",
        "Owner_last_access_date":"2022-09-15 16:01:06.153 UTC",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":"<p>Issue was resolved. I did not change anything in the service principal and running it on second day using same yml got through the issue. I guess there might be some propagation issue, but longer than usual.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-17 01:37:08.623 UTC",
        "Answer_score":0.0,
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72641789",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71694816,
        "Question_title":"Unable to get image details : Environment version Autosave_(date)T(time)Z_******** provided in request doesn't match environ",
        "Question_body":"<p>On AzureML Batchendpoint, I'm recently hitting the following error:<\/p>\n<pre><code>Unable to get image details : Environment version Autosave_(date)T(time)Z_******** provided in request doesn't match environ.\n<\/code><\/pre>\n<p>when I setup the batch-endpoint with a <code>yml<\/code> config:<\/p>\n<p><code>environment: azureml:env-name:env-version<\/code><\/p>\n<p>So, AzureML creates and builds the environment with the version I specify <code>env-version<\/code>, which is just a number (in my case = 3).<\/p>\n<p>and then for some weird reason, AzureML creates an extra environment version called <code>Autosave_(date)T(time)Z_********<\/code>, which is not built, but based on the previous one just created, and then it becomes the <code>latest<\/code> version of that environment.<\/p>\n<p>In summary, AzureML instead of looking for the version that I specified as <code>env-name:3<\/code> it seems to be looking for <code>env-name:Autosave_(date)T(time)Z_********<\/code> and then throws the error message mentioned above.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-31 14:58:12.993 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"batch-processing|azure-batch|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":92,
        "Owner_creation_date":"2020-05-12 14:25:08.567 UTC",
        "Owner_last_access_date":"2022-09-20 13:49:41.073 UTC",
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Answer_body":"<p>I found the problem was that when creating an environment from a YAML specification file, one of my <strong>conda dependencies<\/strong> was <code>cmake<\/code>, which I needed to allow installation of another python module. The docker image is exactly the same as a previously created environment.<\/p>\n<p>Removing the <code>cmake<\/code> dependency from the YAML file, eliminated the issue. So the workaround is to install it using a Dockerfile.<\/p>\n<p>The error message was very misleading to start with, but got there in the end after understanding that AzureML reuses a cached image, based on the hash value, from the environment definition accordingly to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-environments#image-caching-and-reuse\" rel=\"nofollow noreferrer\">this<\/a><\/p>\n<p>So for that reason, the automatically created <code>Autosave<\/code> docker image  references to that same build, which only happens once when the first job is sent.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-01 10:13:25.063 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-04-06 11:29:25.4 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71694816",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57896195,
        "Question_title":"Out of disk space",
        "Question_body":"<p>when running an AML pipeline on AML compute, I get this kind of error : <\/p>\n\n<p>I can try rebooting the cluster, but that may not fix the problem (if storage gets accumulated no the nodes, that should be cleaned.<\/p>\n\n<pre><code>Session ID: 933fc468-7a22-425d-aa1b-94eba5784faa\n{\"error\":{\"code\":\"ServiceError\",\"message\":\"Job preparation failed: [Errno 28] No space left on device\",\"detailsUri\":null,\"target\":null,\"details\":[],\"innerError\":null,\"debugInfo\":{\"type\":\"OSError\",\"message\":\"[Errno 28] No space left on device\",\"stackTrace\":\" File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1-setup\/job_prep.py\\\", line 126, in &lt;module&gt;\\n invoke()\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1-setup\/job_prep.py\\\", line 97, in invoke\\n extract_project(project_dir, options.project_zip, options.snapshots)\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1-setup\/job_prep.py\\\", line 60, in extract_project\\n project_fetcher.fetch_project_snapshot(snapshot[\\\"Id\\\"], snapshot[\\\"PathStack\\\"])\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1\/azureml-setup\/project_fetcher.py\\\", line 72, in fetch_project_snapshot\\n _download_tree(sas_tree, path_stack)\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1\/azureml-setup\/project_fetcher.py\\\", line 106, in _download_tree\\n _download_tree(child, path_stack)\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1\/azureml-setup\/project_fetcher.py\\\", line 106, in _download_tree\\n _download_tree(child, path_stack)\\n File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/jj2\/azureml\/piperun-20190911_1568231788841835_1\/mounts\/workspacefilestore\/azureml\/PipeRun-20190911_1568231788841835_1\/azureml-setup\/project_fetcher.py\\\", line 98, in _download_tree\\n fh.write(response.read())\\n\",\"innerException\":null,\"data\":null,\"errorResponse\":null}},\"correlation\":null,\"environment\":null,\"location\":null,\"time\":\"0001-01-01T00:00:00+00:00\"}\n<\/code><\/pre>\n\n<p>I would expect the job to run as it should. And in fact, I've checked on the node and the node do have lots of available harddrive space :<\/p>\n\n<pre><code>root@4f57957ac829466a86bad4d4dc51fadd000001:~# df -kh                                                                                               Filesystem      Size  Used Avail Use% Mounted on\nudev             28G     0   28G   0% \/dev\ntmpfs           5.6G  9.0M  5.5G   1% \/run\n\/dev\/sda1       125G  2.8G  122G   3% \/\ntmpfs            28G     0   28G   0% \/dev\/shm\ntmpfs           5.0M     0  5.0M   0% \/run\/lock\ntmpfs            28G     0   28G   0% \/sys\/fs\/cgroup\n\/dev\/sdb1       335G  6.7G  311G   3% \/mnt\ntmpfs           5.6G     0  5.6G   0% \/run\/user\/1002\n<\/code><\/pre>\n\n<p>Suggestions on what I should check?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-11 20:14:26.207 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":738,
        "Owner_creation_date":"2018-09-30 02:52:40.603 UTC",
        "Owner_last_access_date":"2022-07-22 02:57:21.83 UTC",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Answer_body":"<p>Seems like you've run into Azure file share constraints. You can use the following sample code to change your runs to use blob storage which can scale to large number of jobs running in parallel:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-access-data#accessing-source-code-during-training\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-access-data#accessing-source-code-during-training<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-09-12 17:26:46.067 UTC",
        "Answer_score":1.0,
        "Owner_location":"Montreal, QC, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57896195",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46963846,
        "Question_title":"Azure ML Workbench Kubernetes Deployment Failed",
        "Question_body":"<p>I am trying to deploy a prediction web service to Azure using ML Workbench process using cluster mode in this tutorial (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-3#prepare-to-operationalize-locally\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-3#prepare-to-operationalize-locally<\/a>)<\/p>\n\n<p>The model gets sent to the manifest, the scoring script and schema <\/p>\n\n<blockquote>\n  <p>Creating\n  service..........................................................Error\n  occurred: {'Error': {'Code': 'KubernetesDeploymentFailed', 'Details':\n  [{'Message': 'Back-off 40s restarting failed container=...pod=...',\n  'Code': 'CrashLoopBackOff'}], 'StatusCode': 400, 'Message':\n  'Kubernetes Deployment failed'}, 'OperationType': 'Service',\n  'State':'Failed', 'Id': '...', 'ResourceLocation':\n  '\/api\/subscriptions\/...', 'CreatedTime':\n  '2017-10-26T20:30:49.77362Z','EndTime': '2017-10-26T20:36:40.186369Z'}<\/p>\n<\/blockquote>\n\n<p>Here is the result of checking the ml service realtime logs <\/p>\n\n<pre><code>C:\\Users\\userguy\\Documents\\azure_ml_workbench\\projecto&gt;az ml service logs realtime -i projecto\n2017-10-26 20:47:16,118 CRIT Supervisor running as root (no user in config file)\n2017-10-26 20:47:16,120 INFO supervisord started with pid 1\n2017-10-26 20:47:17,123 INFO spawned: 'rsyslog' with pid 9\n2017-10-26 20:47:17,124 INFO spawned: 'program_exit' with pid 10\n2017-10-26 20:47:17,124 INFO spawned: 'nginx' with pid 11\n2017-10-26 20:47:17,125 INFO spawned: 'gunicorn' with pid 12\n2017-10-26 20:47:18,160 INFO success: rsyslog entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2017-10-26 20:47:18,160 INFO success: program_exit entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2017-10-26 20:47:22,164 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 5 seconds (startsecs)\n2017-10-26T20:47:22.519159Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting gunicorn 19.6.0\n2017-10-26T20:47:22.520097Z, INFO, 00000000-0000-0000-0000-000000000000, , Listening at: http:\/\/127.0.0.1:9090 (12)\n2017-10-26T20:47:22.520375Z, INFO, 00000000-0000-0000-0000-000000000000, , Using worker: sync\n2017-10-26T20:47:22.521757Z, INFO, 00000000-0000-0000-0000-000000000000, , worker timeout is set to 300\n2017-10-26T20:47:22.522646Z, INFO, 00000000-0000-0000-0000-000000000000, , Booting worker with pid: 22\n2017-10-26 20:47:27,669 WARN received SIGTERM indicating exit request\n2017-10-26 20:47:27,669 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26T20:47:27.669556Z, INFO, 00000000-0000-0000-0000-000000000000, , Handling signal: term\n2017-10-26 20:47:30,673 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26 20:47:33,675 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\nInitializing logger\n2017-10-26T20:47:36.564469Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up app insights client\n2017-10-26T20:47:36.564991Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up request id generator\n2017-10-26T20:47:36.565316Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up app insight hooks\n2017-10-26T20:47:36.565642Z, INFO, 00000000-0000-0000-0000-000000000000, , Invoking user's init function\n2017-10-26 20:47:36.715933: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instruc\ntions, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36,716 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26 20:47:36.716376: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instruc\ntions, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716542: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructio\nns, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716703: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructi\nons, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716860: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructio\nns, but these are available on your machine and could speed up CPU computations.\nthis is the init\n2017-10-26T20:47:37.551940Z, INFO, 00000000-0000-0000-0000-000000000000, , Users's init has completed successfully\nUsing TensorFlow backend.\n2017-10-26T20:47:37.553751Z, INFO, 00000000-0000-0000-0000-000000000000, , Worker exiting (pid: 22)\n2017-10-26T20:47:37.885303Z, INFO, 00000000-0000-0000-0000-000000000000, , Shutting down: Master\n2017-10-26 20:47:37,885 WARN killing 'gunicorn' (12) with SIGKILL\n2017-10-26 20:47:37,886 INFO stopped: gunicorn (terminated by SIGKILL)\n2017-10-26 20:47:37,889 INFO stopped: nginx (exit status 0)\n2017-10-26 20:47:37,890 INFO stopped: program_exit (terminated by SIGTERM)\n2017-10-26 20:47:37,891 INFO stopped: rsyslog (exit status 0)\n\nReceived 41 lines of log\n<\/code><\/pre>\n\n<p>My best guess is theres something silent happening to cause \"WARN received SIGTERM indicating exit request\". The rest of the scoring.py script seems to kick off - see tensorflow get initiated and the \"this is the init\" print statement.<\/p>\n\n<p><a href=\"http:\/\/127.0.0.1:63437\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:63437<\/a> is accessible from my local machine, but the ui endpoint is blank.<\/p>\n\n<p>Any ideas on how to get this up and running in an Azure cluster? I'm not very familiar with how Kubernetes works, so any basic debugging guidance would be appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2017-10-26 21:08:48.353 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-11-22 00:27:10.993 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":447,
        "Owner_creation_date":"2015-01-12 16:58:02.987 UTC",
        "Owner_last_access_date":"2022-09-23 20:26:46.323 UTC",
        "Owner_reputation":588,
        "Owner_up_votes":47,
        "Owner_down_votes":3,
        "Owner_views":64,
        "Answer_body":"<p>We discovered a bug in our system that could have caused this. The fix was deployed last night. Can you please try again and let us know if you still encounter this issue?<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-10-27 14:32:20.967 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46963846",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50870166,
        "Question_title":"Can not open new Python or R notebook in Azure Machine Learning Studio",
        "Question_body":"<p>I recently (and sceptically) started messing around with <strong>Azure Machine Learning Studio<\/strong>. When I stumbled accross the menu option for a machine learning work-flow <strong>Open in a new Notebook<\/strong> (For Python 3, 2 or R) I thought it was too good to be true:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/AYDbo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AYDbo.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And it most likely is, since this option is seemingly only available for the first step of the process. The option still exists in the <strong>right-click menu<\/strong> elsewhere, but it's greyed out:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Cy6MG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Cy6MG.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Does anyone know why it is like this? Do I have to activate something in the menus, or buy some sort of a premium license? Is the functionality only available for <em>some<\/em> of the machine learning algorithms? Or is it just not supposed to be an available option in the menus?<\/p>\n\n<p>By the way, if you click <kbd>Python 3<\/kbd> 3 in the first step, you get a corresponding Python 3 code snippet in a Jupyter Notebook where you immediately can start messing around with the dataset:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gTHGF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gTHGF.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I realize that making this functionality available for each step in each and every model that anyone chooses to design would be an extremely difficult and maybe even impossible thing to do. But again, why is the option still in the menu?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-06-15 06:25:33.7 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|jupyter-notebook|azure-machine-learning-studio",
        "Question_view_count":1386,
        "Owner_creation_date":"2014-03-19 13:20:13.383 UTC",
        "Owner_last_access_date":"2022-09-25 01:13:28.253 UTC",
        "Owner_reputation":46807,
        "Owner_up_votes":5274,
        "Owner_down_votes":1175,
        "Owner_views":3021,
        "Answer_body":"<p>Following the suggestion from @Jon in the comment section as well as a suggestion on <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/windowsdesktop\/en-US\/84a33ecc-1db2-4d11-83d2-3e96f0bcfaa7\/why-open-in-a-new-notebook-is-invalid?forum=MachineLearning\" rel=\"nofollow noreferrer\">microsoft.com<\/a>, I added a <strong>Convert to CSV Module<\/strong> at the end. After running the experiment, <strong>Open in a new Notebook<\/strong> is available when you right clik the <strong>Convert to CSV Module<\/strong>:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Bz7nJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Bz7nJ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What you get by clicking <kbd>Python 3<\/kbd> is this:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ywbHz.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ywbHz.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The functionality is certainly not as magnificent as I was hoping, but it's still pretty cool. If anyone knows <em>anything<\/em> about other possibilites or plans for future development, please don't hesitate to contribute with an answer!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2018-06-15 13:09:37.343 UTC",
        "Answer_score":1.0,
        "Owner_location":"Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50870166",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34335483,
        "Question_title":"Uniquely identify instances of VMs (Azure ML - web services)",
        "Question_body":"<p>I'm posting this more as a 'probe' question and plan to expand the discussion in case some interest shows up. The reason behind this is that in my experience, the SO community on <code>azure-ml<\/code> (and related) is still developing and there is not much feedback - but I would be happy to help it grow stronger. <\/p>\n\n<p>My situation is as follows: I have an experiment in Azure ML which does all its work inside an <code>R<\/code> module. I published this as a web service and set the 'max concurrent calls' slider to 10 - which I believe guarantees me that there will be at most 10 instances of my web service up and running at any time, to serve requests (please correct me if i am wrong). <\/p>\n\n<p>Now, I am trying to do some performance testing by firing 10 parallel calls to my webservice, but get unexpected results...<\/p>\n\n<p>I am trying to run the load tests and log where each of them actually goes to (which instance). My idea is to get a glimpse into how these calls are actually distributed to the instances by the load balancer, under certain max number of concurrent calls = X. I am doing this by firing a call to \"bot.whatismyipaddress.com\" from inside the <code>R<\/code> script. Here is the important snip of the code:<\/p>\n\n<pre><code>library(rjson)\nmachine.ip &lt;- readLines(\"http:\/\/bot.whatismyipaddress.com\/\", warn=F)\nresult$MachineIP &lt;- machine.ip\n<\/code><\/pre>\n\n<p>Additionally, I am using the sample <code>R<\/code> code from the web service RRS help page to fire up to 70 (sequential) calls to my web service. This sample code returns some info back to the console : the results of my web service as well as some info on to which hostname the call goes through. Here is a sample :<\/p>\n\n<pre><code>* Hostname was NOT found in DNS cache\n*   Trying 40.114.242.9...\n* Connected to europewest.services.azureml.net (40.114.242.9) port 443 (#0)\n<\/code><\/pre>\n\n<p>The difficulty that I am facing is that I cannot <strong>uniquely identify<\/strong> the different instances of my web service. The info out to console from the call (the second snippet) often shows a different IP address than the one from inside-<code>R<\/code>-code logs (<code>result$MachineIP<\/code>)...<\/p>\n\n<p>Can someone point out what am i doing wrong, and how could i uniquely identify the different instances that are serving the calls? Any help would be really appreciated. Thanks!<\/p>\n\n<p>P.S. I've tried <a href=\"https:\/\/stackoverflow.com\/questions\/14357219\/function-for-retrieving-own-ip-address-from-within-r\">this<\/a> as well, but the first apporach does not work when calling it from inside the <code>R<\/code> script and I'm using a modified version of the second apporach (the one suggested there does not work). <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/93f07abf-f0ec-4baa-8225-1ca1a072ca2d\/system-call-from-inside-r-script-does-not-work?forum=MachineLearning\" rel=\"nofollow noreferrer\">Here<\/a> are also my <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/ee6ff5a6-2995-4f3f-b4db-0229b1d9d1d3\/lifetime-of-azure-ml-web-service-container?forum=MachineLearning\" rel=\"nofollow noreferrer\">questions<\/a> on the Azure forum, in case someone is interested.<\/p>\n\n<p>If anyone could help or point me to some source of info I would be really grateful! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-12-17 13:13:29.79 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-05-23 11:51:59.593 UTC",
        "Question_score":1,
        "Question_tags":"r|web-services|azure|azure-machine-learning-studio",
        "Question_view_count":61,
        "Owner_creation_date":"2015-05-28 16:10:15.467 UTC",
        "Owner_last_access_date":"2018-11-18 20:44:24.587 UTC",
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Answer_body":"<p>This question was resolved thanks to some people on the Azure ML forum so \nI'm going to post an answer for anyone landing here in search for some answers...<\/p>\n\n<p>The short answer is no, this is not possible. The more detailed version is:<br>\n\"From within the R script you cannot identify the internal AzureML IP addresses or the unique web service instances. When you make an external network call from the R script to an outside URL, that URL will see one of the AzureML public virtual IP's as the source IP. These are IP's of the load balancers, and not of the machines that are physically running the web service. AzureML dynamically allocates the instances of R engine in the backend, handles failures, and uses multiple nodes for running the web service for high availability. The exact layout of these for a given web service is not programmatically discoverable.\"<br>\nHere is also the <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/dd1f0658-7b0b-46d8-8e32-3fe4e96ec4be\/uniquely-identify-instances-of-vms-web-services?forum=MachineLearning#cde28631-828d-4d83-9c93-1a1cf0dfb6fb\" rel=\"nofollow\">link<\/a> to the original discussion. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-01-08 09:07:08.967 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34335483",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42017727,
        "Question_title":"Upload Saved ML Model in R (local) to Azure Machine Learning Studio",
        "Question_body":"<p>I am trying to reduce my development headaches for creating a ML Webservice on Azure ML Studio. One of the things that stuck me was can we just upload .rda files in the workbench and load it via an RScript (like in the figure below). <\/p>\n\n<p><img src=\"https:\/\/raw.githubusercontent.com\/pratos\/pratos.github.io\/master\/images\/stackb1model.png\" alt=\"Do\"><\/p>\n\n<p>But can't connect directly to the R Script block. There's another way to do it (works to upload packages that aren't available in Azure's R directories) -- using zip. But there isn't really any resource out there that I found to access the .rda file in .zip.<\/p>\n\n<p>I have 2 options here, make the .zip work or any other work around where I can directly use my .rda model. If someone could guide me about how to go forward it would appreciate it.<\/p>\n\n<p>Note: Currently, I'm creating models via the \"Create RModel\" block, training them and saving it, so that I can use it to make a predictive web service. But for models like Random Forest, not sure how the randomness might create models (local versions and Azure versions are different, the setting of seed also isn't very helpful). A bit tight on schedule, Azure ML seems boxed for creating iterations and automating the ML workflow (or maybe I'm doing it wrong).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-03 06:00:42.917 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":730,
        "Owner_creation_date":"2016-11-17 06:17:48.55 UTC",
        "Owner_last_access_date":"2018-10-22 11:25:03.6 UTC",
        "Owner_reputation":108,
        "Owner_up_votes":125,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Answer_body":"<p>Here is an example of uploading a .rda file for scoring:\n<a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Womens-Health-Risk-Assessment-using-the-XGBoost-classification-algorithm-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Womens-Health-Risk-Assessment-using-the-XGBoost-classification-algorithm-1<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-02-03 06:47:19.2 UTC",
        "Answer_score":2.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42017727",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57488706,
        "Question_title":"Deploying custom model on Azure ML Studio",
        "Question_body":"<p>In Azure ML Studio, we have the option of choosing a number of inbuilt ML models like Classification, Regression, etc. , which we can drag and drop to our workflow.<\/p>\n\n<p>My question is, can I upload a custom ML model that I have built locally on my system in Python, and add it to the workflow?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-08-14 05:41:22.107 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-14 07:21:17.47 UTC",
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1187,
        "Owner_creation_date":"2019-08-14 05:39:38.21 UTC",
        "Owner_last_access_date":"2021-02-15 12:53:37.227 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<ol>\n<li>Take the model.pkl file, zip it, and upload it into Azure Machine Learning Studio. Click the \u201cNew\u201d icon in the bottom left:\n<a href=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" alt=\"\"><\/a><\/li>\n<li>In the pane that comes up, click on dataset, and then \u201cFrom Local File\u201d:\n<a href=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" alt=\"\"><\/a><\/li>\n<li>Select the zip file where you stored your serialized model and click the tick. You expirement should look like this:\n<a href=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" alt=\"\"><\/a><\/li>\n<li>Put the following code to run your classification experiment:<\/li>\n<\/ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport sys\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    sys.path.insert(0,\".\\Script Bundle\")\n    model = pickle.load(open(\".\\Script Bundle\\model.pkl\", 'rb'))\n    pred = model.predict(dataframe1)\n    return pd.DataFrame([pred[0]])\n<\/code><\/pre>\n\n<p><strong>Update<\/strong> \nIf you want to declare this experiment as an API you need to add web input and output to the Python script module.\n<a href=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2019-08-19 08:14:31.557 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2019-08-23 13:08:16.98 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57488706",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37807158,
        "Question_title":"Train multiple models with various measures and accumulate predictions",
        "Question_body":"<p>So I have been playing around with Azure ML lately, and I got one dataset where I have multiple values I want to predict. All of them uses different algorithms and when I try to train multiple models within one experiment; it says the \u201ctrain model can only predict one value\u201d, and there are not enough input ports on the train-model to take in multiple values even if I was to use the same algorithm for each measure. I tried launching the column selector and making rules, but I get the same error as mentioned. How do I predict multiple values and later put the predicted columns together for the web service output so I don\u2019t have to have multiple API\u2019s?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-14 08:47:55.71 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1763,
        "Owner_creation_date":"2016-05-12 08:21:29.043 UTC",
        "Owner_last_access_date":"2016-06-14 14:37:43.043 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>What you would want to do is to train each model and save them as already trained models.\nSo create a new experiment, train your models and save them by right clicking on each model and they will show up in the left nav bar in the Studio. Now you are able to drag your models into the canvas and have them score predictions where you eventually make them end up in the same output as I have done in my example through the \u201cAdd columns\u201d module. I made this example for Ronaldo (Real Madrid CF player) on how he will perform in match after training day. You can see my demo on <a href=\"http:\/\/ronaldoinform.azurewebsites.net\" rel=\"nofollow noreferrer\">http:\/\/ronaldoinform.azurewebsites.net<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" alt=\"Ronaldo InForm\"><\/a><\/p>\n\n<p>For more detailed explanation on how to save the models and train multiple values; you can check out Raymond Langaeian (MSFT) answer in the comment section on this link:\n<a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-06-14 11:42:44.903 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37807158",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50954802,
        "Question_title":"Recommender Split Returning Empty Dataset",
        "Question_body":"<p>I'm using a \"Split Data\" module set to recommender split to split data for training and testing a matchbox recommender. The input data is a valid user-item-rating tuple (for example, 575978 - 157381 - 3) and I've left the parameters for the recommender split as default (0s for everything), besides changing it to a .75 and .25 split. However, when this module finishes, it returns the complete, unsplit dataset for dataset1 and a completely empty (but labelled) dataset for dataset2. This also happens when doing a stratified split using the \"Split Rows\" mode. Any idea what's going on?<\/p>\n\n<p>Thanks.<\/p>\n\n<p>Edit: Including a sample of my data.<\/p>\n\n<pre><code>UserID  ItemID  Rating\n835793  165937  3\n154738  11214   3\n938459  748288  3\n819375  789768  6\n738571  98987   3\n847509  153777  3\n991757  124458  3\n968685  288070  2\n236349  8337    3\n127299  545885  3\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2018-06-20 18:24:47.767 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-06-20 20:49:50.943 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":88,
        "Owner_creation_date":"2015-07-13 20:16:19.27 UTC",
        "Owner_last_access_date":"2022-06-30 20:42:10.207 UTC",
        "Owner_reputation":474,
        "Owner_up_votes":322,
        "Owner_down_votes":12,
        "Owner_views":28,
        "Answer_body":"<p>Figured it out. In my \"Remove Duplicate Rows\" module up the chain a bit I was only removing duplicates by UserID instead of UserID <em>and<\/em> ItemID. This still left quite a bit of rows but I'm assuming it messed with the stratification. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-06-21 16:34:37.083 UTC",
        "Answer_score":0.0,
        "Owner_location":"Eugene, OR, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50954802",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70538271,
        "Question_title":"Any recommendation on republish an endpoint to remain same",
        "Question_body":"<p>For AzureML we\u2019re using the REST api provided in published pipelines to launch them as part of scheduled jobs.<\/p>\n<p>It looks like if we republish an endpoint the GUID at the end of the URL changes.\nDo you have any recommendations for how to alias this so the URL can remain the same for a caller or keep it constant?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 01:39:42.27 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":124,
        "Owner_creation_date":"2021-09-24 05:28:30.82 UTC",
        "Owner_last_access_date":"2022-04-25 04:15:48.037 UTC",
        "Owner_reputation":107,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>These are static, unique URLs that can be associated with multiple published pipeline versions (you can make one pipeline the default).<\/p>\n<p>Pipeline Endpoints:<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipelineendpoint?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.pipeline.core.PipelineEndpoint class - Azure Machine Learning Python | Microsoft Docs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-12-31 12:07:40.163 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70538271",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32060196,
        "Question_title":"Azure ML Internal Error",
        "Question_body":"<p>When I try to test my Azure ML model, I get the following error: \u201cError code: InternalError, Http status code: 500\u201d, so it appears something is failing inside of the machine learning service. How do I get around this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-08-17 21:44:21.947 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-08-18 13:57:02.223 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1408,
        "Owner_creation_date":"2015-08-17 21:40:18.3 UTC",
        "Owner_last_access_date":"2016-04-28 08:03:01.207 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>I've run into this error before, and unfortunately, the only workaround I found was to create a new ML workspace backed by a storage account that you know is online. Then copy your experiment over to the new workspace, and things should work. It can be a bit cumbersome, but it should get rid of your error message. With the service being relatively new, things sometimes get corrupted as updates are being made, so I recommend checking the box labeled \"disable updates\" within your experiment.  Hope that helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-08-17 21:47:56.38 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32060196",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52819122,
        "Question_title":"What is the best practice on folder structure for Azure Machine Learning service (preview) projects",
        "Question_body":"<p>I'm very excited on the newly released Azure Machine Learning service (preview), which is a great step up from the previous (and deprecated) Machine Learning Workbench.<\/p>\n\n<p>However, I am thinking a lot about the best practice on structuring the folders and files in my project(s). I'll try to explain my thoughts.<\/p>\n\n<p>Looking at the documentation for the training of a model (e.g. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml#create-an-estimator\" rel=\"nofollow noreferrer\">Tutorial #1<\/a>), there seems to be good-practice to put all training scripts and necessary additional scripts inside a subfolder, so that it can be passed into the <code>Estimator<\/code> object without also passing all other files in the project. This is fine.<\/p>\n\n<p>But when working with the deployment of the service, specifically the deployment of the image, the documentation (e.g. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml#deploy-in-aci\" rel=\"nofollow noreferrer\">Tutorial #2<\/a>) seems to indicate that the scoring script need to be located in the root folder. If I try to refer to a script located in a subfolder, I get an error message saying<\/p>\n\n<p><code>WebserviceException: Unable to use a driver file not in current directory. Please navigate to the location of the driver file and try again.<\/code><\/p>\n\n<p>This may not be a big deal. Except, I have some additional scripts that I import both in the training script and in the scoring script, and I don't want to duplicate those additional scripts to be able to import them in both the training and the scoring scripts.<\/p>\n\n<p>I am working mainly in Jupyter Notebooks when executing the training and the deployment, and I could of course use some tricks to read the particular scripts from some other folder, save them to disk as a copy, execute the training or deployment while referring to the copies and finally delete the copies. This would be a decent workaround, but it seems to me that there should be a better way than just decent.<\/p>\n\n<p>What do you think?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-15 14:33:51.87 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":782,
        "Owner_creation_date":"2016-05-20 15:01:49.237 UTC",
        "Owner_last_access_date":"2022-09-05 14:52:13.07 UTC",
        "Owner_reputation":400,
        "Owner_up_votes":146,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>Currently, the score.py needs to be in current working directory, but dependency scripts - the <em>dependencies<\/em> argument to  <em>ContainerImage.image_configuration<\/em> - can be in a subfolder.<\/p>\n\n<p>Therefore, you should be able to use folder structure like this:<\/p>\n\n<pre><code>.\/score.py \n.\/myscripts\/train.py \n.\/myscripts\/common.py\n<\/code><\/pre>\n\n<p>Note that the relative folder structure is preserved during web service deployment; if you reference the common file in subfolder from your score.py, that reference should be valid within deployed image.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2018-10-23 15:41:31.403 UTC",
        "Answer_score":0.0,
        "Owner_location":"Uppsala, Sverige",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52819122",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60778546,
        "Question_title":"pip install azureml-sdk with latest patches to underlying libraries",
        "Question_body":"<p>How do I upgrade <code>azureml-sdk<\/code> such that the newest release of <code>azureml-core<\/code>, <code>1.1.5.5<\/code>, is installed? \nIf <code>azureml-sdk<\/code> is not installed, <code>pip install --upgrade azureml-sdk<\/code> will install <code>azureml-core==1.1.5.5<\/code>. If it is already installed, then it won't.<\/p>\n\n<pre><code>$ pip list --format=freeze | grep 'azureml-core'`\n&gt; azureml-core==1.1.5.1\n$ pip install --upgrade azureml-sdk[interpret,notebooks]\n$ pip list --format=freeze | grep 'azureml-core'`\n&gt; azureml-core==1.1.5.1\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-20 17:04:10.063 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-20 17:20:28.66 UTC",
        "Question_score":0,
        "Question_tags":"python|pip|azure-machine-learning-service",
        "Question_view_count":1142,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>You can use the eager strategy to force an upgrade of requirements:<\/p>\n\n<pre><code>pip install -U --upgrade-strategy eager azureml-sdk\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-20 20:23:55.707 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60778546",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58035744,
        "Question_title":"AML run.log() and run.log_list() fail without error",
        "Question_body":"<p>I have a Pipeline with DatabricksSteps each containing:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\n#do stuff\nrun.log(name, val, desc)\nrun.log_list(name, vals, desc)\nrun.log_image(title, fig, desc)\n<\/code><\/pre>\n\n<p>Only <code>log_image()<\/code> seems to work.  The image appears in the \"images\" section of the AML experiment workspace as expected, but the \"tracked metrics\" and \"charts\" areas are blank.  In an interactive job, <code>run.log()<\/code> and <code>run.log_list()<\/code> work as expected.  I tested that there is no problem with the arguments by using <code>print()<\/code> instead of <code>run.log()<\/code>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-20 22:23:24.223 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":121,
        "Owner_creation_date":"2016-06-07 17:33:54.943 UTC",
        "Owner_last_access_date":"2021-04-01 15:14:27.47 UTC",
        "Owner_reputation":677,
        "Owner_up_votes":13,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":"<p>Add run.flush() at the end of the script.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-09-25 16:11:01.03 UTC",
        "Answer_score":2.0,
        "Owner_location":"Redmond, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58035744",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57500954,
        "Question_title":"Automatically delete files in storage",
        "Question_body":"<p>So I've noticed that whenever I do a machine learning train\/retrain (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/retrain-machine-learning-model\" rel=\"nofollow noreferrer\">from here<\/a>), it generates a lot of files in my Azure blob storage as shown here<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/QN08i.png\" alt=\"Screenshot\"><\/p>\n\n<p>I wanted to ask if it was possible to automatically delete all these files or prevent them from ever being generated?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-14 19:33:41.207 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-15 01:26:33.773 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-storage|azure-machine-learning-studio",
        "Question_view_count":2077,
        "Owner_creation_date":"2018-05-21 00:50:14.91 UTC",
        "Owner_last_access_date":"2020-09-11 03:56:16.18 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Answer_body":"<p>For automatically delete all these files in blob storage, you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">Lifecycle Management<\/a> of blob storage.<\/p>\n<p>It's easy to set up a rule and filter, after the rule is set up, all the files will be deleted as per the rule you defined.<\/p>\n<p>Simple steps:<\/p>\n<p>1.Nav to azure portal -&gt; your storage account -&gt; Blob services -&gt; Lifecycle Management, then click &quot;Add rule&quot;.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>2.In the &quot;Action set&quot; tab, select Delete blob and fill in the textbox; Then in &quot;Filter set&quot; tab, select a path.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more details\/instructions, please follow this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">article<\/a>.<\/p>\n<p>Also note that the rule runs once per day, and for the first time, it may take 24 hours to take effect.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2019-08-15 01:23:49.083 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57500954",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43249220,
        "Question_title":"Need more than 2 datasets for \u201cExecute R Script\u201d module in \u201cAzure Machine Learning Studio\u201d",
        "Question_body":"<p>Since connecting to Azure SQL database from \u201cExecute R Script\u201d module in \u201cAzure Machine Learning Studio\u201d is not possible, and using Import Data modules (a.k.a Readers) is the only recommended approach, my question is that what can I do when I need more than 2 datasets as input for \"Execute R Script module\"?<\/p>\n\n<pre><code>\/\/ I'm already doing the following to get first 2 datasets,\ndataset1 &lt;- maml.mapInputPort(1)\ndataset2 &lt;- maml.mapInputPort(2)\n<\/code><\/pre>\n\n<p>How can I \"import\" a dataset3?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-04-06 08:02:51.163 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":337,
        "Owner_creation_date":"2017-02-24 01:57:57.287 UTC",
        "Owner_last_access_date":"2022-09-25 04:55:54.313 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>One thing you can do is combining two data-sets together and selecting the appropriate fields using the R script. That would be an easy workaround.   <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2017-04-06 15:34:15.983 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43249220",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37728314,
        "Question_title":"Refactor columns and features in Azure Machine Learning",
        "Question_body":"<p>Is there any way I can make my dataset features in Azure ML into something else than what it already is? <\/p>\n\n<p>I found a dataset of the Titanic ship in the sample datasets which I would like to work with but all of my columns are either a numeric feature or string feature, but I would like to categorize these. Also is there any possibility to rename the columns within my model so it\u2019s more descriptive than what I initially got? I have no clue what SibSp means for instance.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-09 14:08:01.33 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-06-15 07:52:59.12 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":297,
        "Owner_creation_date":"2016-06-07 19:08:35.433 UTC",
        "Owner_last_access_date":"2016-06-16 07:03:45.923 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>What you are doing is essentially recreating this experiment made by Raja Iqbal for the Titanic dataset. I recommend you check that out here: <a href=\"http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1\" rel=\"nofollow noreferrer\">http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1<\/a><\/p>\n\n<p>To answer your question, the module you can drag to your canvas in order to make the features into categories; is the Edit Metadata module where you select the columns you want and change the \u201cunchanged\u201d into \u201cMake categorical\u201d within the Categorical-properties pane like in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/2NDht.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2NDht.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>You can also use the same module to make better sense from your columns by giving them a different column name. SibSp means SiblingSpouse like I have renamed it to in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And at last you can assign the targeted value (survived) and make the field into a label for ease of use.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-06-09 14:56:24.003 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37728314",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41743792,
        "Question_title":"Is there an Azure Machine Learning Studio module that works like the Pandas 'mask' method?",
        "Question_body":"<p>I'm trying to perform the following Python Pandas operation in Azure Machine Learning Studio, but cannot find a module that handles it:<\/p>\n\n<pre><code>df.credit_score = df.credit_score.mask(df.credit_score &gt; 800, df.credit_score \/ 10)\n<\/code><\/pre>\n\n<p>So I'm effectively just trying to find all values in my 'credit_score' column that are greater than 800 and divide them by 10.  I have been unable so far to find a module in AML Studio that does that.<\/p>\n\n<p>Also, I should add that I'm having issues with my Python script in AML Studio, which is why I'm attempting to replicate all of my code using AML built-in modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-19 14:07:57.413 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-01-19 14:17:35.797 UTC",
        "Question_score":1,
        "Question_tags":"pandas|azure-machine-learning-studio",
        "Question_view_count":57,
        "Owner_creation_date":"2017-01-08 15:14:18.947 UTC",
        "Owner_last_access_date":"2019-05-03 18:29:28.66 UTC",
        "Owner_reputation":107,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>To my knowledge, there's no built-in module to do this succinctly (to my knowledge). If you prefer to use built-ins, you could:<\/p>\n\n<ol>\n<li>Use a Split Dataset module to split the entries based on credit\nscore<\/li>\n<li>Divide the credit score in large-credit-score rows by 10 using\nApply Math Operation<\/li>\n<li>Concatenate the two datasets row-wise with an Add Rows module<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-01-25 13:26:55.923 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41743792",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36154971,
        "Question_title":"AZURE ML getting model weights",
        "Question_body":"<p>I have deployed a regression model on azure ML , is it possible to get the model weights\/coefficients of the model programatically from azure, rather than getting predicted value? .<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-22 12:55:23.657 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1044,
        "Owner_creation_date":"2015-02-01 20:05:09.973 UTC",
        "Owner_last_access_date":"2022-09-24 08:12:42.76 UTC",
        "Owner_reputation":1238,
        "Owner_up_votes":45,
        "Owner_down_votes":5,
        "Owner_views":172,
        "Answer_body":"<p>No. Currently we do not feature exporting weights from the models including with Azure Machine Learning. <\/p>\n\n<p>If you have a method for extracting weights from Python models, you may be able to work this out using the execute Python Script module.<\/p>\n\n<p>The primary purpose of Azure Machine Learning is to make deployable and scalable web services from the machine learning modules. Though the authoring experience for creating ML models is great, it is not intended to be a place to create and export models, but instead a place to create and operationalize your models. <\/p>\n\n<p><em>UPDATE<\/em> New features may make this answer outdated. <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-03-23 12:49:37.17 UTC",
        "Answer_score":2.0,
        "Owner_location":"India",
        "Answer_last_edit_date":"2017-05-24 04:56:34.133 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36154971",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66504979,
        "Question_title":"Getting the error while removing the duplicates in python AzureML classification problem",
        "Question_body":"<p>I'm getting this error while calling drop.duplicate function:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;train.py&quot;, line 159, in &lt;module&gt;\n    orders_dfx = preprocess_orders(orders_df)\n  File &quot;train.py&quot;, line 20, in preprocess_orders\n    ao = ao.drop_duplicates(subset=['order_id'], keep='last')\nAttributeError: 'TabularDataset' object has no attribute 'drop_duplicates'\n<\/code><\/pre>\n<p>Here is a part of <code>train.py<\/code> code<\/p>\n<pre><code>def preprocess_orders(ao):\n  ao = ao.drop_duplicates(subset=['order_id'], keep='last')\n  ao['order_id'] = ao['order_id'].astype('str')\n  ao['class'] = ao['class'].astype('int')\n  ao['age'] = ao['age'].astype('float').fillna(ao['age'].mean()).round(2)\n  return ao\n\norders_df = Dataset.get_by_name(ws, name='class_cancelled_orders')\norders_df.to_pandas_dataframe()\n# Doing processing\norders_dfx = preprocess_orders(orders_df)\n<\/code><\/pre>\n<p>I'm getting the data from the datasets in azureml studio. The job.py file is used for running experiment as:<\/p>\n<pre><code># submit job\nrun = Experiment(ws, experiment_name).submit(src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-06 11:05:31.157 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-03-06 11:25:02.28 UTC",
        "Question_score":0,
        "Question_tags":"python|pandas|azure|azure-databricks|azure-machine-learning-service",
        "Question_view_count":37,
        "Owner_creation_date":"2020-08-21 14:08:03.05 UTC",
        "Owner_last_access_date":"2022-09-22 16:06:05.087 UTC",
        "Owner_reputation":77,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Answer_body":"<p>The <code>to_pandas_dataframe()<\/code>method <em>returns<\/em> a pandas DataFrame, so you need to assign it back your variable:<\/p>\n<pre><code>orders_df = orders_df.to_pandas_dataframe()\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-03-06 11:54:11.63 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66504979",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60303714,
        "Question_title":"Failed to parse column picker rules - azure ML designer",
        "Question_body":"<p>I am trying to use the azure ML designer (preview).<\/p>\n\n<p>referencing this - <a href=\"https:\/\/docs.microsoft.com\/en-in\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-in\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a><\/p>\n\n<p>using my own input sheet which has four columns and some decimal values. nothing fancy and identical to the sample datasets provided. <\/p>\n\n<p>I do this step (from the linked document above)<\/p>\n\n<p><em>Select the Train Model module.\nIn the module details pane to the right of the canvas, select Edit column selector.\nIn the Label column dialog box, expand the drop-down menu and select Column names.\nIn the text box, enter price to specify the value that your model is going to predict.<\/em><\/p>\n\n<p>and I get this (but there are no errors in the actual designer window.<\/p>\n\n<p>\"Failed to parse column picker rules\"<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-19 15:25:53.377 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-02-19 15:35:56.24 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":156,
        "Owner_creation_date":"2015-09-15 16:27:17.953 UTC",
        "Owner_last_access_date":"2022-09-24 06:49:58.907 UTC",
        "Owner_reputation":2272,
        "Owner_up_votes":1340,
        "Owner_down_votes":67,
        "Owner_views":516,
        "Answer_body":"<p>Okay, I found an answer myself. Hope that is okay.<\/p>\n\n<p>In my input sheet, the title was something like this \"Interest Rate %\". Looks like azure was trying to say that it does not like special characters it the column names.<\/p>\n\n<p>I edited my original csv file in excel, and removed the % in all the titles. <\/p>\n\n<p>Then, created a new data store. problem solved. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-02-19 15:34:56.627 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60303714",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71063820,
        "Question_title":"AzureML: Dataset Profile fails when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I trigger &quot;Generate Profile&quot; operation for the dataset, it throws following error while handling empty parquet file and then the profile generation stops.<\/p>\n<pre><code>User program failed with ExecutionError: \nError Code: ScriptExecution.StreamAccess.Validation\nValidation Error Code: NotSupported\nValidation Target: ParquetFile\nFailed Step: 77866d0a-8243-4d3d-8bc6-599d466488dd\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  Failed to read Parquet file at: &lt;my_blob_path&gt;\/20211217.parquet\n    Current parquet file is not supported.\n      Exception of type 'Thrift.Protocol.TProtocolException' was thrown.\n| session_id=6be4db0b-bdc1-4dd6-b8a6-6e9466f7bc54\n\n<\/code><\/pre>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (<code>pd.read_parquet<\/code>), it results in an empty DF (df.empty == True).<\/p>\n<p>Any suggestion to avoid this error will be appreciated.<\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-10 10:53:07.177 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-30 12:31:36.673 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":255,
        "Owner_creation_date":"2010-07-30 15:52:19.753 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:17.867 UTC",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-03-04 22:22:14.34 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bangalore, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71063820",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67966905,
        "Question_title":"How to extract a dataset from azureml.core.model.Model Class?",
        "Question_body":"<p>Azure Machine Learning Service's Model Artifact has the ability to store references to the Datasets associated with the model. We can use <code>azureml.core.model.Model.add_dataset_references([('relation-as-a-string', Dataset)])<\/code> to add these dataset references.\nHow do we retrieve a Dataset from the references stored in this Model class by using a reference to the Model Class?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-14 08:13:50.013 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":225,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>Consider that a Dataset was added as a reference to a Model with the name <code>'training_dataset'<\/code><\/p>\n<p>In order to get a reference to this Dataset we use:<\/p>\n<pre><code>model = Model(workspace, name)\ndataset_id = next(dictionary['id'] for dictionary in model.serialize()['datasets'] if dictionary[&quot;name&quot;] == 'training_dataset')\ndataset_reference = Dataset.get_by_id(workspace, dataset_id )\n<\/code><\/pre>\n<p>After this step we can use <code>dataset_reference<\/code> as any other AzureML Dataset Class object.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-18 09:34:22.167 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67966905",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52010761,
        "Question_title":"Azure MachineLearning WebService Not Using Passed .ilearner Model",
        "Question_body":"<p>We are currently working on making an Azure MachineLearning Studio experiment operational.<\/p>\n\n<p>Our most recent iteration has a webjob that accepts a queue message, gets some data to train the model, and consumes the ML Experiment webservice to put a trained model in a blob location.<\/p>\n\n<p>A second webjob accepts a queue message, pulls the data to be used in the predictive experiment, gets the location path of the trained .ilearner model, and then consumes THAT ML Experiment webservice.<\/p>\n\n<p>The data used to make the predictions is passed in as an input parameter, and the storage account name, key, and .ilearner path are all passed in as global parameters--Dictionary objects defined according to what the data scientist provided.<\/p>\n\n<p>Everything <em>appears<\/em> to work correctly--except in some cases, the predictive experiment fails, and the error message makes it clear the wrong .ilearner file is being used.<\/p>\n\n<p>When a non-existent blob path is passed to the experiment webservice, the error message reflects there is no such blob, so it's clear the webservice is at least validating the .ilearner's existence. <\/p>\n\n<p>The data scientist can run it locally, but has to change the name of the .ilearner file when he exports it locally through PowerShell. Ensuring each trained model has a unique file name did not resolve this issue.<\/p>\n\n<p>All files, when I view them in the Azure Storage Explorer, appear to be getting updated as expected based on last-modified dates. It's almost like there's a cached version of the .ilearner somewhere that isn't being overridden properly.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-24 19:39:35.903 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"c#|azure|web-services|azure-webjobs|azure-machine-learning-studio",
        "Question_view_count":65,
        "Owner_creation_date":"2016-10-21 13:46:29.223 UTC",
        "Owner_last_access_date":"2022-09-21 14:30:39.16 UTC",
        "Owner_reputation":547,
        "Owner_up_votes":1387,
        "Owner_down_votes":1,
        "Owner_views":45,
        "Answer_body":"<p>After ruling out all possibility of passing in the wrong file, our data scientist took a closer look at the experiment itself. He discovered that it was defaulting to one hardcoded .ilearner path he had been using in development.<\/p>\n\n<p>At one point in time, he had created webservice parameters to override this value (hence why I had them defined in my webservice call), but they had been removed during one of the redesigns of the experiment with anyone noticing, because the webservice will apparently accept superfluous arguments.<\/p>\n\n<p><strong>The webservice was accepting my global parameters<\/strong>, and apparently even validating them. But since they weren't wired to anything inside <strong>the experiment the passed .ilearner file info was never applied to anything<\/strong>--the hardcoded .ilearner was being applied no matter what.<\/p>\n\n<p>We were all very surprised there was no exception thrown about passing in parameters to the webservice that weren't actually defined. Had <em>that<\/em> happened, we would have gotten to the bottom of it much more quickly.<\/p>\n\n<p>tl\/dr: The experiment wasn't properly configured to accept an .ilearner file path (or Account Name, or Account Key) as a parameter, and the webservice was happily accepting and ignoring the parameter arguments without raising any alarm since it had the hardcoded value to run with.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-08-24 19:39:35.903 UTC",
        "Answer_score":1.0,
        "Owner_location":"Columbus, OH, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52010761",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37228027,
        "Question_title":"How do get my custom Python code into Azure Machine Learning for use a a ZIP resource?",
        "Question_body":"<p>The <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">documentation<\/a> for the Azure Machine Learning Python script module describes using a ZIP file containing code as a resource, but I don't see how to create and upload such a ZIP file in the first place.<\/p>\n\n<p>How do get my custom Python code into Azure Machine Learning for use as a ZIP resource?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-14 14:45:05.637 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-05-14 15:00:39.27 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":664,
        "Owner_creation_date":"2011-03-12 19:54:30.313 UTC",
        "Owner_last_access_date":"2022-09-21 19:06:38.42 UTC",
        "Owner_reputation":41475,
        "Owner_up_votes":1198,
        "Owner_down_votes":107,
        "Owner_views":1912,
        "Answer_body":"<p>Just upload it as a dataset. <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">Reference.<\/a> (search for it, as it is not on the first page).<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-walkthrough-2-upload-data\/#upload-the-dataset-to-machine-learning-studio\" rel=\"nofollow\">Reference<\/a> on how to upload the dataset. <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-05-14 15:02:38.72 UTC",
        "Answer_score":1.0,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37228027",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37749862,
        "Question_title":"Azure Machine Learning, 1 web input with multiple outputs?",
        "Question_body":"<p>Im trying to deploy a web app that takes 1 web input, then \"Set Column In Dataset\" a few times for each model , and then sends out a web output for each model.  <\/p>\n\n<p>Right now the way I have it setup is I have a few web inputs, then a model that runs for each, and then a web output for each.  It works for now, but it's a hassle because every time I want to add a new model to be predicted I have to add a bunch of stuff in both azure and my web application.  Just wondering if there is an easier way I'm missing.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-10 13:44:11.803 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":492,
        "Owner_creation_date":"2013-04-10 15:14:42.047 UTC",
        "Owner_last_access_date":"2018-03-16 19:19:12.72 UTC",
        "Owner_reputation":810,
        "Owner_up_votes":10,
        "Owner_down_votes":1,
        "Owner_views":49,
        "Answer_body":"<p>I am not quite sure I understand the workflow you described. Can you provide more details on what are you trying to accomplish with your web app and your experiment? For example, what do you mean when you say \"I have to add a bunch of stuff\"?<\/p>\n\n<p>Azure ML does support multiple web service inputs and outputs. Adding a new model to the experiment requires you to re-deploy your web service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-06-27 18:14:52.427 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37749862",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58691120,
        "Question_title":"Metric Document is too large in Azure ML Service",
        "Question_body":"<p>I am trying to save metrics : loss, validation loss and mAP at every epoch during 100 and 50 epochs but at the end of the experiment I have this error: \nRun failed: RunHistory finalization failed: ServiceException: Code: 400 Message: (ValidationError) Metric Document is too large<\/p>\n\n<p>I am using this code to save the metrics<\/p>\n\n<pre><code>run.log_list(\"loss\", history.history[\"loss\"])\nrun.log_list(\"val_loss\", history.history[\"val_loss\"])\nrun.log_list(\"val_mean_average_precision\", history.history[\"val_mean_average_precision\"])\n<\/code><\/pre>\n\n<p>I don't understand why trying to save only 3 metrics exceeds the limits of Azure ML Service.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2019-11-04 10:07:16.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-11-04 10:39:12.217 UTC",
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":368,
        "Owner_creation_date":"2017-03-01 16:02:15.02 UTC",
        "Owner_last_access_date":"2022-09-22 09:21:57.883 UTC",
        "Owner_reputation":620,
        "Owner_up_votes":589,
        "Owner_down_votes":5,
        "Owner_views":54,
        "Answer_body":"<p>You could break the run history list writes into smaller blocks like this:<\/p>\n\n<pre><code>run.log_list(\"loss\", history.history[\"loss\"][:N])\nrun.log_list(\"loss\", history.history[\"loss\"][N:])\n<\/code><\/pre>\n\n<p>Internally, the run history service concatenates the blocks with same metric name into a contiguous list.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-11-04 15:07:15.733 UTC",
        "Answer_score":3.0,
        "Owner_location":"Paris, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58691120",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67021176,
        "Question_title":"Azure Machine Learning - Use personal container registry",
        "Question_body":"<p>I tried to run this code to create an ml workspace from the azure-ml-cli, referencing an existing azure container registry from another subscription:<\/p>\n<pre><code>az ml workspace create --workspace-name &quot;test-mlws&quot; --keyvault &quot;&lt;key-vault-service-id&gt;&quot; --container-registry &quot;&lt;container-registry-zervice-id&gt;&quot; --location westeurope\n<\/code><\/pre>\n<p>The deploy failed with this error code:<\/p>\n<pre><code>{'code': 'InternalServerError', 'message': 'Received 403 from a service request'}\n<\/code><\/pre>\n<p>I can't find any documentation about it, and I guess it's due to the container registry I used which belongs to another subscription. Anyone who knows if it's mandatory for the registry to be in the same subscription?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-09 12:28:18.56 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2021-04-12 02:35:25.573 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":773,
        "Owner_creation_date":"2018-02-22 11:13:04.923 UTC",
        "Owner_last_access_date":"2022-09-23 16:29:44.727 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":34,
        "Owner_down_votes":1,
        "Owner_views":21,
        "Answer_body":"<p>From <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations<\/a><\/p>\n<blockquote>\n<p>If you want to use <strong>existing services from a different Azure\nsubscription<\/strong> than the workspace, you must register the Azure Machine\nLearning namespace in the subscription that contains those services.<\/p>\n<\/blockquote>\n<p>So, in order to use the ACR in that different subscription, you need to register resource provider <code>Microsoft.MachineLearningServices<\/code> in that subscription contains ACR. For information on how to see if it is registered and how to register it, see the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/resource-providers-and-types\" rel=\"nofollow noreferrer\">Azure resource providers and types<\/a> article.<\/p>\n<p>To register a resource provider, use:<\/p>\n<pre><code>Register-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>\n<p>To see information for a particular resource provider, use:<\/p>\n<pre><code>Get-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-12 02:34:47.617 UTC",
        "Answer_score":1.0,
        "Owner_location":"Cagliari, CA, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67021176",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53908529,
        "Question_title":"How to fix ModuleNotFoundError in azureml-sdk when installed inside conda environment",
        "Question_body":"<p>I'm setting up a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12 and have done a pip install of azureml-sdk inside the environment but get a ModuleNotFoundError when attempting to execute the following code:<\/p>\n\n<pre><code>import azureml.core\nazureml.core.VERSION\n<\/code><\/pre>\n\n<p>This is the output:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\n  File \"D:\\Projects\\style-transfer\\azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\nModuleNotFoundError: No module named 'azureml.core'; 'azureml' is not a package\n<\/code><\/pre>\n\n<p>The code above has been run from the conda prompt, with the test environment active as well as in vscode with the same environment selected.<\/p>\n\n<p>I setup the conda environment as per the following:<\/p>\n\n<ol>\n<li>Created the conda environment <code>conda create -n test<\/code>.<\/li>\n<li>Activated the environment <code>activate test<\/code>.<\/li>\n<li>Installed pip <code>conda install pip<\/code>.<\/li>\n<li>Installed azureml-sdk <code>pip install azureml-sdk<\/code>.<\/li>\n<\/ol>\n\n<p>This results in the following packages being installed in the environment as per <code>conda list<\/code>:<\/p>\n\n<pre><code>adal                      1.2.0                     &lt;pip&gt;\nantlr4-python3-runtime    4.7.2                     &lt;pip&gt;\napplicationinsights       0.11.7                    &lt;pip&gt;\nargcomplete               1.9.4                     &lt;pip&gt;\nasn1crypto                0.24.0                    &lt;pip&gt;\nazure-cli-command-modules-nspkg 2.0.2                     &lt;pip&gt;\nazure-cli-core            2.0.54                    &lt;pip&gt;\nazure-cli-nspkg           3.0.3                     &lt;pip&gt;\nazure-cli-profile         2.1.2                     &lt;pip&gt;\nazure-cli-telemetry       1.0.0                     &lt;pip&gt;\nazure-common              1.1.16                    &lt;pip&gt;\nazure-graphrbac           0.53.0                    &lt;pip&gt;\nazure-mgmt-authorization  0.51.1                    &lt;pip&gt;\nazure-mgmt-containerregistry 2.5.0                     &lt;pip&gt;\nazure-mgmt-keyvault       1.1.0                     &lt;pip&gt;\nazure-mgmt-nspkg          3.0.2                     &lt;pip&gt;\nazure-mgmt-resource       2.0.0                     &lt;pip&gt;\nazure-mgmt-storage        3.1.0                     &lt;pip&gt;\nazure-nspkg               3.0.2                     &lt;pip&gt;\nazure-storage-blob        1.4.0                     &lt;pip&gt;\nazure-storage-common      1.4.0                     &lt;pip&gt;\nazure-storage-nspkg       3.1.0                     &lt;pip&gt;\nazureml-core              1.0.6                     &lt;pip&gt;\nazureml-pipeline          1.0.6                     &lt;pip&gt;\nazureml-pipeline-core     1.0.6                     &lt;pip&gt;\nazureml-pipeline-steps    1.0.6                     &lt;pip&gt;\nazureml-sdk               1.0.6                     &lt;pip&gt;\nazureml-telemetry         1.0.6                     &lt;pip&gt;\nazureml-train             1.0.6                     &lt;pip&gt;\nazureml-train-core        1.0.6                     &lt;pip&gt;\nazureml-train-restclients-hyperdrive 1.0.6                     &lt;pip&gt;\nbackports.tempfile        1.0                       &lt;pip&gt;\nbackports.weakref         1.0.post1                 &lt;pip&gt;\nbcrypt                    3.1.5                     &lt;pip&gt;\nca-certificates           2018.03.07                    0\ncertifi                   2018.11.29               py37_0\ncffi                      1.11.5                    &lt;pip&gt;\nchardet                   3.0.4                     &lt;pip&gt;\ncolorama                  0.4.1                     &lt;pip&gt;\ncontextlib2               0.5.5                     &lt;pip&gt;\ncryptography              2.4.2                     &lt;pip&gt;\ndocker                    3.6.0                     &lt;pip&gt;\ndocker-pycreds            0.4.0                     &lt;pip&gt;\nfutures                   3.1.1                     &lt;pip&gt;\nhumanfriendly             4.17                      &lt;pip&gt;\nidna                      2.8                       &lt;pip&gt;\nisodate                   0.6.0                     &lt;pip&gt;\njmespath                  0.9.3                     &lt;pip&gt;\njsonpickle                1.0                       &lt;pip&gt;\nknack                     0.5.1                     &lt;pip&gt;\nmsrest                    0.6.2                     &lt;pip&gt;\nmsrestazure               0.6.0                     &lt;pip&gt;\nndg-httpsclient           0.5.1                     &lt;pip&gt;\noauthlib                  2.1.0                     &lt;pip&gt;\nopenssl                   1.1.1a               he774522_0\nparamiko                  2.4.2                     &lt;pip&gt;\npathspec                  0.5.9                     &lt;pip&gt;\npip                       18.1                     py37_0\nportalocker               1.2.1                     &lt;pip&gt;\npyasn1                    0.4.4                     &lt;pip&gt;\npycparser                 2.19                      &lt;pip&gt;\nPygments                  2.3.1                     &lt;pip&gt;\nPyJWT                     1.7.1                     &lt;pip&gt;\nPyNaCl                    1.3.0                     &lt;pip&gt;\npyOpenSSL                 18.0.0                    &lt;pip&gt;\npypiwin32                 223                       &lt;pip&gt;\npyreadline                2.1                       &lt;pip&gt;\npython                    3.7.1                h8c8aaf0_6\npython-dateutil           2.7.5                     &lt;pip&gt;\npytz                      2018.7                    &lt;pip&gt;\npywin32                   224                       &lt;pip&gt;\nPyYAML                    3.13                      &lt;pip&gt;\nrequests                  2.21.0                    &lt;pip&gt;\nrequests-oauthlib         1.0.0                     &lt;pip&gt;\nruamel.yaml               0.15.51                   &lt;pip&gt;\nSecretStorage             2.3.1                     &lt;pip&gt;\nsetuptools                40.6.3                   py37_0\nsix                       1.12.0                    &lt;pip&gt;\nsqlite                    3.26.0               he774522_0\ntabulate                  0.8.2                     &lt;pip&gt;\nurllib3                   1.23                      &lt;pip&gt;\nvc                        14.1                 h0510ff6_4\nvs2015_runtime            14.15.26706          h3a45250_0\nwebsocket-client          0.54.0                    &lt;pip&gt;\nwheel                     0.32.3                   py37_0\nwheel                     0.30.0                    &lt;pip&gt;\nwincertstore              0.2                      py37_0\n<\/code><\/pre>\n\n<p>If I run <code>which pip<\/code>, I get the following output, which confirms that I used the pip inside the environment to install azureml-sdk, I think:<\/p>\n\n<pre><code>\/c\/Users\/allan\/Miniconda3\/envs\/test\/Scripts\/pip\n<\/code><\/pre>\n\n<p>I can also see that the azureml packages do in fact exist within the environment folder structure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2018-12-24 02:04:42.117 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|conda|azure-machine-learning-studio",
        "Question_view_count":6343,
        "Owner_creation_date":"2016-04-12 10:16:44.197 UTC",
        "Owner_last_access_date":"2021-01-08 07:54:19.52 UTC",
        "Owner_reputation":140,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>It's probably because the name if your python file is the same as a module name you are trying import. In this case, rename the file to something other than <code>azureml.py<\/code>.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-12-24 06:38:18.167 UTC",
        "Answer_score":3.0,
        "Owner_location":"Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53908529",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71747545,
        "Question_title":"Commands in the Azure ML yml files",
        "Question_body":"<p>When reading the examples from Microsoft on azure ML CLI v2, they use the symbols:\n&quot;|&quot;, &quot;&gt;&quot;, etc., in their yml files.<\/p>\n<p>What do they mean, and where can I find explanations of possible syntax for the Azure CLI v2 engine?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-05 07:07:09.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"yaml|command-line-interface|azure-machine-learning-studio",
        "Question_view_count":100,
        "Owner_creation_date":"2021-05-03 13:44:35.61 UTC",
        "Owner_last_access_date":"2022-09-23 09:41:27.86 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>| - This pipe symbol in YAML document is used for <em><strong>&quot;Multiple line statements&quot;<\/strong><\/em><\/p>\n<pre><code>description: |\n  # Azure Machine Learning &quot;hello world&quot; job\n\n  This is a &quot;hello world&quot; job running in the cloud via Azure Machine Learning!\n\n  ## Description\n\n  Markdown is supported in the studio for job descriptions! You can edit the description there or via CLI.\n<\/code><\/pre>\n<p>in the above example, we need to write some multiple line description. So, we need to use &quot;|&quot; symbol<\/p>\n<p>&quot;&gt;&quot; - This symbol is used to save some content directly to a specific location document.<\/p>\n<pre><code>command: echo &quot;hello world&quot; &gt; .\/outputs\/helloworld.txt\n<\/code><\/pre>\n<p>In this above command, we need to post <strong>&quot;hello world&quot;<\/strong> to <em><strong>&quot;helloworld.txt&quot;<\/strong><\/em><\/p>\n<p>Check the below link for complete documentation regarding YAML files.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command<\/a><\/p>\n<p>All these symbols are the YAML job commands which are used to accomplish a specific task through CLI.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-06 07:55:01.843 UTC",
        "Answer_score":0.0,
        "Owner_location":"Denmark",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747545",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57596224,
        "Question_title":"How to expose port from locally-deployed AzureML container?",
        "Question_body":"<p>I want to be able to debug a running <code>entry_script.py<\/code> script in VSCode. This code runs in the container created through <code>az ml deploy<\/code> with its own docker run command. This is a local deployment so I'm using a deployment config that looks like this:<\/p>\n\n<pre><code>{\n    \"computeType\": \"LOCAL\",\n    \"port\": 32267\n}\n<\/code><\/pre>\n\n<p>I was thinking about using <code>ptvsd<\/code> to set up a VSCode server but I need to also expose\/map the 5678 port in addition to that 32267 port for the endpoint itself. So it's not clear to me how to map an additional exposed port (typically using the <code>-p<\/code> or <code>-P<\/code> flags in the <code>docker run<\/code> command). <\/p>\n\n<p>Sure, I can <code>EXPOSE<\/code> it in the <code>extra_dockerfile_steps<\/code> configuration but that won't actually map it to a host port that I can connect to\/attach to in VSCode.<\/p>\n\n<p>I tried to determine the run command and maybe modify it but I couldn't find out what that run command is. If I knew how to run the image that's created through AzureML local deployment then I could modify these flags. <\/p>\n\n<p>Ultimately it felt too hacky - if there was a more supported way through <code>az ml deploy<\/code> or through the deployment configuration that would be preferred.<\/p>\n\n<p>This is the code I'm using at the start of the entry_script to enable attachment via <code>ptvsd<\/code>: <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code># 5678 is the default attach port in the VS Code debug configurations\nprint(\"Waiting for debugger attach\")\nptvsd.enable_attach(address=('localhost', 5678), redirect_output=True)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-21 17:00:35.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":206,
        "Owner_creation_date":"2009-09-30 03:04:37.887 UTC",
        "Owner_last_access_date":"2022-09-23 16:14:18.72 UTC",
        "Owner_reputation":153,
        "Owner_up_votes":101,
        "Owner_down_votes":1,
        "Owner_views":111,
        "Answer_body":"<p>Unfortunately az ml deploy local doesn't support binding any ports other then the port hosting the scoring server. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-21 20:27:54.223 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seattle, WA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57596224",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66264795,
        "Question_title":"Azure ML studio - Container Registry Error while trying to submit a pipeline",
        "Question_body":"<p>I'm having the following error while trying to submit an Azure ML Studio pipeline<\/p>\n<p><code>Get credentials or pull docker image failed with err: error response from daemon: get https:\/\/lgcrmldev.azurecr.io\/v2\/azureml\/azureml_977f5bda2f6f4f634482661c121c8959\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.<\/code><\/p>\n<p>The notebook python code I'm doing is something on these lines:<\/p>\n<pre><code># create a Python script to do the actual work and save it in the pipeline folder:\n\n%%writefile $experiment_folder\/batch_online_retail.py\nimport os\nimport numpy as np\nfrom azureml.core import Model\nimport joblib\n\n\n# Called when the service is loaded\ndef init():\n    global model\n    \n    # Load the model\n    model_path = Model.get_model_path('Random_Forest_model')\n    model = joblib.load(model_path)\n\ndef run(batch):\n    try:\n        result = []\n        \n    # Process each line\n    for in range (len(batch)):\n        # Read the comma-delimited data into an array\n        data = np.genfromtxt(f, delimiter=',')        \n        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n        prediction = model.predict(data.reshape(1, -1))        \n        # Append prediction to results\n        resultList.append(&quot;{}: {}&quot;.format(os.path.basename(f), prediction[0]))\n    return resultList      \n<\/code><\/pre>\n<pre><code># Creating the run context\nfrom azureml.core import Environment\nfrom azureml.core.runconfig import DEFAULT_CPU_IMAGE\nfrom azureml.core.runconfig import CondaDependencies\n\n# Add dependencies required by the model\n# For scikit-learn models, you need scikit-learn\n# For parallel pipeline steps, you need azureml-core and azureml-dataprep[fuse]\ncd = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n                              pip_packages=['azureml-defaults','azureml-core','azureml-dataprep[fuse,pandas]'])\n\nbatch_env = Environment(name='batch_environment')\nbatch_env.python.conda_dependencies = cd\nbatch_env.docker.enabled = True\nbatch_env.docker.base_image = DEFAULT_CPU_IMAGE\nprint('Configuration ready.')\n\n<\/code><\/pre>\n<pre><code># Creating the ParallelRunStep\nfrom azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\nfrom azureml.pipeline.core import PipelineData\n\ndefault_ds = ws.get_default_datastore()\n\noutput_dir = PipelineData(name='inferences', \n                          datastore=default_ds, \n                          output_path_on_compute='online-retail\/results')\n\nparallel_run_config = ParallelRunConfig(\n    source_directory=experiment_folder,\n    entry_script=&quot;batch_online_retail.py&quot;,\n    mini_batch_size=&quot;5&quot;,\n    error_threshold=10,\n    output_action=&quot;append_row&quot;,\n    environment=batch_env,\n    compute_target=inference_cluster,\n    node_count=2)\n\nparallelrun_step = ParallelRunStep(\n    name='batch-score-retail',\n    parallel_run_config=parallel_run_config,\n    inputs=[batch_data_set.as_named_input('online_retail_batch')],\n    output=output_dir,\n    arguments=[],\n    allow_reuse=True\n)\n\nprint('Steps defined')\n<\/code><\/pre>\n<p>and finally,<\/p>\n<pre><code># Create an Azure ML experiment in your workspace, put the step into a pipeline and run it\nfrom azureml.core import Experiment\nfrom azureml.pipeline.core import Pipeline\n\npipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\npipeline_run = Experiment(ws, 'online-retail-deployment-cf').submit(pipeline)\npipeline_run.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>It's in this final step that I keep getting the error above.<\/p>\n<p>My Container Registry has my user and Azure ML resource as a Contributor in the access control panel, so I don't think it's lack of permissions.<\/p>\n<p>I've found this Microsoft page that seems to have a fix for the error I'm having:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-faq#docker-push-succeeds-but-docker-pull-fails-with-error-unauthorized-authentication-required\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-faq#docker-push-succeeds-but-docker-pull-fails-with-error-unauthorized-authentication-required<\/a><\/p>\n<p>But I don't understand how can I implement the suggested fix. This is because the Docker image the notebook uses is inside the Compute Instance created in Azure ML which we have limited access.<\/p>\n<p>Any ideas on what is the problem and how to fix it?<\/p>\n<p>Thank you in advance,\nCarla<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-18 17:11:59.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-container-registry|azure-machine-learning-service",
        "Question_view_count":869,
        "Owner_creation_date":"2021-02-18 16:28:16.487 UTC",
        "Owner_last_access_date":"2021-03-29 15:35:38.4 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>According to the example <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-custom-image#define-your-environment\" rel=\"nofollow noreferrer\">here<\/a>, I think you need to configure the environment variables for the docker images stored in the Azure Container Registry:<\/p>\n<pre><code>batch_env = Environment(name='batch_environment')\nbatch_env.python.conda_dependencies = cd\nbatch_env.docker.enabled = True\n# Set the container registry information.\nbatch_env.docker.base_image_registry.address = &quot;myregistry.azurecr.io&quot;\nbatch_env.docker.base_image_registry.username = &quot;username&quot;\nbatch_env.docker.base_image_registry.password = &quot;password&quot;\nbatch_env.docker.base_image = &quot;myregistry.azurecr.io\/DEFAULT_CPU_IMAGE&quot;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-02-19 09:12:25.093 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66264795",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69036277,
        "Question_title":"Run independent `PythonScriptStep` steps in parallel",
        "Question_body":"<p>In my pipeline multiple steps are independent and so I would like them to run in parallel based on input dependencies.<\/p>\n<p>As the compute I use has multiple nodes I would have expected this to be the default.<\/p>\n<p>For example:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Iye85.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iye85.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>All 3 upper steps should run in parallel, then both <code>finetune<\/code> steps in parallel as soon as their inputs are satisfied and the same for <code>rgb_test<\/code>.<\/p>\n<p>Currently only 1 step runs at a time, the other are <code>Queued<\/code>.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-09-02 19:49:26.28 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":156,
        "Owner_creation_date":"2012-01-26 14:27:40.553 UTC",
        "Owner_last_access_date":"2022-09-24 16:26:41.58 UTC",
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Answer_body":"<p>It ended up being because of vCPU quota.<\/p>\n<p>After increasing the quota, parallel tasks can run at the same time as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-27 19:02:52.63 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69036277",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67258465,
        "Question_title":"AzureML ParallelRunStep runs only on one node",
        "Question_body":"<p>I have an inference pipeline with some PythonScriptStep with a ParallelRunStep in the middle. Everything works fine except for the fact that all mini batches are run on one node during the ParallelRunStep, no matter how many nodes I put in the <code>node_count<\/code> config argument.<\/p>\n<p>All the nodes seem to be up and running in the cluster, and according to the logs the <code>init()<\/code> function has been run on them multiple times. Diving into the logs I can see in <strong>sys\/error\/10.0.0.*<\/strong> that all the workers except the one that is working are saying:<\/p>\n<p><code>FileNotFoundError: [Errno 2] No such file or directory: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/virtualstage\/azureml\/c36eb050-adc9-4c34-8a33-5f6d42dcb19c\/wd\/tmp8_txakpm\/bg.png'<\/code><\/p>\n<p><strong>bg.png<\/strong> happens to be a side argument created in a previous PythonScriptStep that I'm passing to the ParallelRunStep:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bg_file = PipelineData('bg',  datastore=data_store)\nbg_file_ds = bg_file.as_dataset()\nbg_file_named = bg_file_ds.as_named_input(&quot;bg&quot;)\nbg_file_dw = bg_file_named.as_download()\n\n...\n\nparallelrun_step = ParallelRunStep(\n    name='batch-inference',\n    parallel_run_config=parallel_run_config,\n    inputs=[frames_data_named.as_download()],\n    arguments=[&quot;--bg_folder&quot;, bg_file_dw],\n    side_inputs=[bg_file_dw],\n    output=inference_frames_ds,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>What's happening here? Why the side argument seems to be available only in one worker while it fails in the others?<\/p>\n<p>BTW I found <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/957\" rel=\"nofollow noreferrer\">this<\/a> similar but unresolved question.<\/p>\n<p>Any help is much appreciated, thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-25 21:28:29.403 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":244,
        "Owner_creation_date":"2012-08-01 13:43:34.45 UTC",
        "Owner_last_access_date":"2022-09-24 18:09:44.127 UTC",
        "Owner_reputation":359,
        "Owner_up_votes":265,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Answer_body":"<p>Apparently you need to specify a local mount path to use side_inputs in more than one node:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>bg_file_named = bg_file_ds.as_named_input(f&quot;bg&quot;)\nbg_file_mnt = bg_file_named.as_mount(f&quot;\/tmp\/{str(uuid.uuid4())}&quot;)\n\n...\n\nparallelrun_step = ParallelRunStep(\n    name='batch-inference',\n    parallel_run_config=parallel_run_config,\n    inputs=[frames_data_named.as_download()],\n    arguments=[&quot;--bg_folder&quot;, bg_file_mnt],\n    side_inputs=[bg_file_mnt],\n    output=inference_frames_ds,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>Sources:<\/p>\n<ul>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18355\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18355<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-29 11:08:05.79 UTC",
        "Answer_score":0.0,
        "Owner_location":"Seville, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67258465",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60562966,
        "Question_title":"Transfer from ADLS2 to Compute Target very slow Azure Machine Learning",
        "Question_body":"<p>During a training script executed on a compute target, we're trying to download a registered Dataset from an ADLS2 Datastore. The problem is that it takes <strong>hours<\/strong> to download ~1.5Gb (splitted into ~8500 files) to the compute target with the following method : <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Datastore, Dataset, Run, Workspace\n\n# Retrieve the run context to get Workspace\nRUN = Run.get_context(allow_offline=True)\n\n# Retrieve the workspace\nws = RUN.experiment.workspace\n\n# Creating the Dataset object based on a registered Dataset\ndataset = Dataset.get_by_name(ws, name='my_dataset_registered')\n\n# Download the Dataset locally\ndataset.download(target_path='\/tmp\/data', overwrite=False)\n<\/code><\/pre>\n\n<p><strong>Important note :<\/strong> the Dataset is registered to a path in the Datalake that contains a lot of subfolders (as well subsubfolders, ..) containing small files of around 170Kb.<\/p>\n\n<p><strong>Note:<\/strong> I'm able to download the complete dataset to local computer within a few minutes using <code>az copy<\/code> or the Storage Explorer. Also, the Dataset is defined at a folder stage with the ** wildcard for scanning subfolders : <code>datalake\/relative\/path\/to\/folder\/**<\/code><\/p>\n\n<p>Is that a known issue ? How can I improve transfer speed ?<\/p>\n\n<p>Thanks !<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-06 11:14:36.803 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-03-06 20:28:02.777 UTC",
        "Question_score":5,
        "Question_tags":"python|azure|azure-data-lake|azure-machine-learning-service|azure-data-lake-gen2",
        "Question_view_count":593,
        "Owner_creation_date":"2015-11-12 09:22:17.14 UTC",
        "Owner_last_access_date":"2022-09-21 16:03:24.94 UTC",
        "Owner_reputation":313,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":40,
        "Answer_body":"<p><em>Edited to be more answer-like:<\/em><\/p>\n\n<p>It'd be helpful to include: what versions of azureml-core and azureml-dataprep SDK you are using, what type of VM you are running as the compute instance, and what types of files (e.g. jpg? txt?) your dataset is using. Also, what are you trying to achieve by downloading the complete dataset to your compute?<\/p>\n\n<p>Currently, compute instance image comes with azureml-core 1.0.83 and azureml-dataprep 1.1.35 pre-installed, which are 1-2 months old. You might be using even older versions. You can try upgrading by running in your notebook:<\/p>\n\n<pre><code>%pip install -U azureml-sdk\n<\/code><\/pre>\n\n<p>If you don't see any improvements to your scenario, you can file an issue on the official docs page to get someone to help debug your issue, such as the ref page for <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.file_dataset.filedataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">FileDataset<\/a>.<\/p>\n\n<p><em>(edited on June 9, 2020 to remove mention of experimental release because that is not happening anymore)<\/em><\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-03-11 02:52:07.88 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-06-10 00:53:21.34 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60562966",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62170192,
        "Question_title":"Compute Instance: Best practice for custom Anaconda env",
        "Question_body":"<p>I'd like to use a compute instance as my develop machine.\nAre there any best practices on how to handle custom Anaconda enviroments on these machines?<\/p>\n\n<p>So far, I do it this way:<\/p>\n\n<pre><code>conda create --name testenv python=3\nconda activate testenv\nconda install ipykernel\nipython kernel install --user --name=testenv\nsudo systemctl restart jupyter.service\n<\/code><\/pre>\n\n<p>--> Reload the JupyterHub in your browser.<\/p>\n\n<p>Do you see any drawbacks by doing it this way? I know, some special package combinations in the standard env are lost, but I'd like to know what I've installed in my system.\nOf course, one could combine it with an <code>environment.yml<\/code>.<\/p>\n\n<p>What do you think?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-03 10:04:21.87 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-11 08:51:17.773 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":116,
        "Owner_creation_date":"2020-05-11 13:50:20.747 UTC",
        "Owner_last_access_date":"2022-09-15 09:14:33.43 UTC",
        "Owner_reputation":163,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>Your workaround is the best option as of now. But I know that the Azure ML product group has been working on exactly this problem, but I can't make any promises as to timeline.<\/p>\n\n<p>I share your dream of an easily configurable data science cloud development environment that allows for Git repo cloning and environment creation w\/ a conda yml. We're so close especially given all the press &amp; announcements around Visual Studio Codespaces!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-06-04 17:04:16.907 UTC",
        "Answer_score":1.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62170192",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64394661,
        "Question_title":"Erro InvalidInputDatatype: Input of type 'Unknown' is not supported in azure (azureml.train.automl)",
        "Question_body":"<p>I have a pandas's DataFrame created by:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TB_HISTORICO_MODELO = pd.read_sql(&quot;&quot;&quot;select DAT_INICIO_SEMANA_PLAN\n,COD_NEGOCIO\n,VENDA\n,LUCRO\n,MODULADO\n,RUPTURA\n,QTD_ESTOQUE_MEDIO\n,PECAS from TB&quot;&quot;&quot;, cursor)\n\nTB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;] = pd.to_datetime(TB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;])\n\ndataset = TB_HISTORICO_MODELO[TB_HISTORICO_MODELO['COD_NEGOCIO']=='A101'].drop(columns=['COD_NEGOCIO']) .reset_index(drop=True)\n<\/code><\/pre>\n<p>Everything look like right.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; dataset.dtypes\nDAT_INICIO_SEMANA_PLAN    datetime64[ns]\nVENDA                            float64\nLUCRO                            float64\nMODULADO                           int64\nRUPTURA                            int64\nQTD_ESTOQUE_MEDIO                  int64\nPECAS                            float64\ndtype: object\n<\/code><\/pre>\n<p>But when I rum this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#%% Create the AutoML Config file and run the experiment on Azure\n\nfrom azureml.train.automl import AutoMLConfig\n\ntime_series_settings = {\n   'time_column_name': 'DAT_INICIO_SEMANA_PLAN',\n   'max_horizon': 14,\n   'country_or_region': 'BR',\n   'target_lags': 'auto'\n}\n\nautoml_config = AutoMLConfig(task='forecasting',\n                            primary_metric='normalized_root_mean_squared_error',\n                            blocked_models=['ExtremeRandomTrees'],\n                            experiment_timeout_minutes=30,\n                            training_data=dataset,\n                            label_column_name='VENDA',\n                            compute_target = compute_cluster,\n                            enable_early_stopping=True,\n                            n_cross_validations=3,\n                            # max_concurrent_iterations=4,\n                            # max_cores_per_iteration=-1,\n                            verbosity=logging.INFO,\n                            **time_series_settings)\n\nremote_run = Experimento.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<p>I get the message<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; remote_run = Experimento.submit(automl_config, show_output=True)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/core\/experiment.py&quot;, line 219, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 92, in _automl_static_submit\n    automl_config_object._validate_config_settings(workspace)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 1775, in _validate_config_settings\n    supported_types=&quot;, &quot;.join(SupportedInputDatatypes.REMOTE_RUN_SCENARIO)\nazureml.train.automl.exceptions.ConfigException: ConfigException:\n        Message: Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]\n        InnerException: None\n        ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;training_data&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;,\n                &quot;inner_error&quot;: {\n                    &quot;code&quot;: &quot;InvalidInputDatatype&quot;\n                }\n            }\n        }\n    }\n}\n\n<\/code><\/pre>\n<p>Where is wrong?<\/p>\n<p>documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-16 18:36:27.197 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|pandas|azure|azure-machine-learning-service",
        "Question_view_count":382,
        "Owner_creation_date":"2018-04-02 02:01:36.793 UTC",
        "Owner_last_access_date":"2022-09-23 14:36:15.803 UTC",
        "Owner_reputation":264,
        "Owner_up_votes":276,
        "Owner_down_votes":2,
        "Owner_views":23,
        "Answer_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#data-source-and-format?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">Configure AutoML Doc<\/a> says:<\/p>\n<blockquote>\n<p>For remote experiments, training data must be accessible from the remote compute. AutoML only accepts Azure Machine Learning TabularDatasets when working on a remote compute.<\/p>\n<\/blockquote>\n<p>It looks as if your <code>dataset<\/code> object is a Pandas DataFrame, when it should really be an Azure ML <code>Dataset<\/code>. Check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">this doc<\/a> on creating Datasets.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-10-18 07:07:46.533 UTC",
        "Answer_score":3.0,
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Answer_last_edit_date":"2020-10-18 07:14:19.15 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64394661",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41010551,
        "Question_title":"predicting the possibility of Active members becoming Inactive?",
        "Question_body":"<p>I have a database of members, some are active and some are inactive. <\/p>\n\n<p>I want to predict the possibility of Active members becoming Inactive?<\/p>\n\n<p>Should I run the AML on the inactive members (no splitting) and when I publish the model i pass in the active members?<\/p>\n\n<p>I have tried many AML datasets before however usually you will have a column that contains the values you want to predict (Active-Inactive) (True-False) (Red-Black-White) but i never tried having only one value to trina your model with.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-12-07 06:09:21.2 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-12-07 06:51:43.17 UTC",
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":83,
        "Owner_creation_date":"2016-12-07 06:02:33.287 UTC",
        "Owner_last_access_date":"2020-02-03 08:25:54.213 UTC",
        "Owner_reputation":15,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>you will need to train your model with both active and inactive members.  I would split your dataset so there are examples of active and inactive members in both your training and your test set.  <\/p>\n\n<p>Let's discuss why we split the data.  Remember that with supervised learning, you need data with labeled examples.  For example, let\u2019s say I want to predict how much a house will cost based on its square footage and zip code.  To train my model, I need a dataset of existing houses with their square footage, zip codes, and prices, like this:<\/p>\n\n<p>SquareFootage ZipCode Price <br\/>\n2000          48075   200,000 <br\/>\n3000 48075 300,000 <br\/>\n4000 48075 400,000 <br\/>\n5000 48075 500,000 <br\/><\/p>\n\n<p>In this example, square footage and zip code are my features (things that influence the thing you want to predict) and price is my label (the thing that you want to predict).  I could train a model on some data like the above, and then use the trained model to predict prices, given only a square footage and zip code.  <\/p>\n\n<p>So, the reason I split the data is to provide most of the data to train the model (it will process the data to figure out correlations between the features and labels in the \u201ctrain model\u201d module), but we want to hold back some of that labeled data to test the model that we built.  Then, we can compare the price value that the trained model generates against the actual labeled price value in the test dataset (in the \u201cscore model\u201d module) to see how well the model is performing.  (We can\u2019t use the same data for both...the model is built using the training data, so it will perform pretty accurately with that; we hold back unused data to test.)  <\/p>\n\n<p>So, for your example, I would try a random split so there are examples of both active and inactive members (that is your label - inactive or active) and you will also need to provide relevant features that influence activity.  <\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2016-12-07 06:53:22.247 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41010551",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57431340,
        "Question_title":"Is it possible to use HyperDriveStep with time-series cross-validation?",
        "Question_body":"<p>I want to deploy a stacked model to Azure Machine Learning Service. The architecture of the solution consists of three models and one meta-model.\nData is a time-series data. <\/p>\n\n<p>I'd like the model to automatically re-train based on some schedule. I'd also like to re-tune hyperparameters during each re-training. <\/p>\n\n<p>AML Service offers <code>HyperDriveStep<\/code> class that can be used in the pipeline for automatic hyperparameter optimization. <\/p>\n\n<p>Is it possible - and if so, how to do it - to use <code>HyperDriveStep<\/code> with time-series CV?<\/p>\n\n<p>I checked the documentation, but haven't found a satisfying answer.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-09 13:40:21.917 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|hyperparameters|azure-machine-learning-service",
        "Question_view_count":189,
        "Owner_creation_date":"2017-03-23 13:26:01.927 UTC",
        "Owner_last_access_date":"2022-09-22 20:27:37.72 UTC",
        "Owner_reputation":83,
        "Owner_up_votes":30,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Answer_body":"<p>AzureML HyperDrive is a black box optimizer, meaning that it will just run your code with different parameter combinations based on the configuration you chose. At the same time, it supports Random and Bayesian sampling and has different policies for early stopping (see here for relevant <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-tune-hyperparameters\" rel=\"nofollow noreferrer\">docs<\/a> and here for an <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training-with-deep-learning\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\" rel=\"nofollow noreferrer\">example<\/a> -- HyperDrive is towards the end of the notebook).<\/p>\n\n<p>The only thing that your model\/script\/training needs to adhere to is to be launched from a script that takes <code>--param<\/code> style parameters. As long as that holds you could optimize the parameters for each of your models individually and then tune the meta-model, or you could tune them all in one run. It will mainly depend on the size of the parameter space and the amount of compute you want to use (or pay for).<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-08-13 20:26:43.107 UTC",
        "Answer_score":1.0,
        "Owner_location":"Tel Aviv",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57431340",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32422626,
        "Question_title":"Part of speech tagging and entity recognition - python",
        "Question_body":"<p>I want to perform part of speech tagging and entity recognition in python similar to Maxent_POS_Tag_Annotator and Maxent_Entity_Annotator functions of openNLP in R.  I would prefer a code in python which takes input as textual sentence and gives output as different features- like number of \"CC\", number of \"CD\", number of \"DT\" etc.. CC, CD, DT are POS tags as used in Penn Treebank. So there should be 36 columns\/features for POS tagging corresponding to 36 POS tags as in <a href=\"http:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html\" rel=\"nofollow\">Penn Treebank POS<\/a>. I want to implement this on Azure ML \"Execute Python Script\" module and Azure ML supports python 2.7.7. I heard nltk in python may does the job, but I am a beginner on python. Any help would be appreciated. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-09-06 10:36:34.287 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-09-09 05:30:51.843 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|named-entity-recognition|part-of-speech|azure-machine-learning-studio",
        "Question_view_count":1014,
        "Owner_creation_date":"2015-05-11 06:02:32.36 UTC",
        "Owner_last_access_date":"2015-10-06 01:00:37.57 UTC",
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>Take a look at <a href=\"http:\/\/www.nltk.org\/book\/ch05.html\" rel=\"nofollow\">NTLK book<\/a>, Categorizing and Tagging Words section.<\/p>\n\n<p>Simple example, it uses the Penn Treebank tagset:<\/p>\n\n<pre><code>from nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\npos_tag(word_tokenize(\"John's big idea isn't all that bad.\")) \n\n[('John', 'NNP'),\n(\"'s\", 'POS'),\n ('big', 'JJ'),\n ('idea', 'NN'),\n ('is', 'VBZ'),\n (\"n't\", 'RB'),\n ('all', 'DT'),\n ('that', 'DT'),\n ('bad', 'JJ'),\n ('.', '.')]\n<\/code><\/pre>\n\n<p>Then you can use<\/p>\n\n<pre><code>from collections import defaultdict\ncounts = defaultdict(int)\nfor (word, tag) in pos_tag(word_tokenize(\"John's big idea isn't all that bad.\")):\n    counts[tag] += 1\n<\/code><\/pre>\n\n<p>to get frequencies:<\/p>\n\n<pre><code>defaultdict(&lt;type 'int'&gt;, {'JJ': 2, 'NN': 1, 'POS': 1, '.': 1, 'RB': 1, 'VBZ': 1, 'DT': 2, 'NNP': 1})\n<\/code><\/pre>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2015-09-06 11:39:08.05 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32422626",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56021977,
        "Question_title":"Replace values in a column based on a condition in Azure ML Studio",
        "Question_body":"<p>How do I replace the values in a specific column with a particular value based on a condition in Azure ML Studio. I can do this using pandas in python as foolows:<\/p>\n\n<pre><code>df.loc[df['col_name'] &gt; 1990, 'col_name'] = 1\n<\/code><\/pre>\n\n<p>I'm trying to find a Module in Azure Machine Learning Studio that does the equivalent of this. <\/p>\n\n<p>I understand there is a replace option under the ConverToDataset module and a Replace Discrete Values module. But neither of these seems to do what I want. Is there an option to replace the values in just one column to a specific value based on a condition?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-07 11:51:11.357 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":564,
        "Owner_creation_date":"2015-12-16 10:02:46.773 UTC",
        "Owner_last_access_date":"2022-09-23 17:46:43.357 UTC",
        "Owner_reputation":1587,
        "Owner_up_votes":123,
        "Owner_down_votes":8,
        "Owner_views":540,
        "Answer_body":"<p>You can use either the more general <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/apply-sql-transformation\" rel=\"nofollow noreferrer\">Apply SQL Transformation<\/a>, or the dedicated <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/clip-values\" rel=\"nofollow noreferrer\">Clip Values<\/a> module. If all else fails, there's also <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-python-script\" rel=\"nofollow noreferrer\">Execute Python Script<\/a>.<\/p>\n\n<p>Personally, for your example I'd use <code>Clip Values<\/code> with <code>Clip Peaks<\/code> and <code>Upper Threshold<\/code> set. For more complex rules I'd use either <code>Apply SQL Transformation<\/code> or <code>Execute Python Script<\/code>, depending on the rules but favouring SQL :).<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-05-09 08:52:09.597 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56021977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34047782,
        "Question_title":"Jupyter notebook kernel dies when creating dummy variables with pandas",
        "Question_body":"<p>I am working on the Walmart Kaggle competition and I'm trying to create a dummy column of of the \"FinelineNumber\" column. For context, <code>df.shape<\/code> returns <code>(647054, 7)<\/code>. I am trying to make a dummy column for <code>df['FinelineNumber']<\/code>, which has 5,196 unique values. The results should be a dataframe of shape <code>(647054, 5196)<\/code>, which I then plan to <code>concat<\/code> to the original dataframe. <\/p>\n\n<p>Nearly every time I run <code>fineline_dummies = pd.get_dummies(df['FinelineNumber'], prefix='fl')<\/code>, I get the following error message <code>The kernel appears to have died. It will restart automatically.<\/code> I am running python 2.7 in jupyter notebook on a MacBookPro with 16GB RAM.<\/p>\n\n<p>Can someone explain why this is happening (and why it happens most of the time but not every time)? Is it a jupyter notebook or pandas bug? Also, I thought it might have to do with not enough RAM but I get the same error on a Microsoft Azure Machine Learning notebook with >100 GB of RAM. On Azure ML, the kernel dies every time - almost immediately.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-12-02 16:24:31.52 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-02-01 04:22:08.203 UTC",
        "Question_score":5,
        "Question_tags":"python|pandas|ipython-notebook|azure-machine-learning-studio",
        "Question_view_count":5063,
        "Owner_creation_date":"2013-07-10 17:00:15.3 UTC",
        "Owner_last_access_date":"2022-09-21 17:11:58.293 UTC",
        "Owner_reputation":2037,
        "Owner_up_votes":61,
        "Owner_down_votes":1,
        "Owner_views":193,
        "Answer_body":"<p>It very much could be memory usage - a 647054, 5196 data frame has 3,362,092,584 elements, which would be 24GB just for the pointers to the objects on a 64-bit system.  On AzureML while the VM has a large amount of memory you're actually limited in how much memory you have available (currently 2GB, soon to be 4GB) - and when you hit the limit the kernel typically dies.  So it seems very likely it is a memory usage issue.<\/p>\n\n<p>You might try doing <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/sparse.html\" rel=\"noreferrer\">.to_sparse()<\/a> on the data frame first before doing any additional manipulations.  That should allow Pandas to keep most of the data frame out of memory.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-12-10 17:25:00.887 UTC",
        "Answer_score":8.0,
        "Owner_location":"New York, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34047782",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72659937,
        "Question_title":"CI \/ CD and repository integration for Azure ML Workspace",
        "Question_body":"<p>I am interested in knowing how can I integrate a repository with Azure Machine Learning Workspace.<\/p>\n<h2>What have I tried ?<\/h2>\n<p>I have some experience with Azure Data Factory and usually I have setup workflows where<\/p>\n<ol>\n<li><p>I have a <code>dev<\/code> azure data factory instance that is linked to azure repository.<\/p>\n<\/li>\n<li><p>Changes made to the repository using the code editor.<\/p>\n<\/li>\n<li><p>These changes are published via the <code>adf_publish<\/code> branch to the live <code>dev<\/code> instance<\/p>\n<\/li>\n<li><p>I use CI \/ CD pipeline and the AzureRMTemplate task to deploy the templates in the publish branch to release the changes to <code>production<\/code> environment<\/p>\n<\/li>\n<\/ol>\n<h2>Question:<\/h2>\n<ul>\n<li>How can I achieve the same \/ similar workflow with Azure Machine Learning Workspace ?<\/li>\n<li>How is CI \/ CD done with Azure ML Workspace<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-17 13:11:31.697 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":94,
        "Owner_creation_date":"2010-04-12 17:27:26.887 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:17.55 UTC",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Answer_body":"<p>The following workflow is the official practice to be followed to achieve the task required.<\/p>\n<ol>\n<li>Starting with the architecture mentioned below<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>we need to have a specific data store to handle the dataset<\/li>\n<li>Perform the regular code modifications using the IDE like Jupyter Notebook or VS Code<\/li>\n<li>Train and test the model<\/li>\n<li>To register and operate on the model, deploy the model image as a web service and operate the rest.<\/li>\n<\/ul>\n<ol start=\"2\">\n<li><strong>Configure the CI Pipeline:<\/strong><\/li>\n<\/ol>\n<ul>\n<li><p>Follow the below steps to complete the procedure<\/p>\n<p><strong>Before implementation:<\/strong><\/p>\n<pre><code>- We need azure subscription enabled account\n- DevOps activation must be activated.\n<\/code><\/pre>\n<\/li>\n<li><p>Open DevOps portal with enabled SSO<\/p>\n<\/li>\n<li><p>Navigate to <strong>Pipeline -&gt; Builds -&gt; Choose the model which was created -&gt; Click on EDIT<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Build pipeline will be looking like below screen\n<a href=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>We need to use Anaconda distribution for this example to get all the dependencies.<\/p>\n<\/li>\n<li><p>To install environment dependencies, check the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/tasks\/package\/conda-environment?view=azure-devops&amp;viewFallbackFrom=azdevops\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<\/li>\n<li><p>Use the python environment, under <strong>Install Requirements<\/strong> in user setup.<\/p>\n<\/li>\n<li><p>Select <strong>create or get workspace<\/strong> select your account subscription as mentioned in below screen<\/p>\n<\/li>\n<\/ul>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vt0el.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vt0el.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>Save the changes happened in other tasks and all those muse be in same subscription.\n<a href=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<\/ul>\n<p>The entire CI\/CD procedure and solution was documented in <a href=\"https:\/\/www.azuredevopslabs.com\/labs\/vstsextend\/aml\/#author-praneet-singh-solanki\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<p><strong>Document Credit: Praneet Singh Solanki<\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-19 23:45:28.283 UTC",
        "Answer_score":0.0,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72659937",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52807787,
        "Question_title":"Azure machine learning studio get access to the file in upload zip file",
        "Question_body":"<p>I am trying to execute Python script from Azure machine learning studio. I had a script bundle(zip file) connect to the Python script as input. There are python files, txt files and other type of files in this zip file. My question is how do I get the file path from this zip file. For example, if I have language model in this  zip file, named lm.pcl, what's the file path of this language model? \nThanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-14 22:56:34.623 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio",
        "Question_view_count":679,
        "Owner_creation_date":"2012-05-18 17:27:03.537 UTC",
        "Owner_last_access_date":"2022-09-23 21:14:32.923 UTC",
        "Owner_reputation":581,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":49,
        "Answer_body":"<p>They're available under the <code>.\/Script Bundle<\/code> directory. For example, if you were to load a pickled model from the zip file, you'd write something along these lines:<\/p>\n\n<pre><code>import pandas as pd\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n\n    model = pickle.load(open(\".\/Script Bundle\/model.pkl\", \"rb\"))\n    ...\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-10-15 05:48:10.283 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52807787",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57854136,
        "Question_title":"Registering and downloading a fastText .bin model fails with Azure Machine Learning Service",
        "Question_body":"<p>I have a simple RegisterModel.py script that uses the Azure ML Service SDK to register a fastText .bin model. This completes successfully and I can see the model in the Azure Portal UI (I cannot see what model files are in it). I then want to download the model (DownloadModel.py) and use it (for testing purposes), however it throws an error on the <strong>model.download<\/strong> method (<em>tarfile.ReadError: file could not be opened successfully<\/em>) and makes a 0 byte rjtestmodel8.tar.gz file.<\/p>\n\n<p>I then use the Azure Portal and Add Model and select the same bin model file and it uploads fine. Downloading it with the download.py script below works fine, so I am assuming something is not correct with the Register script.<\/p>\n\n<p>Here are the 2 scripts and the stacktrace - let me know if you can see anything wrong:<\/p>\n\n<p><strong>RegisterModel.py<\/strong><\/p>\n\n<pre><code>import azureml.core\nfrom azureml.core import Workspace, Model\nws = Workspace.from_config()\nmodel = Model.register(workspace=ws,\n                       model_name='rjSDKmodel10',\n                       model_path='riskModel.bin')\n<\/code><\/pre>\n\n<p><strong>DownloadModel.py<\/strong><\/p>\n\n<pre><code># Works when downloading the UI Uploaded .bin file, but not the SDK registered .bin file\nimport os\nimport azureml.core\nfrom azureml.core import Workspace, Model\n\nws = Workspace.from_config()\nmodel = Model(workspace=ws, name='rjSDKmodel10')\nmodel.download(target_dir=os.getcwd(), exist_ok=True)\n<\/code><\/pre>\n\n<p><strong>Stacktrace<\/strong><\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"...\\.vscode\\extensions\\ms-python.python-2019.9.34474\\pythonFiles\\ptvsd_launcher.py\", line 43, in &lt;module&gt;\n    main(ptvsdArgs)\n  File \"...\\.vscode\\extensions\\ms-python.python-2019.9.34474\\pythonFiles\\lib\\python\\ptvsd\\__main__.py\", line 432, in main\n    run()\n  File \"...\\.vscode\\extensions\\ms-python.python-2019.9.34474\\pythonFiles\\lib\\python\\ptvsd\\__main__.py\", line 316, in run_file\n    runpy.run_path(target, run_name='__main__')\n  File \"...\\.conda\\envs\\DoC\\lib\\runpy.py\", line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File \"...\\.conda\\envs\\DoC\\lib\\runpy.py\", line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File \"...\\.conda\\envs\\DoC\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"...\\\\DownloadModel.py\", line 21, in &lt;module&gt;\n    model.download(target_dir=os.getcwd(), exist_ok=True)\n  File \"...\\.conda\\envs\\DoC\\lib\\site-packages\\azureml\\core\\model.py\", line 712, in download\n    file_paths = self._download_model_files(sas_to_relative_download_path, target_dir, exist_ok)\n  File \"...\\.conda\\envs\\DoC\\lib\\site-packages\\azureml\\core\\model.py\", line 658, in _download_model_files\n    file_paths = self._handle_packed_model_file(tar_path, target_dir, exist_ok)\n  File \"...\\.conda\\envs\\DoC\\lib\\site-packages\\azureml\\core\\model.py\", line 670, in _handle_packed_model_file\n    with tarfile.open(tar_path) as tar:\n  File \"...\\.conda\\envs\\DoC\\lib\\tarfile.py\", line 1578, in open\n    raise ReadError(\"file could not be opened successfully\")\ntarfile.ReadError: file could not be opened successfully\n<\/code><\/pre>\n\n<p><strong>Environment<\/strong><\/p>\n\n<ul>\n<li>riskModel.bin is 6 megs<\/li>\n<li>AMLS 1.0.60<\/li>\n<li>Python 3.7<\/li>\n<li>Working locally with Visual Code<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-09-09 12:31:46.497 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-09 20:28:30.63 UTC",
        "Question_score":0,
        "Question_tags":"python-3.x|fasttext|azure-machine-learning-service",
        "Question_view_count":281,
        "Owner_creation_date":"2009-10-21 01:51:25.5 UTC",
        "Owner_last_access_date":"2022-09-13 05:24:36.847 UTC",
        "Owner_reputation":4947,
        "Owner_up_votes":277,
        "Owner_down_votes":8,
        "Owner_views":531,
        "Answer_body":"<p>The Azure Machine Learning service SDK has a bug with how it interacts with Azure Storage, which causes it to upload corrupted files if it has to retry uploading. <\/p>\n\n<p>A couple workarounds:<\/p>\n\n<ol>\n<li>The bug was introduced in 1.0.60 release. If you downgrade to AzureML-SDK 1.0.55, the code should fail when there are issue uploading instead of silently corrupting data.<\/li>\n<li>It's possible that the retry is being triggered by the low timeout values that the AzureML-SDK defaults to. You could investigate changing the timeout in <code>site-packages\/azureml\/_restclient\/artifacts_client.py<\/code><\/li>\n<\/ol>\n\n<p>This bug should be fixed in the next release of the AzureML-SDK.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2019-09-09 18:37:20.467 UTC",
        "Answer_score":2.0,
        "Owner_location":"Sydney, Australia",
        "Answer_last_edit_date":"2019-09-09 18:45:11.3 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57854136",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68658385,
        "Question_title":"Azure Machine Learning Studio designer - \"create new version\" unexpected when registering a data set",
        "Question_body":"<p>I am trying to register a data set as a Python step with the Azure Machine Learning Studio designer. Here is my code:<\/p>\n<pre><code>import pandas as pd\nfrom azureml.core import Workspace, Run, Dataset\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    run = Run.get_context()\n    ws = run. experiment.workspace\n    ds = Dataset.from_pandas_dataframe(dataframe1)\n    ds.register(workspace = ws,\n                name = &quot;data set name&quot;,\n                description = &quot;example description&quot;,\n                create_new_version = True)\n    return dataframe1, \n<\/code><\/pre>\n<p>I get an error saying that &quot;create_new_version&quot; in the ds.register line was an unexpected keyword argument. However, this keyword appears in the documentation and I need it to keep track of new versions of the file.<\/p>\n<p>If I remove the argument, I get a different error: &quot;Local data source path not supported for this operation&quot;, so it still does not work. Any help is appreciated. Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2021-08-04 21:49:31.587 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":565,
        "Owner_creation_date":"2013-06-17 20:00:29.817 UTC",
        "Owner_last_access_date":"2022-09-24 13:07:45.427 UTC",
        "Owner_reputation":1111,
        "Owner_up_votes":124,
        "Owner_down_votes":2,
        "Owner_views":191,
        "Answer_body":"<h2>update<\/h2>\n<p>sharing OP's solution here for easier discovery<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom azureml.core import Workspace, Run, Dataset\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    run = Run.get_context()\n    ws = run. experiment.workspace\n    datastore = ws.get_default_datastore()\n    ds = Dataset.Tabular.register_pandas_dataframe(\n        dataframe1, datastore, 'data_set_name',\n        description = 'data set description.')\n    return dataframe1,\n<\/code><\/pre>\n<h2>original answer<\/h2>\n<p>Sorry you're struggling. You're very close!<\/p>\n<p>A few things may be the culprit here.<\/p>\n<ol>\n<li>It looks like you're using the <code>Dataset<\/code> class, which has been deprecated. I recommend trying <code>Dataset.Tabular.register_pandas_dataframe()<\/code> (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#register-pandas-dataframe-dataframe--target--name--description-none--tags-none--show-progress-true-\" rel=\"nofollow noreferrer\">docs link<\/a>) instead of <code>Dataset.from_pandas_dataframe()<\/code>. (<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/dataset-api-change-notice.md\" rel=\"nofollow noreferrer\">more about the Dataset API deprecation<\/a>)<\/li>\n<li>More conjectire here, but another thing is there might be some limitations to using dataset registration within an &quot;Execute Python Script&quot; (EPS) module due to:\n<ol>\n<li>the workspace object might not have the right permissions<\/li>\n<li>you might not be able to use the <code>register_pandas_dataframe<\/code> method inside the EPS module, but might have better luck with save the dataframe first to parquet, then calling <code>Dataset.Tabular.from_parquet_files<\/code><\/li>\n<\/ol>\n<\/li>\n<\/ol>\n<p>Hopefully something works here!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-08-04 23:22:42.627 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-08-05 16:21:12.98 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68658385",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48990264,
        "Question_title":"Operationalize custom R model in Azure ML without loading it on every call of web service",
        "Question_body":"<p>I am trying to serve an R model as a web service in Azure ML.<\/p>\n\n<p>The model is trained locally and uses Xgboost and other packages. I have had issues submitting it directly from AzureML package due to size exceeding 130 MB. The workaround was to upload all the packages and the model as zip to Azure and source it from there.<\/p>\n\n<p>The current issue is that the model is loaded from a zip file by Azure ML EVERY time the service is called making the response time very slow (4.5 seconds).\nHow do I restructure the code so that the model is loaded only once from the file. Thank you for your help.<\/p>\n\n<p>Here is how it looks in AzureML <a href=\"https:\/\/i.stack.imgur.com\/I7QRT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/I7QRT.png\" alt=\"enter image description here\"><\/a>\nAnd here is what is inside Execute R script\n<a href=\"https:\/\/i.stack.imgur.com\/qM1OF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qM1OF.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-02-26 13:59:36.907 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":230,
        "Owner_creation_date":"2013-03-18 14:50:31.43 UTC",
        "Owner_last_access_date":"2022-09-19 15:29:54.03 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>Here is a <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2016\/10\/26\/speeding-up-azure-ml-web-services-containing-r-or-python-modules\/?\" rel=\"nofollow noreferrer\">clever trick<\/a> for running initialization steps only the first time and not on every subsequent call.<\/p>\n<p>My understanding is that you would wrap the first 3 statements (that is through line 11) of your script in the following <code>if<\/code> statement:<\/p>\n<pre><code>if (!is.element(&quot;my_env&quot;, search()))\n<\/code><\/pre>\n<p>The <code>if<\/code> statement would also contain the initialization of the <code>my_env<\/code> variable as shown in the example used in that blog:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/S445n.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/S445n.png\" alt=\"R optimization example\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-02-27 06:27:30.203 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-02-27 08:14:43.923 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48990264",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50576929,
        "Question_title":"Replacing values in dataset within Azure Machine Learning Studio",
        "Question_body":"<p>In Azure Machine Learning studio I need to convert a column of data that has three categorical values 'yes', 'no' and 'maybe', and wish to combine the 'no' and 'maybe' values as just 'no'. <\/p>\n\n<p>I can do this easily using SQL, R, or Python but for these purposes I need to show if it is possible to do this without using these languages. I can't seem to find a way to do this. <\/p>\n\n<p>Does anyone have any ideas? I'm fine if the answer is no but I don't want to say it's not possible if it is. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-29 05:34:12.45 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":484,
        "Owner_creation_date":"2013-05-05 19:34:21.047 UTC",
        "Owner_last_access_date":"2019-11-28 03:19:58.153 UTC",
        "Owner_reputation":1647,
        "Owner_up_votes":365,
        "Owner_down_votes":8,
        "Owner_views":321,
        "Answer_body":"<p>It can be done! :)<\/p>\n\n<p>You would just use the \"Group Categorical Values\" module. Choose the column that has the data you want to group, and you can set the values like the following:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/UGhrR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/UGhrR.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What's going on here is that the default, which will get used if the other levels aren't caught, is set to \"yes\". Then when any values are \"no\", or \"maybe\", it gets grouped into a category of \"no\".<\/p>\n\n<p>However, this will error unless you make that column a categorical type, so you would need to use the \"Edit Metadata\" module to do that.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/45s2Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/45s2Q.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The example I used is <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Replace-Values-in-Dataset\" rel=\"nofollow noreferrer\">published to the gallery<\/a>, if you need to reference it.<\/p>\n\n<p>If you need more info, just let me know.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2018-05-29 12:37:49.393 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50576929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51702359,
        "Question_title":"In Azure ML Studio, score model doesn't return predicted values from an R model",
        "Question_body":"<p>I built a multiclass SVM model in R and used Create R model module from azure to train and predict my testing dataset. Here are the trainer and the score R scripts.<\/p>\n\n<p><strong>Trainer R script:<\/strong> <\/p>\n\n<pre><code>library(e1071)\nfeatures &lt;- get.feature.columns(dataset)\nlabels   &lt;- as.factor(get.label.column(dataset))\ntrain.data &lt;- data.frame(features, labels)\nfeature.names &lt;- get.feature.column.names(dataset)\nnames(train.data) &lt;- c(feature.names, \"Class\")\nmodel &lt;- svm(Class ~ . , train.data)\n<\/code><\/pre>\n\n<p><strong>Scores R script:<\/strong><\/p>\n\n<pre><code>library(e1071)    \nclasses &lt;- predict(model, dataset)\nclasses &lt;- as.factor(classes)\nres &lt;- data.frame(classes, probabilities = 0.5)\nprint(str(res))\nprint(res)\nscores &lt;- res\n<\/code><\/pre>\n\n<p>Note in my code, I hardcoded the probability values to simplify the code.<\/p>\n\n<p>Here is my component design in Azure: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When I run the experiment, all the components work fine. However, in the score model, the scored dataset port does not show the predicted values. It only shows feature values from the testing dataset. I checked the output log of <em>Score model<\/em> and I could see the model has nicely predicted the testing data (note I added print commands in the Scores R script). But this is not enough and I need the prediction returned from the score model so I can pass it via API.<\/p>\n\n<p>Has anyone faced this issue before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-06 07:14:53.247 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-08-06 13:07:27.647 UTC",
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":657,
        "Owner_creation_date":"2017-07-27 00:12:26.137 UTC",
        "Owner_last_access_date":"2020-11-19 13:36:00.497 UTC",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>I found an answer for this. In fact, I cannot see the result in the outcome of the scoring model but when I linked it to a <em>select column in the dataset<\/em> module, I see the predicted columns there.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-08-15 00:59:57.823 UTC",
        "Answer_score":0.0,
        "Owner_location":"Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51702359",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37418265,
        "Question_title":"Azure Machine Learning using Javascript Ajax call",
        "Question_body":"<p>I wanted to know if there is a way to call the Azure Machine Learning webservice using JavaScript Ajax.<\/p>\n\n<p>The Azure ML gives sample code for C#, Python and R.<\/p>\n\n<p>I did try out to call the webservice using JQuery Ajax but it returns a failure.<\/p>\n\n<p>I am able to call the same service using a python script.<\/p>\n\n<p>Here is my Ajax code : <\/p>\n\n<pre><code>  $.ajax({\n        url: webserviceurl,\n        type: \"POST\",           \n        data: sampleData,            \n        dataType:'jsonp',                        \n        headers: {\n        \"Content-Type\":\"application\/json\",            \n        \"Authorization\":\"Bearer \" + apiKey                       \n        },\n        success: function (data) {\n          console.log('Success');\n        },\n        error: function (data) {\n           console.log('Failure ' +  data.statusText + \" \" + data.status);\n        },\n  });\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2016-05-24 15:45:29.493 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-05-11 14:09:52.277 UTC",
        "Question_score":2,
        "Question_tags":"javascript|ajax|azure|azure-machine-learning-studio",
        "Question_view_count":1607,
        "Owner_creation_date":"2016-04-14 20:13:43.627 UTC",
        "Owner_last_access_date":"2017-09-07 19:59:44.707 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>Well after a lot of RnD, I was able to finally call Azure ML using some workarounds.<\/p>\n\n<p>Wrapping Azure ML webservice on Azure API is one option.<\/p>\n\n<p>But, what I did was that I created a python webservice which calls the Azure webservice.<\/p>\n\n<p>So now my HTML App calls the python webservice which calls Azure ML and returns data to the HTML App.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-05-31 18:10:10.4 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37418265",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62623166,
        "Question_title":"Azure ML Error: TimeSeriesImputer object has no attribute '_known_df'",
        "Question_body":"<p>Running <a href=\"http:\/\/%20https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> I get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># The featurized data, aligned to y, will also be returned.\n# This contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, X_trans = fitted_model.forecast(X_test)\n<\/code><\/pre>\n<h3>Error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**AttributeError: 'TimeSeriesImputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-28 13:28:01.953 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-07-07 17:16:36.017 UTC",
        "Question_score":1,
        "Question_tags":"time-series|azure-machine-learning-studio|forecast|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_date":"2015-10-11 07:33:45.377 UTC",
        "Owner_last_access_date":"2022-01-12 11:43:12.04 UTC",
        "Owner_reputation":303,
        "Owner_up_votes":105,
        "Owner_down_votes":7,
        "Owner_views":60,
        "Answer_body":"<p>This is commonly fixed by upgrading to the latest SDK. You can do this by running <code>pip install --upgrade azureml-sdk[explain,automl]<\/code>.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-30 18:43:45.63 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62623166",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53717284,
        "Question_title":"invalid subscript type 'list' Azure Machine Learning",
        "Question_body":"<p><strong>PROBLEM<\/strong> <\/p>\n\n<p>I deployed my experiments in Azure Machine Learning as a Web Service. The experiments ran without error. <\/p>\n\n<p>But when testing using <code>REQUEST\/RESPONSE<\/code>, I'm getting the error below:<\/p>\n\n<blockquote>\n  <p>Execute R Script Piped (RPackage) : The following error occurred during evaluation of R script: R_tryEval: return error: Error in split(df, list(df$PRO_NAME, df$Illness_Code))[Ind] : invalid subscript type 'list'<\/p>\n<\/blockquote>\n\n<p>This is the code:<\/p>\n\n<pre><code># Loop through the dataframe and apply model\nInd &lt;- sapply(split(df, list(df$PRO_NAME,df$Illness_Code)), \n              function(x)nrow(x)&gt;1)\n\nout &lt;- lapply(\n    split(df, list(df$PRO_NAME, df$Illness_Code))[Ind],\n    function(c){\n        m &lt;- lm(formula = COUNT ~ YEAR, data = c)\n        coef(m)\n    })\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-12-11 04:13:37.417 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|lapply|azure-machine-learning-studio",
        "Question_view_count":53,
        "Owner_creation_date":"2016-07-02 09:23:54.137 UTC",
        "Owner_last_access_date":"2021-11-22 08:03:24.557 UTC",
        "Owner_reputation":111,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":36,
        "Answer_body":"<p><strong>FIXED<\/strong><\/p>\n\n<p><strong>Problem:<\/strong><\/p>\n\n<p>Some R codes don't work if input data is limited (e.g 1-2 rows only)<\/p>\n\n<p><strong>Solution:<\/strong><\/p>\n\n<p>Load data by <code>Batch<\/code> instead of <code>REQUEST\/RESPONSE<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-12-12 01:31:48.85 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53717284",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38927230,
        "Question_title":"Panda AssertionError columns passed, passed data had 2 columns",
        "Question_body":"<p>I am working on Azure ML implementation on text analytics with NLTK, the following execution is throwing <\/p>\n\n<pre><code>AssertionError: 1 columns passed, passed data had 2 columns\\r\\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>Below is the code <\/p>\n\n<pre><code># The script MUST include the following function,\n# which is the entry point for this module:\n# Param&lt;dataframe1&gt;: a pandas.DataFrame\n# Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # import required packages\n    import pandas as pd\n    import nltk\n    import numpy as np\n    # tokenize the review text and store the word corpus\n    word_dict = {}\n    token_list = []\n    nltk.download(info_or_id='punkt', download_dir='C:\/users\/client\/nltk_data')\n    nltk.download(info_or_id='maxent_treebank_pos_tagger', download_dir='C:\/users\/client\/nltk_data')\n    for text in dataframe1[\"tweet_text\"]:\n        tokens = nltk.word_tokenize(text.decode('utf8'))\n        tagged = nltk.pos_tag(tokens)\n\n\n      # convert feature vector to dataframe object\n    dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n    return [dataframe_output]\n<\/code><\/pre>\n\n<p>Error is throwing here <\/p>\n\n<pre><code> dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n<\/code><\/pre>\n\n<p>I suspect this to be the tagged data type passed to dataframe, can some one let me know the right approach to add this to dataframe.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-08-12 22:23:17.197 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"python|pandas|dataframe|nltk|azure-machine-learning-studio",
        "Question_view_count":48200,
        "Owner_creation_date":"2013-06-11 04:20:18.39 UTC",
        "Owner_last_access_date":"2022-09-18 05:28:20.357 UTC",
        "Owner_reputation":1748,
        "Owner_up_votes":136,
        "Owner_down_votes":55,
        "Owner_views":339,
        "Answer_body":"<p>Try this:<\/p>\n\n<pre><code>dataframe_output = pd.DataFrame(tagged, columns=['Output', 'temp'])\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-08-12 22:26:09.603 UTC",
        "Answer_score":13.0,
        "Owner_location":"Toronto, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38927230",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62949488,
        "Question_title":"AMLS Experiment run stuck in status \"Running\"",
        "Question_body":"<p>I made an Azure Machine Learning Service Experiment run and logged neural network losses with Jupyter Notebook. Logging worked fine and NN training completed as it should. However, the experiment is stuck in the running status. Shutting down the compute resources does not shut down the Experiment run and I cannot cancel it from the Experiment panel. In addition, the run does not have any log-files.<\/p>\n<p>Has anyone had the same behavior? Run has now lasted for over 24 hours.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KzAoS.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KzAoS.jpg\" alt=\"AMLS Experiment run\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-17 07:51:00.903 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2020-07-17 12:35:03.64 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|neural-network|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":887,
        "Owner_creation_date":"2019-07-23 09:35:53.357 UTC",
        "Owner_last_access_date":"2022-09-23 18:22:54.737 UTC",
        "Owner_reputation":881,
        "Owner_up_votes":1241,
        "Owner_down_votes":14,
        "Owner_views":106,
        "Answer_body":"<p>this totally happens from time to time. it is certainly frustrating especially because the &quot;Cancel&quot; button it grayed out. You can use either the CLI or Python SDK  to cancel the run.<\/p>\n<h2>SDK<\/h2>\n<h3>&gt;= 1.16.0<\/h3>\n<p>As of version <code>1.16.0<\/code> you no longer an <code>Experiment<\/code> object is no longer needed. Instead you can access using the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#get-workspace--run-id-&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\"><code>Run<\/code><\/a> or <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace(class)?view=azure-ml-py#get-run-run-id-&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\"><code>Workspace<\/code><\/a> objects directly<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Experiment, Run, VERSION\nprint(&quot;SDK version:&quot;, VERSION)\n\nws = Workspace.from_config()\n\nrun = ws.get_run('YOUR_RUN_ID')\nrun = Run().get(ws, 'YOUR_RUN_ID') # also works\nrun.cancel()\n<\/code><\/pre>\n<h3>&lt; 1.16.0<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Experiment, Run, VERSION\nprint(&quot;SDK version:&quot;, VERSION)\n\nws = Workspace.from_config()\nexp = Experiment(workspace = ws, name = 'YOUR_EXP_NAME')\n\nrun = Run(exp, run_id='YOUR STEP RUN ID')\n\nrun.cancel() # or run.fail()\n<\/code><\/pre>\n<h1>CLI<\/h1>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-azure-machine-learning-cli#install-the-extension\" rel=\"nofollow noreferrer\">More CLI details here<\/a><\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>az login\naz ml run cancel --run YOUR_RUN_ID\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-17 16:45:39.51 UTC",
        "Answer_score":5.0,
        "Owner_location":"Helsinki, Finland",
        "Answer_last_edit_date":"2020-11-09 08:58:51.753 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62949488",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73418843,
        "Question_title":"Azure ML ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
        "Question_body":"<p>I am using LightGBM in Azure ML Jupyter notebooks, it works fine and I also installed graphviz.<\/p>\n<p>However this line:<\/p>\n<pre><code>lgb.plot_tree(clf, tree_index = 1, figsize=(20,12))\n<\/code><\/pre>\n<p>throws this error:<\/p>\n<pre><code>ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-19 15:11:42.893 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|graphviz|azure-machine-learning-studio|lightgbm",
        "Question_view_count":94,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>Common problem (very common).  There are two systems named Graphviz, and you need both!\nsee <a href=\"https:\/\/stackoverflow.com\/questions\/73040021\/im-getting-this-issue-when-trying-to-run-the-code-i-found-on-github-pydot-and\/73041302#73041302\">I&#39;m getting this issue when trying to run the code I found on GitHub. Pydot and graphivz are installed but still getting this error<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-19 15:22:10.25 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73418843",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51430645,
        "Question_title":"split dataframe column header and values into multiple columns",
        "Question_body":"<p>I've uploaded my <code>csv<\/code> file on Azure, but for some reason it became like this<\/p>\n\n<pre><code> nominal;data;curs;cdx         Column 1\n0          1;21.06.2000;28  2300;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n1          1;22.06.2000;28  2200;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n2          1;23.06.2000;28  1900;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n3          1;24.06.2000;28  1700;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n4          1;27.06.2000;28  1300;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n5          1;28.06.2000;28  1100;\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd \u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\u00ef\u00bf\u00bd\n<\/code><\/pre>\n\n<p>Basically instead of four columns <code>nominal<\/code>, <code>data<\/code>, <code>curs<\/code>, <code>cdx<\/code> I got two columns with one having all the values and the last one (it is empty or something because the last column has encoding issue) - no idea what.<\/p>\n\n<p>I have deleted the column <code>Column 1<\/code> like this<\/p>\n\n<pre><code>import pandas as pd\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    dataframe1.drop(['Column 1'], axis = 1, inplace = True)\n    print('Input pandas.DataFrame #1:\\r\\n\\r\\n{0}'.format(dataframe1))\n    return dataframe1,\n<\/code><\/pre>\n\n<p>How to split the first column into multiple now? To get 4 separate columns<\/p>\n\n<p>I am using pandas 0.18<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":9,
        "Question_creation_date":"2018-07-19 19:43:48.013 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-07-19 19:48:32.493 UTC",
        "Question_score":0,
        "Question_tags":"python|pandas|azure-machine-learning-studio",
        "Question_view_count":1086,
        "Owner_creation_date":"2012-06-02 23:11:08.793 UTC",
        "Owner_last_access_date":"2022-09-18 15:01:49.42 UTC",
        "Owner_reputation":11479,
        "Owner_up_votes":528,
        "Owner_down_votes":1,
        "Owner_views":887,
        "Answer_body":"<p>You need to split the column with:<\/p>\n\n<pre><code>dataframe1['nominal;data;curs;cdx'].str.split(';',expand=True)\n<\/code><\/pre>\n\n<p>Then change the headers with:<\/p>\n\n<pre><code>dataframe1.columns = 'nominal;data;curs;cdx'.split(';')\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-07-19 20:14:57.043 UTC",
        "Answer_score":1.0,
        "Owner_location":"Eindhoven, Netherlands",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51430645",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53143396,
        "Question_title":"What is the difference between Azure Databricks and Azure Batch AI?",
        "Question_body":"<p>I have went throught the documentation of both Microsoft AI services <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/batch-ai\/overview\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/batch-ai\/overview<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/databricks\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/en-us\/services\/databricks\/<\/a> but I still can't understand the difference or when each should be used(purpose).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-11-04 17:20:54.317 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-11-05 20:36:05.28 UTC",
        "Question_score":2,
        "Question_tags":"azure|artificial-intelligence|azure-machine-learning-studio|databricks|azure-cognitive-services",
        "Question_view_count":1267,
        "Owner_creation_date":"2018-08-12 12:36:04.407 UTC",
        "Owner_last_access_date":"2020-04-19 10:48:37.467 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>Microsoft AI is a first party solution Microsoft built, Databricks is based off of Apache Spark that we will manage for you in Azure.  One of the things we are trying to do in Azure is meet the customer where they are most comfortable.  In a way it's similar to how we have Service Fabric (Microsoft Service) and Azure Kubernetes Service (AKS).  Both allow you to run microservices but one is a service we developed and the other is a managed Open Source Project we support.  <\/p>\n\n<p>When to use each is more of a question of preference and skillset. <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2018-11-06 10:41:58.237 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53143396",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52032535,
        "Question_title":"Does the primary key of Web Service API in ML Studio expire?",
        "Question_body":"<p>I deployed a web-service from an experiment in ML studio. I tested the API, and everything was working fine. I tested it in Postman. After 2 hours, I got an authentication error when I sent a request using the same API. So to resolve this, I republished my Web Service and got new authentication code, so the API is working fine for now. I have two questions:<\/p>\n\n<p>1) Does the primary key automatically expire after a while or by signing out from ML studio? \n2) What is the application of the second key in ML Studio APIs? Where do we need the second key? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-27 04:23:23.617 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":228,
        "Owner_creation_date":"2017-07-27 00:12:26.137 UTC",
        "Owner_last_access_date":"2020-11-19 13:36:00.497 UTC",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<blockquote>\n  <p>1) Does the primary key automatically expire after a while or by signing out from ML studio?<\/p>\n<\/blockquote>\n\n<p>I could not find any limit of the primary key in the office docs. Per my test, my primary key does not expire more than two hours or sign out from ML studio.<\/p>\n\n<blockquote>\n  <p>2) What is the application of the second key in ML Studio APIs? Where do we need the second key?<\/p>\n<\/blockquote>\n\n<p>The second key is the same usage of the primary key, like a backup of the primary key. Also, the primary key equals the API key in the ML studio.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-08-28 09:59:03.787 UTC",
        "Answer_score":0.0,
        "Owner_location":"Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52032535",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58019308,
        "Question_title":"ScriptRunConfig with datastore reference on AML",
        "Question_body":"<p>When trying to run a ScriptRunConfig, using :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', ds.as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>\n\n<p>It doesn't work and breaks with this when I submit the job : <\/p>\n\n<pre><code>... lots of things... and then\nTypeError: Object of type 'DataReference' is not JSON serializable\n<\/code><\/pre>\n\n<p>However if I run it with the Estimator, it works. One of the differences is the fact that with a <code>ScriptRunConfig<\/code> we're using a list for parameters and the other is a dictionary.<\/p>\n\n<p>Thanks for any pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-19 21:48:40.367 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1541,
        "Owner_creation_date":"2018-09-30 02:52:40.603 UTC",
        "Owner_last_access_date":"2022-07-22 02:57:21.83 UTC",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Answer_body":"<p>Being able to use <code>DataReference<\/code> in <code>ScriptRunConfig<\/code> is a bit more involved than doing just <code>ds.as_mount()<\/code>. You will need to convert it into a string in <code>arguments<\/code> and then update the <code>RunConfiguration<\/code>'s <code>data_references<\/code> section with the <code>DataReferenceConfiguration<\/code> created from <code>ds<\/code>. Please <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\" rel=\"nofollow noreferrer\">see here<\/a> for an example notebook on how to do that.<\/p>\n<p>If you are just reading from the input location and not doing any writes to it, please check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-register-datasets\" rel=\"nofollow noreferrer\"><code>Dataset<\/code><\/a>. It allows you to do exactly what you are doing without doing anything extra. <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">Here is an example notebook<\/a> that shows this in action.<\/p>\n<p>Below is a short version of the notebook<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\n\n# more imports and code\n\nds = Datastore(workspace, 'mydatastore')\ndataset = Dataset.File.from_files(path=(ds, 'path\/to\/input-data\/within-datastore'))\n\nsrc = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', dataset.as_named_input('input').as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-09-20 02:14:46.667 UTC",
        "Answer_score":4.0,
        "Owner_location":"Montreal, QC, Canada",
        "Answer_last_edit_date":"2020-07-28 22:14:22.437 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58019308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59176241,
        "Question_title":"import custom python module in azure ml deployment environment",
        "Question_body":"<p>I have an sklearn k-means model. I am training the model and saving it in a pickle file so I can deploy it later using azure ml library. The model that I am training uses a custom Feature Encoder called <strong>MultiColumnLabelEncoder<\/strong>.\nThe pipeline model is defined as follow :<\/p>\n\n<pre><code># Pipeline\nkmeans = KMeans(n_clusters=3, random_state=0)\npipe = Pipeline([\n(\"encoder\", MultiColumnLabelEncoder()),\n('k-means', kmeans),\n])\n#Training the pipeline\nmodel = pipe.fit(visitors_df)\nprediction = model.predict(visitors_df)\n#save the model in pickle\/joblib format\nfilename = 'k_means_model.pkl'\njoblib.dump(model, filename)\n<\/code><\/pre>\n\n<p>The model saving works fine. The Deployment steps are the same as the steps in this link : <\/p>\n\n<p><a href=\"https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/how-to-use-azureml\/deploy-to-cloud\/model-register-and-deploy.ipynb\" rel=\"nofollow noreferrer\">https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/how-to-use-azureml\/deploy-to-cloud\/model-register-and-deploy.ipynb<\/a><\/p>\n\n<p>However the deployment always fails with this error :<\/p>\n\n<pre><code>  File \"\/var\/azureml-server\/create_app.py\", line 3, in &lt;module&gt;\n    from app import main\n  File \"\/var\/azureml-server\/app.py\", line 27, in &lt;module&gt;\n    import main as user_main\n  File \"\/var\/azureml-app\/main.py\", line 19, in &lt;module&gt;\n    driver_module_spec.loader.exec_module(driver_module)\n  File \"\/structure\/azureml-app\/score.py\", line 22, in &lt;module&gt;\n    importlib.import_module(\"multilabelencoder\")\n  File \"\/azureml-envs\/azureml_b707e8c15a41fd316cf6c660941cf3d5\/lib\/python3.6\/importlib\/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named 'multilabelencoder'\n<\/code><\/pre>\n\n<p>I understand that pickle\/joblib has some problems unpickling the custom function MultiLabelEncoder. That's why I defined this class in a separate python script (which I executed also). I called this custom function in the training python script, in the deployment script and in the scoring python file (score.py). The importing in the score.py file is not successful. \nSo my question is how can I import custom python module to azure ml deployment environment ?<\/p>\n\n<p>Thank you in advance.<\/p>\n\n<p>EDIT: \nThis is my .yml file<\/p>\n\n<pre><code>name: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  - multilabelencoder==1.0.4\n  - scikit-learn\n  - azureml-defaults==1.0.74.*\n  - pandas\nchannels:\n- conda-forge\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-12-04 12:37:28.677 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-12-06 12:18:18.24 UTC",
        "Question_score":4,
        "Question_tags":"python|pickle|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":2611,
        "Owner_creation_date":"2015-07-27 08:39:50.373 UTC",
        "Owner_last_access_date":"2022-09-23 14:35:41.497 UTC",
        "Owner_reputation":361,
        "Owner_up_votes":61,
        "Owner_down_votes":0,
        "Owner_views":149,
        "Answer_body":"<p>In fact, the solution was to import my customized class <strong>MultiColumnLabelEncoder<\/strong> as a pip package (You can find it through pip install multilllabelencoder==1.0.5).\nThen I passed the pip package to the .yml file or in the InferenceConfig of the azure ml environment.\nIn the score.py file, I imported the class as follows :<\/p>\n\n<pre><code>from multilabelencoder import multilabelencoder\ndef init():\n    global model\n\n    # Call the custom encoder to be used dfor unpickling the model\n    encoder = multilabelencoder.MultiColumnLabelEncoder() \n    # Get the path where the deployed model can be found.\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'k_means_model_45.pkl')\n    model = joblib.load(model_path)\n<\/code><\/pre>\n\n<p>Then the deployment was successful. \nOne more important thing is I had to use the same pip package (multilabelencoder) in the training pipeline as here :<\/p>\n\n<pre><code>from multilabelencoder import multilabelencoder \npipe = Pipeline([\n    (\"encoder\", multilabelencoder.MultiColumnLabelEncoder(columns)),\n    ('k-means', kmeans),\n])\n#Training the pipeline\ntrainedModel = pipe.fit(df)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-12-06 12:24:12.34 UTC",
        "Answer_score":4.0,
        "Owner_location":"M\u00fcnchen, Deutschland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59176241",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60434642,
        "Question_title":"Version control of azure machine learning workspace notebooks",
        "Question_body":"<p>I'm trying to work with the capacities of the new Azure ML Workspace and I can't find any option to track my notebooks on git. <\/p>\n\n<p>It's this possible as well as you can do with Azure notebooks? If not is possible... how it's suposed to work with this notebooks? Only inside this workspace? <\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2020-02-27 13:43:31.92 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":344,
        "Owner_creation_date":"2012-09-20 07:41:45.517 UTC",
        "Owner_last_access_date":"2022-09-23 07:35:28.573 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":50,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Answer_body":"<p>AFAIK, Git isn't currently supported by Azure Machine Learning Notebooks. If you're looking for a more fully-featured development environment, I suggest setting one up locally. There's more work up front, but it will give you the ability to version control. Check out this development environment set-up guide. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment<\/a><\/p>\n\n<pre><code>| Environment                                                   | Pros                                                                                                                                                                                                                                    | Cons                                                                                                                                                                                 |\n|---------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Cloud-based Azure Machine Learning compute instance (preview) | Easiest way to get started. The entire SDK is already installed in your workspace VM, and notebook tutorials are pre-cloned and ready to run.                                                                                           | Lack of control over your development environment and dependencies. Additional cost incurred for Linux VM (VM can be stopped when not in use to avoid charges). See pricing details. |\n| Local environment                                             | Full control of your development environment and dependencies. Run with any build tool, environment, or IDE of your choice.                                                                                                             | Takes longer to get started. Necessary SDK packages must be installed, and an environment must also be installed if you don't already have one.                                      |\n| Azure Databricks                                              | Ideal for running large-scale intensive machine learning workflows on the scalable Apache Spark platform.                                                                                                                               | Overkill for experimental machine learning, or smaller-scale experiments and workflows. Additional cost incurred for Azure Databricks. See pricing details.                          |\n| The Data Science Virtual Machine (DSVM)                       | Similar to the cloud-based compute instance (Python and the SDK are pre-installed), but with additional popular data science and machine learning tools pre-installed. Easy to scale and combine with other custom tools and workflows. | A slower getting started experience compared to the cloud-based compute instance.                                                                                                    |\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-02-27 18:20:41.317 UTC",
        "Answer_score":1.0,
        "Owner_location":"Barcelona",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60434642",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32431471,
        "Question_title":"Not Getting the Expected Output in AzureML",
        "Question_body":"<p>Background: I am working on a project that aims to classify product reviews into positive and negative using Sentiment Analysis in Azure ML. I got stuck when I was classifying reviews into different departments.<\/p>\n\n<p>I am basically reading words from csv files and checking whether the review(v: list of sentences) contains these words. If some of these words are found in the review then I am noting the sentence number and pushing it into respective lists( FinanceList, QualityList, LogisticsList ). In the end I am converting the lists to strings and pushing them into a dataframe.<\/p>\n\n<p>The output is not getting logged for the print statements that I have written in the script in Azure ML.<\/p>\n\n<p>The values in the dataframe are always turning out to be 0 but when I run the code locally I get the expected output.<\/p>\n\n<p>Description of First Image: The columns of the dataframe showing 0 values.<\/p>\n\n<p>Description of Second Image: I have highlighted the expected output that I got locally for the same review which was used in AzureML.<\/p>\n\n<p><a href=\"http:\/\/imgur.com\/0C3wcYj.png\" rel=\"nofollow\">Image 1<\/a><\/p>\n\n<p><a href=\"http:\/\/i.imgur.com\/lyHsM8z.png\" rel=\"nofollow\">Image 2<\/a><\/p>\n\n<p>The things that I have already checked:<\/p>\n\n<ol>\n<li>The csv files are read properly.<\/li>\n<li>The review contains the words that I am searching.<\/li>\n<\/ol>\n\n<p>I am unable to understand where I am going wrong.<\/p>\n\n<p>'<\/p>\n\n<pre><code>import csv\nimport math\nimport pandas as pd\nimport numpy as np\n\ndef azureml_main( data, ud):\n\n   FinanceDept = []\n   LogisticsDept = []\n   QualityDept = []\n  #Reading from the csv files\n   with open('.\\Script Bundle\\\\quality1.csv', 'rb') as fin:\n      reader = csv.reader(fin)\n      QualityDept = list(reader)\n\n   with open('.\\Script Bundle\\\\finance1.csv', 'rb') as f:\n      reader = csv.reader(f)\n      FinanceDept = list(reader)\n\n   with open('.\\Script Bundle\\\\logistics1.csv', 'rb') as f:\n      reader = csv.reader(f)\n      LogisticDept = list(reader)\n\n   FinanceList = []\n   LogisticsList = []\n   QualityList = []\n\n#Initializing the Lists   \n   FinanceList.append(0)\n   LogisticsList.append(0)\n   QualityList.append(0)\n\n   rev = data['Data']\n   v = rev[0].split('.')\n\n   print FinanceDept\n\n   S = 0   \n   for sentence in v:\n      S = S + 1\n      z = sentence.split(' ')\n      for c in z:\n         c = c.lower()\n         if c in FinanceDept and S not in FinanceList:\n            FinanceList.append(S)\n         if c in LogisticsDept and S not in LogisticsList:\n            LogisticsList.append(S)\n         if c in QualityDept and S not in QualityList:\n            QualityList.append(S)\n   #Compute User Reputation Score\n   Upvotes = int(ud['upvotes'].tolist()[0])\n   Downvotes = int(ud['downvotes'].tolist()[0])\n   TotalVotes = max(1,Upvotes+Downvotes)\n\n   q = data['Score']\n\n   print FinanceList\n\n   repScore = float(Upvotes)\/TotalVotes \n   repScore = repScore*float( q[0] )\n   str1 = ','.join(str(e) for e in FinanceList) \n   str2 = ','.join(str(e) for e in QualityList)\n   str3 = ','.join(str(e) for e in LogisticsList)\n\n   x = ud['id']\n\n   #df = pd.DataFrame(  [str(repScore), str1  , str2  , str3 ], columns=[Write the columns])\n   d = {'id': x[0], 'Score': float(repScore),'Logistics':str3,'Finance':str1,'Quality':str2}\n   df = pd.DataFrame(data=d, index=np.arange(1))\n   return df,`\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-09-07 05:11:36.04 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-09-07 05:35:24.89 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1013,
        "Owner_creation_date":"2015-09-06 16:07:31.89 UTC",
        "Owner_last_access_date":"2019-03-21 12:50:57.223 UTC",
        "Owner_reputation":143,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Answer_body":"<p>@Anuj Shankar,\nAfter my colleague tested, we can read data from <code>CSV<\/code> files and get the expected results. Please refer to this experience:<\/p>\n\n<p>1)  Input data  - It has <code>apple.zip<\/code> file which has two <code>csv<\/code> files similar to you and each csv file includes bag of words related to company.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/yrXst.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yrXst.jpg\" alt=\"enter image description here\"><\/a>\n2)  Python script: <\/p>\n\n<pre><code># The script MUST contain a function named azureml_main\n# which is the entry point for this module.\n#\n# The entry point function can contain up to two input arguments:\n#   Param&lt;dataframe1&gt;: a pandas.DataFrame\n#   Param&lt;dataframe2&gt;: a pandas.DataFrame\nimport csv\nimport numpy as np\nimport pandas as pd\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # Execution logic goes here\n    #print('Input pandas.DataFrame #1:\\r\\n\\r\\n{0}'.format(dataframe1))\n\n    # If a zip file is connected to the third input port is connected,\n    # it is unzipped under \".\\Script Bundle\". This directory is added\n    # to sys.path. Therefore, if your zip file contains a Python file\n    # mymodule.py you can import it using:\n    # import mymodule\n\n    apple = {}\n    microsoft = {}\n  #Reading from the csv files\n    with open('.\\Script Bundle\\\\apple.csv', 'rb') as f:\n      reader = csv.reader(f)\n      apple = list_to_dict(list(reader)[0])\n\n    with open('.\\Script Bundle\\\\microsoft.csv', 'rb') as f:\n      reader = csv.reader(f)\n      microsoft = list_to_dict(list(reader)[0])\n\n#    print('hello world' + ' '.join(apple[0]))\n    applecount = 0\n    microsoftcount = 0\n\n    input = \"i want to buy surface which runs on windows\"\n    splitted_input = input.split(' ')\n\n    for word in splitted_input:\n        if word in apple:\n            applecount = applecount + 1\n        if word in microsoft:\n            microsoftcount = microsoftcount + 1\n\n    print(\"apple bag of words count - \" + str(applecount))\n    print(\"microsoft bag of words count - \" + str(microsoftcount))\n    mydata = [{'input words': len(splitted_input)}, {'applecount':applecount},\n        {'microsoftcount':microsoftcount}]       \n    # Return value must be of a sequence of pandas.DataFrame\n    return pd.DataFrame(mydata),\n\n\ndef list_to_dict(li):      \n    dct = {}  \n    for item in li:\n        if dct.has_key(item):              \n            dct[item] = dct[item] + 1  \n        else:  \n            dct[item] = 1  \n    return dct  \n<\/code><\/pre>\n\n<p>3)  Output  - if I consider a string \"i want to buy surface which runs on windows\". It has 2 words related to microsoft and 0 related to apple which are visualized in below snapshot.\n<a href=\"https:\/\/i.stack.imgur.com\/ifE1t.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ifE1t.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-09-30 03:07:41.283 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":"2016-08-23 11:00:10.497 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32431471",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50035628,
        "Question_title":"Include additional scripts when deploying a Azure ML experimentation service",
        "Question_body":"<p>When training my model the data I start with consist of rows of json data and the expected values I would like to predict from that json data. The json data follows the schema I my deployed service will receive the input as. Before training I run a number of python functions to transform the data and extract features calculated from the raw json data. It is that transformed data which my model is trained on.<\/p>\n\n<p>I have extracted the code to transform the json data into the input my model expects into a separate python file. Now I would like to have my scoring script use that python script to prepare the input sent to the service before feeding it into my trained model.<\/p>\n\n<p>Is there a way to include the data transformation script with the scoring script when deploying my service using the cli command:<\/p>\n\n<pre><code>az ml service create realtime \n    -f &lt;scoring-script&gt;.py \n    --model-file model.pkl \n    -s service_schema.json \n    -n &lt;some-name&gt; \n    -r python \n    --collect-model-data true \n    -c aml_config\\conda_dependencies.yml\n<\/code><\/pre>\n\n<p><em>(the new lines in the above command added for clarity)<\/em><\/p>\n\n<p>The two ways I've come up with is to either:<\/p>\n\n<ul>\n<li>Create my own base docker image that contains the transformation script and use that image as the base for my service. Seems a bit cumbersome to do if I need similar (but different) data transformations for later models.<\/li>\n<li>Concatenate the transformation script with my scoring script into a single file. Seems a bit hacky.<\/li>\n<\/ul>\n\n<p><strong>Is there another way to achive my goal of having a separate data transformation script used both in training and in scoring?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-04-26 05:46:14.19 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-04-27 05:20:25.6 UTC",
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":252,
        "Owner_creation_date":"2010-06-01 14:14:54.66 UTC",
        "Owner_last_access_date":"2022-09-24 14:22:02.52 UTC",
        "Owner_reputation":18969,
        "Owner_up_votes":699,
        "Owner_down_votes":20,
        "Owner_views":517,
        "Answer_body":"<p>So running <code>az ml service create realtime -h<\/code> provides information about the <code>-d<\/code> flag.<\/p>\n\n<p><code>-d : Files and directories required by the service. Multiple dependencies can be specified with additional -d arguments.<\/code><\/p>\n\n<p>Please try using this flag and provide the additional python file that you would like to call too from your <code>score.py<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-04-27 05:17:04.53 UTC",
        "Answer_score":1.0,
        "Owner_location":"Gothenburg, Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50035628",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67352949,
        "Question_title":"How to combine pipeline and hyperparameter in AzureML SDK in the training step",
        "Question_body":"<p>Short form:\nI am trying to figure out how can I run the hyperparam within a <strong>training step<\/strong> (i.e. train_step = PythonScriptStep(...)) in the pipeline, I am not sure where shall I put the &quot;config=hyperdrive&quot;<\/p>\n<p>Long form:<\/p>\n<p>General:<\/p>\n<pre><code># Register the environment \ndiabetes_env.register(workspace=ws)\nregistered_env = Environment.get(ws, 'diabetes-pipeline-env')\n\n# Create a new runconfig object for the pipeline\nrun_config = RunConfiguration()\n\n# Use the compute you created above. \nrun_config.target = ComputerTarget_Crea\n\n# Assign the environment to the run configuration\nrun_config.environment = registered_env\n<\/code><\/pre>\n<p>Hyperparam:<\/p>\n<pre><code>script_config = ScriptRunConfig(source_directory=experiment_folder,\n                                script='diabetes_training.py',\n                                # Add non-hyperparameter arguments -in this case, the training dataset\n                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n                                environment=sklearn_env,\n                                compute_target = training_cluster)\n\n# Sample a range of parameter values\nparams = GridParameterSampling(\n    {\n        # Hyperdrive will try 6 combinations, adding these as script arguments\n        '--learning_rate': choice(0.01, 0.1, 1.0),\n        '--n_estimators' : choice(10, 100)\n    }\n)\n\n# Configure hyperdrive settings\nhyperdrive = HyperDriveConfig(run_config=script_config, \n                          hyperparameter_sampling=params, \n                          policy=None, # No early stopping policy\n                          primary_metric_name='AUC', # Find the highest AUC metric\n                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                          max_total_runs=6, # Restict the experiment to 6 iterations\n                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n\n# Run the experiment if I only want to run hyperparam alone without the pipeline\n#experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n#run = experiment.submit(**config=hyperdrive**)\n<\/code><\/pre>\n<p>PipeLine:<\/p>\n<pre><code>prep_step = PythonScriptStep(name = &quot;Prepare Data&quot;,\n                                source_directory = experiment_folder,\n                                script_name = &quot;prep_diabetes.py&quot;,\n                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n                                             '--prepped-data', prepped_data_folder],\n                                outputs=[prepped_data_folder],\n                                compute_target = ComputerTarget_Crea,\n                                runconfig = run_config,\n                                allow_reuse = True)\n\n# Step 2, run the training script\ntrain_step = PythonScriptStep(name = &quot;Train and Register Model&quot;,\n                                source_directory = experiment_folder,\n                                script_name = &quot;train_diabetes.py&quot;,\n                                arguments = ['--training-folder', prepped_data_folder],\n                                inputs=[prepped_data_folder],\n                                compute_target = ComputerTarget_Crea,\n                                runconfig = run_config,\n                                allow_reuse = True)\n# Construct the pipeline\npipeline_steps = [prep_step, train_step]\npipeline = Pipeline(workspace=ws, steps=pipeline_steps)\nprint(&quot;Pipeline is built.&quot;)\n\n# Create an experiment and run the pipeline\n**#How do I need to change these below lines to use hyperdrive????**\nexperiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\npipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n<\/code><\/pre>\n<p>Not sure where I need to put <strong>config=hyperdrive<\/strong> in the Pipeline section?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-02 04:21:17.08 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-02 04:32:20.227 UTC",
        "Question_score":1,
        "Question_tags":"azure|sdk|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":276,
        "Owner_creation_date":"2013-07-30 12:14:04.01 UTC",
        "Owner_last_access_date":"2022-09-10 08:19:49.807 UTC",
        "Owner_reputation":912,
        "Owner_up_votes":334,
        "Owner_down_votes":1,
        "Owner_views":288,
        "Answer_body":"<p>here's how to combine hyperparameters with an AML pipeline: <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.hyperdrivestep?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.hyperdrivestep?view=azure-ml-py<\/a><\/p>\n<p>Alternatively, here's a sample notebook: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-parameter-tuning-with-hyperdrive.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-parameter-tuning-with-hyperdrive.ipynb<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-11 03:23:01.063 UTC",
        "Answer_score":1.0,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67352949",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67015185,
        "Question_title":"How can I match my local azure automl python sdk version to the remote version?",
        "Question_body":"<p>I'm using the azure automl python sdk to download and save a model then reload it. I get the following error:<\/p>\n<pre><code>anaconda3\\envs\\automl_21\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n<\/code><\/pre>\n<p>How can I ensure that the versions match?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-09 04:47:03.52 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":62,
        "Owner_creation_date":"2011-12-20 03:17:46.393 UTC",
        "Owner_last_access_date":"2022-09-15 01:17:57.817 UTC",
        "Owner_reputation":1306,
        "Owner_up_votes":49,
        "Owner_down_votes":5,
        "Owner_views":81,
        "Answer_body":"<p>My Microsoft contact says -<\/p>\n<p>&quot;For this, their best  bet is probably to see what the training env was pinned to and install those same pins. They can get that env by running child_run.get_environment() and then pip install all the pkgs listed in there with the pins listed there.&quot;<\/p>\n<p>A useful code snippet.<\/p>\n<pre><code>for run in experiment.get_runs():\n    tags_dictionary = run.get_tags()\n    best_run = AutoMLRun(experiment, tags_dictionary['automl_best_child_run_id'])\n    env = best_run.get_environment()\n    print(env.python.conda_dependencies.serialize_to_string())\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-11 21:26:49.273 UTC",
        "Answer_score":0.0,
        "Owner_location":"Christchurch, New Zealand",
        "Answer_last_edit_date":"2021-04-11 21:56:22.617 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67015185",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66226685,
        "Question_title":"AzureML create dataset from datastore with multiple files - path not valid",
        "Question_body":"<p>I am trying to create a dataset in Azure ML where the data source are multiple files (eg images) in a Blob Storage. How do you do that correctly?<\/p>\n<h3>Here is the error I get following the documented approach in the UI<\/h3>\n<p>When I create the dataset in the UI and select the blob storage and directory with either just <code>dirname<\/code> or <code>dirname\/**<\/code> then the files can not be found in the explorer tab with the error <code>ScriptExecution.StreamAccess.NotFound: The provided path is not valid or the files could not be accessed.<\/code> When I try to download the data with the code snippet in the consume tab then I get the error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Dataset\n\n# set variables \n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='teststar')\ndataset.download(target_path='.', overwrite=False)\n<\/code><\/pre>\n<pre><code>Error Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: 'https:\/\/mystoragename.blob.core.windows.net\/data\/testdata\/**'\n\n<\/code><\/pre>\n<p>When I just select one of the files instead of <code>dirname<\/code> or <code>dirname\/**<\/code> then everything works. Does AzureML actually support Datasets consisting of multiple files?<\/p>\n<h3>Here is my setup:<\/h3>\n<p>I have a Data Storage with one container <code>data<\/code>. In there is a directory <code>testdata<\/code> containing <code>testfile1.txt<\/code> and <code>testfile2.txt<\/code>.<\/p>\n<p>In AzureML I created a datastore <code>testdatastore<\/code> and there I select the <code>data<\/code> container in my data storage.<\/p>\n<p>Then in Azure ML I create a Dataset from datastore, select file dataset and the datastore above. Then I can browse the files, select a folder and select that files in subdirectories should be included. This then creates the path <code>testdata\/**<\/code> which does not work as described above.<\/p>\n<p>I got the same issue when creating the dataset and datastore in python:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import azureml.core\nfrom azureml.core import Workspace, Datastore, Dataset\n\nws = Workspace.from_config()\n\ndatastore = Datastore(ws, &quot;mydatastore&quot;)\n\ndatastore_paths = [(datastore, 'testdata')]\ntest_ds = Dataset.File.from_files(path=datastore_paths)\ntest_ds.register(ws, &quot;testpython&quot;)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-16 14:52:39.093 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-02-16 15:04:59.54 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":2337,
        "Owner_creation_date":"2013-07-12 17:54:09.053 UTC",
        "Owner_last_access_date":"2022-06-28 11:12:43.343 UTC",
        "Owner_reputation":1066,
        "Owner_up_votes":292,
        "Owner_down_votes":5,
        "Owner_views":60,
        "Answer_body":"<p>I uploaded and registered the files with this script and everything works as expected.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Datastore, Dataset, Workspace\n\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=&quot;%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s&quot;,\n    datefmt=&quot;%Y-%m-%d %H:%M:%S&quot;,\n)\n\ndatastore_name = &quot;mydatastore&quot;\ndataset_path_on_disk = &quot;.\/data\/images_greyscale&quot;\ndataset_path_in_datastore = &quot;images_greyscale&quot;\n\nazure_dataset_name = &quot;images_grayscale&quot;\nazure_dataset_description = &quot;dataset transformed into the coco format and into grayscale images&quot;\n\n\nworkspace = Workspace.from_config()\ndatastore = Datastore.get(workspace, datastore_name=datastore_name)\n\nlogger.info(&quot;Uploading data...&quot;)\ndatastore.upload(\n    src_dir=dataset_path_on_disk, target_path=dataset_path_in_datastore, overwrite=False\n)\nlogger.info(&quot;Uploading data done.&quot;)\n\nlogger.info(&quot;Registering dataset...&quot;)\ndatastore_path = [(datastore, dataset_path_in_datastore)]\ndataset = Dataset.File.from_files(path=datastore_path)\ndataset.register(\n    workspace=workspace,\n    name=azure_dataset_name,\n    description=azure_dataset_description,\n    create_new_version=True,\n)\nlogger.info(&quot;Registering dataset done.&quot;)\n\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-19 17:05:44.877 UTC",
        "Answer_score":0.0,
        "Owner_location":"M\u00fcnchen, Deutschland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66226685",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73134073,
        "Question_title":"How to delete azureml dataset if it already exists",
        "Question_body":"<p>Created an azure ml dataset. how do I delete the dataset if it already exists?<\/p>\n<pre><code>#register dataset\npath='path'\nfile_ds=Dataset.File.from_files(path=path)\nfile_ds=file_ds.register(workspace=ws,name=&quot;Dataset&quot;)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-07-27 07:49:04.6 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":114,
        "Owner_creation_date":"2020-11-30 17:06:44.663 UTC",
        "Owner_last_access_date":"2022-08-31 08:48:49.383 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":"<p>AFAIK, as of now, deleting the dataset using <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/search?q=delete+datasets\" rel=\"nofollow noreferrer\">AzureML Python SDK<\/a> is not possible via <code>delete.datasets()<\/code>. But it might be possible via <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/blob\/396853110f5c15463e5a531ee759446d3389d441\/sdk\/ml\/azure-ai-ml\/azure\/ai\/ml\/_restclient\/dataset_dataplane\/operations\/_delete_operations.py\" rel=\"nofollow noreferrer\">delete_operations.py<\/a><\/p>\n<p>As suggested by <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/567611\/is-there-a-way-to-delete-datasets-on-azureml.html\" rel=\"nofollow noreferrer\">YutongTie<\/a>, you can delete the dataset using the Azure Machine Learning Studio.<\/p>\n<p>References: <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/379022\/how-to-delete-data-backing-a-dataset.html\" rel=\"nofollow noreferrer\">How to Delete Data Backing a Dataset<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-export-delete-data\" rel=\"nofollow noreferrer\">Export or delete your Machine Learning service workspace data<\/a> and <a href=\"https:\/\/rdrr.io\/cran\/AzureML\/man\/delete.datasets.html\" rel=\"nofollow noreferrer\">R interface to AzureML - delete dataset<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-07-27 08:38:47.743 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-07-27 08:50:44.107 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73134073",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70335823,
        "Question_title":"Azure ML ops task to write a file in git repo",
        "Question_body":"<p>I am trying to implement ml ops in azure. I am running a python script through azure cli task in devops. Though I can read files from the git folder but the py script is not able to generate the output csv in git. Strangely its also not giving any error.<\/p>\n<p>I think the file is getting generated in the compute instance directory. How to instead write it to a git folder or any folder which I can see in the compute engine.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-13 13:56:08.173 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|git|azure|azure-devops|azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_date":"2016-12-26 17:11:02.96 UTC",
        "Owner_last_access_date":"2022-09-20 05:53:30.493 UTC",
        "Owner_reputation":349,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":60,
        "Answer_body":"<p>I had a similar situation where python couldn't find the files that were supposed to exist in the root of the Azure ML project folder after deploying. After investigation, I realized that Azure ML invokes your scripting code from a different root folder.<\/p>\n<p>Here is an example of an operation that reads from the relative path where your code exists:<\/p>\n<pre><code>    SCRIPT_DIRECTORY = os.path.dirname(os.path.realpath(__file__))\n    with open(SCRIPT_DIRECTORY+'filename.json', 'w') as outfile:\n        json.dump(dict_object, outfile)\n<\/code><\/pre>\n<p>You can then join to <code>SCRIPT_DIRECTORY <\/code> the relative path of your git folder, before your output.<\/p>\n<p>Alternatively, as per your comment &quot;.\/output is not getting created&quot;, you can force it with:<\/p>\n<p><code>os.makedirs(&quot;.\/outputs&quot;, exist_ok=True)<\/code><\/p>\n<p><code>exist_ok<\/code> (optional) : A default value <code>False<\/code> is used for this parameter. If the target directory already exists an <code>OSError<\/code> is raised if its value is <code>False<\/code> otherwise not. For value <code>True<\/code> leaves directory unaltered.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2022-01-13 15:30:39.3 UTC",
        "Answer_score":1.0,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70335823",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33802274,
        "Question_title":"Error:1411809D:SSL routines - When trying to make https call from inside R module in AzureML",
        "Question_body":"<p>I have an experiment in AzureML which has a R module at its core. Additionally, I have some .RData files stored in Azure blob storage. The blob container is set as private (no anonymous access).<\/p>\n\n<p>Now, I am trying to make a https call from inside the R script to the azure blob storage container in order to download some files. I am using the <code>httr<\/code> package's <code>GET()<\/code> function and properly set up the url, authentication etc...The code works in R on my local machine but the same code gives me the following error when called from inside the R module in the experiment<\/p>\n\n<pre><code>error:1411809D:SSL routines:SSL_CHECK_SERVERHELLO_TLSEXT:tls invalid ecpointformat list\n<\/code><\/pre>\n\n<p>Apparently this is an error from the underlying OpenSSL library (which got fixed a while ago). Some suggested workarounds I found <a href=\"https:\/\/stackoverflow.com\/questions\/20046176\/rcurl-errors-when-fetching-ssl-endpoint\">here<\/a> were to set <code>sslversion = 3<\/code> and <code>ssl_verifypeer = 1<\/code>, or turn off verification <code>ssl_verifypeer = 0<\/code>. Both of these approaches returned the same error.<\/p>\n\n<p>I am guessing that this has something to do with the internal Azure certificate \/ validation...? Or maybe I am missing or overseeing something?<\/p>\n\n<p>Any help or ideas would be greatly appreciated. Thanks in advance.<\/p>\n\n<p>Regards<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2015-11-19 11:11:25.157 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-05-23 11:52:17.367 UTC",
        "Question_score":1,
        "Question_tags":"r|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":358,
        "Owner_creation_date":"2015-05-28 16:10:15.467 UTC",
        "Owner_last_access_date":"2018-11-18 20:44:24.587 UTC",
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Answer_body":"<p>After a while, an answer came back from the support team, so I am going to post the relevant part as an answer here for anyone who lands here with the same problem. <\/p>\n\n<p>\"This is a known issue. The container (a sandbox technology known as \"drawbridge\" running on top of Azure PaaS VM) executing the Execute R module doesn't support outbound HTTPS traffic. Please try to switch to HTTP and that should work.\"<\/p>\n\n<p>As well as that a solution is on the way :<\/p>\n\n<p>\"We are actively looking at how to fix this bug. \"<\/p>\n\n<p>Here is the original <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/5866e16c-a145-481e-8764-f7c7823742b0\/https-call-from-inside-r-module-possible-?forum=MachineLearning\" rel=\"nofollow\">link<\/a> as a reference.\nhth<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-12-17 13:20:02.137 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33802274",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58301879,
        "Question_title":"Unable to upload statsmodels 0.9rc1 python package in Azure ML studio",
        "Question_body":"<p>I'm not able to upload statsmodels 0.9rc1 python package in Azure ML studio for Time series analysis.<\/p>\n\n<p>I have downloaded <a href=\"https:\/\/files.pythonhosted.org\/packages\/df\/6f\/df6cf5faecd8082ee23916ff45d396dfee5a1f17aa275da7bab4f5c8926a\/statsmodels-0.9.0rc1-cp36-cp36m-win_amd64.whl\" rel=\"nofollow noreferrer\">statsmodels 0.9rc1<\/a>, unzipped contents and added statsmodels folder and model.pkl file to zip folder.<\/p>\n\n<p>But, while uploading to Microsoft Azure ML studio it says <strong>failed to build schema and visualization<\/strong><\/p>\n\n<p>I'm using this external package in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts\" rel=\"nofollow noreferrer\">Execute Python script<\/a><\/p>\n\n<p>PS: I have succesfully uploaded packages like Adal, dateutils etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-09 10:14:06.857 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-10-09 11:15:08.227 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|machine-learning|statsmodels|azure-machine-learning-studio",
        "Question_view_count":141,
        "Owner_creation_date":"2019-01-24 14:52:36.52 UTC",
        "Owner_last_access_date":"2022-09-23 08:24:06.773 UTC",
        "Owner_reputation":2907,
        "Owner_up_votes":354,
        "Owner_down_votes":2,
        "Owner_views":238,
        "Answer_body":"<p>I have switched to Azure Jupyter Notebook where I installed package using pip<\/p>\n\n<pre><code>!pip install statsmodels==0.9.0rc1\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-11-07 16:37:35.863 UTC",
        "Answer_score":2.0,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58301879",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71858668,
        "Question_title":"How to use tensorflow hub in Azure ML",
        "Question_body":"<p>I am trying to use  TensorFlow Hub in Azure ML Studio<\/p>\n<p>I am using the kernel Python 3.8 PT and TF<\/p>\n<p>And I installed  a few modules:<\/p>\n<pre><code>!pip install bert-for-tf2\n!pip install sentencepiece\n!pip install &quot;tensorflow&gt;=2.0.0&quot;\n!pip install --upgrade tensorflow-hub\n<\/code><\/pre>\n<p>With pip list, I can see they are installed:<\/p>\n<pre><code>tensorflow                              2.8.0\ntensorflow-estimator                    2.3.0\ntensorflow-gpu                          2.3.0\ntensorflow-hub                          0.12.0\ntensorflow-io-gcs-filesystem            0.24.0\n<\/code><\/pre>\n<p>However when I try to use it as per the documentation (<a href=\"https:\/\/www.tensorflow.org\/hub\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/hub<\/a>)<\/p>\n<p>Then I get the classic:<\/p>\n<pre><code>ModuleNotFoundError: No module named 'tensorflow_hub'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-13 13:51:11.967 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|tensorflow|tensorflow-hub|azure-machine-learning-service",
        "Question_view_count":112,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>To resolve this <code>ModuleNotFoundError: No module named 'tensorflow_hub'<\/code>  error, try following ways:<\/p>\n<ul>\n<li>Try installing\/upgrading the latest version of <code>tensorflow<\/code> and <code>tensorflow-hub<\/code> and then import:<\/li>\n<\/ul>\n<pre><code>!pip install --upgrade tensorflow\n\n!pip install --upgrade tensorflow_hub\n\nimport tensorflow as tf\n\nimport tensorflow_hub as hub\n<\/code><\/pre>\n<ul>\n<li>Install the current environment as a new kernel:<\/li>\n<\/ul>\n<pre><code>python3 -m ipykernel install --user --name=testenvironment\n<\/code><\/pre>\n<p>You can refer to <a href=\"https:\/\/stackoverflow.com\/questions\/63884339\/modulenotfounderror-no-module-named-tensorflow-hub\">ModuleNotFoundError: No module named 'tensorflow_hub', No module named 'tensorflow_hub'<\/a> and <a href=\"https:\/\/github.com\/tensorflow\/hub\/issues\/767\" rel=\"nofollow noreferrer\">How to use Tensorflow Hub Model?<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-26 05:16:05.913 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71858668",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66923216,
        "Question_title":"Change Disk Type Azure ML",
        "Question_body":"<p>I have azure ml , I created compute for learning.\nCost for instance is 2-5usd with my use. But cost for p10(premium SSD) Disk 17usd.<\/p>\n<p>I don't know how change it because its not appear in azure Disk and in ML studio i cant find option for manage storage type for compute.<\/p>\n<p>Some one know how change it ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-02 17:45:41.497 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":150,
        "Owner_creation_date":"2019-06-20 07:29:43.553 UTC",
        "Owner_last_access_date":"2022-09-25 05:21:17.457 UTC",
        "Owner_reputation":97,
        "Owner_up_votes":167,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>There is no possible way to change the compute disk type if you use the Azure ML compute cluster and compute instance. Only when you use the extra computer, you can manage the separate resources such as the disk, network, and so on. For example, you attach a VM as the target computer to the Azure ML. Then when you create the VM you can set the disk type with HDD.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-07 06:57:37.403 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66923216",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62696966,
        "Question_title":"Why does Azure ML Studio (classic) take additional time to execute Python Scripts?",
        "Question_body":"<p>I have been working with ML Studio (classic) and facing a problem with &quot;Execute Python&quot; scripts. I have noticed that it takes additional time to perform some internal tasks after which it starts executing the actual Python code in ML Studio. This delay has caused an increased time of 40-60 seconds per module which is aggregating and causing a delay of 400-500 seconds per execution when consumed through Batch Execution System or on running the experiments manually. (I've multiple Modules of &quot;Execute Python&quot; scripts)<\/p>\n<p>For instance - If I run a code in my local system, suppose it takes 2-3 seconds. The same would consume 50-60 seconds in Azure ML Studio.<\/p>\n<p>Can you please help understand the reason behind this or any optimization that can be done?<\/p>\n<p>Regards,\nAnant<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-02 13:00:19.477 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python-3.x|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":166,
        "Owner_creation_date":"2020-02-20 06:21:24.313 UTC",
        "Owner_last_access_date":"2022-07-04 07:09:05.75 UTC",
        "Owner_reputation":601,
        "Owner_up_votes":86,
        "Owner_down_votes":6,
        "Owner_views":94,
        "Answer_body":"<p>The known limitations of Machine Learning Studio (classic) are:<\/p>\n<p>The Python runtime is sandboxed and does not allow access to the network or to the local file system in a persistent manner.<\/p>\n<p>All files saved locally are isolated and deleted once the module finishes. The Python code cannot access most directories on the machine it runs on, the exception being the current directory and its subdirectories.<\/p>\n<p>When you provide a zipped file as a resource, the files are copied from your workspace to the experiment execution space, unpacked, and then used. Copying and unpacking resources can consume memory.<\/p>\n<p>The module can output a single data frame. It's not possible to return arbitrary Python objects such as trained models directly back to the Studio (classic) runtime. However, you can write objects to storage or to the workspace. Another option is to use pickle to serialize multiple objects into a byte array and then return the array inside a data frame.<\/p>\n<p>Hope this helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-02 13:07:47.95 UTC",
        "Answer_score":2.0,
        "Owner_location":"Hyderabad, Telangana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62696966",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44371692,
        "Question_title":"Install Python Packages in Azure ML?",
        "Question_body":"<p>Similar question as <a href=\"https:\/\/stackoverflow.com\/questions\/43176442\/install-r-packages-in-azure-ml\">here<\/a> but now on Python packages. Currently, the CVXPY is missing in Azure ML. I am also trying to get other solvers such as GLPK, CLP and COINMP working in Azure ML.<\/p>\n<p><strong>How can I install Python packages in Azure ML?<\/strong><\/p>\n<hr \/>\n<p><em>Update about trying to install the Python packages not found in Azure ML.<\/em><\/p>\n<blockquote>\n<p>I did as instructed by Peter Pan but I think the 32bits CVXPY files are wrong for the Anaconda 4 and Python 3.5 in Azure ML, logs and errors are <a href=\"https:\/\/pastebin.com\/zN5QrPtL\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<pre><code>[Information]         Running with Python 3.5.1 |Anaconda 4.0.0 (64-bit)| (default, Feb 16 2016, 09:49:46) [MSC v.1900 64 bit (AMD64)]\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rS0Us.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rS0Us.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6qz3p.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6qz3p.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9glSm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9glSm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/blockquote>\n<p><em>Update 2 with win_amd64 files (paste <a href=\"https:\/\/pastebin.com\/tisWuP5C\" rel=\"nofollow noreferrer\">here<\/a>)<\/em><\/p>\n<blockquote>\n<pre><code>[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         cvxopt-1.1.9-cp35-cp35m-win_amd64.whl          2017-06-07 01:03:34      1972074\n[Information]         __MACOSX\/                                      2017-06-07 01:26:28            0\n[Information]         __MACOSX\/._cvxopt-1.1.9-cp35-cp35m-win_amd64.whl 2017-06-07 01:03:34          452\n[Information]         cvxpy-0.4.10-py3-none-any.whl                  2017-06-07 00:25:36       300880\n[Information]         __MACOSX\/._cvxpy-0.4.10-py3-none-any.whl       2017-06-07 00:25:36          444\n[Information]         ecos-2.0.4-cp35-cp35m-win_amd64.whl            2017-06-07 01:03:40        56522\n[Information]         __MACOSX\/._ecos-2.0.4-cp35-cp35m-win_amd64.whl 2017-06-07 01:03:40          450\n[Information]         numpy-1.13.0rc2+mkl-cp35-cp35m-win_amd64.whl   2017-06-07 01:25:02    127909457\n[Information]         __MACOSX\/._numpy-1.13.0rc2+mkl-cp35-cp35m-win_amd64.whl 2017-06-07 01:25:02          459\n[Information]         scipy-0.19.0-cp35-cp35m-win_amd64.whl          2017-06-07 01:05:12     12178932\n[Information]         __MACOSX\/._scipy-0.19.0-cp35-cp35m-win_amd64.whl 2017-06-07 01:05:12          452\n[Information]         scs-1.2.6-cp35-cp35m-win_amd64.whl             2017-06-07 01:03:34        78653\n[Information]         __MACOSX\/._scs-1.2.6-cp35-cp35m-win_amd64.whl  2017-06-07 01:03:34          449\n[Information]         [ READING ] 0:00:00\n[Information]         Input pandas.DataFrame #1:\n[Information]         Empty DataFrame\n[Information]         Columns: [1]\n[Information]         Index: []\n[Information]         [ EXECUTING ] 0:00:00\n[Information]         [ WRITING ] 0:00:00\n<\/code><\/pre>\n<p>where <code>import cvxpy<\/code>, <code>import cvxpy-0.4.10-py3-none-any.whl<\/code> or <code>cvxpy-0.4.10-py3-none-any<\/code> do not work so<\/p>\n<p><strong>How can I use the following wheel files downloaded from <a href=\"http:\/\/www.lfd.uci.edu\/%7Egohlke\/pythonlibs\/#cvxpy\" rel=\"nofollow noreferrer\">here<\/a> to use the external Python packages not found in Azure ML?<\/strong><\/p>\n<\/blockquote>\n<p><em>Update about permission problem about importing cvxpy (paste <a href=\"https:\/\/pastebin.com\/3kTKgLfc\" rel=\"nofollow noreferrer\">here<\/a>)<\/em><\/p>\n<blockquote>\n<pre><code> [Error]         ImportError: No module named 'canonInterface'\n<\/code><\/pre>\n<p>where the ZIP Bundle is organised a bit differently, the content of each wheel downloaded to a folder and the content having all zipped as a ZIP Bundle.<\/p>\n<\/blockquote>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-06-05 14:52:19.213 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio|cvxpy",
        "Question_view_count":12625,
        "Owner_creation_date":"2009-08-27 11:33:59.053 UTC",
        "Owner_last_access_date":"2022-05-27 10:56:29.307 UTC",
        "Owner_reputation":48616,
        "Owner_up_votes":1240,
        "Owner_down_votes":41,
        "Owner_views":3348,
        "Answer_body":"<p>According to the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts#limitations\" rel=\"nofollow noreferrer\"><code>Limitations<\/code><\/a> and <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn955437.aspx#Anchor_3\" rel=\"nofollow noreferrer\"><code>Technical Notes<\/code><\/a> of <code>Execute Python Script<\/code> tutorial, the only way to add custom Python modules is via the zip file mechanism to package the modules and all dependencies.<\/p>\n\n<p>For example to install <code>CVXPY<\/code>, as below.<\/p>\n\n<ol>\n<li>Download the wheel file of <a href=\"http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#cvxpy\" rel=\"nofollow noreferrer\"><code>CVXPY<\/code><\/a> and its dependencies like <a href=\"http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#cvxopt\" rel=\"nofollow noreferrer\"><code>CVXOPT<\/code><\/a>.<\/li>\n<li>Decompress these wheel files, and package these files in the path <code>cvxpy<\/code> and <code>cvxopt<\/code>, etc as a zipped file with your script.<\/li>\n<li>Upload the zip file as a dataset and use it as the script bundle.<\/li>\n<\/ol>\n\n<p>If you were using IPython, you also can try to install the Python Package via the code <code>!pip install cvxpy<\/code>.<\/p>\n\n<p>And there are some similar SO threads which may be helpful for you, as below.<\/p>\n\n<ol>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/44285641\/azure-ml-python-with-script-bundle-cannot-import-module\">Azure ML Python with Script Bundle cannot import module<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/8663046\/how-to-install-a-python-package-from-within-ipython\">How to install a Python package from within IPython?<\/a><\/li>\n<\/ol>\n\n<p>Hope it helps.<\/p>\n\n<hr>\n\n<p>Update:<\/p>\n\n<p>For IPython interface of Azure ML, you move to the <code>NOTEBOOKS<\/code> tab to create a notebook via <code>ADD TO PROJECT<\/code> button at the bottom of the page, as the figure below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/X2Asv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/X2Asv.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Or you can directly login to the website <code>https:\/\/notebooks.azure.com<\/code> to use it.<\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2017-06-06 06:59:06.28 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2017-06-06 14:44:44.03 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44371692",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35851851,
        "Question_title":"How to delete all non-numeric rows in R?",
        "Question_body":"<p>I have a dataframe like bellow, where <code>ID<\/code> is numeric value, and <code>comment1<\/code> and <code>comment2<\/code> string that I am importing as a csv. But the data frame is giving result something like this bellow, where <code>fifth comment<\/code> should be in the <code>comment2<\/code> and the original <code>ID<\/code> value is replaced by this. This is happening randomly for only few rows. Moreover, this problem is only occurring when I am importing my <strong>R<\/strong> code in <strong>Azure ML<\/strong> studio, in <strong>RStudio<\/strong> no data misplace is occurring. So what I was thinking, just delete the entire row where the first column <code>ID<\/code> is not a numeric value. As the misplace string value is random long sentence, I can not do string matching to delete the row. And the dataframe is big enough that I just cannot delete the rows manually. Suggestion please. <\/p>\n\n<pre><code>  ID                 Comment1                  comment2\n 123             This is first comment        this is second\n 234              third comment               fourth comment\nfifth comment                                                  \n 345               sixth comment              seventh comment\n<\/code><\/pre>\n\n<p>You will find a sample of the dataframe here,<\/p>\n\n<pre><code>    df &lt;-\n  read.csv(\n    \"https:\/\/docs.google.com\/spreadsheets\/d\/171YXjzm3FsapXSkqgOSos6UGXNRcd1yxmLyvaRnCX5E\/pub?output=csv\"\n  )\ndf &lt;- df[-1,]\ndf &lt;- df[, 1:12]\ncolnames(df) &lt;-\n  c(\n    \"ID\",\"Created\",\"Comments\",\"Liked_By\",\"Disliked_By\", \"Recipient_Number\",\n    \"Sender\",\"Recipients\",\"Read_By\", \"Subject\",\"Introduction\",\"Body\"\n  )\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":5,
        "Question_creation_date":"2016-03-07 19:03:43.877 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2017-01-04 08:35:11.967 UTC",
        "Question_score":1,
        "Question_tags":"r|dataframe|delete-row|azure-machine-learning-studio",
        "Question_view_count":5339,
        "Owner_creation_date":"2016-02-17 01:35:51.607 UTC",
        "Owner_last_access_date":"2022-09-24 22:13:14.407 UTC",
        "Owner_reputation":473,
        "Owner_up_votes":289,
        "Owner_down_votes":7,
        "Owner_views":67,
        "Answer_body":"<p>Subset to numeric IDs:<\/p>\n\n<pre><code>subset(df, grepl('^\\\\d+$', df$ID))\n<\/code><\/pre>\n\n<p>The pattern should match values of ID that start and end with digits, and only contain digits.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-03-07 19:12:12.163 UTC",
        "Answer_score":3.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35851851",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67161293,
        "Question_title":"Issues accessing a FileDataset created from HTTP URIs in a PythonScriptStep",
        "Question_body":"<p>I\u2019m having some issues trying to access a FileDataset created from two http URIs in an Azure ML Pipeline PythonScriptStep.<\/p>\n<p>In the step, I\u2019m only getting a single file named <code>['https%3A\u2019]<\/code> when doing an <code>os.listdir()<\/code> on my mount point. I would have expected two files, with their actual names instead. This happens both when sending the dataset <code>as_upload<\/code> and <code>as_mount<\/code>. Even happens when I send the dataset reference to the pipeline step and mount it directly from the step.<\/p>\n<p>The dataset is registered in a notebook, the same notebook that creates and invokes the pipeline, as seen below:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>tempFileData = Dataset.File.from_files(\n        ['https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg',\n        'https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg'])\ntempFileData.register(ws, name='FileData', create_new_version=True)\n\n#...\n\nread_datasets_step = PythonScriptStep(\n    name='The Dataset Reader',\n    script_name='read-datasets.py',\n    inputs=[fileData.as_named_input('Files'), fileData.as_named_input('Files_mount').as_mount(), fileData.as_named_input('Files_download').as_download()],\n    compute_target=compute_target,\n    source_directory='.\/dataset-reader',\n    allow_reuse=False,\n)\n\n<\/code><\/pre>\n<p>The <code>FileDataset<\/code> seems to be registered properly, if I examine it within the notebook I get the following result:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [\n    &quot;https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot;,\n    &quot;https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;\n  ],\n  &quot;definition&quot;: [\n    &quot;GetFiles&quot;\n  ],\n  &quot;registration&quot;: {\n    &quot;id&quot;: &quot;...&quot;,\n    &quot;name&quot;: &quot;FileData&quot;,\n    &quot;version&quot;: 4,\n    &quot;workspace&quot;: &quot;Workspace.create(...)&quot;\n  }\n}\n<\/code><\/pre>\n<p>For reference, the machine running the notebook is using AML SDK v1.24, whereas the node running the pipeline steps is running v1.25.<\/p>\n<p>Has anybody encountered anything like this? Is there a way to make it work?<\/p>\n<p>Note that I'm specifically looking at file datasets created from web uris, and not necessarily interested in getting a <code>FileDataset<\/code> to work with blob storage or similar.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-19 11:38:44.14 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-04-19 16:18:14.43 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_date":"2009-08-13 10:15:52.417 UTC",
        "Owner_last_access_date":"2022-09-22 11:46:38.323 UTC",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Answer_body":"<p>The files should've been mounted at path &quot;https%3A\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot; and &quot;https%3A\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;.<\/p>\n<p>We retain the directory structure following the url structure to avoid potential conflicts.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-19 17:59:29.223 UTC",
        "Answer_score":2.0,
        "Owner_location":"Romania",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67161293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35627916,
        "Question_title":"Azure machine learning even sampling",
        "Question_body":"<p>I'm trying to do some basic multi-label classification in Azure ML. I have some basic data in the following format:<\/p>\n\n<pre><code>value_x value_y label\nx1      y1      label1\nx2      y2      label1\nx3      y3      label2\n.....\n<\/code><\/pre>\n\n<p>My problem is that in my data certain labels (out of a total of five) are overrepresented, as about 40% of the data is label1, about 20% is label 2 and the rest around 10%. <\/p>\n\n<p>I would like to get a sampling out of these to train my model, so that each label is represented in equal amounts. <\/p>\n\n<p>Tried the stratification option in the Sampling module on the labels column, but that just gives me a sampling with the same distribution of labels as in the initial dataset.<\/p>\n\n<p>Any idea how I could do this with a module?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-02-25 12:53:42.827 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-02-25 14:36:19.577 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|classification|sampling|multilabel-classification|azure-machine-learning-studio",
        "Question_view_count":539,
        "Owner_creation_date":"2013-10-10 11:47:41.54 UTC",
        "Owner_last_access_date":"2022-09-22 10:35:54.783 UTC",
        "Owner_reputation":185,
        "Owner_up_votes":42,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>I was able to do this using a combination of <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/70530644-c97a-4ab6-85f7-88bf30a8be5f\" rel=\"nofollow\">Split Data<\/a>, <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/a8726e34-1b3e-4515-b59a-3e4a475654b8\" rel=\"nofollow\">Partition and Sample<\/a>, and <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/b2ebdabd-217d-4915-86cc-5b05972f7270\" rel=\"nofollow\">Add Rows<\/a> modules.  There may be an easier way to do it, but I did confirm it works.  :)  I published my work at <a href=\"http:\/\/gallery.azureml.net\/Details\/1245147fd7004e91bc7a3683cda19cc7\" rel=\"nofollow\">http:\/\/gallery.azureml.net\/Details\/1245147fd7004e91bc7a3683cda19cc7<\/a> so you can grab it directly from there, and run to confirm it does what you expect.  <\/p>\n\n<p>Since you said you wanted a sampling of the data, I just reduced each of the labels to 10% to have all labels represented equally.  Since you have a good understanding of the distribution in your dataset, leave label 3, 4, and 5 all at about 10%, and reduce label 1 by 1\/4 and label 2 by 1\/2 to get about 10% of them as well.  <\/p>\n\n<p>To explain what I did in the workspace linked above:<\/p>\n\n<ul>\n<li>I used some \"Split Data\" modules to filter out the label1 and label2 data.  In the Split Data module, change the Splitting mode to \"Regular Expression\" and set the regular expression to <strong>\\\"Label\" ^label1<\/strong> (to get the label1 data, for example).  <\/li>\n<li>Then I used some \"Partition and Sample\" modules to reduce the size of the label1 and label2 data appropriately.  <\/li>\n<li>Finally, I used some \"Add Rows\" modules to join all of the data back together again.  <\/li>\n<\/ul>\n\n<p>Finally, I didn't include this in my work, but you can also look at the <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/9f3fe1c4-520e-49ac-a152-2e104169912a\" rel=\"nofollow\">SMOTE<\/a> module.  It will increase the number of low-occurring samples using synthetic minority oversampling.  <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-26 03:51:29.16 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35627916",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58188104,
        "Question_title":"Azure Machine Learning REST API: why is the prediction included in the Sample Request?",
        "Question_body":"<p>I followed Microsoft's tutorial on the German credit card risk model, step by step and without mistakes. The algorithm runs, it is deployed successfully, etc.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/tuyDt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tuyDt.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am using the <code>Select Columns in Dataset<\/code> to select the columns to input, and I do the same to select the output columns. <\/p>\n\n<p>I noticed that when I look at the <code>Request\/Response<\/code> tab of the deployed model, the Sample Request includes <em>all<\/em> columns, ignoring the selection I provided. This includes the field to be predicted, which is column 21:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"Col1\",\n        \"Col2\",\n        \"Col3\",\n        \"Col4\",\n        \"Col5\",\n        \"Col6\",\n        \"Col7\",\n        \"Col8\",\n        \"Col9\",\n        \"Col10\",\n        \"Col11\",\n        \"Col12\",\n        \"Col13\",\n        \"Col14\",\n        \"Col15\",\n        \"Col16\",\n        \"Col17\",\n        \"Col18\",\n        \"Col19\",\n        \"Col20\",\n        \"Col21\"\n<\/code><\/pre>\n\n<p><strong>The problem<\/strong>: column 21 is the credit risk itself, so the API is expecting to receive that value. Instead, <strong>that is the value that should be predicted!<\/strong><\/p>\n\n<p>There clearly is a problem with the input schema, but how can I change that? How can I make sure that field is not requested by the API?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-01 15:31:40.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|rest|schema|postman|azure-machine-learning-studio",
        "Question_view_count":119,
        "Owner_creation_date":"2015-10-26 16:55:20.94 UTC",
        "Owner_last_access_date":"2022-07-29 13:54:20.753 UTC",
        "Owner_reputation":1271,
        "Owner_up_votes":1079,
        "Owner_down_votes":0,
        "Owner_views":171,
        "Answer_body":"<p>Don't worry about the input schema for the <code>Col21<\/code> field. The <code>Col21<\/code> field in the input data just adapt for the <code>Edit Metadata<\/code> module which requires the <code>Col21<\/code> data in the training stage.<\/p>\n\n<p>You just fill an invalid value like <code>0<\/code> (<code>0<\/code> is an invalid classified value for risk) into <code>Col21<\/code> field, and then the web service will return a prediction classified value to replace the <code>Col21<\/code> value of your input data.<\/p>\n\n<p>At here, I use the first data record of the sample data with the <code>Col21<\/code> value <code>0<\/code> for testing via the link of <code>Test<\/code> feature on portal, it works fine and return <code>1<\/code> for <code>Credit risk<\/code><\/p>\n\n<p>Fig 1. To click <code>Test<\/code> link to test for <code>Col21<\/code> with <code>0<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/9jqyo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9jqyo.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 2. Use the first record of sample to test<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/lIUiP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lIUiP.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 3. The <code>Col21<\/code> value of <code>input1<\/code> is <code>0<\/code>, and the <code>Credit risk<\/code> value of <code>output1<\/code> is <code>1<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/h5OEH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/h5OEH.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-08 17:04:23.83 UTC",
        "Answer_score":1.0,
        "Owner_location":"Humboldt, Saskatchewan, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58188104",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58500807,
        "Question_title":"Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun' in Azure ML Experiment",
        "Question_body":"<p>I'm using VS Code to submit a Machine Learning experiment in Azure Portal. When running the experiment I'm obtaining the following error:<\/p>\n\n<p>Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun'<\/p>\n\n<p>This is the code structure:<\/p>\n\n<p>.vscode (json configuration file)<\/p>\n\n<p>aml_config<\/p>\n\n<p>scripts<\/p>\n\n<p>----- amlrun.py (a script with some functions)<\/p>\n\n<p>----- model_training.py (a script creating and saving the model)<\/p>\n\n<p>This is the configuration file:<\/p>\n\n<pre><code>{\n    \"script\": \"model_training.py\",\n    \"framework\": \"Python\",\n    \"communicator\": \"None\",\n    \"target\": \"testazure\",\n    \"environment\": {\n        \"python\": {\n            \"userManagedDependencies\": false,\n            \"condaDependencies\": {\n                \"dependencies\": [\n                    \"python=3.6.2\",\n                    \"scikit-learn\",\n                    \"numpy\",\n                    \"pandas\",\n                    {\n                        \"pip\": [\n                            \"azureml-defaults\"\n                        ]\n                    }\n                ]\n            }\n        },\n        \"docker\": {\n            \"baseImage\": \"mcr.microsoft.com\/azureml\/base:0.2.4\",\n            \"enabled\": true,\n            \"baseImageRegistry\": {\n                \"address\": null,\n                \"username\": null,\n                \"password\": null\n            }\n        }\n    },\n    \"history\": {\n        \"outputCollection\": true,\n        \"snapshotProject\": false,\n        \"directoriesToWatch\": [\n            \"logs\"\n        ]\n    }\n}\n<\/code><\/pre>\n\n<p>Am I missing something?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-22 09:10:33.2 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":901,
        "Owner_creation_date":"2019-01-10 16:33:51.703 UTC",
        "Owner_last_access_date":"2020-12-14 18:08:49.513 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>When your training script is running in azure, it's not able to find all your local imports i.e. <code>amlrun.py<\/code> script. <\/p>\n\n<p>The submitted training job to azure builds a docker image with your files first and runs the experiment; but in this case the extension hasn't included <code>amlrun.py<\/code>. <\/p>\n\n<p>This is probably because when you have submit the training job with the extension, the visual studio code window opened is not pointing to be in <code>scripts<\/code> folder.<\/p>\n\n<p>Taken from one of the replies to a <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/24032\" rel=\"nofollow noreferrer\">previously raised github issue<\/a>:<\/p>\n\n<blockquote>\n  <p>The extension currently requires the script you are working on to be\n  in the folder that is open in VS Code and not in a sub-directory.<\/p>\n<\/blockquote>\n\n<hr>\n\n<p>To fix this you can do <strong>either<\/strong> of the following:<\/p>\n\n<ol>\n<li><p>You would need to re-open Visual Studio Code in <code>scripts<\/code> folder instead of parent directory.<\/p><\/li>\n<li><p>Move all files in <code>script<\/code> directory to be in it's parent directory.<\/p><\/li>\n<\/ol>\n\n<hr>\n\n<p>If you're looking for more flexible way to submit training jobs and managing aml - you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro?view=azure-ml-py\" rel=\"nofollow noreferrer\">azure machine learning sdk<\/a> for python.<\/p>\n\n<p>Some examples of using the SDK to manage expirements can be found in the links below:<\/p>\n\n<ol>\n<li><p><a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/service\/tutorial-train-models-with-aml.md\" rel=\"nofollow noreferrer\">Scikit Learn Model Training Docs<\/a> <\/p><\/li>\n<li><p><a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\" rel=\"nofollow noreferrer\">Basic Pytorch Model Training and Deployment Example Repo<\/a><\/p><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-10-23 13:25:18.727 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2019-10-23 13:46:12.44 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58500807",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56558552,
        "Question_title":"How to save your fitted transformer into blob, so your prediction pipeline can use it in AML Service?",
        "Question_body":"<p>I am building a data transformation and training pipeline on Azure Machine Leaning Service. I'd like to save my fitted transformer (e.g. tf-idf) to the blob, so my prediction pipeline can later access it. <\/p>\n\n<pre><code>transformed_data = PipelineData(\"transformed_data\", \n                               datastore = default_datastore,\n                               output_path_on_compute=\"my_project\/tfidf\")\n\nstep_tfidf = PythonScriptStep(name = \"tfidf_step\",\n                              script_name = \"transform.py\",\n                              arguments = ['--input_data', blob_train_data, \n                                           '--output_folder', transformed_data],\n                              inputs = [blob_train_data],\n                              outputs = [transformed_data],\n                              compute_target = aml_compute,\n                              source_directory = project_folder,\n                              runconfig = run_config,\n                              allow_reuse = False)\n\n<\/code><\/pre>\n\n<p>The above code saves the transformer to a current run's folder, which is dynamically generated during each run. <\/p>\n\n<p>I want to save the transformer to a fixed location on blob, so I can access it later, when calling a prediction pipeline.<\/p>\n\n<p>I tried to use an instance of <code>DataReference<\/code> class as <code>PythonScriptStep<\/code> output, but it results in an error: \n<code>ValueError: Unexpected output type: &lt;class 'azureml.data.data_reference.DataReference'&gt;<\/code> <\/p>\n\n<p>It's because <code>PythonScriptStep<\/code> only accepts <code>PipelineData<\/code> or <code>OutputPortBinding<\/code> objects as outputs.<\/p>\n\n<p>How could I save my fitted transformer so it's later accessible by any aribitraly process (e.g. my prediction pipeline)?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-12 09:11:16.657 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1056,
        "Owner_creation_date":"2017-03-23 13:26:01.927 UTC",
        "Owner_last_access_date":"2022-09-22 20:27:37.72 UTC",
        "Owner_reputation":83,
        "Owner_up_votes":30,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Answer_body":"<p>Another solution is to pass <code>DataReference<\/code> as an input to your <code>PythonScriptStep<\/code>. <\/p>\n\n<p>Then inside <code>transform.py<\/code> you're able to read this <code>DataReference<\/code> as a command line argument. <\/p>\n\n<p>You can parse it and use it just as any regular path to save your vectorizer to.<\/p>\n\n<p>E.g. you can:<\/p>\n\n<pre><code>step_tfidf = PythonScriptStep(name = \"tfidf_step\",\n                              script_name = \"transform.py\",\n                              arguments = ['--input_data', blob_train_data, \n                                           '--output_folder', transformed_data,\n                                           '--transformer_path', trained_transformer_path],\n                              inputs = [blob_train_data, trained_transformer_path],\n                              outputs = [transformed_data],\n                              compute_target = aml_compute,\n                              source_directory = project_folder,\n                              runconfig = run_config,\n                              allow_reuse = False)\n<\/code><\/pre>\n\n<p>Then inside your script (<code>transform.py<\/code> in the example above) you can e.g.:<\/p>\n\n<pre><code>import argparse\nimport joblib as jbl\nimport os\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--transformer_path', dest=\"transformer_path\", required=True)\nargs = parser.parse_args()\n\ntfidf = ### HERE CREATE AND TRAIN YOUR VECTORIZER ###\n\nvect_filename = os.path.join(args.transformer_path, 'my_vectorizer.jbl')\n\n<\/code><\/pre>\n\n<hr>\n\n<p>EXTRA: The third way would be to just register the vectorizer as another model in your workspace. You can then use it exactly as any other registered model. (Though this option does not involve explicit writing to blob - as specified in the question above)<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-07-08 11:40:40.653 UTC",
        "Answer_score":1.0,
        "Owner_location":"Tel Aviv",
        "Answer_last_edit_date":"2020-01-10 21:39:12.197 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56558552",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66062015,
        "Question_title":"Executing R script from Azure function",
        "Question_body":"<p>I want to execute a R script every time an azure function is triggered. The R script executes perfectly on Azure machine learning Studio. But I am failing to execute through azure function.\nIs there any way to execute it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-02-05 10:58:02.103 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"r|azure-functions|azure-machine-learning-studio",
        "Question_view_count":640,
        "Owner_creation_date":"2016-09-29 12:55:05.707 UTC",
        "Owner_last_access_date":"2022-09-15 16:11:00.29 UTC",
        "Owner_reputation":79,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>AFAIK you'll have to create your own Runtime as <code>R<\/code> isn't supported natively.<\/p>\n<p>Have you already tried <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-functions\/functions-create-function-linux-custom-image?tabs=bash%2Cportal&amp;pivots=programming-language-other\" rel=\"nofollow noreferrer\">&quot;Create a function on Linux using a custom container&quot;<\/a>? Interestingly they have given <code>R<\/code> as the example of custom runtime, so hopefully that answers your question.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-02-05 22:37:51.217 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66062015",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72729267,
        "Question_title":"Degrading the services automatically by autoscaling in azure services - vCPU",
        "Question_body":"<p>I am designing a learning management system and inflow for the website is more in some cases and  less in another time. I would like to know about the getting the vCPU's which are scaled up to make it down after the stipulated time. I found a document regarding <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/best-practices\/auto-scaling\" rel=\"nofollow noreferrer\">scaling up<\/a> but didn't find a way to scale it down.<\/p>\n<p>Any help is appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-23 11:19:28.11 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-cognitive-services|azure-machine-learning-service",
        "Question_view_count":49,
        "Owner_creation_date":"2022-05-09 19:08:30.643 UTC",
        "Owner_last_access_date":"2022-09-16 03:29:45.173 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>There is a chance of auto scaling for the normal services in azure cloud services, that means for stipulated time you can increase or decrease as mentioned in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/cloud-services\/cloud-services-how-to-scale-portal\" rel=\"nofollow noreferrer\">link<\/a>.<\/p>\n<p>When it comes for vCPU which is cannot be performed automatically. vCPU can be scaled up based on the request criteria and in the same manner we need to request the support team to scale those down to the normal.<\/p>\n<p><strong>There is no specific procedure to make the auto scaling for vCPU operations. We can increase the capacity of core, but to reduce to the normal, we need to approach the support system for manual changing. You can change it from 10 cores to next level 16 cores, but cannot be performed automatic scaling down from 16 cores to 10 cores.<\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-23 11:38:25.567 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72729267",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73833320,
        "Question_title":"parameters error in azure ML designer in evaluation metrics in regression model",
        "Question_body":"<p>I developed a designer to implement regression models in azure machine learning studio. I have taken the data set pill and then split the data set into train and test in prescribed manner. When I am trying to implement the evaluation metrics and run the pipeline, it was showing a warning and error in the moment I called the dataset for the operation. I am bit confused, with the same implementation, when i tried to run with linear regression and it worked as shown in the image. If the same approach is used to implement logistic regression it was showing some warning and error in building the evaluation metrics.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DbEeq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DbEeq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>the above success is in linear regression. When it comes to logistic regression it was showing the warning and error in pipeline.<\/p>\n<p>Any help is appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-23 21:53:30.913 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":29,
        "Owner_creation_date":"2022-05-10 08:49:30.283 UTC",
        "Owner_last_access_date":"2022-09-24 15:47:06.013 UTC",
        "Owner_reputation":19,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>Creating a sample pipeline with designer with mathematical format.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/kCx3A.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kCx3A.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>We need to create a compute instance.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7bQA5.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7bQA5.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/NQWZV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NQWZV.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MpxPY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MpxPY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bAfEv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bAfEv.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Assign the compute instance and click on create<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wIS0d.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wIS0d.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Now the import data warning will be removed. In the same manner, we will be getting similar error in other pills too.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zFK74.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zFK74.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Yk5gY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Yk5gY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Create a mathematical format. If not needed for your case, try to remove that math operation and give the remaining.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/uhKlv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uhKlv.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Assign the column set. Select any option according to the requirement.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mcNZe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mcNZe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Finally, we can find the pills which have no warning or error.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-09-24 12:08:23.563 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73833320",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61415793,
        "Question_title":"Log metrics in PythonScriptStep",
        "Question_body":"<p>In my Azure ML pipeline I've got a PythonScriptStep that is crunching some data. I need to access the Azure ML Logger to track metrics in the step, so I'm trying to import get_azureml_logger but that's bombing out. I'm not sure what dependency I need to install via pip. <\/p>\n\n<p><code>from azureml.logging import get_azureml_logger<\/code><\/p>\n\n<p><code>ModuleNotFoundError: No module named 'azureml.logging'<\/code><\/p>\n\n<p>I came across a similar <a href=\"https:\/\/stackoverflow.com\/questions\/49438358\/azureml-logging-module-not-found\">post<\/a> but it deals with Azure Notebooks. Anyway, I tried adding that blob to my pip dependency, but it's failing with an Auth error.   <\/p>\n\n<pre><code>Collecting azureml.logging==1.0.79 [91m  ERROR: HTTP error 403 while getting\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n[0m91m  ERROR: Could not install requirement azureml.logging==1.0.79 from\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n(from -r \/azureml-environment-setup\/condaenv.g4q7suee.requirements.txt\n(line 3)) because of error 403 Client Error:\nServer failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. for url:\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n<\/code><\/pre>\n\n<p>I'm not sure how to move on this, all I need to do is to log metrics in the step.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-24 19:12:28.897 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-25 10:19:52.913 UTC",
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":361,
        "Owner_creation_date":"2012-02-23 16:54:25.41 UTC",
        "Owner_last_access_date":"2022-09-02 23:23:03.83 UTC",
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Answer_body":"<p>Check out the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-experiments#option-2-use-scriptrunconfig\" rel=\"nofollow noreferrer\">ScriptRunConfig Section of the Monitor Azure ML experiment runs and metrics<\/a>. <code>ScriptRunConfig<\/code> works effectively the same as a <code>PythonScriptStep<\/code>.<\/p>\n\n<p>The idiom is generally to have the following in your the script of your <code>PythonScriptStep<\/code>:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\nrun.log('foo_score', \"bar\")\n<\/code><\/pre>\n\n<p>Side note: You don't need to change your environment dependencies to use this because <code>PythonScriptStep<\/code>s have <code>azureml-defaults<\/code> installed automatically as a dependency.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-04-24 19:27:12.003 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61415793",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49016896,
        "Question_title":"How to bypass ID column without being used in the training model but have it as output - Azure ML",
        "Question_body":"<p>The input data in the model includes column ControlNo.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eqULH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqULH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But I don't want this column being part of learning process so I'm using <code>Select Columns in Dataset<\/code> to exclude <code>ControlNo<\/code> column.<\/p>\n<p>But as a output I want those columns:<\/p>\n<pre><code>ControlNo, Score Label, Score Probability\n<\/code><\/pre>\n<p>So basically I need NOT to include column <code>ControlNo<\/code> into learning process,\nbut have it as output along with <code>Score Label<\/code> column.<\/p>\n<p>How can I do that?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/iPlpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iPlpa.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2018-02-27 19:54:59.607 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|ml-studio",
        "Question_view_count":582,
        "Owner_creation_date":"2016-03-10 08:00:45.393 UTC",
        "Owner_last_access_date":"2022-09-23 23:59:58.457 UTC",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Answer_body":"<p>Instead of removing the ControlNo column from the dataset, you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/edit-metadata\" rel=\"nofollow noreferrer\">Edit Metadata<\/a> module to clear its \"Feature\" flag - just select the column and set <strong>Fields<\/strong> to <strong>Clear feature<\/strong>. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/EUy9A.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EUy9A.png\" alt=\"Edit Metadata settings\"><\/a><\/p>\n\n<p>This will cause the Azure ML Studio algorithms to ignore it during training, and you'll be able to return it as part of your output. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-08-01 08:17:45.72 UTC",
        "Answer_score":3.0,
        "Owner_location":"San Diego, CA, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49016896",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69764100,
        "Question_title":"Endpoints cost on Azure Machine Learning",
        "Question_body":"<p>I have been following the learning path for <a href=\"https:\/\/docs.microsoft.com\/en-us\/learn\/certifications\/exams\/ai-900\" rel=\"nofollow noreferrer\">Microsoft Azure AI 900<\/a>. In the second module, I have deployed my model as an endpoint. It says Container instances for compute type. How much will this cost me. Azure doesn't seem to show any pricing for this. Is this endpoint always active? If yes how much does it cost?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-10-29 05:36:40.157 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":633,
        "Owner_creation_date":"2019-08-17 21:44:53.737 UTC",
        "Owner_last_access_date":"2022-09-23 16:11:06.117 UTC",
        "Owner_reputation":449,
        "Owner_up_votes":370,
        "Owner_down_votes":2,
        "Owner_views":77,
        "Answer_body":"<p>The price depends on the number of <strong>vCPU<\/strong> and <strong>GBs<\/strong> of memory requested for the container group. You are charged based on the <strong>vCPU request<\/strong> for your container group rounded up to the nearest whole number for the duration (measured in seconds) <strong>your instance is running<\/strong>. You are also charged for the <strong>GB request<\/strong> for your container group rounded up to the nearest tenths place for the duration (measured in seconds) your <strong>container group is running<\/strong>. There is an additional charge of $0.000012 per vCPU second for Windows software duration on Windows container groups. Check here <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/container-instances\/\" rel=\"nofollow noreferrer\">Pricing - Container Instances | Microsoft Azure<\/a> for details<\/p>\n<ul>\n<li>After Deployed the Azure Machine Learning managed online endpoint (preview).<\/li>\n<li>Have at least <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/role-based-access-control\/role-assignments-portal.md\" rel=\"nofollow noreferrer\">Billing Reader<\/a> access on the subscription where the endpoint is deployed<\/li>\n<\/ul>\n<p>To know the costs estimation<\/p>\n<ol>\n<li><p>In the <a href=\"https:\/\/portal.azure.com\/\" rel=\"nofollow noreferrer\">Azure portal<\/a>, Go to your subscription<\/p>\n<\/li>\n<li><p>Select <strong>Cost Analysis<\/strong> for your subscription.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/W2eaRIO.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a filter to scope data to your Azure Machine learning workspace resource:<\/p>\n<ol>\n<li><p>At the top navigation bar, select <strong>Add filter<\/strong>.<\/p>\n<\/li>\n<li><p>In the first filter dropdown, select <strong>Resource<\/strong> for the filter type.<\/p>\n<\/li>\n<li><p>In the second filter dropdown, select your Azure Machine Learning workspace.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/HEvprph.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a tag filter to show your managed online endpoint and\/or managed online deployment:<\/p>\n<ol>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremlendpoint<\/strong>: &quot;&lt; your endpoint name&gt;&quot;<\/p>\n<\/li>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremldeployment<\/strong>: &quot;&lt; your deployment name&gt;&quot;.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/1aapYGB.png\" alt=\"enter image description here\" \/><\/p>\n<p>Refer  <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-view-online-endpoints-costs.md\" rel=\"nofollow noreferrer\">here <\/a> for more detailed steps<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-29 11:05:01.917 UTC",
        "Answer_score":2.0,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69764100",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39941622,
        "Question_title":"Parallel *apply in Azure Machine Learning Studio",
        "Question_body":"<p>I have just started to get myself acquainted with parallelism in R. <\/p>\n\n<p>As I am planning to use <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow\">Microsoft Azure Machine Learning Studio<\/a> for my project, I have started investigating what <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">Microsoft R Open<\/a> offers for parallelism, and thus, I found <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">this<\/a>, in which it says that parallelism is done under the hood that leverages the benefit of all available cores, without changing the R code. The article also shows some performance benchmarks, however, most of them demonstrate the performance benefit in doing mathematical operations.<\/p>\n\n<p>This was good so far. In addition, I am also interested to know whether it also parallelize the <code>*apply<\/code> functions under the hood or not. I also found these 2 articles that describes how to parallelize <code>*apply<\/code> functions in general:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/www.r-bloggers.com\/quick-guide-to-parallel-r-with-snow\/\" rel=\"nofollow\">Quick guide to parallel R with snow<\/a>: describes facilitating parallelism using <a href=\"https:\/\/cran.r-project.org\/web\/packages\/snow\/snow.pdf\" rel=\"nofollow\"><code>snow<\/code><\/a> package, <code>par*apply<\/code> function family, and <code>clusterExport<\/code>.<\/li>\n<li><a href=\"http:\/\/www.win-vector.com\/blog\/2016\/01\/parallel-computing-in-r\/\" rel=\"nofollow\">A gentle introduction to parallel computing in R<\/a>: using <code>parallel<\/code> package, <code>par*apply<\/code> function family, and binding values to environment.<\/li>\n<\/ol>\n\n<p>So my question is when I will be using <code>*apply<\/code> functions in Microsoft Azure Machine Learning Studio, will that be parallelized under the hood by default, or I need to make use of packages like <code>parallel<\/code>, <code>snow<\/code> etc.?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-09 08:37:36.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|parallel-processing|azure-machine-learning-studio|microsoft-r",
        "Question_view_count":501,
        "Owner_creation_date":"2013-04-11 12:50:40.14 UTC",
        "Owner_last_access_date":"2022-09-24 10:13:30.763 UTC",
        "Owner_reputation":4588,
        "Owner_up_votes":1194,
        "Owner_down_votes":3,
        "Owner_views":453,
        "Answer_body":"<p>Personally, I think we could have marketed MRO a bit differently, without making such a big deal about parallelism\/multithreading. Ah well.<\/p>\n\n<p>R comes with an Rblas.dll\/.so which implements the routines used for linear algebra computations. These routines are used in various places, but one common use case is for fitting regression models. With MRO, we replace the standard Rblas with one that uses the <a href=\"https:\/\/software.intel.com\/en-us\/intel-mkl\" rel=\"noreferrer\">Intel Math Kernel Library<\/a>. When you call a function like <code>lm<\/code> or <code>glm<\/code>, MRO will use multiple threads and optimized CPU instructions to fit the model, which can get you dramatic speedups over the standard implementation.<\/p>\n\n<p>MRO isn't the only way you can get this sort of speedup; you can also compile\/download other BLAS implementations that are similarly optimized. We just make it an easy one-step download.<\/p>\n\n<p>Note that the MKL only affects code that involves linear algebra. It isn't a general-purpose speedup tool; any R code that doesn't do matrix computations won't see a performance improvement. In particular, it won't speed up any code that involves <em>explicit<\/em> parallelism, such as code using the parallel package, SNOW, or other cluster computing tools.<\/p>\n\n<p>On the other hand, it won't <em>degrade<\/em> them either. You can still use packages like parallel, SNOW, etc to create compute clusters and distribute your code across multiple processes. MRO works just like regular CRAN R in this respect. (One thing you might want to do, though, if you're creating a cluster of nodes on the one machine, is reduce the number of MKL threads. Otherwise you risk contention between the nodes for CPU cores, which will degrade performance.)<\/p>\n\n<p>Disclosure: I work for Microsoft.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-09 14:51:38.777 UTC",
        "Answer_score":5.0,
        "Owner_location":"Paderborn, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39941622",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41686871,
        "Question_title":"How to strip HTML from a text column in Azure ML Execute Python Script step",
        "Question_body":"<p>If I have a column of data of type string in an incoming Azure ML dataset that contains HTML tags screwing up my results, how can I remove those tags?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-16 23:50:22.88 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio",
        "Question_view_count":325,
        "Owner_creation_date":"2010-02-03 22:06:04.77 UTC",
        "Owner_last_access_date":"2022-09-20 18:50:23.373 UTC",
        "Owner_reputation":30577,
        "Owner_up_votes":843,
        "Owner_down_votes":32,
        "Owner_views":6460,
        "Answer_body":"<p>Like this:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n  dataframe1[1] = dataframe1['text'].str.replace('&lt;[^&lt;]+?&gt;', ' ', case=False)\n  return dataframe1,\n<\/code><\/pre>\n\n<p>Remember to precede the <code>Execute Python Script<\/code> step with <code>Clean Missing Data<\/code> step and change the action to remove the entire row (if appropriate). This is important because the <code>Execute Python Script<\/code> step cannot return an empty <code>dataframe<\/code>. Only you know your data, in this case.<\/p>\n\n<p>Let me also point out that the <code>Preprocessing Text<\/code> step allows you to apply a Regular Expression. That is another alternative that might be right for your situation.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-01-16 23:50:22.88 UTC",
        "Answer_score":1.0,
        "Owner_location":"Denver, CO",
        "Answer_last_edit_date":"2017-01-17 18:51:32.913 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41686871",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35376910,
        "Question_title":"How to manipulate Azure ML recommendations in published web service by changing the models threshold",
        "Question_body":"<p><strong>The model<\/strong>\nI have designed, trained and published an Azure ML experiment (using a two class decision jungle) as a web service and can call it fine and it returns the expected result (based on a threshold of 0.5). <\/p>\n\n<p><strong>The problem<\/strong>\nHowever I want to manipulate the result returned to provide a result closer to my desired accuracy, precision and recall which don't happen to coincide with the default threshold of 0.5. I can easily do this via the ML studio by visualizing the evaluation results and moving the threshold slider from the center (0.5) to the left or right.<\/p>\n\n<p>I have googled and read many Azure ML documents and tutorials but so far cannot work out how to alter the threshold and return a different scored probability in my trained and published experiment. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-02-13 06:39:29.067 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-01 16:33:53.427 UTC",
        "Question_score":1,
        "Question_tags":"azure|cortana-intelligence|auc|azure-machine-learning-studio",
        "Question_view_count":251,
        "Owner_creation_date":"2013-08-28 05:51:06.15 UTC",
        "Owner_last_access_date":"2022-09-22 00:30:47.157 UTC",
        "Owner_reputation":397,
        "Owner_up_votes":310,
        "Owner_down_votes":6,
        "Owner_views":37,
        "Answer_body":"<p>The score module also returns the result with scored probabilities. I think you can add a simple math operation to compare the scored probability and add a new column or write a simple R script - see the image below with \"apply math operation\" to generate output based on probability exceeding 0.6 instead of 0.5<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/xNAtf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xNAtf.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-02-15 16:41:27.277 UTC",
        "Answer_score":2.0,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35376910",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64816630,
        "Question_title":"AuthenticationException when creating Azure ML Dataset from Azure Data Lake Gen2 Datastore",
        "Question_body":"<p>I have an Azure Data Lake Gen2 with public endpoint and a standard Azure ML instance.\nI have created both components with my user and I am listed as Contributor.<\/p>\n<p>I want to use data from this data lake in Azure ML.<\/p>\n<p>I have added the data lake as a Datastore using Service Principal authentication.<\/p>\n<p>I then try to create a Tabular Dataset using the Azure ML GUI I get the following error:<\/p>\n<p>Access denied\nYou do not have permission to the specified path or file.<\/p>\n<pre><code>{\n  &quot;message&quot;: &quot;ScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by AuthenticationException.\\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID '1f9e329b-2c2c-49d6-a627-91828def284e', request ID '5ad0e715-a01f-0040-24cb-b887da000000'. Error message: [REDACTED]\\n&quot;\n}\n<\/code><\/pre>\n<p>I have tried having our Azure Portal Admin, with Admin access to both Azure ML and Data Lake try the same and she gets the same error.<\/p>\n<p>I tried creating the Dataset using Python sdk and get a similar error:<\/p>\n<pre><code>ExecutionError: \nError Code: ScriptExecution.StreamAccess.Authentication\nFailed Step: 667ddfcb-c7b1-47cf-b24a-6e090dab8947\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by AuthenticationException.\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for 'https:\/\/mydatalake.dfs.core.windows.net\/mycontainer?directory=mydirectory\/csv&amp;recursive=true&amp;resource=filesystem' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID 'a231f3e9-b32b-4173-b631-b9ed043fdfff', request ID 'c6a6f5fe-e01f-0008-3c86-b9b547000000'. Error message: {&quot;error&quot;:{&quot;code&quot;:&quot;AuthorizationPermissionMismatch&quot;,&quot;message&quot;:&quot;This request is not authorized to perform this operation using this permission.\\nRequestId:c6a6f5fe-e01f-0008-3c86-b9b547000000\\nTime:2020-11-13T06:34:01.4743177Z&quot;}}\n| session_id=75ed3c11-36de-48bf-8f7b-a0cd7dac4d58\n<\/code><\/pre>\n<p>I have created Datastore and Datasets of both a normal blob storage and a managed sql database with no issues and I have only contributor access to those so I cannot understand why I should not be Authorized to add data lake. The fact that our admin gets the same error leads me to believe there are some other issue.<\/p>\n<p>I hope you can help me identify what it is or give me some clue of what more to test.<\/p>\n<p>Edit:\nI see I might have duplicated this post: <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>\nI will test that solution and close this post if it works<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-13 06:49:26.337 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-11-13 07:54:31.243 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-active-directory|azure-data-lake|azure-data-lake-gen2|azure-machine-learning-service",
        "Question_view_count":3179,
        "Owner_creation_date":"2010-10-27 16:14:47.393 UTC",
        "Owner_last_access_date":"2022-09-23 13:31:35.43 UTC",
        "Owner_reputation":1010,
        "Owner_up_votes":1344,
        "Owner_down_votes":1,
        "Owner_views":119,
        "Answer_body":"<p>This was actually a duplicate of <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>.<\/p>\n<p>The solution is to give the service principal that Azure ML uses to access the data lake the Storage Blob Data Reader access. And note you have to wait at least some minutes for this to have effect.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-13 09:42:37.303 UTC",
        "Answer_score":4.0,
        "Owner_location":"Oslo, Norge",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64816630",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44285641,
        "Question_title":"Azure ML Python with Script Bundle cannot import module",
        "Question_body":"<p>In Azure ML, I'm trying to execute a Python module that needs to import the module pyxdameraulevenshtein (<a href=\"https:\/\/pypi.python.org\/pypi\/pyxDamerauLevenshtein\" rel=\"nofollow noreferrer\">https:\/\/pypi.python.org\/pypi\/pyxDamerauLevenshtein<\/a>).<\/p>\n\n<p>I followed the usual way, which is to create a zip file and then import it; however for this specific module, it seems to never be able to find it. The error message is as usual:<\/p>\n\n<p><em>ImportError: No module named 'pyxdameraulevenshtein'<\/em><\/p>\n\n<p>Has anyone included this pyxdameraulevenshtein module in Azure ML with success ?<\/p>\n\n<p>(I took the package from <a href=\"https:\/\/pypi.python.org\/pypi\/pyxDamerauLevenshtein\" rel=\"nofollow noreferrer\">https:\/\/pypi.python.org\/pypi\/pyxDamerauLevenshtein<\/a>.)<\/p>\n\n<p>Thanks for any help you can provide,<\/p>\n\n<p>PH<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-05-31 13:05:11.927 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2017-06-01 01:01:55.287 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":2395,
        "Owner_creation_date":"2017-05-31 12:25:57.193 UTC",
        "Owner_last_access_date":"2022-09-01 14:00:42.997 UTC",
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>I viewed the <code>pyxdameraulevenshtein<\/code> module page, there are two packages you can download which include a wheel file for MacOS and a source code tar file. I don't think you can directly use the both on Azure ML, because the MacOS one is just a share library <code>.so<\/code> file for darwin which is not compatible with Azure ML, and the other you need to first compile it.<\/p>\n\n<p>So my suggestion is as below for using <code>pyxdameraulevenshtein<\/code>.<\/p>\n\n<ol>\n<li>First, compile the source code of <code>pyxdameraulevenshtein<\/code> to a DLL file on Windows, please refer to the document for Python <a href=\"https:\/\/docs.python.org\/2\/extending\/windows.html\" rel=\"nofollow noreferrer\">2<\/a>\/<a href=\"https:\/\/docs.python.org\/3\/extending\/windows.html\" rel=\"nofollow noreferrer\">3<\/a> or search for doing this.<\/li>\n<li>Write a Python script using the DLL you compiled to implement your needs, please refer to the SO thread <a href=\"https:\/\/stackoverflow.com\/questions\/252417\/how-can-i-use-a-dll-file-from-python\">How can I use a DLL file from Python?<\/a> for how to use DLL from Python and refer to the Azure offical <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts\" rel=\"nofollow noreferrer\">tutorial<\/a> to write your Python script<\/li>\n<li>Package your Python script and DLL file as a zip file, then to upload the zip file to use it in <code>Execute Python script<\/code> model of Azure ML.<\/li>\n<\/ol>\n\n<p>Hope it helps.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2017-06-01 09:04:30.777 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44285641",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63458904,
        "Question_title":"Azure-ML Deployment does NOT see AzureML Environment (wrong version number)",
        "Question_body":"<p>I've followed the documentation pretty well as outlined <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-custom-docker-image\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<p>I've setup my azure machine learning environment the following way:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\n# Connect to the workspace\nws = Workspace.from_config()\n\nfrom azureml.core import Environment\nfrom azureml.core import ContainerRegistry\n\nmyenv = Environment(name = &quot;myenv&quot;)\n\nmyenv.inferencing_stack_version = &quot;latest&quot;  # This will install the inference specific apt packages.\n\n# Docker\nmyenv.docker.enabled = True\nmyenv.docker.base_image_registry.address = &quot;myazureregistry.azurecr.io&quot;\nmyenv.docker.base_image_registry.username = &quot;myusername&quot;\nmyenv.docker.base_image_registry.password = &quot;mypassword&quot;\nmyenv.docker.base_image = &quot;4fb3...&quot; \nmyenv.docker.arguments = None\n\n# Environment variable (I need python to look at folders \nmyenv.environment_variables = {&quot;PYTHONPATH&quot;:&quot;\/root&quot;}\n\n# python\nmyenv.python.user_managed_dependencies = True\nmyenv.python.interpreter_path = &quot;\/opt\/miniconda\/envs\/myenv\/bin\/python&quot; \n\nfrom azureml.core.conda_dependencies import CondaDependencies\nconda_dep = CondaDependencies()\nconda_dep.add_pip_package(&quot;azureml-defaults&quot;)\nmyenv.python.conda_dependencies=conda_dep\n\nmyenv.register(workspace=ws) # works!\n<\/code><\/pre>\n<p>I have a score.py file configured for inference (not relevant to the problem I'm having)...<\/p>\n<p>I then setup inference configuration<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.model import InferenceConfig\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=myenv)\n<\/code><\/pre>\n<p>I setup my compute cluster:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.compute import ComputeTarget, AksCompute\nfrom azureml.exceptions import ComputeTargetException\n\n# Choose a name for your cluster\naks_name = &quot;theclustername&quot; \n\n# Check to see if the cluster already exists\ntry:\n    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n    print('Found existing compute target')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    prov_config = AksCompute.provisioning_configuration(vm_size=&quot;Standard_NC6_Promo&quot;)\n\n    aks_target = ComputeTarget.create(workspace=ws, name=aks_name, provisioning_configuration=prov_config)\n\n    aks_target.wait_for_completion(show_output=True)\n\nfrom azureml.core.webservice import AksWebservice\n\n# Example\ngpu_aks_config = AksWebservice.deploy_configuration(autoscale_enabled=False,\n                                                    num_replicas=3,\n                                                    cpu_cores=4,\n                                                    memory_gb=10)\n<\/code><\/pre>\n<p>Everything succeeds; then I try and deploy the model for inference:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.model import Model\n\nmodel = Model(ws, name=&quot;thenameofmymodel&quot;)\n\n# Name of the web service that is deployed\naks_service_name = 'tryingtodeply'\n\n# Deploy the model\naks_service = Model.deploy(ws,\n                           aks_service_name,\n                           models=[model],\n                           inference_config=inference_config,\n                           deployment_config=gpu_aks_config,\n                           deployment_target=aks_target,\n                           overwrite=True)\n\naks_service.wait_for_deployment(show_output=True)\nprint(aks_service.state)\n<\/code><\/pre>\n<p>And it fails saying that it can't find the environment. More specifically, my environment version is <strong>version 11<\/strong>, but it keeps trying to find an environment with a version number that is 1 higher (i.e., <strong>version 12<\/strong>) than the current environment:<\/p>\n<pre><code>FailedERROR - Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 0f03a025-3407-4dc1-9922-a53cc27267d4\nMore information can be found here: \nError:\n{\n  &quot;code&quot;: &quot;BadRequest&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;The request is invalid&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;EnvironmentDetailsFetchFailedUserError&quot;,\n      &quot;message&quot;: &quot;Failed to fetch details for Environment with Name: myenv Version: 12.&quot;\n    }\n  ]\n}\n\n<\/code><\/pre>\n<p>I have tried to manually edit the environment JSON to match the version that azureml is trying to fetch, but nothing works. Can anyone see anything wrong with this code?<\/p>\n<h1>Update<\/h1>\n<p>Changing the name of the environment (e.g., <code>my_inference_env<\/code>) and passing it to <code>InferenceConfig<\/code> seems to be on the right track. However, the error now changes to the following<\/p>\n<pre><code>Running..........\nFailed\nERROR - Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: f0dfc13b-6fb6-494b-91a7-de42b9384692\nMore information can be found here: https:\/\/some_long_http_address_that_leads_to_nothing\nError:\n{\n  &quot;code&quot;: &quot;DeploymentFailed&quot;,\n  &quot;statusCode&quot;: 404,\n  &quot;message&quot;: &quot;Deployment not found&quot;\n}\n<\/code><\/pre>\n<h1>Solution<\/h1>\n<p>The answer from Anders below is <strong>indeed correct<\/strong> regarding the use of azure ML environments. However, the last error I was getting was because I was setting the <em>container image<\/em> using the digest value (a sha) and NOT the image name and tag (e.g., <code>imagename:tag<\/code>). Note the line of code in the first block:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv.docker.base_image = &quot;4fb3...&quot; \n<\/code><\/pre>\n<p>I reference the digest value, but it should be changed to<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv.docker.base_image = &quot;imagename:tag&quot;\n<\/code><\/pre>\n<p>Once I made that change, the deployment succeeded! :)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2020-08-17 21:30:27.673 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-09-10 20:59:18.393 UTC",
        "Question_score":3,
        "Question_tags":"azure|azure-aks|azure-sdk-python|azure-machine-learning-service",
        "Question_view_count":1768,
        "Owner_creation_date":"2015-05-23 18:41:30.59 UTC",
        "Owner_last_access_date":"2022-09-18 19:40:34.717 UTC",
        "Owner_reputation":381,
        "Owner_up_votes":48,
        "Owner_down_votes":4,
        "Owner_views":62,
        "Answer_body":"<p>One concept that took me a while to get was the bifurcation of registering and using an Azure ML <code>Environment<\/code>. If you have already registered your env, <code>myenv<\/code>, and none of the details of the your environment have changed, there is no need re-register it with <code>myenv.register()<\/code>. You can simply get the already register env using <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.environment?view=azure-ml-py#get-workspace--name--version-none-\" rel=\"nofollow noreferrer\"><code>Environment.get()<\/code><\/a> like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv = Environment.get(ws, name='myenv', version=11)\n<\/code><\/pre>\n<p>My recommendation would be to name your environment something new: like <code>&quot;model_scoring_env&quot;<\/code>. Register it once, then pass it to the <code>InferenceConfig<\/code>.<\/p>",
        "Answer_comment_count":9.0,
        "Answer_creation_date":"2020-08-17 22:08:41.697 UTC",
        "Answer_score":1.0,
        "Owner_location":"Milwaukee, WI",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63458904",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46523924,
        "Question_title":"Adding python modules to AzureML workspace",
        "Question_body":"<p>I've been working recently on deploying a machine learning model as a web service. I used Azure Machine Learning Studio for creating my own Workspace ID and Authorization Token. Then, I trained LogisticRegressionCV model from <strong>sklearn.linear_model<\/strong> locally on my machine (using python 2.7.13) and with the usage of below code snippet I wanted to publish my model as web service:<\/p>\n\n<pre><code>from azureml import services\n\n@services.publish('workspaceID','authorization_token')\n@services.types(var_1= float, var_2= float)\n@services.returns(int)\n\ndef predicting(var_1, var_2):\n    input = np.array([var_1, var_2].reshape(1,-1)\nreturn model.predict_proba(input)[0][1]\n<\/code><\/pre>\n\n<p>where <em>input<\/em> variable is a list with data to be scored and <em>model<\/em> variable contains trained classifier. Then after defining above function I want to make a prediction on sample input vector:<\/p>\n\n<pre><code>predicting.service(1.21, 1.34)\n<\/code><\/pre>\n\n<p>However following error occurs:<\/p>\n\n<pre><code>RuntimeError: Error 0085: The following error occurred during script \nevaluation, please view the output log for more information:\n<\/code><\/pre>\n\n<p>And the most important message in log is: <\/p>\n\n<pre><code>AttributeError: 'module' object has no attribute 'LogisticRegressionCV'\n<\/code><\/pre>\n\n<p>The error is strange to me because when I was using normal <em>sklearn.linear_model.LogisticRegression<\/em> everything was fine. I was able to make predictions sending POST requests to created endpoint, so I guess <strong>sklearn<\/strong> worked correctly. \nAfter changing to <em>LogisticRegressionCV<\/em> it does not. <\/p>\n\n<p>Therefore I wanted to update sklearn on my workspace.<\/p>\n\n<p>Do you have any ideas how to do it? Or even more general question: how to install any python module on azure machine learning studio in a way to use predict functions of any model I develpoed locally?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-02 10:37:09.737 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|azure|scikit-learn|python-module|azure-machine-learning-studio",
        "Question_view_count":2578,
        "Owner_creation_date":"2016-03-23 16:31:44.64 UTC",
        "Owner_last_access_date":"2022-09-08 12:42:19.317 UTC",
        "Owner_reputation":186,
        "Owner_up_votes":108,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Answer_body":"<p>For installing python module on Azure ML Studio, there is a section <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/cdb56f95-7f4c-404d-bde7-5bb972e6f232\/#Anchor_3\" rel=\"nofollow noreferrer\"><code>Technical Notes<\/code><\/a> of the offical document <code>Execute Python Script<\/code> which introduces it.<\/p>\n\n<p>The general steps as below.<\/p>\n\n<ol>\n<li>Create a Python project via <code>virtualenv<\/code> and active it.<\/li>\n<li>Install all packages you want via <code>pip<\/code> on the virtual Python environment, and then<\/li>\n<li>Package all files and directorys under the path <code>Lib\\site-packages<\/code> of your project as a zip file.<\/li>\n<li>Upload the zip package into your Azure ML WorkSpace as a dataSet.<\/li>\n<li>Follow the offical <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts#importing-existing-python-script-modules\" rel=\"nofollow noreferrer\">document<\/a> to import Python Module for your <code>Execute Python Script<\/code>.<\/li>\n<\/ol>\n\n<p>For more details, you can refer to the other similar SO thread <a href=\"https:\/\/stackoverflow.com\/questions\/46222606\/updating-pandas-to-version-0-19-in-azure-ml-studio\/46232963#46232963\">Updating pandas to version 0.19 in Azure ML Studio<\/a>, it even introduced how to update the version of Python packages installed by Azure.<\/p>\n\n<p>Hope it helps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-10-03 07:03:59.333 UTC",
        "Answer_score":2.0,
        "Owner_location":"Warszawa, Polska",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46523924",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58323029,
        "Question_title":"Azure ML deploy locally: tarfile.ReadError: file could not be opened successfully",
        "Question_body":"<p>I am trying to deploy(local) using this line:<\/p>\n\n<pre><code>local_service = Model.deploy(ws, \"test\", [model], inference_config, deployment_config)\n<\/code><\/pre>\n\n<p>Then I get this output in the terminal:<\/p>\n\n<pre><code>tarfile.ReadError: file could not be opened successfully\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WXbPe.png\" rel=\"nofollow noreferrer\">Screenshot of the output<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-10 12:35:41.163 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|deployment|azure-machine-learning-service",
        "Question_view_count":77,
        "Owner_creation_date":"2019-10-10 10:48:01.987 UTC",
        "Owner_last_access_date":"2020-07-12 09:32:11.983 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>There was a bug with the retry logic when files were being uploaded. That bug has since been fixed, so updating your SDK should fix the issue.<\/p>\n\n<p>Similar post: <a href=\"https:\/\/stackoverflow.com\/questions\/57854136\/registering-and-downloading-a-fasttext-bin-model-fails-with-azure-machine-learn\">Registering and downloading a fastText .bin model fails with Azure Machine Learning Service<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-10 16:46:03.837 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58323029",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30396392,
        "Question_title":"Azure Machine Learning Prediction - Input and Outputs",
        "Question_body":"<p>I am attempting to follow this <a href=\"http:\/\/www.toptal.com\/machine-learning\/predicting-gas-prices-using-azure-machine-learning-studio\" rel=\"nofollow\">tutorial<\/a> however I was attempting to predict MPG for a set of cars rather than oil prices and have the following set up:<\/p>\n\n<ol>\n<li>MPG Sample dataset<\/li>\n<li>Remove missing values, project everything (weight, displacement, cylinders, etc) except model name<\/li>\n<li>Split 75 to train model, 25 to score model<\/li>\n<li>Train model on MPG column with neural network<\/li>\n<li>Score model which is fed by Train Model and Split<\/li>\n<li>Score model is fed to Evaluate model<\/li>\n<\/ol>\n\n<p>This all seems to run fine and without issue, so I create a scoring experiment and then publish it as a web service, however when I attempt to input values it is asking for an MPG input. My understanding is that this would be the predicted value, so it seems somewhat opposite to have to enter this as a value, or am I just understanding a basic tenet of machine learning? <\/p>\n\n<p>In short: Ideally I would like to be able to enter everything but the MPG and get a prediction on what the MPG is for a given set of value.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-05-22 12:11:10.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1527,
        "Owner_creation_date":"2012-11-13 14:28:12.227 UTC",
        "Owner_last_access_date":"2022-09-11 02:26:30.947 UTC",
        "Owner_reputation":2054,
        "Owner_up_votes":1029,
        "Owner_down_votes":99,
        "Owner_views":260,
        "Answer_body":"<p>You could also add project columns to exclude label as part of scoring experiment and connect web service output port to the output of project columns<\/p>",
        "Answer_comment_count":8.0,
        "Answer_creation_date":"2015-05-28 01:58:36.97 UTC",
        "Answer_score":2.0,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30396392",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66704314,
        "Question_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Question_body":"<p>Using Azure Machine Learning CLI extension, how do we get the Model ID for the latest version of a Model (with known model name)?<\/p>\n<p>To get the entire list of Model Details with a given name the command is<\/p>\n<pre><code>az ml model list --model-name [Model_Name] --resource-group [RGP_NAME] --subscription-id [SUB_ID] --workspace-name [WS_NAME]\n<\/code><\/pre>\n<p>Running this will give a list of all the models:<\/p>\n<pre><code>[\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T07:02:03.814172+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:2&quot;\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 3\n  },\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T06:46:34.301054+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:2&quot;,\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 2\n  },\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T06:38:56.558385+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:1&quot;,\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 1\n  }\n]\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest#ext_azure_cli_ml_az_ml_model_list\" rel=\"nofollow noreferrer\">Microsoft Documentation<\/a> mentions, we can use a <code>-l<\/code> parameter to get the latest version details:<\/p>\n<pre><code>az ml model list --model-name [Model_Name] --resource-group [RGP_NAME] --subscription-id [SUB_ID] --workspace-name [WS_NAME] -l\n<\/code><\/pre>\n<p>However, running this gives the following error:<\/p>\n<pre><code>ERROR: UnrecognizedArgumentError: unrecognized arguments: -l\n<\/code><\/pre>\n<p>What is the syntax to use this <code>-l<\/code> flag?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_date":"2021-03-19 07:51:09.54 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":545,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>If we wish to obtain the model-id for the latest model, instead of using <code>az ml model<\/code> list with <code>-l<\/code> flag, using <code>az model show<\/code> will return the details for the latest model. The syntax to get a string for model-id will be:<\/p>\n<pre><code>az ml model show --model-id $(TRN_MODEL_ID) --resource-group $(AML_TRN_RG) --subscription-id $(AML_TRN_SUB_ID) --workspace-name $(AML_TRN_WS) --query name -o tsv\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-03-22 14:35:49.203 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66704314",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72518344,
        "Question_title":"Logging and Fetching Run Parameters in AzureML",
        "Question_body":"<p>I am able to log and fetch metrics to AzureML using Run.log, however, I need a way to also log run parameters, like Learning Rate, or Momentum. I can't seem to find anything in the AzureML Python SDK documentation to achieve this. However, if I use MLflow's mlflow.log_param, I am able to log parameters, and they even nicely show up on the AzureML Studio Dashboard (bottom right of the image):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Again, I am able to fetch this using MLflow's get_params() function, but I can't find a way to do this using just AzureML's Python SDK. Is there a way to do this directly using <code>azureml<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-06 13:22:27.343 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|mlflow|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":73,
        "Owner_creation_date":"2019-04-05 20:51:24.963 UTC",
        "Owner_last_access_date":"2022-09-24 07:41:48.093 UTC",
        "Owner_reputation":438,
        "Owner_up_votes":15,
        "Owner_down_votes":2,
        "Owner_views":120,
        "Answer_body":"<p>The retrieving of log run parameters like <strong>Learning Rate, or Momentum<\/strong> is not possible with <strong>AzureML<\/strong> alone. Because it was tied with <strong>MLFlow<\/strong> and <strong>azureml-core<\/strong>. without those two involvements, we cannot retrieve the log run parameters.<\/p>\n<pre><code>pip install azureml-core mlflow azureml-mlflow\n<\/code><\/pre>\n<p>Need to install these three for getting run parameters. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Link<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-05 05:29:14.31 UTC",
        "Answer_score":1.0,
        "Owner_location":"Hyderabad, Telangana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72518344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40108999,
        "Question_title":"Consume Microsoft Cluster API using PowerBI",
        "Question_body":"<p>Thanks for getting back to me.<\/p>\n\n<p>Basically I subscribed to a Cluster API service (cortana analytics). This is the sample application as per Microsoft Machine Learning site<\/p>\n\n<p><a href=\"http:\/\/microsoftazuremachinelearning.azurewebsites.net\/ClusterModel.aspx\" rel=\"nofollow\">http:\/\/microsoftazuremachinelearning.azurewebsites.net\/ClusterModel.aspx<\/a><\/p>\n\n<p>As you could see there are 2 arguments to be passed on<\/p>\n\n<p>Input<\/p>\n\n<p>K<\/p>\n\n<p>Where input could be 10;5;2,18;1;6,7;5;5,22;3;4,12;2;1,10;3;4 (each row is separated by semi colon)<\/p>\n\n<p>And K is cluster number: 5 (for example)<\/p>\n\n<p>So to consume this API I use PowerBI Edit Query, <\/p>\n\n<p>So go to Get Data > More > Azure > Microsoft Data MarketPlace, I can see the list of APIs I subscribed to, one of them is the one I referred to in the link above.<\/p>\n\n<p>So I load that as Function lets called it \"Score\"<\/p>\n\n<p>Then I got energy table which I loaded in from a csv file, I want to cluster energy consumption into 5 clusters.<\/p>\n\n<p>So my data layout is<\/p>\n\n<p>Year   Energy<\/p>\n\n<p>2001   6.28213<\/p>\n\n<p>2002  14.12845<\/p>\n\n<p>2003   5.55851<\/p>\n\n<p>and so on, lets say I got 100 rows of the data.<\/p>\n\n<p>So I tried to pass \"6.28213;14.12845;5.55851\", \"5\" to Score function but I dont know how to <\/p>\n\n<ol>\n<li><p>Convert my table into records<\/p><\/li>\n<li><p>pass 2 argument records and constant value 5 as K.<\/p><\/li>\n<\/ol>\n\n<p>Hope this makes sense.<\/p>\n\n<p>Please help! :)<\/p>\n\n<p>Thank you in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-18 13:00:01.683 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"api|powerbi|powerquery|azure-machine-learning-studio",
        "Question_view_count":137,
        "Owner_creation_date":"2015-04-01 14:40:03.63 UTC",
        "Owner_last_access_date":"2022-03-26 09:51:33.257 UTC",
        "Owner_reputation":403,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":200,
        "Answer_body":"<p>To convert a column of numbers into a semicolon delimited text, do this to your table:<\/p>\n\n<ol>\n<li>Convert your Energy column is type text.<\/li>\n<li>Add <code>[Energy]<\/code> after the name of your table, which gives you a list of the numbers.<\/li>\n<li>Use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/mt253358.aspx\" rel=\"nofollow\"><code>Text.Combine<\/code><\/a> to turn the list into a text value seperated by <code>;<\/code><\/li>\n<\/ol>\n\n<p>Here's a mashup that does that:<\/p>\n\n<pre><code>let\n    Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(\"NcjBCQAgDAPAXfKWYqKR7iLdfw1F8J63N9Q70bBCKQ5Ue6VbnEHl9L9xz2GniaoD\", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type text) meta [Serialized.Text = true]) in type table [Year = _t, Energy = _t]),\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,{{\"Year\", Int64.Type}, {\"Energy\", type text}}),\n    Custom1 = #\"Changed Type\"[Energy],\n    Custom2 = Text.Combine(Custom1, \";\")\nin\n    Custom2\n<\/code><\/pre>\n\n<hr>\n\n<p>Once you have a function, you'll invoke it like <code>YourFunction(Custum2, 5)<\/code><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-10-19 16:58:20.823 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40108999",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60380154,
        "Question_title":"Upload dataframe as dataset in Azure Machine Learning",
        "Question_body":"<p>after download a dataset, convert to dataframe and manipulate it.. how can I upload again as new dataset in Azure Machine Learning? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-24 16:28:56.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":3736,
        "Owner_creation_date":"2012-09-20 07:41:45.517 UTC",
        "Owner_last_access_date":"2022-09-23 07:35:28.573 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":50,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Answer_body":"<p>You can follow the steps below: <br>\n1. write dataframe to a local file (e.g. csv, parquet)<\/p>\n\n<pre><code>local_path = 'data\/prepared.csv'\ndf.to_csv(local_path)\n<\/code><\/pre>\n\n<ol start=\"2\">\n<li>upload the local file to a datastore on the cloud<\/li>\n<\/ol>\n\n<pre><code># azureml-core of version 1.0.72 or higher is required\n# azureml-dataprep[pandas] of version 1.1.34 or higher is required\nfrom azureml.core import Workspace, Dataset\n\nsubscription_id = 'xxxxxxxxxxxxxxxxxxxxx'\nresource_group = 'xxxxxx'\nworkspace_name = 'xxxxxxxxxxxxxxxx'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n# get the datastore to upload prepared data\ndatastore = workspace.get_default_datastore()\n# upload the local file from src_dir to the target_path in datastore\ndatastore.upload(src_dir='data', target_path='data')\n<\/code><\/pre>\n\n<ol start=\"3\">\n<li>create a dataset referencing the cloud location<\/li>\n<\/ol>\n\n<pre><code>ds = Dataset.Tabular.from_delimited_files(datastore.path('data\/prepared.csv'))\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-02-24 18:30:06.873 UTC",
        "Answer_score":7.0,
        "Owner_location":"Barcelona",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60380154",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30859824,
        "Question_title":"Use Azure Machine learning to detect symbol within an image",
        "Question_body":"<p>4 years ago I posted <a href=\"https:\/\/stackoverflow.com\/q\/6999920\/411094\">this question<\/a> and got a few answers that were unfortunately outside my skill level.  I just attended a build tour conference where they spoke about machine learning and this got me thinking of the possibility of using ML as a solution to my problem.  i found <a href=\"https:\/\/gallery.azureml.net\/MachineLearningAPI\/02ce55bbc0ab4fea9422fe019995c02f\" rel=\"noreferrer\">this<\/a> on the azure site but i dont think it will help me because its scope is pretty narrow.<\/p>\n\n<p>Here is what i am trying to achieve:<\/p>\n\n<p>i have a source image:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/6y76s.jpg\" alt=\"source image\"><\/p>\n\n<p>and i want to which one of the following symbols (if any) are contained in the image above:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/SuHkU.jpg\" alt=\"symbols\"><\/p>\n\n<p>the compare needs to support minor distortion, scaling, color differences, rotation, and brightness differences.<\/p>\n\n<p>the number of symbols to match will ultimately at least be greater than 100.<\/p>\n\n<p>is ML a good tool to solve this problem?  if so, any starting tips?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-06-16 05:58:53.36 UTC",
        "Question_favorite_count":3.0,
        "Question_last_edit_date":"2017-05-23 12:10:45.11 UTC",
        "Question_score":14,
        "Question_tags":"opencv|azure|image-processing|machine-learning|azure-machine-learning-studio",
        "Question_view_count":6324,
        "Owner_creation_date":"2010-08-04 17:41:06.9 UTC",
        "Owner_last_access_date":"2022-09-23 19:56:34.233 UTC",
        "Owner_reputation":1141,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":109,
        "Answer_body":"<p>As far as I know, Project Oxford (MS Azure CV API) wouldn't be suitable for your task. Their APIs are very focused to Face related tasks (detection, verification, etc), OCR and Image description. And apparently you can't extend their models or train new ones from the existing ones.<\/p>\n\n<p>However, even though I don't know an out of the box solution for your object detection problem; there are easy enough approaches that you could try and that would give you some start point results.<\/p>\n\n<p>For instance, here is a naive method you could use:<\/p>\n\n<p><strong>1) Create your dataset:<\/strong>\n    This is probably the more tedious step and paradoxically a crucial one. I will assume you have a good amount of images to work with. What would you need to do is to pick a fixed window size and extract positive and negative examples.\n<img src=\"https:\/\/i.stack.imgur.com\/H4uC5.png\" alt=\"enter image description here\"><\/p>\n\n<p>If some of the images in your dataset are in different sizes you would need to rescale them to a common size. You don't need to get too crazy about the size, probably 30x30 images would be more than enough. To make things easier I would turn the images to gray scale too. <\/p>\n\n<p><strong>2) Pick a classification algorithm and train it:<\/strong>\n    There is an awful amount of classification algorithms out there. But if you are new to machine learning I will pick the one I would understand the most. Keeping that in mind, I would check out logistic regression which give decent results, it's easy enough for starters and have a lot of libraries and tutorials. For instance, <a href=\"http:\/\/blog.yhathq.com\/posts\/logistic-regression-and-python.html\" rel=\"noreferrer\">this one<\/a> or <a href=\"https:\/\/msdn.microsoft.com\/en-us\/magazine\/dn948113.aspx\" rel=\"noreferrer\">this one<\/a>. At first I would say to focus in a binary classification problem (like if there is an UD logo in the picture or not) and when you master that one you can jump to the multi-class case. There are resources for that <a href=\"http:\/\/www.codeproject.com\/Articles\/821347\/MultiClass-Logistic-Classifier-in-Python\" rel=\"noreferrer\">too<\/a> or you can always have several models one per logo and run this recipe for each one separately. <\/p>\n\n<p>To train your model, you just need to read the images generated in the step 1 and turn them into a vector and label them accordingly. That would be the  dataset that will feed your model. If you are using images in gray scale, then each position in the vector would correspond to a pixel value in the range 0-255. Depending on the algorithm you might need to rescale those values to the range [0-1] (this is because some algorithms perform better with values in that range). Notice that rescaling the range in this case is fairly easy (new_value = value\/255).<\/p>\n\n<p>You also need to split your dataset, reserving some examples for training, a subset for validation and another one for testing. Again, there are different ways to do this, but I'm keeping this answer as naive as possible.<\/p>\n\n<p><strong>3) Perform the detection:<\/strong>\n    So now let's start the fun part. Given any image you want to run your model and produce coordinates in the picture where there is a logo. There are different ways to do this and I will describe one that probably <strong>is not the best nor the more efficient<\/strong>, but it's easier to develop in my opinion.<\/p>\n\n<p>You are going to scan the picture, extracting the pixels in a \"window\", rescaling those pixels to the size you selected in step 1 and then feed them to your model. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/VGk3f.png\" alt=\"Extracting windows to feed the model\"><\/p>\n\n<p>If the model give you a positive answer then you mark that window in the original image. Since the logo might appear in different scales you need to repeat this process with different window sizes. You also would need to tweak the amount of space between windows.<\/p>\n\n<p><strong>4) Rinse and repeat:<\/strong>\n    At the first iteration it's very likely that you will get a lot of false positives. Then you need to take those as negative examples and retrain your model. This would be an iterative process and hopefully on each iteration you will have less and less false positives and fewer false negatives.<\/p>\n\n<p>Once you are reasonable happy with your solution, you might want to improve it. You might want to try other classification algorithms like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine\" rel=\"noreferrer\">SVM<\/a> or <a href=\"https:\/\/en.wikipedia.org\/wiki\/Deep_learning\" rel=\"noreferrer\">Deep Learning Artificial Neural Networks<\/a>, or to try better object detection frameworks like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Viola%E2%80%93Jones_object_detection_framework\" rel=\"noreferrer\">Viola-Jones<\/a>. Also, you will probably need to use <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross-validation_%28statistics%29\" rel=\"noreferrer\">crossvalidation<\/a> to compare all your solutions (you can actually use crossvalidation from the beginning). By this moment I bet you would be confident enough that you would like to use OpenCV or another ready to use framework in which case you will have a fair understanding of what is going on under the hood. <\/p>\n\n<p>Also you could just disregard all this answer and go for an OpenCV object detection tutorial like this <a href=\"http:\/\/note.sonots.com\/SciSoftware\/haartraining.html\" rel=\"noreferrer\">one<\/a>. Or take another answer from another question like this <a href=\"https:\/\/stackoverflow.com\/questions\/10168686\/algorithm-improvement-for-coca-cola-can-shape-recognition?rq=1\">one<\/a>. Good luck!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2015-06-16 15:38:50.29 UTC",
        "Answer_score":22.0,
        "Owner_location":"Los Angeles, CA",
        "Answer_last_edit_date":"2017-05-23 12:18:30.023 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30859824",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66785273,
        "Question_title":"How to acces output folder from a PythonScriptStep?",
        "Question_body":"<p>I'm new to <code>azure-ml<\/code>, and have been tasked to make some integration tests for a couple of pipeline steps. I have prepared some input test data and some expected output data, which I store on a <code>'test_datastore'<\/code>. The following example code is a simplified version of what I want to do:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>ws = Workspace.from_config('blabla\/config.json')\nds = Datastore.get(ws, datastore_name='test_datastore')\n\nmain_ref = DataReference(datastore=ds,\n                            data_reference_name='main_ref'\n                            )\n\ndata_ref = DataReference(datastore=ds,\n                            data_reference_name='main_ref',\n                            path_on_datastore='\/data'\n                            )\n\n\ndata_prep_step = PythonScriptStep(\n            name='data_prep',\n            script_name='pipeline_steps\/data_prep.py',\n            source_directory='\/.',\n            arguments=['--main_path', main_ref,\n                        '--data_ref_folder', data_ref\n                        ],\n            inputs=[main_ref, data_ref],\n            outputs=[data_ref],\n            runconfig=arbitrary_run_config,\n            allow_reuse=False\n            )\n<\/code><\/pre>\n<p>I would like:<\/p>\n<ul>\n<li>my <code>data_prep_step<\/code> to run,<\/li>\n<li>have it store some data on the path to my <code>data_ref<\/code>), and<\/li>\n<li>I would then like to access this stored data afterwards outside of the pipeline<\/li>\n<\/ul>\n<p>But, I can't find a useful function in the documentation. Any guidance would be much appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_date":"2021-03-24 16:25:38.18 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-03-28 19:58:35.96 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|great-expectations",
        "Question_view_count":1327,
        "Owner_creation_date":"2016-04-01 11:46:31.443 UTC",
        "Owner_last_access_date":"2022-09-24 15:11:08.35 UTC",
        "Owner_reputation":445,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":96,
        "Answer_body":"<p>two big ideas here -- let's start with the main one.<\/p>\n<h2>main ask<\/h2>\n<blockquote>\n<p>With an Azure ML Pipeline, how can I access the output data of a <code>PythonScriptStep<\/code> outside of the context of the pipeline?<\/p>\n<\/blockquote>\n<h3>short answer<\/h3>\n<p>Consider using <code>OutputFileDatasetConfig<\/code> (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.output_dataset_config.outputdatasetconfig?view=azure-ml-py&amp;viewFallbackFrom=experimental&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">docs<\/a> <a href=\"http:\/\/%20https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines?WT.mc_id=AI-MVP-5003930#use-outputfiledatasetconfig-for-intermediate-data\" rel=\"nofollow noreferrer\">example<\/a>), instead of <code>DataReference<\/code>.<\/p>\n<p>To your example above, I would just change your last two definitions.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>data_ref = OutputFileDatasetConfig(\n    name='data_ref',\n    destination=(ds, '\/data')\n).as_upload()\n\n\ndata_prep_step = PythonScriptStep(\n    name='data_prep',\n    script_name='pipeline_steps\/data_prep.py',\n    source_directory='\/.',\n    arguments=[\n        '--main_path', main_ref,\n        '--data_ref_folder', data_ref\n                ],\n    inputs=[main_ref, data_ref],\n    outputs=[data_ref],\n    runconfig=arbitrary_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>some notes:<\/p>\n<ul>\n<li>be sure to check out how <code>DataPath<\/code>s work. Can be tricky at first glance.<\/li>\n<li>set <code>overwrite=False<\/code> in the `.as_upload() method if you don't want future runs to overwrite the first run's data.<\/li>\n<\/ul>\n<h3>more context<\/h3>\n<p><code>PipelineData<\/code> used to be the defacto object to pass data ephemerally between pipeline steps. The idea was to make it easy to:<\/p>\n<ol>\n<li>stitch steps together<\/li>\n<li>get the data after the pipeline runs if need be (<code>datastore\/azureml\/{run_id}\/data_ref<\/code>)<\/li>\n<\/ol>\n<p>The downside was that you have no control over <em>where<\/em> the pipeline is saved. If you wanted to data for more than just as a baton that gets passed between steps, you could have a <code>DataTransferStep<\/code> to land the <code>PipelineData<\/code> wherever you please after the <code>PythonScriptStep<\/code> finishes.<\/p>\n<p>This downside is what motivated <code>OutputFileDatasetConfig<\/code><\/p>\n<h2>auxilary ask<\/h2>\n<blockquote>\n<p>how might I programmatically test the functionality of my Azure ML pipeline?<\/p>\n<\/blockquote>\n<p>there are not enough people talking about data pipeline testing, IMHO.<\/p>\n<p>There are three areas of data pipeline testing:<\/p>\n<ol>\n<li>unit testing (the code in the step works?<\/li>\n<li>integration testing (the code works when submitted to the Azure ML service)<\/li>\n<li>data expectation testing (the data coming out of the meets my expectations)<\/li>\n<\/ol>\n<p>For #1, I think it should be done outside of the pipeline perhaps as part of a package of helper functions\nFor #2, Why not just see if the whole pipeline completes, I think get more information that way. That's how we run our CI.<\/p>\n<p>#3 is the juiciest, and we do this in our pipelines with the <a href=\"https:\/\/greatexpectations.io\/\" rel=\"nofollow noreferrer\">Great Expectations (GE)<\/a> Python library. The GE community calls these &quot;expectation tests&quot;. To me you have two options for including expectation tests in your Azure ML pipeline:<\/p>\n<ol>\n<li>within the <code>PythonScriptStep<\/code> itself, i.e.\n<ol>\n<li>run whatever code you have<\/li>\n<li>test the outputs with GE before writing them out; or,<\/li>\n<\/ol>\n<\/li>\n<li>for each functional <code>PythonScriptStep<\/code>, hang a downstream <code>PythonScriptStep<\/code> off of it in which you run your expectations against the output data.<\/li>\n<\/ol>\n<p>Our team does #1, but either strategy should work. What's great about this approach is that you can run your expectation tests by just running your pipeline (which also makes integration testing easy).<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-03-24 22:47:56.987 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-03-24 22:56:02.7 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66785273",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40302499,
        "Question_title":"Recommendation API: what is the difference between null results and empty results",
        "Question_body":"<p>In the Azure Recommendation API sample there is a snippet like this:<\/p>\n\n<pre><code>     if (itemSets.RecommendedItemSetInfo != null)\n        {\n            ...\n        }\n        else\n        {\n            Console.WriteLine(\"No recommendations found.\");\n        }\n<\/code><\/pre>\n\n<p>So I assume that nullable recommended set means no recommendations. But what is the case with this set being not nullable but still empty ( as I am having it running the example)?<\/p>\n\n<p>I provided my own usages and catalog files. I have not too many entries there however for i2i recommendations I have results and for u2i there is an empty set.\nAllowColdItemPlacement doesn't change a think here.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-28 09:51:28.96 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|microsoft-cognitive|azure-machine-learning-studio",
        "Question_view_count":130,
        "Owner_creation_date":"2012-11-28 16:00:34.117 UTC",
        "Owner_last_access_date":"2021-02-19 16:07:20.957 UTC",
        "Owner_reputation":393,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>We did not mean to convey a difference in meaning between null recommendations and empty recommendations. I will check why we may be sending two different types of results. Either way, don't treat those two cases as different cases. <\/p>\n\n<p>If you are not getting results for user-to-item recommendations, most likely there was no data for that user when the build was created or the items that the user interacted with do not have enough co-occurrences with other items in the usage.<\/p>\n\n<p>What to do when you get empty recommendations is up to you, you may decide to not show any recommendations, or back-fill with popular items you may want to promote.<\/p>\n\n<p>Thanks!<\/p>\n\n<p>Luis Cabrera\nProgram Manager - Recommendations API.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-11-03 15:27:31.717 UTC",
        "Answer_score":1.0,
        "Owner_location":"Wroc\u0142aw, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40302499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67533091,
        "Question_title":"where are registered models in azure machine learning",
        "Question_body":"<p>I try to use azuremlsdk to deploy a locally trained model (a perfectly valid use case AFIK). I follow <a href=\"https:\/\/cran.r-project.org\/web\/packages\/azuremlsdk\/vignettes\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">this<\/a> and managed to create a ML workspace and register a &quot;model&quot; like so:<\/p>\n<pre><code>library(azuremlsdk)\n\ninteractive_auth &lt;- interactive_login_authentication(tenant_id=&quot;xxx&quot;)\nws &lt;- get_workspace(\n        name = &quot;xxx&quot;, \n        subscription_id = &quot;xxx&quot;, \n        resource_group =&quot;xxx&quot;, \n        auth = interactive_auth\n)\n\nadd &lt;- function(a, b) {\n    return(a + b)\n}\n\nadd(1,2)\n\nsaveRDS(add, file = &quot;D:\/add.rds&quot;)\n\nmodel &lt;- register_model(\n    ws, \n    model_path = &quot;D:\/add.rds&quot;, \n    model_name = &quot;add_model&quot;,\n    description = &quot;An amazing model&quot;\n)\n<\/code><\/pre>\n<p>This seemed to work fine, as I get some nice log messages telling me that the model was registered. For my sanity, I wonder where can I find this registered (&quot;materialised&quot;) model\/object\/function in the Azure UI please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-14 10:49:27.11 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":41,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":"<p>On ml.azure.com, there is a &quot;Models&quot; option on the left-hand blade.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" alt=\"UI Sidebar\" \/><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-05-14 14:13:53.74 UTC",
        "Answer_score":1.0,
        "Owner_location":"Somewhere",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67533091",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60334889,
        "Question_title":"\"No Kernel!\" error Azure ML compute JupyterLab",
        "Question_body":"<p>When using the JupyterLab found within the azure ML compute instance, every now and then, I run into an issue where it will say that network connection is lost. <\/p>\n\n<p>I have confirmed that the computer is still running.\nthe notebook itself can be edited and saved, so the computer\/VM is definitely running\nOf course, the internet is fully functional<\/p>\n\n<p>On the top right corner <em>next to the now blank circle<\/em> it will say \"No Kernel!\"<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-21 08:39:54.26 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":1026,
        "Owner_creation_date":"2015-09-15 16:27:17.953 UTC",
        "Owner_last_access_date":"2022-09-24 06:49:58.907 UTC",
        "Owner_reputation":2272,
        "Owner_up_votes":1340,
        "Owner_down_votes":67,
        "Owner_views":516,
        "Answer_body":"<p>We can't repro the issue, can you help gives us more details? One possibility is that the kernel has bugs and hangs (could be due to extensions, widgets installed) or the resources on the machine are exhausted and kernel dies. What VM type are you using? If it's a small VM you may ran out of resources.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-02-21 22:12:37.643 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60334889",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35631267,
        "Question_title":"Azure ML in \"Execute Python Script\" module :Common table expressions is not supported in sqlite3",
        "Question_body":"<p>I ran into this issue yesterday, while trying to use the same sqlite script I used in \"Apply SQL Transformation\" module in Azure ML, in Sqlite over Python module in Azure ML:<\/p>\n\n<pre><code>with tbl as (select * from t1)\nselect * from tbl\n<\/code><\/pre>\n\n<p>Here is the error I got:<\/p>\n\n<pre><code>[Critical]     Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\n  File \"C:\\server\\invokepy.py\", line 169, in batch\ndata:text\/plain,Caught exception while executing function: Traceback (most recent call last):\n    odfs = mod.azureml_main(*idfs)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 388, in read_sql\n  File \"C:\\temp\\azuremod.py\", line 193, in azureml_main\n    results = pd.read_sql(query,con)\n    coerce_float=coerce_float, parse_dates=parse_dates)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1017, in execute\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1022, in read_sql\n    cursor = self.execute(*args)\n    raise_with_traceback(ex)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1006, in execute\n---------- End of error message from Python  interpreter  ----------\n    cur.execute(*args)\nDatabaseError: Execution failed on sql:  with tbl as (select * from t1)\n                    select * from tbl\n<\/code><\/pre>\n\n<p>and the Python code:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n    import pandas as pd\n    import sqlite3 as lite\n    import sys\n    con = lite.connect('data1.db')\n    con.text_factory = str\n    with con:\n        cur = con.cursor()\n\n        if (dataframe1 is not None):\n            cur.execute(\"DROP TABLE IF EXISTS t1\")\n            dataframe1.to_sql('t1',con)\n        query = '''with tbl as (select * from t1)\n                    select * from tbl'''                      \n        results = pd.read_sql(query,con)    \n\n    return results,\n<\/code><\/pre>\n\n<p>when replacing the query with:<\/p>\n\n<pre><code>select * from t1\n<\/code><\/pre>\n\n<p>It worked as expected.\nAs you probably know, Common table expressions is a key feature in Sqlite, the ability to run recursive code is a \"must have\" in any functional language such as Sqlite.<\/p>\n\n<p>I also tried to run my Python script in Jupyter Notebook in Azure, that also worked as expected.<\/p>\n\n<p>Is it possible we have a different configuration for Sqlite in the Python module than in Jupyter Notebook and in \"Apply SQL Transformation\" module?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-02-25 15:17:01.317 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-03-01 06:14:43.803 UTC",
        "Question_score":2,
        "Question_tags":"python|sqlite|common-table-expression|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":280,
        "Owner_creation_date":"2011-10-31 11:53:18.253 UTC",
        "Owner_last_access_date":"2022-06-28 13:56:00.827 UTC",
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Answer_body":"<p>I reproduced your issue and reviewed the <code>SQL Queries<\/code> doc of <code>pandas.io.sql<\/code> at <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/io.html#sql-queries\" rel=\"nofollow\">http:\/\/pandas.pydata.org\/pandas-docs\/stable\/io.html#sql-queries<\/a>. I tried to use <code>read_sql_query<\/code> to solve it, but failed.<\/p>\n\n<p>According to the <code>pandas<\/code> doc, tt seems that <code>Pandas<\/code> not support the usage for this SQL syntax.<\/p>\n\n<p>Base on my experience and according to your SQL, I tried to do the SQL <code>select * from (select * from t1) as tbl<\/code> instead of your SQL that work for <code>Pandas<\/code>.<\/p>\n\n<p>Hope it helps. Best Regards. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-02-26 11:11:05.183 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35631267",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60720060,
        "Question_title":"ContextualVersionConflict issue with azureml-automl-core in AzureML designer",
        "Question_body":"<p>I am using AutoML called via Custom Python Script module in AzureML designer.\nFor that, I need to install automl packages:<\/p>\n\n<pre><code>os.system(f\"pip install azureml-sdk[automl]==1.0.85 --upgrade\")\n<\/code><\/pre>\n\n<p>It worked correctly, but now when I call automl training I received this error:<\/p>\n\n<pre><code>pkg_resources.ContextualVersionConflict: (azureml-dataprep 1.3.2 (\/azureml-envs\/azureml_8d08fe76aaa5abe0ec642fd2de335a04\/lib\/python3.6\/site-packages), Requirement.parse('azureml-dataprep&lt;1.2.0a,&gt;=1.1.37a'), {'azureml-automl-core'})\n<\/code><\/pre>\n\n<p>Looks like there was an update in azureml-dataprep to version 1.3.2 which is not compatible with azureml-sdk[automl]==1.0.85.<\/p>\n\n<ol>\n<li>Would it be possible to add AutoML packages as default package in AzureML designer?<\/li>\n<li>Would it be possible to update azureml-sdk version in AzureML designer?<\/li>\n<li>Is there any workaround right now?<\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-17 10:03:48.327 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-17 10:50:15.113 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":210,
        "Owner_creation_date":"2015-07-13 07:04:51.48 UTC",
        "Owner_last_access_date":"2022-05-18 13:47:42.557 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Fixed after release new version of AzureML SDK in designer and update script to:<\/p>\n\n<pre><code>os.system(f\"pip install azureml-sdk[automl]==1.4.0 --upgrade\")\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-05-15 06:15:03.107 UTC",
        "Answer_score":0.0,
        "Owner_location":"Brno, \u010cesko",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60720060",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":27987910,
        "Question_title":"Azure Machine Learning - CORS",
        "Question_body":"<p>I've searched for hours for this and can't find a single thing that answers the question. I've created and published a new Azure Machine Learning service, and have created an endpoint. I can call the service using the Postman REST CLient, but accessing it via a JavaScript webpage returns a console log saying that CORS is enabled for the service. Now, for the life of me, I can't figure out how to disable CORS for Azure Machine Learning services. Any help would be much appreciated, thanks!<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":4,
        "Question_creation_date":"2015-01-16 16:00:31.317 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-02-01 16:15:55.233 UTC",
        "Question_score":12,
        "Question_tags":"azure|machine-learning|cors|azure-machine-learning-studio",
        "Question_view_count":3242,
        "Owner_creation_date":"2014-06-28 09:44:15.637 UTC",
        "Owner_last_access_date":"2022-05-29 02:05:51.72 UTC",
        "Owner_reputation":135,
        "Owner_up_votes":36,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>Currently, we don't support disabling CORS on API side but you can either use the above option or you can use the API management service to disable CORS. The links below should help you with this<\/p>\n\n<p>Here are the links: <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/api-management-get-started\/\" rel=\"noreferrer\">step by step<\/a> guide, also this <a href=\"http:\/\/channel9.msdn.com\/Blogs\/AzureApiMgmt\/Last-mile-Security\" rel=\"noreferrer\">video<\/a> on setting headers, and <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn894084.aspx#JSONP\" rel=\"noreferrer\">this doc<\/a> on policies.<\/p>\n\n<p>API Management service allow CORS by enabling it in the API configuration page<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-02 04:31:32.627 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/27987910",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44416344,
        "Question_title":"Azure Machine Learning Studio Custom Module Upload Error 0114 : An item with the same key has already been added",
        "Question_body":"<p>When trying to upload a custom R module to Azure Machine Learning Studio what causes the following error.<\/p>\n\n<blockquote>\n  <p>[ModuleOutput]<\/p>\n<\/blockquote>\n\n<pre><code>\"ErrorId\":\"BuildCustomModuleFailed\",\"ErrorCode\":\"0114\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0114: Custom module build failed with error(s): An item with the same key has already been added.\"}} [ModuleOutput] Error: Error 0114: Custom module build failed with error(s): An item with the same key has already been added. \n<\/code><\/pre>\n\n<p>I have tried renaming the module so a name that does not exists.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-06-07 15:03:41.797 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":75,
        "Owner_creation_date":"2011-09-26 15:52:22.823 UTC",
        "Owner_last_access_date":"2022-09-22 19:57:35.203 UTC",
        "Owner_reputation":8183,
        "Owner_up_votes":598,
        "Owner_down_votes":2,
        "Owner_views":727,
        "Answer_body":"<p>The duplicate key exception is a red herring. <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn962112.aspx\" rel=\"nofollow noreferrer\" title=\"MSDN Module Error Code 0114\">Build error 0114<\/a> is a general error that occurs if there is a system exception while building the custom module. The real issue my module was compressed using the built in compress folder option in the Mac Finder. To fix this compress the file using the command line interface for <code>zip<\/code> in Terminal in the following very specific manner.<\/p>\n\n<blockquote>\n  <p>The following example:<\/p>\n<\/blockquote>\n\n<pre><code>cd ScoredDatasetMetadata\/\nzip ScoredDatasetMetadata *\nmv ScoredDatasetMetadata.zip ..\/\n<\/code><\/pre>\n\n<p>Builds a zip file with the correct file structure.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-06-07 15:03:41.797 UTC",
        "Answer_score":0.0,
        "Owner_location":"Franklin, TN",
        "Answer_last_edit_date":"2017-06-07 16:01:12.47 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44416344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65769868,
        "Question_title":"Where does the Azure Machine ACI Webservice deploy?",
        "Question_body":"<p>When we deploy a model as an ACIWebService in Azure Machine Learning Service, we do not need to specify any <code>deployment_target<\/code>.<\/p>\n<p>According to the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false-\" rel=\"nofollow noreferrer\">AzureML documentation<\/a> for <code>azureml.core.model.model<\/code> class,<\/p>\n<pre><code>deployment_target\nComputeTarget\ndefault value: None\nA ComputeTarget to deploy the Webservice to. As Azure Container Instances has no associated ComputeTarget, leave this parameter as None to deploy to Azure Container Instances.\n<\/code><\/pre>\n<p>What does Microsoft mean by<\/p>\n<blockquote>\n<p>As Azure Container Instances has no associated ComputeTarget<\/p>\n<\/blockquote>\n<p>In which &quot;Compute Target&quot; is an ACIWebService deployed?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-18 06:40:43.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":317,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-overview\" rel=\"nofollow noreferrer\">Azure Container Instances<\/a> itself is the compute platform. It spins up a container in a serverless-fashion.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-18 08:30:55.96 UTC",
        "Answer_score":3.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65769868",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49056593,
        "Question_title":"Convert a datatable string from Azure ML WS to an actual Datatable C# Object?",
        "Question_body":"<p>Basically I'm receiving an output like this from my azure ws output:<\/p>\n\n<pre><code>{\n    'Results': {\n        'WSOutput': {\n            'type': 'table',\n            'value': {\n                'ColumnNames': ['ID', 'Start', 'Ask', 'Not', 'Passed', 'Suggest'],\n                'ColumnTypes': ['Int32', 'Int32', 'Int32', 'Double', 'Int64', 'Int32'],\n                'Values': [['13256025', '25000', '19000', '0.35', '1', '25000']]\n            }\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>The string, as you can see, has the info to create a datatable object. Now, I can't seem to find an easy way to cast it to an actual datatable POCO. I'm able to manually code a parser with Newtonsoft.Json.Linq but there has to be an easier way. <\/p>\n\n<p>Does anybody know how? I can't seem to find anything on the net.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":7,
        "Question_creation_date":"2018-03-01 18:43:02.813 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-03-01 18:47:18.023 UTC",
        "Question_score":2,
        "Question_tags":"c#|azure|datatable|azure-machine-learning-studio",
        "Question_view_count":83,
        "Owner_creation_date":"2011-12-23 15:42:00.387 UTC",
        "Owner_last_access_date":"2022-09-22 11:15:01.067 UTC",
        "Owner_reputation":5211,
        "Owner_up_votes":3857,
        "Owner_down_votes":192,
        "Owner_views":449,
        "Answer_body":"<p>Yes, there is a open source online gernator on the net (<a href=\"http:\/\/jsonutils.com\/\" rel=\"nofollow noreferrer\">http:\/\/jsonutils.com\/<\/a>). Copy paste your result will give you that:<\/p>\n\n<pre><code> public class Value\n    {\n        public IList&lt;string&gt; ColumnNames { get; set; }\n        public IList&lt;string&gt; ColumnTypes { get; set; }\n        public IList&lt;IList&lt;string&gt;&gt; Values { get; set; }\n    }\n\n    public class WSOutput\n    {\n        public string type { get; set; }\n        public Value value { get; set; }\n    }\n\n    public class Results\n    {\n        public WSOutput WSOutput { get; set; }\n    }\n\n    public class Example\n    {\n        public Results Results { get; set; }\n    }\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-03-01 18:45:28.907 UTC",
        "Answer_score":2.0,
        "Owner_location":"Waterloo, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49056593",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57716459,
        "Question_title":"Copying models between workspaces",
        "Question_body":"<p>I am setting up deployment pipelines for our models and I wanted to support this scenario:<\/p>\n\n<ol>\n<li>User registers model in <code>test<\/code> AML workspace in test subscription, checks in deployment code\/configs that references the model version (there is a <code>requirements.txt<\/code>-like file that specifies the model ID - name and version)<\/li>\n<li>Azure DevOps CI is triggered after code checkin to run <code>az ml model deploy<\/code> to a test environment.<\/li>\n<li>User decides after that endpoint works well, wants to deploy to prod. In Azure DevOps, manually invokes a prod pipeline that will use the same checked-in code\/configs (with the same referenced model):\n\n<ul>\n<li>copy the model from the <code>test<\/code> AML workspace to a new registered model in the <code>prod<\/code> AML workspace in a different subscription, <em>with the same version<\/em><\/li>\n<li>run <code>az ml model deploy<\/code> with different variables corresponding to the <code>prod<\/code> env, but using the same checked-in AML code\/configs<\/li>\n<\/ul><\/li>\n<\/ol>\n\n<p>I've looked at the MLOps references but can't seem to figure out how to support step 3 in the above scenario. <\/p>\n\n<p>I thought I could do an <code>az ml model download<\/code> to download the model from the <code>test<\/code> env and register it in the <code>prod<\/code> env. The registration process automatically sets the version number so, e.g. the config that references <code>myModel:12<\/code> is no longer valid since in <code>prod<\/code> the ID is <code>myModel:1<\/code><\/p>\n\n<p>How can I copy the model from one workspace in one subscription to another and preserve the ID?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-29 19:06:50.797 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":515,
        "Owner_creation_date":"2009-09-30 03:04:37.887 UTC",
        "Owner_last_access_date":"2022-09-23 16:14:18.72 UTC",
        "Owner_reputation":153,
        "Owner_up_votes":101,
        "Owner_down_votes":1,
        "Owner_views":111,
        "Answer_body":"<p>You could use model tags to set up your own identifiers that are shared across workspace, and query models with specific tags:<\/p>\n\n<pre><code>az ml model update --add-tag\naz ml model list --tag\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-08-30 18:33:30.65 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seattle, WA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57716459",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56364828,
        "Question_title":"Azure ML - Train a model on segments of the data-set",
        "Question_body":"<p>I could really use some help!<\/p>\n\n<p>The company I work for is made up of 52 very different businesses so I can't predict at the company level but instead need to predict business by business then roll up the result to give company wide prediction.<\/p>\n\n<p>I have written an ML model in studio.azureml.net\nIt works great with a 0.947 Coefficient of Determination, but this is for 1 of the businesses.\nI now need to train the model for the other 51.<\/p>\n\n<p>Is there a way to do this in a single ML model rather than having to create 52 very similar models?<\/p>\n\n<p>Any help would be much appreciated !!!<\/p>\n\n<p>Kind Regards\nMartin<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-29 16:20:52.583 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-06-19 07:48:42.38 UTC",
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":123,
        "Owner_creation_date":"2011-03-18 15:21:15.98 UTC",
        "Owner_last_access_date":"2022-09-12 16:19:34.123 UTC",
        "Owner_reputation":189,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Answer_body":"<p>You can use Ensembles, combining several models to improve predictions. The most direct is stacking when the outputs of all the models are trained on the entire dataset. \nThe method that, I think, corresponds the best to your problem is bagging (bootstrap aggregation). You need to divide the training set into different subsets (each corresponding to a certain business), then train a different model on each subset and combine the result of each classifier. \nAnother way is boosting but it is difficult to implement in Azure ML. \nYou can see an example in <a href=\"https:\/\/gallery.azure.ai\/Experiment\/b6b09fc0c26047e6b4c733ab78a86498\" rel=\"nofollow noreferrer\">Azure ML Gallery<\/a>. <\/p>\n\n<p>Quote from book:<\/p>\n\n<blockquote>\n  <p>Stacking and bagging can be easily implemented in Azure Machine\n  Learning, but other ensemble methods are more difficult. Also, it\n  turns out to be very tedious to implement in Azure Machine Learning an\n  ensemble of, say, more than five models. The experiment is filled with\n  modules and is quite difficult to maintain. Sometimes it is worthwhile\n  to use any ensemble method available in R or Python. Adding more\n  models to an ensemble written in a script can be as trivial as\n  changing a number in the code, instead of copying and pasting modules\n  into the experiment.<\/p>\n<\/blockquote>\n\n<p>You may also have a look at <a href=\"http:\/\/scikit-learn.org\/stable\/modules\/ensemble.html\" rel=\"nofollow noreferrer\">sklearn (Python)<\/a> and caret (R) documentation for further details.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-07 08:46:54.22 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56364828",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50514817,
        "Question_title":"Azure Machine Learning Studio SelectColumnsTransform - how to patch or set web service input parameter?",
        "Question_body":"<p>The sentiment analysis sample at <a href=\"https:\/\/gallery.azure.ai\/Collection\/Twitter-Sentiment-Analysis-Collection-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.azure.ai\/Collection\/Twitter-Sentiment-Analysis-Collection-1<\/a> shows use of Filter Based Feature Selection in the training experiment, which is used to generate a SelectColumnsTransform to be saved and used in the predictive experiment, alongside the trained model. The article at <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-models-and-endpoints-with-powershell\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-models-and-endpoints-with-powershell<\/a> explains how you can programmatically train multiple models on different datasets, save those models and create then patch multiple new endpoints, so that each can be used for scoring using a different model. The same technique can also be used to create and save multiple SelectColumnsTransform outputs, for feature selection specific to a given set of training data. However, the Patch-AmlWebServiceEndpoint does not appear to allow a SelectColumnsTransform in a scoring web service to be amended to use the relevant itransform saved during training. An 'EditableResourcesNotAvailable' message is returned, along with a list of resources that can be edited which includes models but not transformations. In addition, unlike (say) ImportData, a SelectColumnsTransform does not offer any parameters that can be exposed as web service parameters. <\/p>\n\n<p>So, how is it possible to create multiple web service endpoints programmatically that each use different SelectColumnsTransform itransform blobs, such as for a document classification service where each endpoint is based on a different set of training data?<\/p>\n\n<p>Any information much appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-24 17:14:19.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":74,
        "Owner_creation_date":"2018-04-25 12:15:35.683 UTC",
        "Owner_last_access_date":"2020-10-23 11:00:26.277 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>Never mind. I got rid of the SelectColumnsTransform altogether (departing from the example experiment), instead using a R script in the training experiment to save the names of the columns selected, then another R script in the predictive experiment to load those names and remove any other feature columns.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-06-01 15:11:30.43 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50514817",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32884296,
        "Question_title":"Web service input into SQL query into R in Azure ML",
        "Question_body":"<p>I have the following simple setup in Azure ML. <a href=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" alt=\"ML setup\"><\/a> \nBasically the Reader is a SQL query to a DB which returns a vector called Pdelta, which is then passed to the R script for further processing  and the results are then returned back to the web service. The DB query is simple (<code>SELECT Pdelta FROM ...<\/code>) and it works fine. I have set the DB query as a web service paramater as well. <\/p>\n\n<p>Everything seems to work fine, but at the end when i publish it as a web service and test it, it somehow asks for an additional input parameter. The additional parameter gets called <code>PDELTA<\/code>.\n<a href=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am wondering why is this happening, what is it that I am overlooking? I would like to make this web service ask for only one parameter - the SQL query (Delta Query) which would then deliver the Pdeltas. <\/p>\n\n<p>Any ideas or suggestions would be grealty appreciated! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-10-01 09:40:39.63 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-01 16:34:35.24 UTC",
        "Question_score":3,
        "Question_tags":"web-services|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":347,
        "Owner_creation_date":"2015-05-28 16:10:15.467 UTC",
        "Owner_last_access_date":"2018-11-18 20:44:24.587 UTC",
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Answer_body":"<p>You can remove the web service input block and publish the web service without it. That way the Pdelta input will be passed in only from the Reader module.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-10-06 16:13:01.107 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32884296",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69245175,
        "Question_title":"Error in azureml \"Non numeric value(s) were encountered in the target column.\"",
        "Question_body":"<p>I am using Automated ML to run a time series forecasting pipeline.<\/p>\n<p>When the AutoMLStep gets triggered, I get this error: <code>Non numeric value(s) were encountered in the target column<\/code>.<\/p>\n<p>The data to this step is passed through an OutputTabularDatasetConfig, after applying the read_delimited_files() on an OutputFileDatasetConfig. I've inspected the prior step, and the data is comprised of a 'Date' column and a numeric column called 'Place' with +80 observations in monthly frequencies.<\/p>\n<p>Nothing seems to be wrong with the column type or the data. I've also applied a number of techniques on the data prep side e.g. pd.to_numeric(), astype(float) to ensure it is numeric.<\/p>\n<p>I've also tried forcing this through the FeaturizationConfig() <code>add_column_purpose('Place','Numeric')<\/code> but in this case, I get another error: <code>Expected column(s) Place in featurization config's column purpose not found in X.<\/code><\/p>\n<p>Any thoughts on how to solve?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-19 16:41:20.553 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"automl|azure-machine-learning-service",
        "Question_view_count":127,
        "Owner_creation_date":"2014-06-11 05:02:56.833 UTC",
        "Owner_last_access_date":"2022-09-24 23:36:40.86 UTC",
        "Owner_reputation":525,
        "Owner_up_votes":70,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Answer_body":"<p>So a few learnings on this interacting with the stellar Azure Machine Learning engineering team.<\/p>\n<ol>\n<li>When calling the <code>read_delimited_files()<\/code> method, ensure that the output folder does not have many inputs or files. For example, if all intermediate outputs are saved to a common folder, it may read all the prior inputs into this folder, and depending upon the shape of the data, borrow the schema from the first file, or confuse all of them together. This can lead to inconsistencies and errors. In my case, I was dumping many files to the same location, hence this was causing confusion for this method. The fix is either to distinctly mark the output folder (e.g. with a UUID) or give different paths.<\/li>\n<li>The dataframe from <code>read_delimiter_files()<\/code> may treat all columns as object type which can lead to a data type check failure (i.e. label_column needs to be numeric). To mitigate, explictly state the type. For example:<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.data import DataType\nprepped_data = prepped_data.read_delimited_files(set_column_types={&quot;Place&quot;:DataType.to_float()})\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-30 21:36:16.347 UTC",
        "Answer_score":1.0,
        "Owner_location":"Redmond, WA, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69245175",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59328925,
        "Question_title":"Is it possible to speed up local AzureML model deployment?",
        "Question_body":"<p>We want to be able to quickly test changes to <code>entry_script.py<\/code>. We can test minor changes with unit tests but we want to run a model in the context of our other backend pieces, locally. <\/p>\n\n<p>So we run <code>az ml model deploy<\/code> with a deployment config with a <code>computeType<\/code> of <code>LOCAL<\/code>. Non-local deployment is slow, but we were hoping that local deployment would be faster. Unfortunately it isn't. In some cases it can take up to 20 minutes to deploy a model to a local endpoint.<\/p>\n\n<p>Is there a way to speed this up for faster edit-debug loops or a better way of handling this scenario?<\/p>\n\n<p>Few things I was thinking of:<\/p>\n\n<ul>\n<li>I was thinking <code>az ml service update<\/code> could be an option but even that takes a long time.<\/li>\n<li>Editing the file directly in the container is an option, but this is still annoying to manually synchronize with changes in your local filesystem.<\/li>\n<li>I was thinking of a folder mount in the container, but it seems there is some magic AzureML does, for example copying the <code>entry_script.py<\/code> to <code>\/var\/azureml-app\/main.py<\/code>. We could maybe emulate this by creating a <code>dist<\/code> folder locally that matches the layout and mounting that to the container, but I'm not sure if this folder layout would change or there's other things that AzureML does.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-13 19:47:53.653 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-12-16 06:12:31.263 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":339,
        "Owner_creation_date":"2009-09-30 03:04:37.887 UTC",
        "Owner_last_access_date":"2022-09-23 16:14:18.72 UTC",
        "Owner_reputation":153,
        "Owner_up_votes":101,
        "Owner_down_votes":1,
        "Owner_views":111,
        "Answer_body":"<p>Please follow the below notebook, If you want to test deploying a model rapidly you should check out \n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/deployment\/deploy-to-local\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/deployment\/deploy-to-local<\/a><\/p>\n\n<p>the SDK enables building and running the docker locally and updating in place as you iterate on your script to save time.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-12-16 11:53:02.733 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seattle, WA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59328925",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46797468,
        "Question_title":"Incorrect neural network schema in training output",
        "Question_body":"<p>I'm training a model in Azure ML Studio and the Net# specification I'm using doesn't match the NET# specification in the training output.<\/p>\n\n<p>Here's my experiment - <a href=\"https:\/\/i.stack.imgur.com\/WFMGs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WFMGs.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and here are my NN params - <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/sVzcA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sVzcA.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and finally here is the NET# specification in the Hyperparams output -<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ehImq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ehImq.png\" alt=\"enter image description here\"><\/a>\nIt's not using two hidden layers and it's also using sigmoid instead of ReLu. Is this expected behavior?<\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-10-17 19:06:41.98 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":36,
        "Owner_creation_date":"2010-05-17 19:24:54.967 UTC",
        "Owner_last_access_date":"2022-01-17 19:08:54.253 UTC",
        "Owner_reputation":655,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Answer_body":"<p>There is an issue with using custom NET# and parameter sweeps together: it switches over to using the default fully connected topology. <\/p>\n\n<p>Unfortunately, the workaround is to train the model for each parameter value separately.  <\/p>\n\n<p>-Roope  <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-10-18 14:25:07.887 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46797468",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39150834,
        "Question_title":"probability on azure recommendations api",
        "Question_body":"<p>I am using the azure recommendation api on <a href=\"http:\/\/recommendations.azurewebsites.net\/\" rel=\"nofollow noreferrer\">http:\/\/recommendations.azurewebsites.net\/<\/a>.\nI prepared the catalog to be like <code>&lt;Item Id&gt;<\/code>, <code>&lt;Item Name&gt;<\/code>, <code>&lt;Item Category&gt;<\/code>, <code>&lt;Features list&gt;<\/code> and the usage file : <code>&lt;userId&gt;<\/code>, <code>&lt;ItemId&gt;<\/code>.\nNow when I test the recommender, I always get a probability of 0.5 for all items, so I had to presume something is not right.\nIn order to know what's the problem I added two items to the catalog \none with same features as an other item but with different name and id,\nand an other item with different id and one different feature.\nI still get the 0.5 probability and now i'm sure something is not right but I still can figure out what the problem.<\/p>\n\n<p>here is a screenshot of what I get when I add the item to the cart<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/zhwiq.png\" alt=\"\"><\/p>\n\n<p>Is there any possibility to use the azure ml matchbox recommender with features and without ratings? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-08-25 16:54:45.38 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-04-02 12:27:40.303 UTC",
        "Question_score":0,
        "Question_tags":"recommendation-engine|azure-machine-learning-studio",
        "Question_view_count":98,
        "Owner_creation_date":"2015-11-11 15:15:48.3 UTC",
        "Owner_last_access_date":"2022-09-21 14:00:23.953 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":61,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":"<p>Tayehi, <\/p>\n\n<p>Nice to meet you. I am the program manager in charge of the recommendations API.\n2 things:<\/p>\n\n<ol>\n<li><p>If you get a 0.5 probability you are most likely getting \"default recommendations\". This usually means that you do not have enough training data or that there are not enough co-occurrences for the item you are testing in the data. To describe the extreme case, imagine an item A that only gets purchased with an item B only one or two times -- it would be hard to say with confidence (statistical significance) that someone that likes item A is also likely to like item B.<\/p><\/li>\n<li><p>It looks like you are still using the old recommendations API. I would like to encourage you to use our newer version (the Recommendations API cognitive service). Please take a look at <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to\" rel=\"nofollow\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to<\/a> help you in this process.<\/p><\/li>\n<\/ol>\n\n<p>Thanks!\nLuis Cabrera\nCortana Intelligence Applications.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-13 15:40:08.683 UTC",
        "Answer_score":0.0,
        "Owner_location":"Tunis, Gouvernorat de Tunis, Tunisie",
        "Answer_last_edit_date":"2016-10-14 20:13:37.407 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39150834",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30133814,
        "Question_title":"How to build an image classification dataset in Azure?",
        "Question_body":"<p>I've a set of images that have a single classification of OPEN (they show something that is open).  I couldn't find a way to directly add a status of open to the image reader dataset so I have FULL OUTER JOIN-ed a single ENTER DATA to an IMAGE READER as per the following.  This seems like a hack, does anyone know the \"right\" way to do this?\n<img src=\"https:\/\/i.stack.imgur.com\/Kt1Rv.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2015-05-08 22:33:55.077 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2015-10-30 08:06:38.65 UTC",
        "Question_score":16,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1403,
        "Owner_creation_date":"2011-12-02 22:06:32.97 UTC",
        "Owner_last_access_date":"2022-09-24 11:04:39.013 UTC",
        "Owner_reputation":373,
        "Owner_up_votes":119,
        "Owner_down_votes":4,
        "Owner_views":34,
        "Answer_body":"<p>Another way is to have R or python code that replicates the status for each image and then use add-columns. I think R\/Python code to just replicate the status for each image may be easier and faster than outer join.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2015-05-17 18:13:01.62 UTC",
        "Answer_score":5.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30133814",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46500756,
        "Question_title":"Azure ML Studio workspace from 3rd party does not show up in workspace list on https:\/\/studio.azureml.net\/",
        "Question_body":"<p>I have had a few azure ml workspaces though my own Azure account for a while. Recently I was added as \"Contributor\" to a new Azure workspace as Contributor. In Azure Portal I can see it clearly and have access to it. When going to <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> It does not show up in the list of workspaces of the correct region, nor in any other region. <\/p>\n\n<p>In Azure Portal I have to change \"Directory\" (top right account menu) to the 3rd party directory to see it.<\/p>\n\n<p>Is there a way to do that in azureml.net ? Or is there something else that might be wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-09-30 07:54:42.96 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":56,
        "Owner_creation_date":"2014-06-19 13:45:10.317 UTC",
        "Owner_last_access_date":"2020-08-26 08:34:48.713 UTC",
        "Owner_reputation":383,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":36,
        "Answer_body":"<p>access to the workspace is controlled by the workspace owner from the settings page inside of the Azure ML workspace. the owners\/contributors etc. listed in Azure portal does NOT grant you access to the workspace. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-10-02 01:19:53.29 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46500756",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73166561,
        "Question_title":"Error while defining sampling algorithm in hyper parameter tuning using random sampling - Version V1",
        "Question_body":"<p>I am trying to perform the random sampling to accomplish the hyper parameter tuning and tuning parameter version 1 (v1). I would like to get the chance to define the algorithm as sampling algorithm explicitly.<\/p>\n<p>Currently using the below code block and is there any chance of implementing explicitly defining sampling in V1? If not, any specific procedure to solve the issue is helpful.<\/p>\n<pre><code>from azureml.train.hyperdrive import RandomParameterSampling\nfrom azureml.train.hyperdrive import normal, uniform, choice\nparam_sampling = RandomParameterSampling( {\n        &quot;learning_rate&quot;: normal(10, 3),\n        &quot;keep_probability&quot;: uniform(0.05, 0.1),\n        &quot;batch_size&quot;: choice(16, 32, 64, 128)\n    }\n)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-29 12:13:14.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":34,
        "Owner_creation_date":"2022-04-27 21:21:09.217 UTC",
        "Owner_last_access_date":"2022-08-17 18:50:07.473 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":"<p>There is an explicit procedure called a <strong>sweep job<\/strong>. This sweep job in <strong>hyperparameter value<\/strong>. We can mention the random sampling using the sweep job explicitly.<\/p>\n<p>From azure.ai.ml.sweep import Normal, Uniform, RandomParameterSampling<\/p>\n<pre><code>Command_job_for_sweep = command_job(\n    learning_rate = Normal(mu=value, sigma=value),\n    keep_probability=Uniform(min_value= your value, max_value= value),\n    batch_size = Choice(value=[.your values in list]),\n)\n\nSweep_job = command_job_sweep.sweep(\n    Computer =\u201dcluster\u201d,\n    sampling_algorithm=\u201drandom\u201d,\n    ....\n)\n<\/code><\/pre>\n<p>This will be available in <strong>version 2 (v2)<\/strong> of hyperparameter tuning in random sampling.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-29 13:07:07.59 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73166561",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52705769,
        "Question_title":"Azure ML Tune Model Hyper Parameters",
        "Question_body":"<p>Here's question proposed at the end of the chapter in 70-774 exam reference book. <\/p>\n\n<blockquote>\n  <p>If you connect a neural network with a Tune Model Hyperparameters module configured\n  with Random Sweep and Maximum number of runs on random sweep = 1, how\n  many neural networks are trained during the execution of the experiment? Why? If you\n  connect a validation dataset to the third input of the Tune Model Hyperparameters\n  module, how many neural networks are trained now?<\/p>\n<\/blockquote>\n\n<p>And the answer is :<\/p>\n\n<blockquote>\n  <p>Without validation dataset 11 (10 of k-fold cross validation + 1 trained with all the data\n  with the best combination of hyperparameters). With the validation set only 1 neural\n  network is trained, so the best model is not trained using the validation set if you provide\n  it.<\/p>\n<\/blockquote>\n\n<p>Where does 10 come from? As far as I understand the number should be 2 and 1 respectively. Shouldn't it create n-folds where n is equal to the number of runs?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-08 15:39:36.61 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"machine-learning|neural-network|azure-machine-learning-studio",
        "Question_view_count":329,
        "Owner_creation_date":"2018-06-12 08:07:17.107 UTC",
        "Owner_last_access_date":"2022-08-10 15:40:49.397 UTC",
        "Owner_reputation":610,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":203,
        "Answer_body":"<p>When you use the Tune Model Hyperparameters module without a validation dataset, this means, when you use only the 2nd input data port, the module works in cross-validation mode. So the best-parameters model is found by doing cross-validation over the provided dataset, and to do this, the dataset is splitted in k-folds. By default, the module splits the data in 10 folds. In case you want to split the data in a different number of folds, you can connect a Partition and Sample module at the 2nd input, selecting Assign to Folds and indicating the number of folds desired. In many cases k=5 is a reasonable option.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-10-10 20:12:16.323 UTC",
        "Answer_score":3.0,
        "Owner_location":"Paris, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52705769",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62780977,
        "Question_title":"Threshold for allowed amount of failed Hyperdrive runs",
        "Question_body":"<p>Because &quot;reasons&quot;, we know that when we use <code>azureml-sdk<\/code>'s <code>HyperDriveStep<\/code> we expect a number of <code>HyperDrive<\/code> runs to fail -- normally around 20%. How can we handle this without failing the entire <code>HyperDriveStep<\/code> (and then all downstream steps)? Below is an example of the pipeline.<\/p>\n<p>I thought there would be an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriverunconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>HyperDriveRunConfig<\/code><\/a> param to allow for this, but it doesn't seem to exist. Perhaps this is controlled on the Pipeline itself with the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline(class)?view=azure-ml-py#remarks\" rel=\"nofollow noreferrer\"><code>continue_on_step_failure<\/code><\/a> param?<\/p>\n<p>The workaround we're considering is to catch the failed run within our <code>train.py<\/code> script and manually log the primary_metric as zero.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-07 17:41:09.73 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-07 21:59:41.91 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":185,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>thanks for your question.<\/p>\n<p>I'm assuming that HyperDriveStep is one of the steps in your Pipeline and that you want the remaining Pipeline steps to continue, when HyperDriveStep fails, is that correct?\nEnabling continue_on_step_failure, should allow the rest of the pipeline steps to continue, when any single steps fails.<\/p>\n<p>Additionally, the HyperDrive run consists of multiple child runs, controlled by the HyperDriveConfig. If the first 3 child runs explored by HyperDrive fail (e.g. with user script errors), the system automatically cancels the entire HyperDrive run, in order to avoid further wasting resources.<\/p>\n<p>Are you looking to continue other Pipeline steps when the HyperDriveStep fails? or are you looking to continue other child runs within the HyperDrive run, when the first 3 child runs fail?<\/p>\n<p>Thanks!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-07-07 20:47:43.553 UTC",
        "Answer_score":2.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62780977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50133056,
        "Question_title":"Add a column in Microsoft Azure ML Studio",
        "Question_body":"<p>I'm playing around with Azure ML Studio. Now I would like to add a new column in my dataset to calculate and in a further step to cluster my data. What's the best way to do it? I tried to add a column with sql (alter table) but it didn't work.<\/p>\n\n<p>btw. the \"add columns\" function only adds columns from another dataset...<\/p>\n\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-02 11:01:17.877 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":517,
        "Owner_creation_date":"2016-05-14 16:15:10.133 UTC",
        "Owner_last_access_date":"2018-05-04 08:27:32.183 UTC",
        "Owner_reputation":15,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":"<p>The \"Apply SQL Transformation\" module should be able to do it. For example, I have a dataset with an <em>age<\/em> column and here's the SQL to create another column called <em>double_age<\/em>:<\/p>\n\n<pre><code>select age, age * 2 as double_age from t1;\n<\/code><\/pre>\n\n<p>Which produces a dataset with just the <em>age<\/em> and <em>double_age<\/em> columns:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/uZblo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uZblo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-05-02 12:47:42.093 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50133056",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36125274,
        "Question_title":"Refresh the dataset in Azure machine learning",
        "Question_body":"<p>I have an experiment (exp) which is published as a web service (exp [Predictive Exp.])  in the azure machine learning studio, the data used by this experiment was pushed by R using AzureML package<\/p>\n\n<pre><code>library(AzureML)\n\nws &lt;- workspace(\n  id = 'xxxxxxxxx',\n  auth = 'xxxxxxxxxxx'\n)\n\nupload.dataset(data_for_azure, ws, \"data_for_azure\")\n<\/code><\/pre>\n\n<p>The above thing worked, but lets say I want to update the dataset(same schema just added more rows)<\/p>\n\n<p>I tired this but this does not work:<\/p>\n\n<pre><code>delete.datasets(ws, \"data_for_azure\")\n\nrefresh(ws, what = c(\"everything\", \"data_for_azure\", \"exp\", \"exp [Predictive Exp.]\")) \n<\/code><\/pre>\n\n<p>I get the error stating the following:<\/p>\n\n<pre><code>Error: AzureML returns error code:\nHTTP status code : 409\nUnable to delete dataset due to lingering dependants\n<\/code><\/pre>\n\n<p>I went through the documentation, and I know that a simple refresh is not possible(same name), the only alternative I see is to delete the web service and perform everything again<\/p>\n\n<p>Any solution will be greatly helped!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-21 07:29:33.34 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-21 13:32:55.057 UTC",
        "Question_score":1,
        "Question_tags":"r|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1196,
        "Owner_creation_date":"2014-07-25 05:27:39.94 UTC",
        "Owner_last_access_date":"2022-09-15 08:56:29.147 UTC",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Answer_body":"<p>From the R doc.<\/p>\n\n<blockquote>\n  <p>The AzureML API does not support uploads for <em>replacing<\/em> datasets with\n  new data by re-using a name. If you need to do this, first delete the\n  dataset from the AzureML Studio interface, then upload a new version.<\/p>\n<\/blockquote>\n\n<p>Now, I think this is particular for the R sdk, as the Python SDK, and the AzureML Studio UI lets you upload a new dataset. Will check in with the R team about this.<\/p>\n\n<p>I would recommend uploading it as a new dataset with a new name, and then replacing the dataset in your experiment with this new dataset. Sorry this seem's round about, but I think is the easier option.<\/p>\n\n<p>Unless you want to upload the new version using the AzureML Studio, in which case go to +NEW, Dataset, select your file and select the checkbox that says this is an existing dataset. The filename should be the same. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-03-21 13:32:42.307 UTC",
        "Answer_score":1.0,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36125274",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70929123,
        "Question_title":"AzureMLCompute job failed with `FailedLoginToImageRegistry`",
        "Question_body":"<p>I've been trying to send a train job through azure ml python sdk with:<\/p>\n<pre><code>from azureml.core import Workspace, Experiment, ScriptRunConfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='ConstructionTopicsModel')\n\n    config = ScriptRunConfig(source_directory='.\/',\n                         script='src\/azureml\/train.py',\n                         arguments=None,\n                         compute_target='ComputeTargetName',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=True)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>But I was getting the <code>ServiceError<\/code> message:<\/p>\n<pre><code>AzureMLCompute job failed. FailedLoginToImageRegistry: Unable to login to docker image repo\nReason: Failed to login to the docker registry\nerror: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nserviceURL: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nReason: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>I also tried using the azure cli without success, same error message<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-31 16:08:50.913 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":202,
        "Owner_creation_date":"2020-05-12 14:25:08.567 UTC",
        "Owner_last_access_date":"2022-09-20 13:49:41.073 UTC",
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Answer_body":"<p>The only way I've found so far to make this work, was to run it on a terminal of the compute-target itself. That's how the docker error goes away. Trying to run the experiment from a terminal of a different compute instance raises the exception.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-31 16:08:50.913 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70929123",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39652384,
        "Question_title":"How can I import into Azure machine learning studio from azure table storage with ODATA query?",
        "Question_body":"<p>The Import Data module for Azure Table documention can be found here: <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/mt674699\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/mt674699<\/a><\/p>\n\n<p>In there it mentions that:<\/p>\n\n<blockquote>\n  <p>The Import Data module does not support filtering as data is being read. The exception is reading from data feeds, which sometimes allow you to specify a filter condition as part of the feed URL.<\/p>\n<\/blockquote>\n\n<p>There is a large amount of data in our table storage and it is not feasible to re-download the entire data set each time we run the experiment. I'm aware that there is the option to cache the data, however there is new data constantly being inserted and we would like to be able to use the new data whenever the experiment is run.<\/p>\n\n<p>Is there an alternative to the Import Data module that we could use to get table storage data with an ODATA query instead?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-09-23 03:59:43.637 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-table-storage|azure-machine-learning-studio",
        "Question_view_count":324,
        "Owner_creation_date":"2015-12-20 22:57:46.693 UTC",
        "Owner_last_access_date":"2020-12-29 19:40:03.983 UTC",
        "Owner_reputation":802,
        "Owner_up_votes":30,
        "Owner_down_votes":1,
        "Owner_views":152,
        "Answer_body":"<p>There is no generic way to incrementally update a dataset. <\/p>\n\n<p>However, depending on what you want to do with the data, there are different options for adding new data:<\/p>\n\n<p>The Add Rows module effectively concatenates two datasets. So you could use the old, cached dataset on the left-hand input and add the new data on the right-hand input. That way you only have to read in the new data.\nHowever, you would have to create some complex logic for figuring out which rows were new and old, and then maintain that outside Azure ML.<\/p>\n\n<p>You could create an OData feed based on table storage, to enable filtering and get the new data that way. Just be aware that right now only public feeds are supported. And you would have to use Join or Add Rows to recombine the old and new data as described above. <\/p>\n\n<p>You might also look into ways of using the <a href=\"https:\/\/blog.maartenballiauw.be\/post\/2012\/10\/08\/what-partitionkey-and-rowkey-are-for-in-windows-azure-table-storage.html\" rel=\"nofollow\">table names<\/a>, partitions, and rowkeys to chunk your data. <\/p>\n\n<p>If you are retraining a model and you want to update your feature statistics, the <a href=\"https:\/\/msdn.microsoft.com\/library\/dn913056.aspx\" rel=\"nofollow\">Learning with Counts<\/a> modules support incremental updates of count-based features. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-09-24 01:03:09.117 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brisbane, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39652384",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69768602,
        "Question_title":"How to output data to Azure ML Batch Endpoint correctly using python?",
        "Question_body":"<p>When invoking Azure ML Batch Endpoints (creating jobs for inferencing), the run() method should return a pandas DataFrame or an array as explained <a href=\"https:\/\/i.stack.imgur.com\/azJDX.png\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<p>However this example shown, doesn't represent an output with headers for a csv, as it is often needed.<\/p>\n<p>The first thing I've tried was to return the data as a <em>pandas DataFrame<\/em> and the result is just a simple csv with a single column and without the headers.<\/p>\n<p>When trying to pass the values with several columns and it's corresponding headers, to be later saved as csv, as a result, I'm getting awkward square brackets (representing the lists in python) and the apostrophes (representing strings)<\/p>\n<p>I haven't been able to find documentation elsewhere, to fix this:\n<a href=\"https:\/\/i.stack.imgur.com\/azJDX.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/azJDX.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-29 12:06:32.96 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|batch-processing|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":295,
        "Owner_creation_date":"2020-05-12 14:25:08.567 UTC",
        "Owner_last_access_date":"2022-09-20 13:49:41.073 UTC",
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Answer_body":"<p>This is the way I found to create a clean output in csv format using python, from a batch endpoint invoke in AzureML:<\/p>\n<pre><code>def run(mini_batch):\n    batch = []\n    for file_path in mini_batch:\n        df = pd.read_csv(file_path)\n        \n        # Do any data quality verification here:\n        if 'id' not in df.columns:\n            logger.error(&quot;ERROR: CSV file uploaded without id column&quot;)\n            return None\n        else:\n            df['id'] = df['id'].astype(str)\n\n        # Now we need to create the predictions, with previously loaded model in init():\n        df['prediction'] = model.predict(df)\n        # or alternative, df[MULTILABEL_LIST] = model.predict(df)\n\n        batch.append(df)\n\n    batch_df = pd.concat(batch)\n\n    # After joining all data, we create the columns headers as a string,\n    # here we remove the square brackets and apostrophes:\n    azureml_columns = str(batch_df.columns.tolist())[1:-1].replace('\\'','')\n    result = []\n    result.append(azureml_columns)\n\n    # Now we have to parse all values as strings, row by row, \n    # adding a comma between each value\n    for row in batch_df.iterrows():\n        azureml_row = str(row[1].values).replace(' ', ',')[1:-1].replace('\\'','').replace('\\n','')\n        result.append(azureml_row)\n\n    logger.info(&quot;Finished Run&quot;)\n    return result\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-29 12:06:32.96 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-11-30 10:09:45.653 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69768602",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54003442,
        "Question_title":"Azure Machine Learning Studio training 24 hour timeout",
        "Question_body":"<p>I'm a newbie trying out Azure's Machine Learning (ML) Studio module. I own a standard subscription level account which grants me an experimental duration of \"Up to 7 days per experiment with a maximum of 24 hours per module\" according to the <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning-studio\/\" rel=\"nofollow noreferrer\">ML Studio's pricing site<\/a>.<\/p>\n\n<p>However, since my dataset is extremely large, I would need a much longer training duration than the allocated 24 hours (I have tried and it timeout-ed even with the simplest NN architecture). Is there workaround for this issue? <\/p>\n\n<p>Thank you in advance. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-02 08:47:44.137 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":228,
        "Owner_creation_date":"2016-02-17 08:01:02.413 UTC",
        "Owner_last_access_date":"2022-06-12 13:02:55.067 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":2,
        "Owner_down_votes":1,
        "Owner_views":46,
        "Answer_body":"<p>I would suggest to stop using <code>Azure Machine Learning Studio<\/code> and switch to \"real\" Azure ML with <code>Azure Machine Learning Services<\/code>, where you will have much more control on your compute needs.<\/p>\n\n<p>Azure ML Studio roadmap is really limited and the purpose of this solution was to help people coming to Machine Learning. If you have a real use-case, use Azure Machine Learning Services.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-01-02 10:00:09.8 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54003442",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72166808,
        "Question_title":"OpenCV issue while using DNN implementation with any version in Machine Learning Services",
        "Question_body":"<p>I am using Machine Learning Services and when I am trying to implement Deep Neural Network, I am getting CV2 issue. The CV2 library is being bothering the code block. The following is the error I am getting when I am trying to use CV2 for DNN_BACKEND_CUDA.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/hTSXM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hTSXM.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Any help is appreciable.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2022-05-09 03:50:34.317 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-09 10:31:18.25 UTC",
        "Question_score":1,
        "Question_tags":"python|opencv|computer-vision|azure-machine-learning-service",
        "Question_view_count":86,
        "Owner_creation_date":"2022-04-27 21:21:09.217 UTC",
        "Owner_last_access_date":"2022-08-17 18:50:07.473 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":"<p>The issue raised is very rare and there are less chances of getting the success rate even after the proper installation of libraries. When the code was deployed in Azure Machine Learning some of the issues might be resolved. Checkout the following steps to be taken care of:<\/p>\n<ol>\n<li>Check with the version of Open CV<\/li>\n<\/ol>\n<p><code>import cv2<\/code><\/p>\n<p><code>cv2.__version__<\/code><\/p>\n<ol start=\"2\">\n<li>After installation, implement the following steps<\/li>\n<\/ol>\n<p>these steps are very much time taking.<\/p>\n<pre><code>%cd \/content\n!git clone https:\/\/github.com\/opencv\/opencv\n!git clone https:\/\/github.com\/opencv_contrib\n!mkdir \/content\/build\n%cd \/content\/build\n!cmake -DOPENCV_EXTRA_MODULES_PATH=\/content\/opencv_contrib\/modules  -DBUILD_SHARED_LIBS=OFF  -DBUILD_TESTS=OFF  -DBUILD_PERF_TESTS=OFF -DBUILD_EXAMPLES=OFF -DWITH_OPENEXR=OFF -DWITH_CUDA=ON -DWITH_CUBLAS=ON -DWITH_CUDNN=ON -DOPENCV_DNN_CUDA=ON \/content\/opencv\n!make -j8 install\n<\/code><\/pre>\n<ol start=\"3\">\n<li>Check the version of Open CV again.<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-05-09 04:51:23.273 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72166808",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37363883,
        "Question_title":"Azure Machine learning - Strip top X rows from dataset",
        "Question_body":"<p>I have a plain text csv file, which i am trying to read in Azure ML studio - the file format is pretty much like this<\/p>\n\n<pre><code>Geolife trajectory\nWGS 84\nAltitude is in Feet\nReserved 3\n0,2,255,My Track,0,0,2,8421376\n0\n39.984702,116.318417,0,492,39744.1201851852,2008-10-23,02:53:04\n39.984683,116.31845,0,492,39744.1202546296,2008-10-23,02:53:10\n39.984686,116.318417,0,492,39744.1203125,2008-10-23,02:53:15\n39.984688,116.318385,0,492,39744.1203703704,2008-10-23,02:53:20\n39.984655,116.318263,0,492,39744.1204282407,2008-10-23,02:53:25\n39.984611,116.318026,0,493,39744.1204861111,2008-10-23,02:53:30\n<\/code><\/pre>\n\n<p>The real data starts from Line 7, how could i strip it off, these files need to be downloaded on the fly so I don't think i would like to strip off the data by some code.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-21 14:01:20.2 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":53,
        "Owner_creation_date":"2012-03-06 08:24:53.613 UTC",
        "Owner_last_access_date":"2022-09-06 04:38:14.59 UTC",
        "Owner_reputation":4743,
        "Owner_up_votes":265,
        "Owner_down_votes":31,
        "Owner_views":811,
        "Answer_body":"<p>What is your source location - SQL or Blob or http?<\/p>\n\n<p>If SQL, then you can use query to start from line 6.<\/p>\n\n<p>If Blob\/http, I would suggest reading a file as a single column TSV format, use simple R\/Python script to drop first 6 rows and convert to csv<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-05-22 19:43:50.187 UTC",
        "Answer_score":1.0,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37363883",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42766263,
        "Question_title":"How to Find Azure ML Experiment based on Deployed Web Service",
        "Question_body":"<p>I have a list of ML experiments which I have created in Azure Machine Learning Studio.  I have deployed them as web services (the new version, not classic).  <\/p>\n\n<p>How can I go into Azure Machine Learning Web Services, click on a web service (which was deployed from an experiment), then navigate back to the experiment \/ predictive model which feeds it?<\/p>\n\n<p>The only link I can find between the two is by updating the web service from the predictive experiment, which then confirms what the web service is. I can see that the \"ExperimentId\" is a GUID in the URL when in the experiment and the web service, so hopefully this is possible.<\/p>\n\n<p>My reasoning is that relying on matching naming conventions, etc., to select the appropriate model to update is subject to human error.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-03-13 14:35:50.577 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"web-services|azure|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_date":"2013-08-28 15:24:36.33 UTC",
        "Owner_last_access_date":"2021-07-14 22:35:47.19 UTC",
        "Owner_reputation":592,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>The <em>new<\/em> web service does not store any information about the experiment or workspace that was deployed (not all <em>new<\/em> web services are deployed from an experiment).<\/p>\n\n<p>Here are the options available to track the relationship between the experiment and a <em>new<\/em> web service.<\/p>\n\n<h2>last deployment<\/h2>\n\n<p>However, the experiment keeps track of the <strong>last<\/strong> <em>new<\/em> web service that was deployed from the experiment. each deployment to a <em>new<\/em> web service overwrites this value.<\/p>\n\n<p>The value is stored in the experiment graph. One way to get the graph is to use the powershell module <a href=\"http:\/\/aka.ms\/amlps\" rel=\"nofollow noreferrer\">amlps<\/a><\/p>\n\n<p><code>Export-AmlExperimentGraph -ExperimentId &lt;Experiment Id&gt; -OutputFile e.json<\/code><\/p>\n\n<p><strong>e.json<\/strong><\/p>\n\n<pre><code>{\n\"ExperimentId\":\"&lt;Experiment Id&gt;\",\n\/\/ . . .\n\"WebService\":{\n\/\/ . . .\n\"ArmWebServiceId\":\"&lt;Arm Id&gt;\"\n},\n\/\/ . . . \n}\n<\/code><\/pre>\n\n<h2>azure resource tags<\/h2>\n\n<p>The tags feature for Azure resources is supported by the <em>new<\/em> web services. Setting a <code>tag<\/code> on the web service programmatically, with powershell or via the azure portal UX can be used to store a reference to the experiment on the <em>new<\/em> web service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-03-23 15:38:46.69 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bristol, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42766263",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48087407,
        "Question_title":"How to deal with missing values in Azure Machine Learning Studio",
        "Question_body":"<p>Looks like I have 672 mission values, according to statistics. \nThere are NULL value in QuotedPremium column.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/p9Z3X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/p9Z3X.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I implemented Clean Missing Data module where it should substitute missing values with 0, but for some reason I'm still seeing NULL values as QuotedPremium, but...it says that missing values are = 0<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PDg97.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PDg97.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/BEdHD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BEdHD.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Here you see it tells me that missing values = 0, but there are still NULLs <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WKlGZ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WKlGZ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>So what really happened after I ran Clean Missing Data module? Why it ran succesfully but there are still NULL values, even though it tells that number of missing values are 0. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2018-01-04 01:15:40.763 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|ml-studio",
        "Question_view_count":1556,
        "Owner_creation_date":"2016-03-10 08:00:45.393 UTC",
        "Owner_last_access_date":"2022-09-23 23:59:58.457 UTC",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Answer_body":"<p><code>NULL<\/code> is indeed a value; entries containing NULLs are <em>not<\/em> missing, hence they are neither cleaned with the 'Clean Missing Data' operator nor reported as missing.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-01-04 01:43:00.7 UTC",
        "Answer_score":2.0,
        "Owner_location":"San Diego, CA, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48087407",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49818134,
        "Question_title":"how connect to Azure Machine Learning Web service using PowerShell?",
        "Question_body":"<p>To use Azure Machine Learning Web service <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/consume-web-services\" rel=\"nofollow noreferrer\">here<\/a> you can find some sample code in C#, R, Python and JavaScript. I want to use it in PowerShell.\nI found <a href=\"https:\/\/www.sepago.com\/blog\/2015\/11\/30\/zugriff-mit-powershell-auf-azure-machine-learning-api-azureml\" rel=\"nofollow noreferrer\">this<\/a> tutorial, but when I am running bellow line of code, it will return error that it is not recognized:<\/p>\n\n<pre><code>Set-AzureMLWebServiceConnection -URI $Url -APIKey $API_key\n\nOutput:\nSet-AzureMLWebServiceConnection : The term 'Set-AzureMLWebServiceConnection' is not recognized as the name of a cmdlet, function, script file, or operable \nprogram. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.\nAt C:\\Users\\Reza\\Desktop\\ndbench\\Azure\\Automation\\01_get_metrics\\add_target_to_tables - runbook_01.ps1:33 char:1\n+ Set-AzureMLWebServiceConnection -URI $Url -APIKey $API_key\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : ObjectNotFound: (Set-AzureMLWebServiceConnection:String) [], CommandNotFoundException\n    + FullyQualifiedErrorId : CommandNotFoundException\n<\/code><\/pre>\n\n<p>I can't found <code>Set-AzureMLWebServiceConnection<\/code> in my PowerShell command-list and I don't know how I can enable\/install it.\n<a href=\"https:\/\/i.stack.imgur.com\/YMso7.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YMso7.jpg\" alt=\"enter image description here\"><\/a>\nCan you please guide me, how I can connect to Azure Machine Learning Web service using PowerShell?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-04-13 13:25:08.693 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"powershell|azure|azure-powershell|azure-machine-learning-studio",
        "Question_view_count":303,
        "Owner_creation_date":"2015-06-09 17:29:10.22 UTC",
        "Owner_last_access_date":"2022-09-23 10:58:01.917 UTC",
        "Owner_reputation":1316,
        "Owner_up_votes":180,
        "Owner_down_votes":11,
        "Owner_views":201,
        "Answer_body":"<p>The comment @gvee mentioned may be the best to use going forward though it is in beta.<\/p>\n\n<p>However, to answer your question, use the <code>Install-Module -Name AzureML<\/code> <a href=\"https:\/\/www.powershellgallery.com\/packages\/AzureML\/1.0.1\" rel=\"nofollow noreferrer\">command<\/a> to get access to the Azure ML commands.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZerMp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZerMp.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-04-14 16:51:26.213 UTC",
        "Answer_score":1.0,
        "Owner_location":"Tehran, Iran",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49818134",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64554615,
        "Question_title":"Import cv2 error when deploying in Azure Kubernetes Service - python",
        "Question_body":"<p>I have read similar questions regarding azure app service, but I still can't find an answer. I was trying to deploy a model in azure kubernetes service, but I came across an error when importing cv2 (which is essential to me).<\/p>\n<p>Opencv-python is included in my environment .yaml file:<\/p>\n<pre><code>name: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  # You must list azureml-defaults as a pip dependency\n  - azureml-defaults&gt;=1.0.45\n  - Cython\n  - matplotlib&gt;=3.2.2\n  - numpy&gt;=1.18.5\n  - opencv-python&gt;=4.1.2\n  - pillow\n  - PyYAML&gt;=5.3\n  - scipy&gt;=1.4.1\n  - torch&gt;=1.6.0\n  - torchvision&gt;=0.7.0\n  - tqdm&gt;=4.41.0\nchannels:\n- conda-forge\n<\/code><\/pre>\n<p>I am deploying as follows:<\/p>\n<pre><code>aks_service = Model.deploy(ws,\n                       models=[model],\n                       inference_config=inference_config,\n                       deployment_config=gpu_aks_config,\n                       deployment_target=aks_target,\n                       name=aks_service_name)\n<\/code><\/pre>\n<p>And I get this error:<\/p>\n<pre><code>    Traceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process\n    self.load_wsgi()\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load\n    return self.load_wsgiapp()\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app\n    __import__(module)\n  File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n    from app import main\n  File &quot;\/var\/azureml-server\/app.py&quot;, line 32, in &lt;module&gt;\n    from aml_blueprint import AMLBlueprint\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 23, in &lt;module&gt;\n    main_module_spec.loader.exec_module(main)\n  File &quot;\/var\/azureml-app\/score.py&quot;, line 8, in &lt;module&gt;\n    import cv2\n  File &quot;\/azureml-envs\/azureml_659b55e5b05510a45f41f0ca31d3ac02\/lib\/python3.6\/site-packages\/cv2\/__init__.py&quot;, line 5, in &lt;module&gt;\n    from .cv2 import *\nImportError: libGL.so.1: cannot open shared object file: No such file or directory\nWorker exiting (pid: 41)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-27 12:38:18.68 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|opencv|kubernetes|azure-aks|azure-machine-learning-service",
        "Question_view_count":484,
        "Owner_creation_date":"2016-09-07 14:19:15.533 UTC",
        "Owner_last_access_date":"2022-09-13 12:45:40.607 UTC",
        "Owner_reputation":145,
        "Owner_up_votes":842,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>This might go wrong at some point, but my workaround was installing opencv-python-headless instead of opencv.<\/p>\n<p>In the environment .yaml file, just replace:<\/p>\n<pre><code>- opencv-python&gt;=4.1.2\n<\/code><\/pre>\n<p>with:<\/p>\n<pre><code>- opencv-python-headless\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-28 14:58:13.47 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64554615",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52603929,
        "Question_title":"AML Studio: Register mutliple gateways on the same server",
        "Question_body":"<p>I am struggling to find a way to register multiple gateways. I have a local instance of my SQL server and have created a gateway to access to it from the AML Studio workspace. It works fine but now I would like to access to the same SQL server instance from another workspace. So the question is: how to register a new gateway without removing the previous one?\nI followed this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a>.\nDoes the following explanation mean that there is no way to do that?<\/p>\n\n<blockquote>\n  <p>You can create and set up multiple gateways in Studio for each workspace. For example, you may have a gateway that you want to connect to your test data sources during development, and a different gateway for your production data sources. Azure Machine Learning gives you the flexibility to set up multiple gateways depending upon your corporate environment. Currently you can\u2019t share a gateway between workspaces and only one gateway can be installed on a single computer.<\/p>\n<\/blockquote>\n\n<p>It is quite limiting as connecting to the same server from multiple workspaces may be sometimes crucial.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-02 07:41:30.42 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-10-02 13:04:34.347 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":40,
        "Owner_creation_date":"2018-06-12 08:07:17.107 UTC",
        "Owner_last_access_date":"2022-08-10 15:40:49.397 UTC",
        "Owner_reputation":610,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":203,
        "Answer_body":"<p>Well, finally I have found a way to bypass this limitation. From this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a> I have found that: <\/p>\n\n<blockquote>\n  <p>The IR does not need to be on the same machine as the data source. But staying closer to the data source reduces the time for the gateway to connect to the data source. We recommend that you install the IR on a machine that's different from the one that hosts the on-premises data source so that the gateway and data source don't compete for resources.<\/p>\n<\/blockquote>\n\n<p>So the  logic is pretty simple. You provide access to your local server to another machine on vpn and install your gateway there. Important: I have set up the firewall rules on the server before, to be able to establish the connection remotely.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-10-04 10:15:58.57 UTC",
        "Answer_score":0.0,
        "Owner_location":"Paris, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52603929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37540703,
        "Question_title":"Test multiple algorithms in one experiment",
        "Question_body":"<p>Is there any way to test multiple algorithms rather than doing it once for each and every algorithm; then checking the result? There are a lot of times where I don\u2019t really know which one to use, so I would like to test multiple and get the result (error rate) fairly quick in Azure Machine Learning Studio.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2016-05-31 08:33:50.827 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-06-15 08:05:20.52 UTC",
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":425,
        "Owner_creation_date":"2016-02-24 10:28:58.853 UTC",
        "Owner_last_access_date":"2016-08-22 12:20:52.243 UTC",
        "Owner_reputation":39,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>The module you are looking for, is the one called \u201c<strong>Cross-Validate Model<\/strong>\u201d. It basically splits whatever comes in from the input-port (dataset) into 10 pieces, then reserves the last piece as the \u201canswer\u201d; and trains the nine other subset models and returns a set of accuracy statistics measured towards the last subset. What you would look at is the column called \u201cMean absolute error\u201d which is the average error for the trained models. You can connect whatever algorithm you want to one of the ports, and subsequently you will receive the result for that algorithm in particular after you \u201cright-click\u201d the port which gives the score.<\/p>\n\n<p>After that you can assess which algorithm did the best. And as a pro-tip; you could use the <strong>Filter-based-feature selection<\/strong> to actually see which column had a significant impact on the result.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-05-31 08:58:13.653 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37540703",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66592313,
        "Question_title":"Get local workspace in azureml",
        "Question_body":"<p>I am trying to run a machine learning experiment in azureml.<\/p>\n<p>I can't figure out how to get the workspace context from the control script.  Examples like <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data#control-script\" rel=\"nofollow noreferrer\">this one<\/a> in the microsoft docs use Workspace.from_config().  When I use this in the control script I get the following error:<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;We could not find config.json in: [path] or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;<\/p>\n<\/blockquote>\n<p>I've also tried including my subscription id and the resource specs like so:<\/p>\n<pre><code>subscription_id = 'id'\nresource_group = 'name'\nworkspace_name = 'name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n<\/code><\/pre>\n<p>In this case I have to monitor the log and authenticate on each run as I would locally.<\/p>\n<p>How do you get the local workspace from a control script for azureml?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-12 00:03:37.267 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":333,
        "Owner_creation_date":"2017-12-06 00:36:24.493 UTC",
        "Owner_last_access_date":"2022-09-22 22:49:47.607 UTC",
        "Owner_reputation":868,
        "Owner_up_votes":109,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>This had no answers for 10 months, and now they are coming in :).  I figuerd this out quite a while ago but haven't gotten around to posting the answer.  Here it is.<\/p>\n<p>From the training script, you can get the workspace from the run context as follows:<\/p>\n<pre><code>from azureml.core import Run\nRun.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-12 03:28:12.267 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bloomington, IN, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66592313",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64486262,
        "Question_title":"Is there a way to un-register an environment in Azure ML studio",
        "Question_body":"<p>I am trying to deploy a model in Azure ML and kept on getting the error 'model not found' from my score.py. So I decided to start from scratch again. I had my custom environment registered, and the Azure ML API for Environment class doesn't seem to have anything like 'delete' or 'unregister'. is there a way to work around this? Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-22 16:12:00.473 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-11-01 23:56:25.247 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":424,
        "Owner_creation_date":"2020-07-19 00:31:40.083 UTC",
        "Owner_last_access_date":"2021-08-19 14:16:52.393 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>You can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py&amp;preserve-view=true#delete--\" rel=\"nofollow noreferrer\">delete<\/a> method in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py\" rel=\"nofollow noreferrer\">Model<\/a> class to delete a registered model.<\/p>\n<p>This can also be done via the Azure CLI as:<\/p>\n<pre><code>az ml model delete &lt;model id&gt;\n<\/code><\/pre>\n<p>Other commands can be found here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest\" rel=\"nofollow noreferrer\">az ml model<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-31 13:34:49.467 UTC",
        "Answer_score":0.0,
        "Owner_location":"Toronto, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64486262",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60638587,
        "Question_title":"How to get insights in exceptions and logging of AzureML endpoint deployment",
        "Question_body":"<p>Because of a faulty score.py file in my InferenceConfig, a Model.Deploy failed to Azure Machine Learning, using ACI.  I wanted to create the endpoint in the cloud, but the only state I can see in the portal is Unhealthy.  My local script to deploy the model (using ) keeps running, until it times out. (using the <code>service.wait_for_deployment(show_output=True)<\/code>statement).<\/p>\n\n<p>Is there an option to get more insights in the actual reason\/error message of the deployment turning \"Unhealthy\"?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-11 14:39:32.18 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-14 19:54:48.01 UTC",
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":364,
        "Owner_creation_date":"2013-02-12 07:50:30.743 UTC",
        "Owner_last_access_date":"2022-09-21 18:28:12.907 UTC",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Answer_body":"<p>Usually the timeout is caused by an error in init() function in scoring script. You can get the detailed logs using <code>print(service.get_logs())<\/code> to find the Python error.<\/p>\n\n<p>For more comprehensive troubleshooting guide, see:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-13 21:02:44.177 UTC",
        "Answer_score":2.0,
        "Owner_location":"Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60638587",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50113374,
        "Question_title":"What is a trait in Azure ML matchbox recommender?",
        "Question_body":"<p>Azure Machine Learning has an item called <code>Train Matchbox Recommender<\/code>. It can be configured with a <code>Number of traits<\/code>. Unfortunately, the documentation does not describe what such a trait is.<\/p>\n\n<p>What are traits? Is this related to <a href=\"https:\/\/en.wikipedia.org\/wiki\/Latent_variable\" rel=\"nofollow noreferrer\">latent variables<\/a>?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-01 08:21:19.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-05-11 13:43:51.817 UTC",
        "Question_score":0,
        "Question_tags":"azure|recommendation-engine|azure-machine-learning-studio",
        "Question_view_count":859,
        "Owner_creation_date":"2010-11-26 05:44:11.813 UTC",
        "Owner_last_access_date":"2022-09-23 20:35:12.343 UTC",
        "Owner_reputation":55864,
        "Owner_up_votes":1621,
        "Owner_down_votes":31,
        "Owner_views":4960,
        "Answer_body":"<p><a href=\"http:\/\/apprize.info\/microsoft\/azure_1\/9.html\" rel=\"nofollow noreferrer\">This<\/a> page may have better descriptions on it.<\/p>\n\n<p>Basically, traits are the features the algorithm will learn about each user related to each item. For example, in the <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Recommender-Restaurant-ratings-2\" rel=\"nofollow noreferrer\">restaurant ratings recommender<\/a> traits could include a user's birth year, if they're a student or working professional, martial status, etc.<\/p>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2018-05-01 10:46:03.377 UTC",
        "Answer_score":1.0,
        "Owner_location":"Nimes, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50113374",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73187536,
        "Question_title":"Error while detaching AKS cluster through Azure ML SDK extension",
        "Question_body":"<p>I created an AKS cluster using Azure Machine Learning SDK extension and I attached to the workspace created. When the cluster is created and attached, I doesn't show any error. When I am trying to detach it from workspace, it is not accepting the operations.<\/p>\n<p>I would like to detach the existing AKS cluster from workspace either by program manner, using CLI or even using Azure portal.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-31 23:06:39.773 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-aks|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_date":"2022-04-27 21:06:54.703 UTC",
        "Owner_last_access_date":"2022-08-01 06:25:38.797 UTC",
        "Owner_reputation":19,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>If we are using any <strong>extensions of SDK or Azure CLI<\/strong> for machine learning to detach AKS cluster, it <strong>will not work<\/strong> and it will not get deleted or detached. Instead, we need to use <strong>Azure CLI with AKS<\/strong>. There are two types of implementations we can perform.<\/p>\n<p><strong>Python:<\/strong><\/p>\n<pre><code>Aks_target.detach()\n<\/code><\/pre>\n<p><strong>Azure CLI:<\/strong><\/p>\n<p>Before performing this step, we need to get the details of the working AKS cluster name attached to our workspace. Resource Group details and workspace name<\/p>\n<pre><code>az ml computertarget detach -n youraksname -g yourresourcegroup -w yourworkspacename\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-01 05:50:06.09 UTC",
        "Answer_score":1.0,
        "Owner_location":"Netherland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73187536",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56859324,
        "Question_title":"Best practice about the frequency of sentiment analysis in Azure Text Analytics",
        "Question_body":"<p>In my asp.net application, I want to do a sentiment analysis on each discussion forum item as they are posted by the users. I wonder if it is a good practice to make a request to Azure Text Analytics server to do a new Sentiment Analysis each time a text is posted by any user. Or, is it better to do this somehow once a day on all posts as a batch. I wonder what is the best practice about this.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-02 20:02:08.357 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"asp.net|azure|azure-machine-learning-studio|azure-analytics",
        "Question_view_count":59,
        "Owner_creation_date":"2012-11-22 14:59:22.917 UTC",
        "Owner_last_access_date":"2022-09-10 15:02:49.86 UTC",
        "Owner_reputation":8007,
        "Owner_up_votes":1304,
        "Owner_down_votes":38,
        "Owner_views":792,
        "Answer_body":"<p>We are working on a similar project as you. My suggestion for your question is, you should select proper interval based on your requirement and need. For example, if you want to react based on the sentiment result of every post in a timely manner, you need to do a analysis every time you pull a new post. Also you can adjust your time interval of \"pull and analyze\" based on your business\/ research need. IF you just want to train your model and predict something based on the data you get and you have no need for timely reaction, I think once a day is enough.<\/p>\n\n<p>For our project, we are in the situation 1. So we will do a quick analysis when we receive any new post so that we can have a quick reaction.<\/p>\n\n<p>Hope this helps.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-07-09 18:41:01.557 UTC",
        "Answer_score":1.0,
        "Owner_location":"USA",
        "Answer_last_edit_date":"2019-07-09 18:47:06.6 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56859324",
        "Question_exclusive_tag":"Azure Machine Learning"
    }
]